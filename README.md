# SEP-Nets
This repository contains instroduction, instruction, models, prototxt and logs file along experiments for SEP-Nets introduced in the paper  ["SEP-Nets: Small and Effective Pattern Networks"](https://arxiv.org/pdf/1706.03912.pdf) by Zhe Li, Xiaoyu Wang, Xutao Lv, Tianbao Yang.

### Citting SEP-Nets
If you are using SEP-Nets, please cite as folowing:

        @article{li2017sep,
          title={SEP-Nets: Small and Effective Pattern Networks},
          author={Li, Zhe and Wang, Xiaoyu and Lv, Xutao and Yang, Tianbao},
          journal={arXiv preprint arXiv:1706.03912},
          year={2017}
        }

## Contents:
1. [Introduction](#Introduction)
2. [Instruction](#Instruction)
3. [Experiments on CIFAR10 with ResNet](#Experiments-on-CIFAR10-with-ResNet)
4. [Experiments on ImageNet with GoogleNet](#Experiments-on-ImageNet-with-GoogleNet)
5. [Experiments on ImageNet with Customized-InceptionNet](#Experiments-on-ImageNet-with-Customized-InceptionNet)
6. [Summary](#Summary)

## Introduction
SEP-Nets are very small yet powerful deep neural network structures based on the invented techniques pattern binarization, pattern residual blocks and the existing group convolution. The two invented techniques pattern binarization, pattern residual blocks are of their interests. For pattern binarization, the striking difference from most previous work on parameter binarization/quantization lies at different treatments of 1 x 1 convolutions and  k x k convolutions (k>1), where we only binarize k x k convolutions into binary patterns.  The resulting networks are referred to as pattern networks. By doing this, we show that previous deep CNNs such as GoogLeNet and Inception-type Nets can be compressed dramatically with marginal drop in performance. In light of the different functionalities of  1 x 1 (data projection/transformation) and k x k convolutions (pattern extraction), we propose a new block structure codenamed the pattern residual block that adds transformed feature maps generated by 1 x 1 convolutions to the pattern feature maps generated by k x k convolutions. Based on the above techniques, the designed SEP-Net could achieve better performance on ImageNet than using similar sized networks including recently released Google MobileNets.

## Instruction
For Justifying pattern binarization could dramtically compressed original model with marginal drop in performance, we conducted experiments in three steps (shown in the following Figure 1):
<img src= "https://user-images.githubusercontent.com/13735345/31589251-38a76466-b1c4-11e7-89b9-42def3bc47b1.png" width ="240">

Figure 1: Procedure to apply pattern binarization technique

The general instructions are the following steps: (In the folllowing three sections, we will give the detailed instructions)
1. train original model using tain_val.prototxt and solver.txt, after training process we obtain the original model;
```
caffe/build/tools/caffe train --solver solver.txt 2>&1 | tee train.log
```
2. quantilize k x k filters (k > 1, for example often k = 3, 5, or at same time quantilize both 3 and 5) in the original model, we obtained the quantilized model. Note that we first fine-tune offset value to quantilize to from range(0.02, 0.09, 0.01); Theoretically we could omit this step but expeirmentally we find it can give better performance. 
```
python quant_pattern.py --offeset 0.05 --models xxx_xxx.caffemodel
```
3. fine-tune the above quantilized models with fixed pattern (we simply set the learning rate for those convolution layer as 0) prototxt and solver file; 
```
caffe/build/tools/caffe train --solver finetune_solver.txt --weights xxx_xxx_quant_0.05.caffemodel 2>&1 | tee fine_tune.log
```

## Experiments on CIFAR10 with ResNet
In general, different data augumentation techniques results in different test accuracy. In order to obtain better performance, we train ResNet-20,ResNet-32, ResNet-44 and ResNet-55 on cifar10 dataset with three different augumentation techniques. 
1. CIFAR-10 dataset download from [NIN](https://gist.github.com/ebenolson/91e2cfa51fdb58782c26)
2. CIFAR-10 dataset download from [Highway Network](https://github.com/flukeskywalker/highway-networks)
3. CIFAR-10 dataset download from [Highway Network](https://github.com/flukeskywalker/highway-networks) using additional 4 pixels padded on each side of each image and with GCN preprocessed. 

The following is the comparison Top 1 and Top 5 test accuracy with cifar10 dataset with different augumentation techniques on the four ResNets. The column marked Test accuracy (num) refer to test accuracy on with CIFAR-10 dataset. 

| Model     | Test Accuracy (1) | Test Accuracy (2) | Test Accuracy (3) |
|-----------|-------------------|-------------------|-------------------|
| ResNet-20 | 0.8204 <br /> 0.9861     | 0.8893 <br /> 0.9957     | 0.9118 <br /> 0.9974     |
| ResNet-32 | 0.8477 <br /> 0.9899     | 0.9031 <br /> 0.9963     | 0.9276 <br /> 0.9972     |
| ResNet-44 | 0.8380 <br /> 0.9895     | 0.9006 <br /> 0.9956     | 0.9283 <br /> 0.9982     |
| ResNet-56 | 0.4555 <br /> 0.8322     | 0.9027 <br /> 0.9957     | 0.9375 <br /> 0.9977     |

Then, we conducted the following experiments on the third version CIFAR-10 dataset.


## Experiments on ImageNet with GoogleNet
You can find prototxt and solver files in googlenet/prototxt folder and resulting models and logs files in the corresponding models and logs folders as well. As illustrated in the Instruction part, we applied same procedure to googlenet on ImageNet.(Assume ImageNet downloaded and prepared).
1. train googlenet using train_val.prototxt and quick_solver.prototxt 
```
caffe/builds/tools/caffe train --solver quick_solver.prototxt 2>&1 | tee googlenet_train_quick_solver_from_scratch_zl.log
```
As reference, you can check the log file from my training.  After entire training process we obtain caffe model: bvlc_googlenet_quick_iter_600000.caffemodel

2. quantilize 1x1, 3x3, 5x5 or 3x3 and 5x5 filters using quant_pattern.py script
```
python quant_pattern.py --offset 0.09 --filter 1x1 --model bvlc_googlenet_quick_iter_600000.caffemodel
```
```
python quant_pattern.py --offset 0.06 --filter 3x3 --model bvlc_googlenet_quick_iter_600000.caffemodel
```
```
python quant_pattern.py --offset 0.05 --filter 5x5 --model bvlc_googlenet_quick_iter_600000.caffemodel
```
```
python quant_pattern.py --offset 0.06 --filter 3x3 5x5 --model bvlc_googlenet_quick_iter_600000.caffemodel
```
The above offeset value we tune from range(0.02,0.09,0.01) as mentioned in the above. After this step, we obtain the following quantilized models:
1. googlenet_600000_quant_3x3_0.06.caffemodel
2. googlenet_600000_quant_5x5.caffemodel
3. googlenet_600000_quant_3x3_5x5_0.06.caffemodel
4. googlenet_600000_quant_projAll1x1_0.09.caffemodel

Those models could be found in googlenet/models folder as well. 

3. fine-tuning the above quantilized models using train_val_fix_xxx_pattern.prototxt and quick_solver_fix_xxx_pattern.prototxt
```
caffe/build/tools/caffe train --solver quick_solver_fix_1x1_pattern.prototxt --weights googlenet_600000_quant_projAll1x1_0.09.caffemodel 2>&1 | tee googlenet_fine_tune_quant_600000_caffemodel_fix_Proj1x1_pattern_train.log
```
```
caffe/build/tools/caffe train --solver quick_solver_fix_3x3_pattern.prototxt --weights googlenet_600000_quant_3x3_0.06.caffemodel 2>&1 | tee googlenet_fine_tune_quant_600000_caffemodel_fix_3x3_pattern_train.log
```
```
caffe/build/tools/caffe train --solver quick_solver_fix_5x5_pattern.prototxt --weights googlenet_600000_quant_5x5.caffemodel 2>&1 | tee googlenet_fine_tune_quant_600000_caffemodel_fix_5x5_pattern_train.log
```
```
caffe/build/tools/caffe train --solver quick_solver_fix_3x3_5x5_pattern.prototxt --weights googlenet_600000_quant_3x3_5x5_0.06.caffemodel 2>&1 | tee googlenet_fine_tune_quant_600000_caffemodel_fix_3x3_5x5_pattern_train.log
```
As same as the above, you could find fine-tune log file in log foder, for examples, let's check googlenet_fine_tune_quant_600000_caffemodel_fix_3x3_pattern_train.log file, 


        I0409 18:10:46.352432 12840 solver.cpp:311] Iteration 600000, loss = 1.67377
        I0409 18:10:46.352474 12840 solver.cpp:331] Iteration 600000, Testing net (#0)
        I0409 18:12:03.574512 12849 data_layer.cpp:73] Restarting data prefetching from start.
        I0409 18:12:03.837461 12840 solver.cpp:398]     Test net output #0: loss1/loss1 = 1.77901 (* 0.3 = 0.533704 loss)
        I0409 18:12:03.837510 12840 solver.cpp:398]     Test net output #1: loss1/top-1 = 0.57818
        I0409 18:12:03.837514 12840 solver.cpp:398]     Test net output #2: loss1/top-5 = 0.816221
        I0409 18:12:03.837522 12840 solver.cpp:398]     Test net output #3: loss2/loss2 = 1.4836 (* 0.3 = 0.44508 loss)
        I0409 18:12:03.837525 12840 solver.cpp:398]     Test net output #4: loss2/top-1 = 0.63776
        I0409 18:12:03.837528 12840 solver.cpp:398]     Test net output #5: loss2/top-5 = 0.859861
        I0409 18:12:03.837535 12840 solver.cpp:398]     Test net output #6: loss3/loss3 = 1.36136 (* 1 = 1.36136 loss)
        I0409 18:12:03.837539 12840 solver.cpp:398]     Test net output #7: loss3/top-1 = 0.679699
        I0409 18:12:03.837543 12840 solver.cpp:398]     Test net output #8: loss3/top-5 = 0.882702
        I0409 18:12:03.837548 12840 solver.cpp:316] Optimization Done.
        I0409 18:12:03.926012 12840 caffe.cpp:259] Optimization Done.

The following is the comparison of test accuracy among original googlenet models, quantilized modeds and fine-tuned models. 


|Model | Acc | Ref | BiPattern | Refined | Multicrop|
|-----------|-------------------|-------------------|-------------------|-------------------|-------------------|
|googlenet| Top 1 <br /> Top 5| - <br /> 0.8993 | 1x1 pattern  <br /> 0.0013 <br /> 0.0075 | <br /> 0.6117 <br /> 0.8395 | <br /> 0.636 <br /> 0.856 |

## Experiments on ImageNet with Customized-InceptionNet
## Summary



