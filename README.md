# SEP-Nets
This repository contains instroduction, instruction, models, prototxt and logs file along experiments for SEP-Nets introduced in the paper  ["SEP-Nets: Small and Effective Pattern Networks"](https://arxiv.org/pdf/1706.03912.pdf) by Zhe Li, Xiaoyu Wang, Xutao Lv, Tianbao Yang.

### Citting SEP-Nets
If you are using SEP-Nets, please cite as folowing:

        @article{li2017sep,
          title={SEP-Nets: Small and Effective Pattern Networks},
          author={Li, Zhe and Wang, Xiaoyu and Lv, Xutao and Yang, Tianbao},
          journal={arXiv preprint arXiv:1706.03912},
          year={2017}
        }

## Contents:
1. [Introduction](#Introduction)
2. [Instruction](#Instruction)
3. [Experiments on CIFAR10 with ResNet](#Experiments-on-CIFAR10-with-ResNet)
4. [Experiments on ImageNet with GoogleNet](#Experiments-on-ImageNet-with-GoogleNet)
5. [Experiments on ImageNet with Customized-InceptionNet](#Experiments-on-ImageNet-with-Customized-InceptionNet)
6. [Summary](#Summary)

## Introduction
SEP-Nets are very small yet powerful deep neural network structures based on the invented techniques pattern binarization, pattern residual blocks and the existing group convolution. The two invented techniques pattern binarization, pattern residual blocks are of their interests. For pattern binarization, the striking difference from most previous work on parameter binarization/quantization lies at different treatments of 1 x 1 convolutions and  k x k convolutions (k>1), where we only binarize k x k convolutions into binary patterns.  The resulting networks are referred to as pattern networks. By doing this, we show that previous deep CNNs such as GoogLeNet and Inception-type Nets can be compressed dramatically with marginal drop in performance. In light of the different functionalities of  1 x 1 (data projection/transformation) and k x k convolutions (pattern extraction), we propose a new block structure codenamed the pattern residual block that adds transformed feature maps generated by 1 x 1 convolutions to the pattern feature maps generated by k x k convolutions. Based on the above techniques, the designed SEP-Net could achieve better performance on ImageNet than using similar sized networks including recently released Google MobileNets.

## Instruction
For Justifying pattern binarization could dramtically compressed original model with marginal drop in performance, we conducted experiments in three steps (shown in the following Figure 1):
<img src= "https://user-images.githubusercontent.com/13735345/31589251-38a76466-b1c4-11e7-89b9-42def3bc47b1.png" width ="240">

Figure 1: Procedure to apply pattern binarization technique

The general instructions are the following steps: (In the folllowing three sections, we will give the detailed instructions)
1. train original model using tain_val.prototxt and solver.txt, after training process we obtain the original model;
```
caffe/build/tools/caffe train --solver solver.txt 2>&1 | tee train.log
```
2. quantilize k x k filters (k > 1, for example often k = 3, 5, or at same time quantilize both 3 and 5) in the original model, we obtained the quantilized model. Note that we first fine-tune offset value to quantilize to from range(0.02, 0.09, 0.01); Theoretically we could omit this step but expeirmentally we find it can give better performance. 
```
python quant_pattern.py --offeset 0.05 --models xxx_xxx.caffemodel
```
3. fine-tune the above quantilized models with fixed pattern (we simply set the learning rate for those convolution layer as 0) prototxt and solver file; 
```
caffe/build/tools/caffe train --solver finetune_solver.txt --weights xxx_xxx_quant_0.05.caffemodel 2>&1 | tee fine_tune.log
```

## Experiments on CIFAR10 with ResNet
In general, different data augumentation techniques results in different test accuracy. In order to obtain better performance, we train ResNet-20,ResNet-32, ResNet-44 and ResNet-55 on cifar10 dataset with three different augumentation techniques. 
1. CIFAR-10 dataset download from [NIN](https://gist.github.com/ebenolson/91e2cfa51fdb58782c26)
2. CIFAR-10 dataset download from [Highway Network](https://github.com/flukeskywalker/highway-networks)
3. CIFAR-10 dataset download from [Highway Network](https://github.com/flukeskywalker/highway-networks) using additional 4 pixels padded on each side of each image and with GCN preprocessed. 

The following is the comparison Top 1 and Top 5 test accuracy with cifar10 dataset with different augumentation techniques on the four ResNets. The column marked Test accuracy (num) refer to test accuracy on with CIFAR-10 dataset. 

| Model     | Test Accuracy (1) | Test Accuracy (2) | Test Accuracy (3) |
|-----------|-------------------|-------------------|-------------------|
| ResNet-20 | 0.8204 <br /> 0.9861     | 0.8893 <br /> 0.9957     | 0.9118 <br /> 0.9974     |
| ResNet-32 | 0.8477 <br /> 0.9899     | 0.9031 <br /> 0.9963     | 0.9276 <br /> 0.9972     |
| ResNet-44 | 0.8380 <br /> 0.9895     | 0.9006 <br /> 0.9956     | 0.9283 <br /> 0.9982     |
| ResNet-56 | 0.4555 <br /> 0.8322     | 0.9027 <br /> 0.9957     | 0.9375 <br /> 0.9977     |

Then, we conducted the following experiments on the third version CIFAR-10 dataset.


## Experiments on ImageNet with GoogleNet
You can find prototxt and solver files in googlenet/prototxt folder and resulting models and logs files in the corresponding models and logs folders as well. As illustrated in the Instruction part, we applied same procedure to googlenet on ImageNet.(Assume ImageNet downloaded and prepared).
1. train googlenet using train_val.prototxt and quick_solver.prototxt 
```
caffe/builds/tools/caffe train --solver quick_solver.prototxt 2>&1 | tee googlenet_train_quick_solver_from_scratch_zl.log
```
As reference, you can check the log file from my training.  After entire training process we obtain caffe model: bvlc_googlenet_quick_iter_600000.caffemodel

2. quantilize 1x1, 3x3, 5x5 or 3x3 and 5x5 filters using quant_pattern.py script
```
python quant_pattern.py --offset 0.09 --filter 1x1 --model bvlc_googlenet_quick_iter_600000.caffemodel
```
```
python quant_pattern.py --offset 0.06 --filter 3x3 --model bvlc_googlenet_quick_iter_600000.caffemodel
```
```
python quant_pattern.py --offset 0.05 --filter 5x5 --model bvlc_googlenet_quick_iter_600000.caffemodel
```
```
python quant_pattern.py --offset 0.06 --filter 3x3 5x5 --model bvlc_googlenet_quick_iter_600000.caffemodel
```
The above offeset value we tune from range(0.02,0.09,0.01) as mentioned in the above. After this step, we obtain the following quantilized models:
1. googlenet_600000_quant_3x3_0.06.caffemodel
2. googlenet_600000_quant_5x5.caffemodel
3. googlenet_600000_quant_3x3_5x5_0.06.caffemodel
4. googlenet_600000_quant_projAll1x1_0.09.caffemodel

Those models could be found in googlenet/models folder as well. 

       




## Experiments on ImageNet with Customized-InceptionNet
## Summary



