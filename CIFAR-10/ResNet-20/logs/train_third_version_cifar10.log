I0418 16:30:46.830205  2203 caffe.cpp:218] Using GPUs 0
I0418 16:30:46.850384  2203 caffe.cpp:223] GPU 0: Tesla P100-PCIE-16GB
I0418 16:30:48.828479  2203 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "model/ResNet20_highway_padded_data"
solver_mode: GPU
device_id: 0
net: "resnet20_relu_msra_cifar10.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 48000
stepvalue: 64000
I0418 16:30:48.832203  2203 solver.cpp:87] Creating training net from net file: resnet20_relu_msra_cifar10.prototxt
I0418 16:30:48.835101  2203 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet20_relu_msra_cifar10.prototxt
I0418 16:30:48.835114  2203 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0418 16:30:48.835350  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0418 16:30:48.835362  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv1
I0418 16:30:48.835368  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_1_bn_a
I0418 16:30:48.835374  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_1_bn_b
I0418 16:30:48.835382  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_2_bn_a
I0418 16:30:48.835387  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_2_bn_b
I0418 16:30:48.835393  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_3_bn_a
I0418 16:30:48.835399  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_3_bn_b
I0418 16:30:48.835404  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_proj
I0418 16:30:48.835409  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_a
I0418 16:30:48.835415  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_b
I0418 16:30:48.835420  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_2_bn_a
I0418 16:30:48.835425  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_2_bn_b
I0418 16:30:48.835431  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_3_bn_a
I0418 16:30:48.835436  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_3_bn_b
I0418 16:30:48.835443  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_proj
I0418 16:30:48.835448  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_a
I0418 16:30:48.835453  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_b
I0418 16:30:48.835458  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_2_bn_a
I0418 16:30:48.835464  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_2_bn_b
I0418 16:30:48.835469  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_3_bn_a
I0418 16:30:48.835474  2203 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_3_bn_b
I0418 16:30:48.835955  2203 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
    mean_file: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/paddedmean.binaryproto"
  }
  data_param {
    source: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_full_train_leveldb_padded/"
    batch_size: 128
    backend: LEVELDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "map16_1_conv_a"
  type: "Convolution"
  bottom: "conv1"
  top: "map16_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_a"
  type: "BatchNorm"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_1_scale_a"
  type: "Scale"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_relu_a"
  type: "ReLU"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
}
layer {
  name: "map16_1_conv_b"
  type: "Convolution"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_b"
  type: "BatchNorm"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_1_scale_b"
  type: "Scale"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_eltsum"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "map16_1_conv_b"
  top: "map16_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_1_relu_after_sum"
  type: "ReLU"
  bottom: "map16_1_eltsum"
  top: "map16_1_eltsum"
}
layer {
  name: "map16_2_conv_a"
  type: "Convolution"
  bottom: "map16_1_eltsum"
  top: "map16_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_a"
  type: "BatchNorm"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_2_scale_a"
  type: "Scale"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_relu_a"
  type: "ReLU"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
}
layer {
  name: "map16_2_conv_b"
  type: "Convolution"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_b"
  type: "BatchNorm"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_2_scale_b"
  type: "Scale"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_eltsum"
  type: "Eltwise"
  bottom: "map16_1_eltsum"
  bottom: "map16_2_conv_b"
  top: "map16_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_2_relu_after_sum"
  type: "ReLU"
  bottom: "map16_2_eltsum"
  top: "map16_2_eltsum"
}
layer {
  name: "map16_3_conv_a"
  type: "Convolution"
  bottom: "map16_2_eltsum"
  top: "map16_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_a"
  type: "BatchNorm"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_3_scale_a"
  type: "Scale"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_relu_a"
  type: "ReLU"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
}
layer {
  name: "map16_3_conv_b"
  type: "Convolution"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_b"
  type: "BatchNorm"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_3_scale_b"
  type: "Scale"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_eltsum"
  type: "Eltwise"
  bottom: "map16_2_eltsum"
  bottom: "map16_3_conv_b"
  top: "map16_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_3_relu_after_sum"
  type: "ReLU"
  bottom: "map16_3_eltsum"
  top: "map16_3_eltsum"
}
layer {
  name: "map32_1_conv_proj"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_proj"
  type: "BatchNorm"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_proj"
  type: "Scale"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_conv_a"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_a"
  type: "BatchNorm"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_a"
  type: "Scale"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_relu_a"
  type: "ReLU"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
}
layer {
  name: "map32_1_conv_b"
  type: "Convolution"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_b"
  type: "BatchNorm"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_b"
  type: "Scale"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_eltsum"
  type: "Eltwise"
  bottom: "map32_1_conv_proj"
  bottom: "map32_1_conv_b"
  top: "map32_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_1_relu_after_sum"
  type: "ReLU"
  bottom: "map32_1_eltsum"
  top: "map32_1_eltsum"
}
layer {
  name: "map32_2_conv_a"
  type: "Convolution"
  bottom: "map32_1_eltsum"
  top: "map32_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_a"
  type: "BatchNorm"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_2_scale_a"
  type: "Scale"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_relu_a"
  type: "ReLU"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
}
layer {
  name: "map32_2_conv_b"
  type: "Convolution"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_b"
  type: "BatchNorm"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_2_scale_b"
  type: "Scale"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_eltsum"
  type: "Eltwise"
  bottom: "map32_1_eltsum"
  bottom: "map32_2_conv_b"
  top: "map32_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_2_relu_after_sum"
  type: "ReLU"
  bottom: "map32_2_eltsum"
  top: "map32_2_eltsum"
}
layer {
  name: "map32_3_conv_a"
  type: "Convolution"
  bottom: "map32_2_eltsum"
  top: "map32_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_a"
  type: "BatchNorm"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_3_scale_a"
  type: "Scale"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_relu_a"
  type: "ReLU"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
}
layer {
  name: "map32_3_conv_b"
  type: "Convolution"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_b"
  type: "BatchNorm"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_3_scale_b"
  type: "Scale"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_eltsum"
  type: "Eltwise"
  bottom: "map32_2_eltsum"
  bottom: "map32_3_conv_b"
  top: "map32_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_3_relu_after_sum"
  type: "ReLU"
  bottom: "map32_3_eltsum"
  top: "map32_3_eltsum"
}
layer {
  name: "map64_1_conv_proj"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_proj"
  type: "BatchNorm"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_proj"
  type: "Scale"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_conv_a"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_a"
  type: "BatchNorm"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_a"
  type: "Scale"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_relu_a"
  type: "ReLU"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
}
layer {
  name: "map64_1_conv_b"
  type: "Convolution"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_b"
  type: "BatchNorm"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_b"
  type: "Scale"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_eltsum"
  type: "Eltwise"
  bottom: "map64_1_conv_proj"
  bottom: "map64_1_conv_b"
  top: "map64_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_1_relu_after_sum"
  type: "ReLU"
  bottom: "map64_1_eltsum"
  top: "map64_1_eltsum"
}
layer {
  name: "map64_2_conv_a"
  type: "Convolution"
  bottom: "map64_1_eltsum"
  top: "map64_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_a"
  type: "BatchNorm"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_2_scale_a"
  type: "Scale"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_relu_a"
  type: "ReLU"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
}
layer {
  name: "map64_2_conv_b"
  type: "Convolution"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_b"
  type: "BatchNorm"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_2_scale_b"
  type: "Scale"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_eltsum"
  type: "Eltwise"
  bottom: "map64_1_eltsum"
  bottom: "map64_2_conv_b"
  top: "map64_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_2_relu_after_sum"
  type: "ReLU"
  bottom: "map64_2_eltsum"
  top: "map64_2_eltsum"
}
layer {
  name: "map64_3_conv_a"
  type: "Convolution"
  bottom: "map64_2_eltsum"
  top: "map64_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_a"
  type: "BatchNorm"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_3_scale_a"
  type: "Scale"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_relu_a"
  type: "ReLU"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
}
layer {
  name: "map64_3_conv_b"
  type: "Convolution"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_b"
  type: "BatchNorm"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_3_scale_b"
  type: "Scale"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_eltsum"
  type: "Eltwise"
  bottom: "map64_2_eltsum"
  bottom: "map64_3_conv_b"
  top: "map64_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_3_relu_after_sum"
  type: "ReLU"
  bottom: "map64_3_eltsum"
  top: "map64_3_eltsum"
}
layer {
  name: "pool_global"
  type: "Pooling"
  bottom: "map64_3_eltsum"
  top: "pool_global"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_global"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc/top1"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc/top5"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop5"
  accuracy_param {
    top_k: 5
  }
}
I0418 16:30:48.836372  2203 layer_factory.hpp:77] Creating layer data
I0418 16:30:49.012328  2203 db_leveldb.cpp:18] Opened leveldb /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_full_train_leveldb_padded/
I0418 16:30:49.030612  2203 net.cpp:84] Creating Layer data
I0418 16:30:49.030668  2203 net.cpp:380] data -> data
I0418 16:30:49.030704  2203 net.cpp:380] data -> label
I0418 16:30:49.030727  2203 data_transformer.cpp:25] Loading mean file from: /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/paddedmean.binaryproto
I0418 16:30:49.037977  2203 data_layer.cpp:45] output data size: 128,3,32,32
I0418 16:30:49.053103  2203 net.cpp:122] Setting up data
I0418 16:30:49.053165  2203 net.cpp:129] Top shape: 128 3 32 32 (393216)
I0418 16:30:49.053170  2203 net.cpp:129] Top shape: 128 (128)
I0418 16:30:49.053174  2203 net.cpp:137] Memory required for data: 1573376
I0418 16:30:49.053184  2203 layer_factory.hpp:77] Creating layer label_data_1_split
I0418 16:30:49.053201  2203 net.cpp:84] Creating Layer label_data_1_split
I0418 16:30:49.053207  2203 net.cpp:406] label_data_1_split <- label
I0418 16:30:49.053223  2203 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0418 16:30:49.053234  2203 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0418 16:30:49.053246  2203 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0418 16:30:49.053355  2203 net.cpp:122] Setting up label_data_1_split
I0418 16:30:49.053361  2203 net.cpp:129] Top shape: 128 (128)
I0418 16:30:49.053365  2203 net.cpp:129] Top shape: 128 (128)
I0418 16:30:49.053369  2203 net.cpp:129] Top shape: 128 (128)
I0418 16:30:49.053400  2203 net.cpp:137] Memory required for data: 1574912
I0418 16:30:49.053402  2203 layer_factory.hpp:77] Creating layer conv1
I0418 16:30:49.053421  2203 net.cpp:84] Creating Layer conv1
I0418 16:30:49.053426  2203 net.cpp:406] conv1 <- data
I0418 16:30:49.053432  2203 net.cpp:380] conv1 -> conv1
I0418 16:30:54.194620  2203 net.cpp:122] Setting up conv1
I0418 16:30:54.194674  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.194679  2203 net.cpp:137] Memory required for data: 9963520
I0418 16:30:54.194705  2203 layer_factory.hpp:77] Creating layer bn_conv1
I0418 16:30:54.194728  2203 net.cpp:84] Creating Layer bn_conv1
I0418 16:30:54.194733  2203 net.cpp:406] bn_conv1 <- conv1
I0418 16:30:54.194741  2203 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0418 16:30:54.194901  2203 net.cpp:122] Setting up bn_conv1
I0418 16:30:54.194908  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.194912  2203 net.cpp:137] Memory required for data: 18352128
I0418 16:30:54.194923  2203 layer_factory.hpp:77] Creating layer scale_conv1
I0418 16:30:54.194937  2203 net.cpp:84] Creating Layer scale_conv1
I0418 16:30:54.194941  2203 net.cpp:406] scale_conv1 <- conv1
I0418 16:30:54.194947  2203 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0418 16:30:54.194983  2203 layer_factory.hpp:77] Creating layer scale_conv1
I0418 16:30:54.195078  2203 net.cpp:122] Setting up scale_conv1
I0418 16:30:54.195086  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.195088  2203 net.cpp:137] Memory required for data: 26740736
I0418 16:30:54.195094  2203 layer_factory.hpp:77] Creating layer relu_conv1
I0418 16:30:54.195103  2203 net.cpp:84] Creating Layer relu_conv1
I0418 16:30:54.195107  2203 net.cpp:406] relu_conv1 <- conv1
I0418 16:30:54.195112  2203 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0418 16:30:54.195281  2203 net.cpp:122] Setting up relu_conv1
I0418 16:30:54.195291  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.195294  2203 net.cpp:137] Memory required for data: 35129344
I0418 16:30:54.195297  2203 layer_factory.hpp:77] Creating layer conv1_relu_conv1_0_split
I0418 16:30:54.195304  2203 net.cpp:84] Creating Layer conv1_relu_conv1_0_split
I0418 16:30:54.195308  2203 net.cpp:406] conv1_relu_conv1_0_split <- conv1
I0418 16:30:54.195314  2203 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_0
I0418 16:30:54.195322  2203 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_1
I0418 16:30:54.195355  2203 net.cpp:122] Setting up conv1_relu_conv1_0_split
I0418 16:30:54.195363  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.195366  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.195369  2203 net.cpp:137] Memory required for data: 51906560
I0418 16:30:54.195374  2203 layer_factory.hpp:77] Creating layer map16_1_conv_a
I0418 16:30:54.195385  2203 net.cpp:84] Creating Layer map16_1_conv_a
I0418 16:30:54.195389  2203 net.cpp:406] map16_1_conv_a <- conv1_relu_conv1_0_split_0
I0418 16:30:54.195395  2203 net.cpp:380] map16_1_conv_a -> map16_1_conv_a
I0418 16:30:54.197371  2203 net.cpp:122] Setting up map16_1_conv_a
I0418 16:30:54.197384  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.197388  2203 net.cpp:137] Memory required for data: 60295168
I0418 16:30:54.197399  2203 layer_factory.hpp:77] Creating layer map16_1_bn_a
I0418 16:30:54.197409  2203 net.cpp:84] Creating Layer map16_1_bn_a
I0418 16:30:54.197414  2203 net.cpp:406] map16_1_bn_a <- map16_1_conv_a
I0418 16:30:54.197422  2203 net.cpp:367] map16_1_bn_a -> map16_1_conv_a (in-place)
I0418 16:30:54.197574  2203 net.cpp:122] Setting up map16_1_bn_a
I0418 16:30:54.197582  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.197585  2203 net.cpp:137] Memory required for data: 68683776
I0418 16:30:54.197592  2203 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0418 16:30:54.197598  2203 net.cpp:84] Creating Layer map16_1_scale_a
I0418 16:30:54.197602  2203 net.cpp:406] map16_1_scale_a <- map16_1_conv_a
I0418 16:30:54.197635  2203 net.cpp:367] map16_1_scale_a -> map16_1_conv_a (in-place)
I0418 16:30:54.197669  2203 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0418 16:30:54.197757  2203 net.cpp:122] Setting up map16_1_scale_a
I0418 16:30:54.197762  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.197765  2203 net.cpp:137] Memory required for data: 77072384
I0418 16:30:54.197772  2203 layer_factory.hpp:77] Creating layer map16_1_relu_a
I0418 16:30:54.197780  2203 net.cpp:84] Creating Layer map16_1_relu_a
I0418 16:30:54.197783  2203 net.cpp:406] map16_1_relu_a <- map16_1_conv_a
I0418 16:30:54.197789  2203 net.cpp:367] map16_1_relu_a -> map16_1_conv_a (in-place)
I0418 16:30:54.198154  2203 net.cpp:122] Setting up map16_1_relu_a
I0418 16:30:54.198168  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.198170  2203 net.cpp:137] Memory required for data: 85460992
I0418 16:30:54.198175  2203 layer_factory.hpp:77] Creating layer map16_1_conv_b
I0418 16:30:54.198187  2203 net.cpp:84] Creating Layer map16_1_conv_b
I0418 16:30:54.198191  2203 net.cpp:406] map16_1_conv_b <- map16_1_conv_a
I0418 16:30:54.198199  2203 net.cpp:380] map16_1_conv_b -> map16_1_conv_b
I0418 16:30:54.198865  2203 net.cpp:122] Setting up map16_1_conv_b
I0418 16:30:54.198876  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.198880  2203 net.cpp:137] Memory required for data: 93849600
I0418 16:30:54.198886  2203 layer_factory.hpp:77] Creating layer map16_1_bn_b
I0418 16:30:54.198895  2203 net.cpp:84] Creating Layer map16_1_bn_b
I0418 16:30:54.198899  2203 net.cpp:406] map16_1_bn_b <- map16_1_conv_b
I0418 16:30:54.198906  2203 net.cpp:367] map16_1_bn_b -> map16_1_conv_b (in-place)
I0418 16:30:54.199051  2203 net.cpp:122] Setting up map16_1_bn_b
I0418 16:30:54.199059  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.199061  2203 net.cpp:137] Memory required for data: 102238208
I0418 16:30:54.199071  2203 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0418 16:30:54.199079  2203 net.cpp:84] Creating Layer map16_1_scale_b
I0418 16:30:54.199084  2203 net.cpp:406] map16_1_scale_b <- map16_1_conv_b
I0418 16:30:54.199089  2203 net.cpp:367] map16_1_scale_b -> map16_1_conv_b (in-place)
I0418 16:30:54.199118  2203 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0418 16:30:54.199205  2203 net.cpp:122] Setting up map16_1_scale_b
I0418 16:30:54.199211  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.199214  2203 net.cpp:137] Memory required for data: 110626816
I0418 16:30:54.199220  2203 layer_factory.hpp:77] Creating layer map16_1_eltsum
I0418 16:30:54.201457  2203 net.cpp:84] Creating Layer map16_1_eltsum
I0418 16:30:54.201465  2203 net.cpp:406] map16_1_eltsum <- conv1_relu_conv1_0_split_1
I0418 16:30:54.201472  2203 net.cpp:406] map16_1_eltsum <- map16_1_conv_b
I0418 16:30:54.201478  2203 net.cpp:380] map16_1_eltsum -> map16_1_eltsum
I0418 16:30:54.201510  2203 net.cpp:122] Setting up map16_1_eltsum
I0418 16:30:54.201517  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.201520  2203 net.cpp:137] Memory required for data: 119015424
I0418 16:30:54.201524  2203 layer_factory.hpp:77] Creating layer map16_1_relu_after_sum
I0418 16:30:54.201532  2203 net.cpp:84] Creating Layer map16_1_relu_after_sum
I0418 16:30:54.201536  2203 net.cpp:406] map16_1_relu_after_sum <- map16_1_eltsum
I0418 16:30:54.201540  2203 net.cpp:367] map16_1_relu_after_sum -> map16_1_eltsum (in-place)
I0418 16:30:54.201915  2203 net.cpp:122] Setting up map16_1_relu_after_sum
I0418 16:30:54.201927  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.201930  2203 net.cpp:137] Memory required for data: 127404032
I0418 16:30:54.201934  2203 layer_factory.hpp:77] Creating layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0418 16:30:54.201946  2203 net.cpp:84] Creating Layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0418 16:30:54.201949  2203 net.cpp:406] map16_1_eltsum_map16_1_relu_after_sum_0_split <- map16_1_eltsum
I0418 16:30:54.201956  2203 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0418 16:30:54.201977  2203 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0418 16:30:54.202014  2203 net.cpp:122] Setting up map16_1_eltsum_map16_1_relu_after_sum_0_split
I0418 16:30:54.202021  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.202024  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.202028  2203 net.cpp:137] Memory required for data: 144181248
I0418 16:30:54.202030  2203 layer_factory.hpp:77] Creating layer map16_2_conv_a
I0418 16:30:54.202041  2203 net.cpp:84] Creating Layer map16_2_conv_a
I0418 16:30:54.202045  2203 net.cpp:406] map16_2_conv_a <- map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0418 16:30:54.202051  2203 net.cpp:380] map16_2_conv_a -> map16_2_conv_a
I0418 16:30:54.202932  2203 net.cpp:122] Setting up map16_2_conv_a
I0418 16:30:54.202945  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.202950  2203 net.cpp:137] Memory required for data: 152569856
I0418 16:30:54.202955  2203 layer_factory.hpp:77] Creating layer map16_2_bn_a
I0418 16:30:54.202965  2203 net.cpp:84] Creating Layer map16_2_bn_a
I0418 16:30:54.202970  2203 net.cpp:406] map16_2_bn_a <- map16_2_conv_a
I0418 16:30:54.202975  2203 net.cpp:367] map16_2_bn_a -> map16_2_conv_a (in-place)
I0418 16:30:54.203125  2203 net.cpp:122] Setting up map16_2_bn_a
I0418 16:30:54.203132  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.203135  2203 net.cpp:137] Memory required for data: 160958464
I0418 16:30:54.203143  2203 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0418 16:30:54.203150  2203 net.cpp:84] Creating Layer map16_2_scale_a
I0418 16:30:54.203155  2203 net.cpp:406] map16_2_scale_a <- map16_2_conv_a
I0418 16:30:54.203160  2203 net.cpp:367] map16_2_scale_a -> map16_2_conv_a (in-place)
I0418 16:30:54.203189  2203 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0418 16:30:54.203285  2203 net.cpp:122] Setting up map16_2_scale_a
I0418 16:30:54.203292  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.203295  2203 net.cpp:137] Memory required for data: 169347072
I0418 16:30:54.203302  2203 layer_factory.hpp:77] Creating layer map16_2_relu_a
I0418 16:30:54.203308  2203 net.cpp:84] Creating Layer map16_2_relu_a
I0418 16:30:54.203312  2203 net.cpp:406] map16_2_relu_a <- map16_2_conv_a
I0418 16:30:54.203318  2203 net.cpp:367] map16_2_relu_a -> map16_2_conv_a (in-place)
I0418 16:30:54.203462  2203 net.cpp:122] Setting up map16_2_relu_a
I0418 16:30:54.203471  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.203474  2203 net.cpp:137] Memory required for data: 177735680
I0418 16:30:54.203477  2203 layer_factory.hpp:77] Creating layer map16_2_conv_b
I0418 16:30:54.203488  2203 net.cpp:84] Creating Layer map16_2_conv_b
I0418 16:30:54.203492  2203 net.cpp:406] map16_2_conv_b <- map16_2_conv_a
I0418 16:30:54.203498  2203 net.cpp:380] map16_2_conv_b -> map16_2_conv_b
I0418 16:30:54.204543  2203 net.cpp:122] Setting up map16_2_conv_b
I0418 16:30:54.204556  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.204560  2203 net.cpp:137] Memory required for data: 186124288
I0418 16:30:54.204566  2203 layer_factory.hpp:77] Creating layer map16_2_bn_b
I0418 16:30:54.204577  2203 net.cpp:84] Creating Layer map16_2_bn_b
I0418 16:30:54.204582  2203 net.cpp:406] map16_2_bn_b <- map16_2_conv_b
I0418 16:30:54.204591  2203 net.cpp:367] map16_2_bn_b -> map16_2_conv_b (in-place)
I0418 16:30:54.204743  2203 net.cpp:122] Setting up map16_2_bn_b
I0418 16:30:54.204751  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.204754  2203 net.cpp:137] Memory required for data: 194512896
I0418 16:30:54.204764  2203 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0418 16:30:54.204773  2203 net.cpp:84] Creating Layer map16_2_scale_b
I0418 16:30:54.204777  2203 net.cpp:406] map16_2_scale_b <- map16_2_conv_b
I0418 16:30:54.204782  2203 net.cpp:367] map16_2_scale_b -> map16_2_conv_b (in-place)
I0418 16:30:54.204826  2203 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0418 16:30:54.204919  2203 net.cpp:122] Setting up map16_2_scale_b
I0418 16:30:54.204926  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.204929  2203 net.cpp:137] Memory required for data: 202901504
I0418 16:30:54.204936  2203 layer_factory.hpp:77] Creating layer map16_2_eltsum
I0418 16:30:54.204942  2203 net.cpp:84] Creating Layer map16_2_eltsum
I0418 16:30:54.204946  2203 net.cpp:406] map16_2_eltsum <- map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0418 16:30:54.204951  2203 net.cpp:406] map16_2_eltsum <- map16_2_conv_b
I0418 16:30:54.204957  2203 net.cpp:380] map16_2_eltsum -> map16_2_eltsum
I0418 16:30:54.204977  2203 net.cpp:122] Setting up map16_2_eltsum
I0418 16:30:54.204983  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.204987  2203 net.cpp:137] Memory required for data: 211290112
I0418 16:30:54.204989  2203 layer_factory.hpp:77] Creating layer map16_2_relu_after_sum
I0418 16:30:54.204995  2203 net.cpp:84] Creating Layer map16_2_relu_after_sum
I0418 16:30:54.204998  2203 net.cpp:406] map16_2_relu_after_sum <- map16_2_eltsum
I0418 16:30:54.205003  2203 net.cpp:367] map16_2_relu_after_sum -> map16_2_eltsum (in-place)
I0418 16:30:54.205152  2203 net.cpp:122] Setting up map16_2_relu_after_sum
I0418 16:30:54.205159  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.205163  2203 net.cpp:137] Memory required for data: 219678720
I0418 16:30:54.205168  2203 layer_factory.hpp:77] Creating layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0418 16:30:54.205173  2203 net.cpp:84] Creating Layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0418 16:30:54.205178  2203 net.cpp:406] map16_2_eltsum_map16_2_relu_after_sum_0_split <- map16_2_eltsum
I0418 16:30:54.205183  2203 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0418 16:30:54.205190  2203 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0418 16:30:54.205224  2203 net.cpp:122] Setting up map16_2_eltsum_map16_2_relu_after_sum_0_split
I0418 16:30:54.205230  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.205235  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.205241  2203 net.cpp:137] Memory required for data: 236455936
I0418 16:30:54.205245  2203 layer_factory.hpp:77] Creating layer map16_3_conv_a
I0418 16:30:54.205256  2203 net.cpp:84] Creating Layer map16_3_conv_a
I0418 16:30:54.205260  2203 net.cpp:406] map16_3_conv_a <- map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0418 16:30:54.205266  2203 net.cpp:380] map16_3_conv_a -> map16_3_conv_a
I0418 16:30:54.206145  2203 net.cpp:122] Setting up map16_3_conv_a
I0418 16:30:54.206156  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.206161  2203 net.cpp:137] Memory required for data: 244844544
I0418 16:30:54.206167  2203 layer_factory.hpp:77] Creating layer map16_3_bn_a
I0418 16:30:54.206176  2203 net.cpp:84] Creating Layer map16_3_bn_a
I0418 16:30:54.206179  2203 net.cpp:406] map16_3_bn_a <- map16_3_conv_a
I0418 16:30:54.206185  2203 net.cpp:367] map16_3_bn_a -> map16_3_conv_a (in-place)
I0418 16:30:54.206346  2203 net.cpp:122] Setting up map16_3_bn_a
I0418 16:30:54.206354  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.206357  2203 net.cpp:137] Memory required for data: 253233152
I0418 16:30:54.206363  2203 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0418 16:30:54.206373  2203 net.cpp:84] Creating Layer map16_3_scale_a
I0418 16:30:54.206377  2203 net.cpp:406] map16_3_scale_a <- map16_3_conv_a
I0418 16:30:54.206382  2203 net.cpp:367] map16_3_scale_a -> map16_3_conv_a (in-place)
I0418 16:30:54.206413  2203 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0418 16:30:54.206502  2203 net.cpp:122] Setting up map16_3_scale_a
I0418 16:30:54.206508  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.206511  2203 net.cpp:137] Memory required for data: 261621760
I0418 16:30:54.206529  2203 layer_factory.hpp:77] Creating layer map16_3_relu_a
I0418 16:30:54.206537  2203 net.cpp:84] Creating Layer map16_3_relu_a
I0418 16:30:54.206540  2203 net.cpp:406] map16_3_relu_a <- map16_3_conv_a
I0418 16:30:54.206545  2203 net.cpp:367] map16_3_relu_a -> map16_3_conv_a (in-place)
I0418 16:30:54.206691  2203 net.cpp:122] Setting up map16_3_relu_a
I0418 16:30:54.206699  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.206702  2203 net.cpp:137] Memory required for data: 270010368
I0418 16:30:54.206706  2203 layer_factory.hpp:77] Creating layer map16_3_conv_b
I0418 16:30:54.206715  2203 net.cpp:84] Creating Layer map16_3_conv_b
I0418 16:30:54.206719  2203 net.cpp:406] map16_3_conv_b <- map16_3_conv_a
I0418 16:30:54.206725  2203 net.cpp:380] map16_3_conv_b -> map16_3_conv_b
I0418 16:30:54.207619  2203 net.cpp:122] Setting up map16_3_conv_b
I0418 16:30:54.207633  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.207635  2203 net.cpp:137] Memory required for data: 278398976
I0418 16:30:54.207643  2203 layer_factory.hpp:77] Creating layer map16_3_bn_b
I0418 16:30:54.207655  2203 net.cpp:84] Creating Layer map16_3_bn_b
I0418 16:30:54.207659  2203 net.cpp:406] map16_3_bn_b <- map16_3_conv_b
I0418 16:30:54.207667  2203 net.cpp:367] map16_3_bn_b -> map16_3_conv_b (in-place)
I0418 16:30:54.207820  2203 net.cpp:122] Setting up map16_3_bn_b
I0418 16:30:54.207828  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.207831  2203 net.cpp:137] Memory required for data: 286787584
I0418 16:30:54.207837  2203 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0418 16:30:54.207845  2203 net.cpp:84] Creating Layer map16_3_scale_b
I0418 16:30:54.207849  2203 net.cpp:406] map16_3_scale_b <- map16_3_conv_b
I0418 16:30:54.207854  2203 net.cpp:367] map16_3_scale_b -> map16_3_conv_b (in-place)
I0418 16:30:54.207885  2203 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0418 16:30:54.207976  2203 net.cpp:122] Setting up map16_3_scale_b
I0418 16:30:54.207983  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.207985  2203 net.cpp:137] Memory required for data: 295176192
I0418 16:30:54.207991  2203 layer_factory.hpp:77] Creating layer map16_3_eltsum
I0418 16:30:54.207998  2203 net.cpp:84] Creating Layer map16_3_eltsum
I0418 16:30:54.208003  2203 net.cpp:406] map16_3_eltsum <- map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0418 16:30:54.208008  2203 net.cpp:406] map16_3_eltsum <- map16_3_conv_b
I0418 16:30:54.208012  2203 net.cpp:380] map16_3_eltsum -> map16_3_eltsum
I0418 16:30:54.208034  2203 net.cpp:122] Setting up map16_3_eltsum
I0418 16:30:54.208040  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.208043  2203 net.cpp:137] Memory required for data: 303564800
I0418 16:30:54.208045  2203 layer_factory.hpp:77] Creating layer map16_3_relu_after_sum
I0418 16:30:54.208050  2203 net.cpp:84] Creating Layer map16_3_relu_after_sum
I0418 16:30:54.208055  2203 net.cpp:406] map16_3_relu_after_sum <- map16_3_eltsum
I0418 16:30:54.208058  2203 net.cpp:367] map16_3_relu_after_sum -> map16_3_eltsum (in-place)
I0418 16:30:54.208201  2203 net.cpp:122] Setting up map16_3_relu_after_sum
I0418 16:30:54.208209  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.208212  2203 net.cpp:137] Memory required for data: 311953408
I0418 16:30:54.208215  2203 layer_factory.hpp:77] Creating layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0418 16:30:54.208221  2203 net.cpp:84] Creating Layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0418 16:30:54.208225  2203 net.cpp:406] map16_3_eltsum_map16_3_relu_after_sum_0_split <- map16_3_eltsum
I0418 16:30:54.208230  2203 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0418 16:30:54.208235  2203 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0418 16:30:54.208274  2203 net.cpp:122] Setting up map16_3_eltsum_map16_3_relu_after_sum_0_split
I0418 16:30:54.208281  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.208297  2203 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 16:30:54.208299  2203 net.cpp:137] Memory required for data: 328730624
I0418 16:30:54.208303  2203 layer_factory.hpp:77] Creating layer map32_1_conv_proj
I0418 16:30:54.208313  2203 net.cpp:84] Creating Layer map32_1_conv_proj
I0418 16:30:54.208317  2203 net.cpp:406] map32_1_conv_proj <- map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0418 16:30:54.208323  2203 net.cpp:380] map32_1_conv_proj -> map32_1_conv_proj
I0418 16:30:54.209445  2203 net.cpp:122] Setting up map32_1_conv_proj
I0418 16:30:54.209458  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.209462  2203 net.cpp:137] Memory required for data: 332924928
I0418 16:30:54.209470  2203 layer_factory.hpp:77] Creating layer map32_1_bn_proj
I0418 16:30:54.209478  2203 net.cpp:84] Creating Layer map32_1_bn_proj
I0418 16:30:54.209483  2203 net.cpp:406] map32_1_bn_proj <- map32_1_conv_proj
I0418 16:30:54.209489  2203 net.cpp:367] map32_1_bn_proj -> map32_1_conv_proj (in-place)
I0418 16:30:54.209637  2203 net.cpp:122] Setting up map32_1_bn_proj
I0418 16:30:54.209645  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.209647  2203 net.cpp:137] Memory required for data: 337119232
I0418 16:30:54.209653  2203 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0418 16:30:54.209661  2203 net.cpp:84] Creating Layer map32_1_scale_proj
I0418 16:30:54.209664  2203 net.cpp:406] map32_1_scale_proj <- map32_1_conv_proj
I0418 16:30:54.209668  2203 net.cpp:367] map32_1_scale_proj -> map32_1_conv_proj (in-place)
I0418 16:30:54.209697  2203 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0418 16:30:54.209781  2203 net.cpp:122] Setting up map32_1_scale_proj
I0418 16:30:54.209789  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.209791  2203 net.cpp:137] Memory required for data: 341313536
I0418 16:30:54.209796  2203 layer_factory.hpp:77] Creating layer map32_1_conv_a
I0418 16:30:54.209806  2203 net.cpp:84] Creating Layer map32_1_conv_a
I0418 16:30:54.209810  2203 net.cpp:406] map32_1_conv_a <- map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0418 16:30:54.209817  2203 net.cpp:380] map32_1_conv_a -> map32_1_conv_a
I0418 16:30:54.210876  2203 net.cpp:122] Setting up map32_1_conv_a
I0418 16:30:54.210889  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.210893  2203 net.cpp:137] Memory required for data: 345507840
I0418 16:30:54.210899  2203 layer_factory.hpp:77] Creating layer map32_1_bn_a
I0418 16:30:54.210907  2203 net.cpp:84] Creating Layer map32_1_bn_a
I0418 16:30:54.210911  2203 net.cpp:406] map32_1_bn_a <- map32_1_conv_a
I0418 16:30:54.210917  2203 net.cpp:367] map32_1_bn_a -> map32_1_conv_a (in-place)
I0418 16:30:54.211064  2203 net.cpp:122] Setting up map32_1_bn_a
I0418 16:30:54.211071  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.211074  2203 net.cpp:137] Memory required for data: 349702144
I0418 16:30:54.211081  2203 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0418 16:30:54.211088  2203 net.cpp:84] Creating Layer map32_1_scale_a
I0418 16:30:54.211092  2203 net.cpp:406] map32_1_scale_a <- map32_1_conv_a
I0418 16:30:54.211097  2203 net.cpp:367] map32_1_scale_a -> map32_1_conv_a (in-place)
I0418 16:30:54.211127  2203 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0418 16:30:54.211212  2203 net.cpp:122] Setting up map32_1_scale_a
I0418 16:30:54.211218  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.211221  2203 net.cpp:137] Memory required for data: 353896448
I0418 16:30:54.211227  2203 layer_factory.hpp:77] Creating layer map32_1_relu_a
I0418 16:30:54.211232  2203 net.cpp:84] Creating Layer map32_1_relu_a
I0418 16:30:54.211236  2203 net.cpp:406] map32_1_relu_a <- map32_1_conv_a
I0418 16:30:54.211246  2203 net.cpp:367] map32_1_relu_a -> map32_1_conv_a (in-place)
I0418 16:30:54.211388  2203 net.cpp:122] Setting up map32_1_relu_a
I0418 16:30:54.211396  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.211400  2203 net.cpp:137] Memory required for data: 358090752
I0418 16:30:54.211414  2203 layer_factory.hpp:77] Creating layer map32_1_conv_b
I0418 16:30:54.211427  2203 net.cpp:84] Creating Layer map32_1_conv_b
I0418 16:30:54.211431  2203 net.cpp:406] map32_1_conv_b <- map32_1_conv_a
I0418 16:30:54.211437  2203 net.cpp:380] map32_1_conv_b -> map32_1_conv_b
I0418 16:30:54.212471  2203 net.cpp:122] Setting up map32_1_conv_b
I0418 16:30:54.212484  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.212487  2203 net.cpp:137] Memory required for data: 362285056
I0418 16:30:54.212501  2203 layer_factory.hpp:77] Creating layer map32_1_bn_b
I0418 16:30:54.212508  2203 net.cpp:84] Creating Layer map32_1_bn_b
I0418 16:30:54.212512  2203 net.cpp:406] map32_1_bn_b <- map32_1_conv_b
I0418 16:30:54.212518  2203 net.cpp:367] map32_1_bn_b -> map32_1_conv_b (in-place)
I0418 16:30:54.212662  2203 net.cpp:122] Setting up map32_1_bn_b
I0418 16:30:54.212669  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.212672  2203 net.cpp:137] Memory required for data: 366479360
I0418 16:30:54.212678  2203 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0418 16:30:54.212687  2203 net.cpp:84] Creating Layer map32_1_scale_b
I0418 16:30:54.212690  2203 net.cpp:406] map32_1_scale_b <- map32_1_conv_b
I0418 16:30:54.212694  2203 net.cpp:367] map32_1_scale_b -> map32_1_conv_b (in-place)
I0418 16:30:54.212724  2203 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0418 16:30:54.212810  2203 net.cpp:122] Setting up map32_1_scale_b
I0418 16:30:54.212815  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.212818  2203 net.cpp:137] Memory required for data: 370673664
I0418 16:30:54.212824  2203 layer_factory.hpp:77] Creating layer map32_1_eltsum
I0418 16:30:54.212831  2203 net.cpp:84] Creating Layer map32_1_eltsum
I0418 16:30:54.212834  2203 net.cpp:406] map32_1_eltsum <- map32_1_conv_proj
I0418 16:30:54.212837  2203 net.cpp:406] map32_1_eltsum <- map32_1_conv_b
I0418 16:30:54.212842  2203 net.cpp:380] map32_1_eltsum -> map32_1_eltsum
I0418 16:30:54.212860  2203 net.cpp:122] Setting up map32_1_eltsum
I0418 16:30:54.212865  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.212868  2203 net.cpp:137] Memory required for data: 374867968
I0418 16:30:54.212872  2203 layer_factory.hpp:77] Creating layer map32_1_relu_after_sum
I0418 16:30:54.212878  2203 net.cpp:84] Creating Layer map32_1_relu_after_sum
I0418 16:30:54.212882  2203 net.cpp:406] map32_1_relu_after_sum <- map32_1_eltsum
I0418 16:30:54.212885  2203 net.cpp:367] map32_1_relu_after_sum -> map32_1_eltsum (in-place)
I0418 16:30:54.213263  2203 net.cpp:122] Setting up map32_1_relu_after_sum
I0418 16:30:54.213274  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.213277  2203 net.cpp:137] Memory required for data: 379062272
I0418 16:30:54.213280  2203 layer_factory.hpp:77] Creating layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0418 16:30:54.213287  2203 net.cpp:84] Creating Layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0418 16:30:54.213291  2203 net.cpp:406] map32_1_eltsum_map32_1_relu_after_sum_0_split <- map32_1_eltsum
I0418 16:30:54.213296  2203 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0418 16:30:54.213304  2203 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0418 16:30:54.213338  2203 net.cpp:122] Setting up map32_1_eltsum_map32_1_relu_after_sum_0_split
I0418 16:30:54.213345  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.213348  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.213351  2203 net.cpp:137] Memory required for data: 387450880
I0418 16:30:54.213354  2203 layer_factory.hpp:77] Creating layer map32_2_conv_a
I0418 16:30:54.213364  2203 net.cpp:84] Creating Layer map32_2_conv_a
I0418 16:30:54.213368  2203 net.cpp:406] map32_2_conv_a <- map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0418 16:30:54.213373  2203 net.cpp:380] map32_2_conv_a -> map32_2_conv_a
I0418 16:30:54.214139  2203 net.cpp:122] Setting up map32_2_conv_a
I0418 16:30:54.214149  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.214154  2203 net.cpp:137] Memory required for data: 391645184
I0418 16:30:54.214159  2203 layer_factory.hpp:77] Creating layer map32_2_bn_a
I0418 16:30:54.214166  2203 net.cpp:84] Creating Layer map32_2_bn_a
I0418 16:30:54.214170  2203 net.cpp:406] map32_2_bn_a <- map32_2_conv_a
I0418 16:30:54.214176  2203 net.cpp:367] map32_2_bn_a -> map32_2_conv_a (in-place)
I0418 16:30:54.214324  2203 net.cpp:122] Setting up map32_2_bn_a
I0418 16:30:54.214331  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.214335  2203 net.cpp:137] Memory required for data: 395839488
I0418 16:30:54.214344  2203 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0418 16:30:54.214350  2203 net.cpp:84] Creating Layer map32_2_scale_a
I0418 16:30:54.214354  2203 net.cpp:406] map32_2_scale_a <- map32_2_conv_a
I0418 16:30:54.214359  2203 net.cpp:367] map32_2_scale_a -> map32_2_conv_a (in-place)
I0418 16:30:54.214388  2203 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0418 16:30:54.214474  2203 net.cpp:122] Setting up map32_2_scale_a
I0418 16:30:54.214480  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.214483  2203 net.cpp:137] Memory required for data: 400033792
I0418 16:30:54.214488  2203 layer_factory.hpp:77] Creating layer map32_2_relu_a
I0418 16:30:54.214494  2203 net.cpp:84] Creating Layer map32_2_relu_a
I0418 16:30:54.214498  2203 net.cpp:406] map32_2_relu_a <- map32_2_conv_a
I0418 16:30:54.214503  2203 net.cpp:367] map32_2_relu_a -> map32_2_conv_a (in-place)
I0418 16:30:54.214876  2203 net.cpp:122] Setting up map32_2_relu_a
I0418 16:30:54.214887  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.214891  2203 net.cpp:137] Memory required for data: 404228096
I0418 16:30:54.214895  2203 layer_factory.hpp:77] Creating layer map32_2_conv_b
I0418 16:30:54.214905  2203 net.cpp:84] Creating Layer map32_2_conv_b
I0418 16:30:54.214908  2203 net.cpp:406] map32_2_conv_b <- map32_2_conv_a
I0418 16:30:54.214913  2203 net.cpp:380] map32_2_conv_b -> map32_2_conv_b
I0418 16:30:54.216024  2203 net.cpp:122] Setting up map32_2_conv_b
I0418 16:30:54.216037  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.216040  2203 net.cpp:137] Memory required for data: 408422400
I0418 16:30:54.216047  2203 layer_factory.hpp:77] Creating layer map32_2_bn_b
I0418 16:30:54.216058  2203 net.cpp:84] Creating Layer map32_2_bn_b
I0418 16:30:54.216061  2203 net.cpp:406] map32_2_bn_b <- map32_2_conv_b
I0418 16:30:54.216068  2203 net.cpp:367] map32_2_bn_b -> map32_2_conv_b (in-place)
I0418 16:30:54.216215  2203 net.cpp:122] Setting up map32_2_bn_b
I0418 16:30:54.216223  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.216225  2203 net.cpp:137] Memory required for data: 412616704
I0418 16:30:54.216233  2203 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0418 16:30:54.216243  2203 net.cpp:84] Creating Layer map32_2_scale_b
I0418 16:30:54.216248  2203 net.cpp:406] map32_2_scale_b <- map32_2_conv_b
I0418 16:30:54.216253  2203 net.cpp:367] map32_2_scale_b -> map32_2_conv_b (in-place)
I0418 16:30:54.216284  2203 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0418 16:30:54.216369  2203 net.cpp:122] Setting up map32_2_scale_b
I0418 16:30:54.216375  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.216378  2203 net.cpp:137] Memory required for data: 416811008
I0418 16:30:54.216383  2203 layer_factory.hpp:77] Creating layer map32_2_eltsum
I0418 16:30:54.216390  2203 net.cpp:84] Creating Layer map32_2_eltsum
I0418 16:30:54.216394  2203 net.cpp:406] map32_2_eltsum <- map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0418 16:30:54.216399  2203 net.cpp:406] map32_2_eltsum <- map32_2_conv_b
I0418 16:30:54.216404  2203 net.cpp:380] map32_2_eltsum -> map32_2_eltsum
I0418 16:30:54.216423  2203 net.cpp:122] Setting up map32_2_eltsum
I0418 16:30:54.216428  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.216442  2203 net.cpp:137] Memory required for data: 421005312
I0418 16:30:54.216445  2203 layer_factory.hpp:77] Creating layer map32_2_relu_after_sum
I0418 16:30:54.216452  2203 net.cpp:84] Creating Layer map32_2_relu_after_sum
I0418 16:30:54.216455  2203 net.cpp:406] map32_2_relu_after_sum <- map32_2_eltsum
I0418 16:30:54.216460  2203 net.cpp:367] map32_2_relu_after_sum -> map32_2_eltsum (in-place)
I0418 16:30:54.216601  2203 net.cpp:122] Setting up map32_2_relu_after_sum
I0418 16:30:54.216609  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.216612  2203 net.cpp:137] Memory required for data: 425199616
I0418 16:30:54.216615  2203 layer_factory.hpp:77] Creating layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0418 16:30:54.216621  2203 net.cpp:84] Creating Layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0418 16:30:54.216625  2203 net.cpp:406] map32_2_eltsum_map32_2_relu_after_sum_0_split <- map32_2_eltsum
I0418 16:30:54.216630  2203 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0418 16:30:54.216639  2203 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0418 16:30:54.216672  2203 net.cpp:122] Setting up map32_2_eltsum_map32_2_relu_after_sum_0_split
I0418 16:30:54.216680  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.216682  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.216686  2203 net.cpp:137] Memory required for data: 433588224
I0418 16:30:54.216688  2203 layer_factory.hpp:77] Creating layer map32_3_conv_a
I0418 16:30:54.216696  2203 net.cpp:84] Creating Layer map32_3_conv_a
I0418 16:30:54.216701  2203 net.cpp:406] map32_3_conv_a <- map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0418 16:30:54.216706  2203 net.cpp:380] map32_3_conv_a -> map32_3_conv_a
I0418 16:30:54.217628  2203 net.cpp:122] Setting up map32_3_conv_a
I0418 16:30:54.217639  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.217643  2203 net.cpp:137] Memory required for data: 437782528
I0418 16:30:54.217649  2203 layer_factory.hpp:77] Creating layer map32_3_bn_a
I0418 16:30:54.217659  2203 net.cpp:84] Creating Layer map32_3_bn_a
I0418 16:30:54.217664  2203 net.cpp:406] map32_3_bn_a <- map32_3_conv_a
I0418 16:30:54.217669  2203 net.cpp:367] map32_3_bn_a -> map32_3_conv_a (in-place)
I0418 16:30:54.217816  2203 net.cpp:122] Setting up map32_3_bn_a
I0418 16:30:54.217823  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.217825  2203 net.cpp:137] Memory required for data: 441976832
I0418 16:30:54.217833  2203 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0418 16:30:54.217839  2203 net.cpp:84] Creating Layer map32_3_scale_a
I0418 16:30:54.217842  2203 net.cpp:406] map32_3_scale_a <- map32_3_conv_a
I0418 16:30:54.217846  2203 net.cpp:367] map32_3_scale_a -> map32_3_conv_a (in-place)
I0418 16:30:54.217876  2203 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0418 16:30:54.217962  2203 net.cpp:122] Setting up map32_3_scale_a
I0418 16:30:54.217968  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.217970  2203 net.cpp:137] Memory required for data: 446171136
I0418 16:30:54.217977  2203 layer_factory.hpp:77] Creating layer map32_3_relu_a
I0418 16:30:54.217983  2203 net.cpp:84] Creating Layer map32_3_relu_a
I0418 16:30:54.217986  2203 net.cpp:406] map32_3_relu_a <- map32_3_conv_a
I0418 16:30:54.217990  2203 net.cpp:367] map32_3_relu_a -> map32_3_conv_a (in-place)
I0418 16:30:54.218134  2203 net.cpp:122] Setting up map32_3_relu_a
I0418 16:30:54.218142  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.218145  2203 net.cpp:137] Memory required for data: 450365440
I0418 16:30:54.218148  2203 layer_factory.hpp:77] Creating layer map32_3_conv_b
I0418 16:30:54.218163  2203 net.cpp:84] Creating Layer map32_3_conv_b
I0418 16:30:54.218166  2203 net.cpp:406] map32_3_conv_b <- map32_3_conv_a
I0418 16:30:54.218171  2203 net.cpp:380] map32_3_conv_b -> map32_3_conv_b
I0418 16:30:54.219104  2203 net.cpp:122] Setting up map32_3_conv_b
I0418 16:30:54.219130  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.219133  2203 net.cpp:137] Memory required for data: 454559744
I0418 16:30:54.219141  2203 layer_factory.hpp:77] Creating layer map32_3_bn_b
I0418 16:30:54.219148  2203 net.cpp:84] Creating Layer map32_3_bn_b
I0418 16:30:54.219152  2203 net.cpp:406] map32_3_bn_b <- map32_3_conv_b
I0418 16:30:54.219158  2203 net.cpp:367] map32_3_bn_b -> map32_3_conv_b (in-place)
I0418 16:30:54.219313  2203 net.cpp:122] Setting up map32_3_bn_b
I0418 16:30:54.219321  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.219323  2203 net.cpp:137] Memory required for data: 458754048
I0418 16:30:54.219331  2203 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0418 16:30:54.219339  2203 net.cpp:84] Creating Layer map32_3_scale_b
I0418 16:30:54.219343  2203 net.cpp:406] map32_3_scale_b <- map32_3_conv_b
I0418 16:30:54.219347  2203 net.cpp:367] map32_3_scale_b -> map32_3_conv_b (in-place)
I0418 16:30:54.219378  2203 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0418 16:30:54.219466  2203 net.cpp:122] Setting up map32_3_scale_b
I0418 16:30:54.219472  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.219475  2203 net.cpp:137] Memory required for data: 462948352
I0418 16:30:54.219481  2203 layer_factory.hpp:77] Creating layer map32_3_eltsum
I0418 16:30:54.219488  2203 net.cpp:84] Creating Layer map32_3_eltsum
I0418 16:30:54.219492  2203 net.cpp:406] map32_3_eltsum <- map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0418 16:30:54.219497  2203 net.cpp:406] map32_3_eltsum <- map32_3_conv_b
I0418 16:30:54.219502  2203 net.cpp:380] map32_3_eltsum -> map32_3_eltsum
I0418 16:30:54.219519  2203 net.cpp:122] Setting up map32_3_eltsum
I0418 16:30:54.219525  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.219528  2203 net.cpp:137] Memory required for data: 467142656
I0418 16:30:54.219532  2203 layer_factory.hpp:77] Creating layer map32_3_relu_after_sum
I0418 16:30:54.219537  2203 net.cpp:84] Creating Layer map32_3_relu_after_sum
I0418 16:30:54.219540  2203 net.cpp:406] map32_3_relu_after_sum <- map32_3_eltsum
I0418 16:30:54.219543  2203 net.cpp:367] map32_3_relu_after_sum -> map32_3_eltsum (in-place)
I0418 16:30:54.219684  2203 net.cpp:122] Setting up map32_3_relu_after_sum
I0418 16:30:54.219692  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.219696  2203 net.cpp:137] Memory required for data: 471336960
I0418 16:30:54.219698  2203 layer_factory.hpp:77] Creating layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0418 16:30:54.219704  2203 net.cpp:84] Creating Layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0418 16:30:54.219708  2203 net.cpp:406] map32_3_eltsum_map32_3_relu_after_sum_0_split <- map32_3_eltsum
I0418 16:30:54.219712  2203 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0418 16:30:54.219719  2203 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0418 16:30:54.219753  2203 net.cpp:122] Setting up map32_3_eltsum_map32_3_relu_after_sum_0_split
I0418 16:30:54.219759  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.219763  2203 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 16:30:54.219765  2203 net.cpp:137] Memory required for data: 479725568
I0418 16:30:54.219769  2203 layer_factory.hpp:77] Creating layer map64_1_conv_proj
I0418 16:30:54.219779  2203 net.cpp:84] Creating Layer map64_1_conv_proj
I0418 16:30:54.219782  2203 net.cpp:406] map64_1_conv_proj <- map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0418 16:30:54.219787  2203 net.cpp:380] map64_1_conv_proj -> map64_1_conv_proj
I0418 16:30:54.222124  2203 net.cpp:122] Setting up map64_1_conv_proj
I0418 16:30:54.222141  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.222144  2203 net.cpp:137] Memory required for data: 481822720
I0418 16:30:54.222151  2203 layer_factory.hpp:77] Creating layer map64_1_bn_proj
I0418 16:30:54.222169  2203 net.cpp:84] Creating Layer map64_1_bn_proj
I0418 16:30:54.222174  2203 net.cpp:406] map64_1_bn_proj <- map64_1_conv_proj
I0418 16:30:54.222183  2203 net.cpp:367] map64_1_bn_proj -> map64_1_conv_proj (in-place)
I0418 16:30:54.222352  2203 net.cpp:122] Setting up map64_1_bn_proj
I0418 16:30:54.222360  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.222363  2203 net.cpp:137] Memory required for data: 483919872
I0418 16:30:54.222371  2203 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0418 16:30:54.222378  2203 net.cpp:84] Creating Layer map64_1_scale_proj
I0418 16:30:54.222381  2203 net.cpp:406] map64_1_scale_proj <- map64_1_conv_proj
I0418 16:30:54.222385  2203 net.cpp:367] map64_1_scale_proj -> map64_1_conv_proj (in-place)
I0418 16:30:54.222419  2203 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0418 16:30:54.222514  2203 net.cpp:122] Setting up map64_1_scale_proj
I0418 16:30:54.222522  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.222524  2203 net.cpp:137] Memory required for data: 486017024
I0418 16:30:54.222529  2203 layer_factory.hpp:77] Creating layer map64_1_conv_a
I0418 16:30:54.222543  2203 net.cpp:84] Creating Layer map64_1_conv_a
I0418 16:30:54.222546  2203 net.cpp:406] map64_1_conv_a <- map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0418 16:30:54.222553  2203 net.cpp:380] map64_1_conv_a -> map64_1_conv_a
I0418 16:30:54.223708  2203 net.cpp:122] Setting up map64_1_conv_a
I0418 16:30:54.223722  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.223726  2203 net.cpp:137] Memory required for data: 488114176
I0418 16:30:54.223733  2203 layer_factory.hpp:77] Creating layer map64_1_bn_a
I0418 16:30:54.223743  2203 net.cpp:84] Creating Layer map64_1_bn_a
I0418 16:30:54.223747  2203 net.cpp:406] map64_1_bn_a <- map64_1_conv_a
I0418 16:30:54.223753  2203 net.cpp:367] map64_1_bn_a -> map64_1_conv_a (in-place)
I0418 16:30:54.223922  2203 net.cpp:122] Setting up map64_1_bn_a
I0418 16:30:54.223929  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.223932  2203 net.cpp:137] Memory required for data: 490211328
I0418 16:30:54.223939  2203 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0418 16:30:54.223947  2203 net.cpp:84] Creating Layer map64_1_scale_a
I0418 16:30:54.223949  2203 net.cpp:406] map64_1_scale_a <- map64_1_conv_a
I0418 16:30:54.223954  2203 net.cpp:367] map64_1_scale_a -> map64_1_conv_a (in-place)
I0418 16:30:54.223987  2203 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0418 16:30:54.224087  2203 net.cpp:122] Setting up map64_1_scale_a
I0418 16:30:54.224093  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.224097  2203 net.cpp:137] Memory required for data: 492308480
I0418 16:30:54.224102  2203 layer_factory.hpp:77] Creating layer map64_1_relu_a
I0418 16:30:54.224107  2203 net.cpp:84] Creating Layer map64_1_relu_a
I0418 16:30:54.224110  2203 net.cpp:406] map64_1_relu_a <- map64_1_conv_a
I0418 16:30:54.224114  2203 net.cpp:367] map64_1_relu_a -> map64_1_conv_a (in-place)
I0418 16:30:54.224269  2203 net.cpp:122] Setting up map64_1_relu_a
I0418 16:30:54.224279  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.224282  2203 net.cpp:137] Memory required for data: 494405632
I0418 16:30:54.224285  2203 layer_factory.hpp:77] Creating layer map64_1_conv_b
I0418 16:30:54.224297  2203 net.cpp:84] Creating Layer map64_1_conv_b
I0418 16:30:54.224300  2203 net.cpp:406] map64_1_conv_b <- map64_1_conv_a
I0418 16:30:54.224305  2203 net.cpp:380] map64_1_conv_b -> map64_1_conv_b
I0418 16:30:54.225996  2203 net.cpp:122] Setting up map64_1_conv_b
I0418 16:30:54.226008  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.226012  2203 net.cpp:137] Memory required for data: 496502784
I0418 16:30:54.226021  2203 layer_factory.hpp:77] Creating layer map64_1_bn_b
I0418 16:30:54.226030  2203 net.cpp:84] Creating Layer map64_1_bn_b
I0418 16:30:54.226034  2203 net.cpp:406] map64_1_bn_b <- map64_1_conv_b
I0418 16:30:54.226042  2203 net.cpp:367] map64_1_bn_b -> map64_1_conv_b (in-place)
I0418 16:30:54.226223  2203 net.cpp:122] Setting up map64_1_bn_b
I0418 16:30:54.226230  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.226233  2203 net.cpp:137] Memory required for data: 498599936
I0418 16:30:54.226248  2203 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0418 16:30:54.226253  2203 net.cpp:84] Creating Layer map64_1_scale_b
I0418 16:30:54.226258  2203 net.cpp:406] map64_1_scale_b <- map64_1_conv_b
I0418 16:30:54.226263  2203 net.cpp:367] map64_1_scale_b -> map64_1_conv_b (in-place)
I0418 16:30:54.226300  2203 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0418 16:30:54.226400  2203 net.cpp:122] Setting up map64_1_scale_b
I0418 16:30:54.226408  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.226410  2203 net.cpp:137] Memory required for data: 500697088
I0418 16:30:54.226415  2203 layer_factory.hpp:77] Creating layer map64_1_eltsum
I0418 16:30:54.226423  2203 net.cpp:84] Creating Layer map64_1_eltsum
I0418 16:30:54.226428  2203 net.cpp:406] map64_1_eltsum <- map64_1_conv_proj
I0418 16:30:54.226430  2203 net.cpp:406] map64_1_eltsum <- map64_1_conv_b
I0418 16:30:54.226435  2203 net.cpp:380] map64_1_eltsum -> map64_1_eltsum
I0418 16:30:54.226455  2203 net.cpp:122] Setting up map64_1_eltsum
I0418 16:30:54.226461  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.226464  2203 net.cpp:137] Memory required for data: 502794240
I0418 16:30:54.226467  2203 layer_factory.hpp:77] Creating layer map64_1_relu_after_sum
I0418 16:30:54.226474  2203 net.cpp:84] Creating Layer map64_1_relu_after_sum
I0418 16:30:54.226476  2203 net.cpp:406] map64_1_relu_after_sum <- map64_1_eltsum
I0418 16:30:54.226481  2203 net.cpp:367] map64_1_relu_after_sum -> map64_1_eltsum (in-place)
I0418 16:30:54.226641  2203 net.cpp:122] Setting up map64_1_relu_after_sum
I0418 16:30:54.226650  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.226653  2203 net.cpp:137] Memory required for data: 504891392
I0418 16:30:54.226656  2203 layer_factory.hpp:77] Creating layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0418 16:30:54.226662  2203 net.cpp:84] Creating Layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0418 16:30:54.226665  2203 net.cpp:406] map64_1_eltsum_map64_1_relu_after_sum_0_split <- map64_1_eltsum
I0418 16:30:54.226672  2203 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0418 16:30:54.226678  2203 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0418 16:30:54.226716  2203 net.cpp:122] Setting up map64_1_eltsum_map64_1_relu_after_sum_0_split
I0418 16:30:54.226724  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.226728  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.226730  2203 net.cpp:137] Memory required for data: 509085696
I0418 16:30:54.226733  2203 layer_factory.hpp:77] Creating layer map64_2_conv_a
I0418 16:30:54.226742  2203 net.cpp:84] Creating Layer map64_2_conv_a
I0418 16:30:54.226747  2203 net.cpp:406] map64_2_conv_a <- map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0418 16:30:54.226752  2203 net.cpp:380] map64_2_conv_a -> map64_2_conv_a
I0418 16:30:54.228302  2203 net.cpp:122] Setting up map64_2_conv_a
I0418 16:30:54.228315  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.228318  2203 net.cpp:137] Memory required for data: 511182848
I0418 16:30:54.228325  2203 layer_factory.hpp:77] Creating layer map64_2_bn_a
I0418 16:30:54.228335  2203 net.cpp:84] Creating Layer map64_2_bn_a
I0418 16:30:54.228339  2203 net.cpp:406] map64_2_bn_a <- map64_2_conv_a
I0418 16:30:54.228345  2203 net.cpp:367] map64_2_bn_a -> map64_2_conv_a (in-place)
I0418 16:30:54.228516  2203 net.cpp:122] Setting up map64_2_bn_a
I0418 16:30:54.228523  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.228526  2203 net.cpp:137] Memory required for data: 513280000
I0418 16:30:54.228533  2203 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0418 16:30:54.228539  2203 net.cpp:84] Creating Layer map64_2_scale_a
I0418 16:30:54.228554  2203 net.cpp:406] map64_2_scale_a <- map64_2_conv_a
I0418 16:30:54.228560  2203 net.cpp:367] map64_2_scale_a -> map64_2_conv_a (in-place)
I0418 16:30:54.228596  2203 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0418 16:30:54.228703  2203 net.cpp:122] Setting up map64_2_scale_a
I0418 16:30:54.228710  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.228713  2203 net.cpp:137] Memory required for data: 515377152
I0418 16:30:54.228718  2203 layer_factory.hpp:77] Creating layer map64_2_relu_a
I0418 16:30:54.228724  2203 net.cpp:84] Creating Layer map64_2_relu_a
I0418 16:30:54.228729  2203 net.cpp:406] map64_2_relu_a <- map64_2_conv_a
I0418 16:30:54.228734  2203 net.cpp:367] map64_2_relu_a -> map64_2_conv_a (in-place)
I0418 16:30:54.229121  2203 net.cpp:122] Setting up map64_2_relu_a
I0418 16:30:54.229133  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.229136  2203 net.cpp:137] Memory required for data: 517474304
I0418 16:30:54.229140  2203 layer_factory.hpp:77] Creating layer map64_2_conv_b
I0418 16:30:54.229151  2203 net.cpp:84] Creating Layer map64_2_conv_b
I0418 16:30:54.229156  2203 net.cpp:406] map64_2_conv_b <- map64_2_conv_a
I0418 16:30:54.229163  2203 net.cpp:380] map64_2_conv_b -> map64_2_conv_b
I0418 16:30:54.230626  2203 net.cpp:122] Setting up map64_2_conv_b
I0418 16:30:54.230639  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.230643  2203 net.cpp:137] Memory required for data: 519571456
I0418 16:30:54.230650  2203 layer_factory.hpp:77] Creating layer map64_2_bn_b
I0418 16:30:54.230660  2203 net.cpp:84] Creating Layer map64_2_bn_b
I0418 16:30:54.230665  2203 net.cpp:406] map64_2_bn_b <- map64_2_conv_b
I0418 16:30:54.230671  2203 net.cpp:367] map64_2_bn_b -> map64_2_conv_b (in-place)
I0418 16:30:54.230841  2203 net.cpp:122] Setting up map64_2_bn_b
I0418 16:30:54.230849  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.230851  2203 net.cpp:137] Memory required for data: 521668608
I0418 16:30:54.230872  2203 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0418 16:30:54.230880  2203 net.cpp:84] Creating Layer map64_2_scale_b
I0418 16:30:54.230885  2203 net.cpp:406] map64_2_scale_b <- map64_2_conv_b
I0418 16:30:54.230888  2203 net.cpp:367] map64_2_scale_b -> map64_2_conv_b (in-place)
I0418 16:30:54.230923  2203 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0418 16:30:54.231027  2203 net.cpp:122] Setting up map64_2_scale_b
I0418 16:30:54.231034  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.231037  2203 net.cpp:137] Memory required for data: 523765760
I0418 16:30:54.231042  2203 layer_factory.hpp:77] Creating layer map64_2_eltsum
I0418 16:30:54.231051  2203 net.cpp:84] Creating Layer map64_2_eltsum
I0418 16:30:54.231055  2203 net.cpp:406] map64_2_eltsum <- map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0418 16:30:54.231060  2203 net.cpp:406] map64_2_eltsum <- map64_2_conv_b
I0418 16:30:54.231065  2203 net.cpp:380] map64_2_eltsum -> map64_2_eltsum
I0418 16:30:54.231083  2203 net.cpp:122] Setting up map64_2_eltsum
I0418 16:30:54.231089  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.231091  2203 net.cpp:137] Memory required for data: 525862912
I0418 16:30:54.231093  2203 layer_factory.hpp:77] Creating layer map64_2_relu_after_sum
I0418 16:30:54.231101  2203 net.cpp:84] Creating Layer map64_2_relu_after_sum
I0418 16:30:54.231103  2203 net.cpp:406] map64_2_relu_after_sum <- map64_2_eltsum
I0418 16:30:54.231107  2203 net.cpp:367] map64_2_relu_after_sum -> map64_2_eltsum (in-place)
I0418 16:30:54.231271  2203 net.cpp:122] Setting up map64_2_relu_after_sum
I0418 16:30:54.231281  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.231283  2203 net.cpp:137] Memory required for data: 527960064
I0418 16:30:54.231287  2203 layer_factory.hpp:77] Creating layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0418 16:30:54.231292  2203 net.cpp:84] Creating Layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0418 16:30:54.231297  2203 net.cpp:406] map64_2_eltsum_map64_2_relu_after_sum_0_split <- map64_2_eltsum
I0418 16:30:54.231314  2203 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0418 16:30:54.231323  2203 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0418 16:30:54.231361  2203 net.cpp:122] Setting up map64_2_eltsum_map64_2_relu_after_sum_0_split
I0418 16:30:54.231369  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.231372  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.231374  2203 net.cpp:137] Memory required for data: 532154368
I0418 16:30:54.231379  2203 layer_factory.hpp:77] Creating layer map64_3_conv_a
I0418 16:30:54.231389  2203 net.cpp:84] Creating Layer map64_3_conv_a
I0418 16:30:54.231393  2203 net.cpp:406] map64_3_conv_a <- map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0418 16:30:54.231398  2203 net.cpp:380] map64_3_conv_a -> map64_3_conv_a
I0418 16:30:54.232650  2203 net.cpp:122] Setting up map64_3_conv_a
I0418 16:30:54.232662  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.232666  2203 net.cpp:137] Memory required for data: 534251520
I0418 16:30:54.232671  2203 layer_factory.hpp:77] Creating layer map64_3_bn_a
I0418 16:30:54.232681  2203 net.cpp:84] Creating Layer map64_3_bn_a
I0418 16:30:54.232686  2203 net.cpp:406] map64_3_bn_a <- map64_3_conv_a
I0418 16:30:54.232694  2203 net.cpp:367] map64_3_bn_a -> map64_3_conv_a (in-place)
I0418 16:30:54.232861  2203 net.cpp:122] Setting up map64_3_bn_a
I0418 16:30:54.232868  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.232872  2203 net.cpp:137] Memory required for data: 536348672
I0418 16:30:54.232879  2203 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0418 16:30:54.232887  2203 net.cpp:84] Creating Layer map64_3_scale_a
I0418 16:30:54.232890  2203 net.cpp:406] map64_3_scale_a <- map64_3_conv_a
I0418 16:30:54.232894  2203 net.cpp:367] map64_3_scale_a -> map64_3_conv_a (in-place)
I0418 16:30:54.232928  2203 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0418 16:30:54.233031  2203 net.cpp:122] Setting up map64_3_scale_a
I0418 16:30:54.233036  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.233039  2203 net.cpp:137] Memory required for data: 538445824
I0418 16:30:54.233044  2203 layer_factory.hpp:77] Creating layer map64_3_relu_a
I0418 16:30:54.233052  2203 net.cpp:84] Creating Layer map64_3_relu_a
I0418 16:30:54.233057  2203 net.cpp:406] map64_3_relu_a <- map64_3_conv_a
I0418 16:30:54.233060  2203 net.cpp:367] map64_3_relu_a -> map64_3_conv_a (in-place)
I0418 16:30:54.233214  2203 net.cpp:122] Setting up map64_3_relu_a
I0418 16:30:54.233224  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.233227  2203 net.cpp:137] Memory required for data: 540542976
I0418 16:30:54.233232  2203 layer_factory.hpp:77] Creating layer map64_3_conv_b
I0418 16:30:54.233247  2203 net.cpp:84] Creating Layer map64_3_conv_b
I0418 16:30:54.233252  2203 net.cpp:406] map64_3_conv_b <- map64_3_conv_a
I0418 16:30:54.233258  2203 net.cpp:380] map64_3_conv_b -> map64_3_conv_b
I0418 16:30:54.234800  2203 net.cpp:122] Setting up map64_3_conv_b
I0418 16:30:54.234815  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.234818  2203 net.cpp:137] Memory required for data: 542640128
I0418 16:30:54.234825  2203 layer_factory.hpp:77] Creating layer map64_3_bn_b
I0418 16:30:54.234833  2203 net.cpp:84] Creating Layer map64_3_bn_b
I0418 16:30:54.234838  2203 net.cpp:406] map64_3_bn_b <- map64_3_conv_b
I0418 16:30:54.234845  2203 net.cpp:367] map64_3_bn_b -> map64_3_conv_b (in-place)
I0418 16:30:54.235021  2203 net.cpp:122] Setting up map64_3_bn_b
I0418 16:30:54.235028  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.235031  2203 net.cpp:137] Memory required for data: 544737280
I0418 16:30:54.235038  2203 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0418 16:30:54.235045  2203 net.cpp:84] Creating Layer map64_3_scale_b
I0418 16:30:54.235049  2203 net.cpp:406] map64_3_scale_b <- map64_3_conv_b
I0418 16:30:54.235067  2203 net.cpp:367] map64_3_scale_b -> map64_3_conv_b (in-place)
I0418 16:30:54.235103  2203 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0418 16:30:54.235206  2203 net.cpp:122] Setting up map64_3_scale_b
I0418 16:30:54.235218  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.235221  2203 net.cpp:137] Memory required for data: 546834432
I0418 16:30:54.235226  2203 layer_factory.hpp:77] Creating layer map64_3_eltsum
I0418 16:30:54.235232  2203 net.cpp:84] Creating Layer map64_3_eltsum
I0418 16:30:54.235236  2203 net.cpp:406] map64_3_eltsum <- map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0418 16:30:54.235245  2203 net.cpp:406] map64_3_eltsum <- map64_3_conv_b
I0418 16:30:54.235250  2203 net.cpp:380] map64_3_eltsum -> map64_3_eltsum
I0418 16:30:54.235271  2203 net.cpp:122] Setting up map64_3_eltsum
I0418 16:30:54.235277  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.235280  2203 net.cpp:137] Memory required for data: 548931584
I0418 16:30:54.235283  2203 layer_factory.hpp:77] Creating layer map64_3_relu_after_sum
I0418 16:30:54.235288  2203 net.cpp:84] Creating Layer map64_3_relu_after_sum
I0418 16:30:54.235291  2203 net.cpp:406] map64_3_relu_after_sum <- map64_3_eltsum
I0418 16:30:54.235297  2203 net.cpp:367] map64_3_relu_after_sum -> map64_3_eltsum (in-place)
I0418 16:30:54.235455  2203 net.cpp:122] Setting up map64_3_relu_after_sum
I0418 16:30:54.235462  2203 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 16:30:54.235466  2203 net.cpp:137] Memory required for data: 551028736
I0418 16:30:54.235468  2203 layer_factory.hpp:77] Creating layer pool_global
I0418 16:30:54.235482  2203 net.cpp:84] Creating Layer pool_global
I0418 16:30:54.235486  2203 net.cpp:406] pool_global <- map64_3_eltsum
I0418 16:30:54.235491  2203 net.cpp:380] pool_global -> pool_global
I0418 16:30:54.235684  2203 net.cpp:122] Setting up pool_global
I0418 16:30:54.235692  2203 net.cpp:129] Top shape: 128 64 1 1 (8192)
I0418 16:30:54.235695  2203 net.cpp:137] Memory required for data: 551061504
I0418 16:30:54.235698  2203 layer_factory.hpp:77] Creating layer score
I0418 16:30:54.235708  2203 net.cpp:84] Creating Layer score
I0418 16:30:54.235713  2203 net.cpp:406] score <- pool_global
I0418 16:30:54.235718  2203 net.cpp:380] score -> score
I0418 16:30:54.235831  2203 net.cpp:122] Setting up score
I0418 16:30:54.235837  2203 net.cpp:129] Top shape: 128 10 (1280)
I0418 16:30:54.235841  2203 net.cpp:137] Memory required for data: 551066624
I0418 16:30:54.235846  2203 layer_factory.hpp:77] Creating layer score_score_0_split
I0418 16:30:54.235852  2203 net.cpp:84] Creating Layer score_score_0_split
I0418 16:30:54.235855  2203 net.cpp:406] score_score_0_split <- score
I0418 16:30:54.235862  2203 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0418 16:30:54.235867  2203 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0418 16:30:54.235873  2203 net.cpp:380] score_score_0_split -> score_score_0_split_2
I0418 16:30:54.235914  2203 net.cpp:122] Setting up score_score_0_split
I0418 16:30:54.235920  2203 net.cpp:129] Top shape: 128 10 (1280)
I0418 16:30:54.235922  2203 net.cpp:129] Top shape: 128 10 (1280)
I0418 16:30:54.235925  2203 net.cpp:129] Top shape: 128 10 (1280)
I0418 16:30:54.235929  2203 net.cpp:137] Memory required for data: 551081984
I0418 16:30:54.235931  2203 layer_factory.hpp:77] Creating layer loss
I0418 16:30:54.235939  2203 net.cpp:84] Creating Layer loss
I0418 16:30:54.235942  2203 net.cpp:406] loss <- score_score_0_split_0
I0418 16:30:54.235946  2203 net.cpp:406] loss <- label_data_1_split_0
I0418 16:30:54.235950  2203 net.cpp:380] loss -> loss
I0418 16:30:54.235962  2203 layer_factory.hpp:77] Creating layer loss
I0418 16:30:54.236454  2203 net.cpp:122] Setting up loss
I0418 16:30:54.236466  2203 net.cpp:129] Top shape: (1)
I0418 16:30:54.236469  2203 net.cpp:132]     with loss weight 1
I0418 16:30:54.236495  2203 net.cpp:137] Memory required for data: 551081988
I0418 16:30:54.236497  2203 layer_factory.hpp:77] Creating layer acc/top1
I0418 16:30:54.236508  2203 net.cpp:84] Creating Layer acc/top1
I0418 16:30:54.236524  2203 net.cpp:406] acc/top1 <- score_score_0_split_1
I0418 16:30:54.236529  2203 net.cpp:406] acc/top1 <- label_data_1_split_1
I0418 16:30:54.236536  2203 net.cpp:380] acc/top1 -> acctop1
I0418 16:30:54.236548  2203 net.cpp:122] Setting up acc/top1
I0418 16:30:54.236553  2203 net.cpp:129] Top shape: (1)
I0418 16:30:54.236557  2203 net.cpp:137] Memory required for data: 551081992
I0418 16:30:54.236559  2203 layer_factory.hpp:77] Creating layer acc/top5
I0418 16:30:54.236563  2203 net.cpp:84] Creating Layer acc/top5
I0418 16:30:54.236567  2203 net.cpp:406] acc/top5 <- score_score_0_split_2
I0418 16:30:54.236570  2203 net.cpp:406] acc/top5 <- label_data_1_split_2
I0418 16:30:54.236577  2203 net.cpp:380] acc/top5 -> acctop5
I0418 16:30:54.236583  2203 net.cpp:122] Setting up acc/top5
I0418 16:30:54.236588  2203 net.cpp:129] Top shape: (1)
I0418 16:30:54.236590  2203 net.cpp:137] Memory required for data: 551081996
I0418 16:30:54.236594  2203 net.cpp:200] acc/top5 does not need backward computation.
I0418 16:30:54.236598  2203 net.cpp:200] acc/top1 does not need backward computation.
I0418 16:30:54.236601  2203 net.cpp:198] loss needs backward computation.
I0418 16:30:54.236604  2203 net.cpp:198] score_score_0_split needs backward computation.
I0418 16:30:54.236608  2203 net.cpp:198] score needs backward computation.
I0418 16:30:54.236610  2203 net.cpp:198] pool_global needs backward computation.
I0418 16:30:54.236613  2203 net.cpp:198] map64_3_relu_after_sum needs backward computation.
I0418 16:30:54.236615  2203 net.cpp:198] map64_3_eltsum needs backward computation.
I0418 16:30:54.236618  2203 net.cpp:198] map64_3_scale_b needs backward computation.
I0418 16:30:54.236621  2203 net.cpp:198] map64_3_bn_b needs backward computation.
I0418 16:30:54.236624  2203 net.cpp:198] map64_3_conv_b needs backward computation.
I0418 16:30:54.236626  2203 net.cpp:198] map64_3_relu_a needs backward computation.
I0418 16:30:54.236629  2203 net.cpp:198] map64_3_scale_a needs backward computation.
I0418 16:30:54.236631  2203 net.cpp:198] map64_3_bn_a needs backward computation.
I0418 16:30:54.236634  2203 net.cpp:198] map64_3_conv_a needs backward computation.
I0418 16:30:54.236636  2203 net.cpp:198] map64_2_eltsum_map64_2_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.236639  2203 net.cpp:198] map64_2_relu_after_sum needs backward computation.
I0418 16:30:54.236642  2203 net.cpp:198] map64_2_eltsum needs backward computation.
I0418 16:30:54.236645  2203 net.cpp:198] map64_2_scale_b needs backward computation.
I0418 16:30:54.236647  2203 net.cpp:198] map64_2_bn_b needs backward computation.
I0418 16:30:54.236650  2203 net.cpp:198] map64_2_conv_b needs backward computation.
I0418 16:30:54.236652  2203 net.cpp:198] map64_2_relu_a needs backward computation.
I0418 16:30:54.236654  2203 net.cpp:198] map64_2_scale_a needs backward computation.
I0418 16:30:54.236657  2203 net.cpp:198] map64_2_bn_a needs backward computation.
I0418 16:30:54.236660  2203 net.cpp:198] map64_2_conv_a needs backward computation.
I0418 16:30:54.236661  2203 net.cpp:198] map64_1_eltsum_map64_1_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.236665  2203 net.cpp:198] map64_1_relu_after_sum needs backward computation.
I0418 16:30:54.236666  2203 net.cpp:198] map64_1_eltsum needs backward computation.
I0418 16:30:54.236668  2203 net.cpp:198] map64_1_scale_b needs backward computation.
I0418 16:30:54.236671  2203 net.cpp:198] map64_1_bn_b needs backward computation.
I0418 16:30:54.236673  2203 net.cpp:198] map64_1_conv_b needs backward computation.
I0418 16:30:54.236676  2203 net.cpp:198] map64_1_relu_a needs backward computation.
I0418 16:30:54.236678  2203 net.cpp:198] map64_1_scale_a needs backward computation.
I0418 16:30:54.236681  2203 net.cpp:198] map64_1_bn_a needs backward computation.
I0418 16:30:54.236683  2203 net.cpp:198] map64_1_conv_a needs backward computation.
I0418 16:30:54.236686  2203 net.cpp:198] map64_1_scale_proj needs backward computation.
I0418 16:30:54.236690  2203 net.cpp:198] map64_1_bn_proj needs backward computation.
I0418 16:30:54.236699  2203 net.cpp:198] map64_1_conv_proj needs backward computation.
I0418 16:30:54.236703  2203 net.cpp:198] map32_3_eltsum_map32_3_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.236706  2203 net.cpp:198] map32_3_relu_after_sum needs backward computation.
I0418 16:30:54.236709  2203 net.cpp:198] map32_3_eltsum needs backward computation.
I0418 16:30:54.236711  2203 net.cpp:198] map32_3_scale_b needs backward computation.
I0418 16:30:54.236714  2203 net.cpp:198] map32_3_bn_b needs backward computation.
I0418 16:30:54.236716  2203 net.cpp:198] map32_3_conv_b needs backward computation.
I0418 16:30:54.236719  2203 net.cpp:198] map32_3_relu_a needs backward computation.
I0418 16:30:54.236721  2203 net.cpp:198] map32_3_scale_a needs backward computation.
I0418 16:30:54.236723  2203 net.cpp:198] map32_3_bn_a needs backward computation.
I0418 16:30:54.236726  2203 net.cpp:198] map32_3_conv_a needs backward computation.
I0418 16:30:54.236728  2203 net.cpp:198] map32_2_eltsum_map32_2_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.236732  2203 net.cpp:198] map32_2_relu_after_sum needs backward computation.
I0418 16:30:54.236734  2203 net.cpp:198] map32_2_eltsum needs backward computation.
I0418 16:30:54.236737  2203 net.cpp:198] map32_2_scale_b needs backward computation.
I0418 16:30:54.236739  2203 net.cpp:198] map32_2_bn_b needs backward computation.
I0418 16:30:54.236742  2203 net.cpp:198] map32_2_conv_b needs backward computation.
I0418 16:30:54.236743  2203 net.cpp:198] map32_2_relu_a needs backward computation.
I0418 16:30:54.236747  2203 net.cpp:198] map32_2_scale_a needs backward computation.
I0418 16:30:54.236748  2203 net.cpp:198] map32_2_bn_a needs backward computation.
I0418 16:30:54.236750  2203 net.cpp:198] map32_2_conv_a needs backward computation.
I0418 16:30:54.236753  2203 net.cpp:198] map32_1_eltsum_map32_1_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.236757  2203 net.cpp:198] map32_1_relu_after_sum needs backward computation.
I0418 16:30:54.236758  2203 net.cpp:198] map32_1_eltsum needs backward computation.
I0418 16:30:54.236760  2203 net.cpp:198] map32_1_scale_b needs backward computation.
I0418 16:30:54.236765  2203 net.cpp:198] map32_1_bn_b needs backward computation.
I0418 16:30:54.236768  2203 net.cpp:198] map32_1_conv_b needs backward computation.
I0418 16:30:54.236769  2203 net.cpp:198] map32_1_relu_a needs backward computation.
I0418 16:30:54.236773  2203 net.cpp:198] map32_1_scale_a needs backward computation.
I0418 16:30:54.236774  2203 net.cpp:198] map32_1_bn_a needs backward computation.
I0418 16:30:54.236776  2203 net.cpp:198] map32_1_conv_a needs backward computation.
I0418 16:30:54.236780  2203 net.cpp:198] map32_1_scale_proj needs backward computation.
I0418 16:30:54.236783  2203 net.cpp:198] map32_1_bn_proj needs backward computation.
I0418 16:30:54.236785  2203 net.cpp:198] map32_1_conv_proj needs backward computation.
I0418 16:30:54.236788  2203 net.cpp:198] map16_3_eltsum_map16_3_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.236790  2203 net.cpp:198] map16_3_relu_after_sum needs backward computation.
I0418 16:30:54.236793  2203 net.cpp:198] map16_3_eltsum needs backward computation.
I0418 16:30:54.236795  2203 net.cpp:198] map16_3_scale_b needs backward computation.
I0418 16:30:54.236799  2203 net.cpp:198] map16_3_bn_b needs backward computation.
I0418 16:30:54.236800  2203 net.cpp:198] map16_3_conv_b needs backward computation.
I0418 16:30:54.236802  2203 net.cpp:198] map16_3_relu_a needs backward computation.
I0418 16:30:54.236805  2203 net.cpp:198] map16_3_scale_a needs backward computation.
I0418 16:30:54.236807  2203 net.cpp:198] map16_3_bn_a needs backward computation.
I0418 16:30:54.236809  2203 net.cpp:198] map16_3_conv_a needs backward computation.
I0418 16:30:54.236814  2203 net.cpp:198] map16_2_eltsum_map16_2_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.236815  2203 net.cpp:198] map16_2_relu_after_sum needs backward computation.
I0418 16:30:54.236824  2203 net.cpp:198] map16_2_eltsum needs backward computation.
I0418 16:30:54.236826  2203 net.cpp:198] map16_2_scale_b needs backward computation.
I0418 16:30:54.236829  2203 net.cpp:198] map16_2_bn_b needs backward computation.
I0418 16:30:54.236831  2203 net.cpp:198] map16_2_conv_b needs backward computation.
I0418 16:30:54.236834  2203 net.cpp:198] map16_2_relu_a needs backward computation.
I0418 16:30:54.236835  2203 net.cpp:198] map16_2_scale_a needs backward computation.
I0418 16:30:54.236838  2203 net.cpp:198] map16_2_bn_a needs backward computation.
I0418 16:30:54.236840  2203 net.cpp:198] map16_2_conv_a needs backward computation.
I0418 16:30:54.236842  2203 net.cpp:198] map16_1_eltsum_map16_1_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.236845  2203 net.cpp:198] map16_1_relu_after_sum needs backward computation.
I0418 16:30:54.236847  2203 net.cpp:198] map16_1_eltsum needs backward computation.
I0418 16:30:54.236850  2203 net.cpp:198] map16_1_scale_b needs backward computation.
I0418 16:30:54.236853  2203 net.cpp:198] map16_1_bn_b needs backward computation.
I0418 16:30:54.236855  2203 net.cpp:198] map16_1_conv_b needs backward computation.
I0418 16:30:54.236857  2203 net.cpp:198] map16_1_relu_a needs backward computation.
I0418 16:30:54.236861  2203 net.cpp:198] map16_1_scale_a needs backward computation.
I0418 16:30:54.236863  2203 net.cpp:198] map16_1_bn_a needs backward computation.
I0418 16:30:54.236865  2203 net.cpp:198] map16_1_conv_a needs backward computation.
I0418 16:30:54.236868  2203 net.cpp:198] conv1_relu_conv1_0_split needs backward computation.
I0418 16:30:54.236871  2203 net.cpp:198] relu_conv1 needs backward computation.
I0418 16:30:54.236873  2203 net.cpp:198] scale_conv1 needs backward computation.
I0418 16:30:54.236876  2203 net.cpp:198] bn_conv1 needs backward computation.
I0418 16:30:54.236878  2203 net.cpp:198] conv1 needs backward computation.
I0418 16:30:54.236881  2203 net.cpp:200] label_data_1_split does not need backward computation.
I0418 16:30:54.236886  2203 net.cpp:200] data does not need backward computation.
I0418 16:30:54.236888  2203 net.cpp:242] This network produces output acctop1
I0418 16:30:54.236891  2203 net.cpp:242] This network produces output acctop5
I0418 16:30:54.236894  2203 net.cpp:242] This network produces output loss
I0418 16:30:54.236944  2203 net.cpp:255] Network initialization done.
I0418 16:30:54.239464  2203 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet20_relu_msra_cifar10.prototxt
I0418 16:30:54.239477  2203 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0418 16:30:54.239485  2203 solver.cpp:173] Creating test net (#0) specified by net file: resnet20_relu_msra_cifar10.prototxt
I0418 16:30:54.239599  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0418 16:30:54.239609  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv1
I0418 16:30:54.239615  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_1_bn_a
I0418 16:30:54.239621  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_1_bn_b
I0418 16:30:54.239629  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_2_bn_a
I0418 16:30:54.239634  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_2_bn_b
I0418 16:30:54.239639  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_3_bn_a
I0418 16:30:54.239645  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_3_bn_b
I0418 16:30:54.239651  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_proj
I0418 16:30:54.239656  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_a
I0418 16:30:54.239673  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_b
I0418 16:30:54.239681  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_2_bn_a
I0418 16:30:54.239686  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_2_bn_b
I0418 16:30:54.239692  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_3_bn_a
I0418 16:30:54.239697  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_3_bn_b
I0418 16:30:54.239703  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_proj
I0418 16:30:54.239709  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_a
I0418 16:30:54.239714  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_b
I0418 16:30:54.239720  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_2_bn_a
I0418 16:30:54.239727  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_2_bn_b
I0418 16:30:54.239732  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_3_bn_a
I0418 16:30:54.239737  2203 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_3_bn_b
I0418 16:30:54.240180  2203 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 32
    mean_file: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/mean.binaryproto"
  }
  data_param {
    source: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_test_leveldb_copy/"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "map16_1_conv_a"
  type: "Convolution"
  bottom: "conv1"
  top: "map16_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_a"
  type: "BatchNorm"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_1_scale_a"
  type: "Scale"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_relu_a"
  type: "ReLU"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
}
layer {
  name: "map16_1_conv_b"
  type: "Convolution"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_b"
  type: "BatchNorm"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_1_scale_b"
  type: "Scale"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_eltsum"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "map16_1_conv_b"
  top: "map16_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_1_relu_after_sum"
  type: "ReLU"
  bottom: "map16_1_eltsum"
  top: "map16_1_eltsum"
}
layer {
  name: "map16_2_conv_a"
  type: "Convolution"
  bottom: "map16_1_eltsum"
  top: "map16_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_a"
  type: "BatchNorm"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_2_scale_a"
  type: "Scale"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_relu_a"
  type: "ReLU"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
}
layer {
  name: "map16_2_conv_b"
  type: "Convolution"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_b"
  type: "BatchNorm"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_2_scale_b"
  type: "Scale"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_eltsum"
  type: "Eltwise"
  bottom: "map16_1_eltsum"
  bottom: "map16_2_conv_b"
  top: "map16_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_2_relu_after_sum"
  type: "ReLU"
  bottom: "map16_2_eltsum"
  top: "map16_2_eltsum"
}
layer {
  name: "map16_3_conv_a"
  type: "Convolution"
  bottom: "map16_2_eltsum"
  top: "map16_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_a"
  type: "BatchNorm"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_3_scale_a"
  type: "Scale"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_relu_a"
  type: "ReLU"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
}
layer {
  name: "map16_3_conv_b"
  type: "Convolution"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_b"
  type: "BatchNorm"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_3_scale_b"
  type: "Scale"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_eltsum"
  type: "Eltwise"
  bottom: "map16_2_eltsum"
  bottom: "map16_3_conv_b"
  top: "map16_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_3_relu_after_sum"
  type: "ReLU"
  bottom: "map16_3_eltsum"
  top: "map16_3_eltsum"
}
layer {
  name: "map32_1_conv_proj"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_proj"
  type: "BatchNorm"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_proj"
  type: "Scale"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_conv_a"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_a"
  type: "BatchNorm"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_a"
  type: "Scale"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_relu_a"
  type: "ReLU"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
}
layer {
  name: "map32_1_conv_b"
  type: "Convolution"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_b"
  type: "BatchNorm"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_b"
  type: "Scale"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_eltsum"
  type: "Eltwise"
  bottom: "map32_1_conv_proj"
  bottom: "map32_1_conv_b"
  top: "map32_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_1_relu_after_sum"
  type: "ReLU"
  bottom: "map32_1_eltsum"
  top: "map32_1_eltsum"
}
layer {
  name: "map32_2_conv_a"
  type: "Convolution"
  bottom: "map32_1_eltsum"
  top: "map32_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_a"
  type: "BatchNorm"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_2_scale_a"
  type: "Scale"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_relu_a"
  type: "ReLU"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
}
layer {
  name: "map32_2_conv_b"
  type: "Convolution"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_b"
  type: "BatchNorm"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_2_scale_b"
  type: "Scale"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_eltsum"
  type: "Eltwise"
  bottom: "map32_1_eltsum"
  bottom: "map32_2_conv_b"
  top: "map32_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_2_relu_after_sum"
  type: "ReLU"
  bottom: "map32_2_eltsum"
  top: "map32_2_eltsum"
}
layer {
  name: "map32_3_conv_a"
  type: "Convolution"
  bottom: "map32_2_eltsum"
  top: "map32_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_a"
  type: "BatchNorm"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_3_scale_a"
  type: "Scale"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_relu_a"
  type: "ReLU"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
}
layer {
  name: "map32_3_conv_b"
  type: "Convolution"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_b"
  type: "BatchNorm"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_3_scale_b"
  type: "Scale"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_eltsum"
  type: "Eltwise"
  bottom: "map32_2_eltsum"
  bottom: "map32_3_conv_b"
  top: "map32_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_3_relu_after_sum"
  type: "ReLU"
  bottom: "map32_3_eltsum"
  top: "map32_3_eltsum"
}
layer {
  name: "map64_1_conv_proj"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_proj"
  type: "BatchNorm"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_proj"
  type: "Scale"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_conv_a"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_a"
  type: "BatchNorm"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_a"
  type: "Scale"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_relu_a"
  type: "ReLU"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
}
layer {
  name: "map64_1_conv_b"
  type: "Convolution"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_b"
  type: "BatchNorm"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_b"
  type: "Scale"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_eltsum"
  type: "Eltwise"
  bottom: "map64_1_conv_proj"
  bottom: "map64_1_conv_b"
  top: "map64_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_1_relu_after_sum"
  type: "ReLU"
  bottom: "map64_1_eltsum"
  top: "map64_1_eltsum"
}
layer {
  name: "map64_2_conv_a"
  type: "Convolution"
  bottom: "map64_1_eltsum"
  top: "map64_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_a"
  type: "BatchNorm"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_2_scale_a"
  type: "Scale"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_relu_a"
  type: "ReLU"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
}
layer {
  name: "map64_2_conv_b"
  type: "Convolution"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_b"
  type: "BatchNorm"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_2_scale_b"
  type: "Scale"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_eltsum"
  type: "Eltwise"
  bottom: "map64_1_eltsum"
  bottom: "map64_2_conv_b"
  top: "map64_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_2_relu_after_sum"
  type: "ReLU"
  bottom: "map64_2_eltsum"
  top: "map64_2_eltsum"
}
layer {
  name: "map64_3_conv_a"
  type: "Convolution"
  bottom: "map64_2_eltsum"
  top: "map64_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_a"
  type: "BatchNorm"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_3_scale_a"
  type: "Scale"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_relu_a"
  type: "ReLU"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
}
layer {
  name: "map64_3_conv_b"
  type: "Convolution"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_b"
  type: "BatchNorm"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_3_scale_b"
  type: "Scale"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_eltsum"
  type: "Eltwise"
  bottom: "map64_2_eltsum"
  bottom: "map64_3_conv_b"
  top: "map64_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_3_relu_after_sum"
  type: "ReLU"
  bottom: "map64_3_eltsum"
  top: "map64_3_eltsum"
}
layer {
  name: "pool_global"
  type: "Pooling"
  bottom: "map64_3_eltsum"
  top: "pool_global"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_global"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc/top1"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc/top5"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop5"
  accuracy_param {
    top_k: 5
  }
}
I0418 16:30:54.240528  2203 layer_factory.hpp:77] Creating layer data
I0418 16:30:54.252508  2203 db_leveldb.cpp:18] Opened leveldb /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_test_leveldb_copy/
I0418 16:30:54.276716  2203 net.cpp:84] Creating Layer data
I0418 16:30:54.276731  2203 net.cpp:380] data -> data
I0418 16:30:54.276757  2203 net.cpp:380] data -> label
I0418 16:30:54.276764  2203 data_transformer.cpp:25] Loading mean file from: /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/mean.binaryproto
I0418 16:30:54.281316  2203 data_layer.cpp:45] output data size: 100,3,32,32
I0418 16:30:54.287641  2203 net.cpp:122] Setting up data
I0418 16:30:54.287672  2203 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0418 16:30:54.287694  2203 net.cpp:129] Top shape: 100 (100)
I0418 16:30:54.287696  2203 net.cpp:137] Memory required for data: 1229200
I0418 16:30:54.287700  2203 layer_factory.hpp:77] Creating layer label_data_1_split
I0418 16:30:54.287708  2203 net.cpp:84] Creating Layer label_data_1_split
I0418 16:30:54.287714  2203 net.cpp:406] label_data_1_split <- label
I0418 16:30:54.287719  2203 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0418 16:30:54.287727  2203 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0418 16:30:54.287734  2203 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0418 16:30:54.287848  2203 net.cpp:122] Setting up label_data_1_split
I0418 16:30:54.287856  2203 net.cpp:129] Top shape: 100 (100)
I0418 16:30:54.287860  2203 net.cpp:129] Top shape: 100 (100)
I0418 16:30:54.287863  2203 net.cpp:129] Top shape: 100 (100)
I0418 16:30:54.287866  2203 net.cpp:137] Memory required for data: 1230400
I0418 16:30:54.287868  2203 layer_factory.hpp:77] Creating layer conv1
I0418 16:30:54.287879  2203 net.cpp:84] Creating Layer conv1
I0418 16:30:54.287883  2203 net.cpp:406] conv1 <- data
I0418 16:30:54.287890  2203 net.cpp:380] conv1 -> conv1
I0418 16:30:54.289314  2203 net.cpp:122] Setting up conv1
I0418 16:30:54.289326  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.289330  2203 net.cpp:137] Memory required for data: 7784000
I0418 16:30:54.289340  2203 layer_factory.hpp:77] Creating layer bn_conv1
I0418 16:30:54.289355  2203 net.cpp:84] Creating Layer bn_conv1
I0418 16:30:54.289360  2203 net.cpp:406] bn_conv1 <- conv1
I0418 16:30:54.289366  2203 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0418 16:30:54.289551  2203 net.cpp:122] Setting up bn_conv1
I0418 16:30:54.289558  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.289561  2203 net.cpp:137] Memory required for data: 14337600
I0418 16:30:54.289571  2203 layer_factory.hpp:77] Creating layer scale_conv1
I0418 16:30:54.289577  2203 net.cpp:84] Creating Layer scale_conv1
I0418 16:30:54.289582  2203 net.cpp:406] scale_conv1 <- conv1
I0418 16:30:54.289587  2203 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0418 16:30:54.289625  2203 layer_factory.hpp:77] Creating layer scale_conv1
I0418 16:30:54.289729  2203 net.cpp:122] Setting up scale_conv1
I0418 16:30:54.289738  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.289741  2203 net.cpp:137] Memory required for data: 20891200
I0418 16:30:54.289746  2203 layer_factory.hpp:77] Creating layer relu_conv1
I0418 16:30:54.289752  2203 net.cpp:84] Creating Layer relu_conv1
I0418 16:30:54.289757  2203 net.cpp:406] relu_conv1 <- conv1
I0418 16:30:54.289760  2203 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0418 16:30:54.289927  2203 net.cpp:122] Setting up relu_conv1
I0418 16:30:54.289937  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.289942  2203 net.cpp:137] Memory required for data: 27444800
I0418 16:30:54.289943  2203 layer_factory.hpp:77] Creating layer conv1_relu_conv1_0_split
I0418 16:30:54.289949  2203 net.cpp:84] Creating Layer conv1_relu_conv1_0_split
I0418 16:30:54.289965  2203 net.cpp:406] conv1_relu_conv1_0_split <- conv1
I0418 16:30:54.289970  2203 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_0
I0418 16:30:54.289978  2203 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_1
I0418 16:30:54.290020  2203 net.cpp:122] Setting up conv1_relu_conv1_0_split
I0418 16:30:54.290026  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.290030  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.290035  2203 net.cpp:137] Memory required for data: 40552000
I0418 16:30:54.290037  2203 layer_factory.hpp:77] Creating layer map16_1_conv_a
I0418 16:30:54.290046  2203 net.cpp:84] Creating Layer map16_1_conv_a
I0418 16:30:54.290050  2203 net.cpp:406] map16_1_conv_a <- conv1_relu_conv1_0_split_0
I0418 16:30:54.290057  2203 net.cpp:380] map16_1_conv_a -> map16_1_conv_a
I0418 16:30:54.291167  2203 net.cpp:122] Setting up map16_1_conv_a
I0418 16:30:54.291182  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.291185  2203 net.cpp:137] Memory required for data: 47105600
I0418 16:30:54.291193  2203 layer_factory.hpp:77] Creating layer map16_1_bn_a
I0418 16:30:54.291204  2203 net.cpp:84] Creating Layer map16_1_bn_a
I0418 16:30:54.291208  2203 net.cpp:406] map16_1_bn_a <- map16_1_conv_a
I0418 16:30:54.291216  2203 net.cpp:367] map16_1_bn_a -> map16_1_conv_a (in-place)
I0418 16:30:54.291416  2203 net.cpp:122] Setting up map16_1_bn_a
I0418 16:30:54.291424  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.291427  2203 net.cpp:137] Memory required for data: 53659200
I0418 16:30:54.291434  2203 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0418 16:30:54.291443  2203 net.cpp:84] Creating Layer map16_1_scale_a
I0418 16:30:54.291447  2203 net.cpp:406] map16_1_scale_a <- map16_1_conv_a
I0418 16:30:54.291451  2203 net.cpp:367] map16_1_scale_a -> map16_1_conv_a (in-place)
I0418 16:30:54.291491  2203 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0418 16:30:54.291596  2203 net.cpp:122] Setting up map16_1_scale_a
I0418 16:30:54.291604  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.291606  2203 net.cpp:137] Memory required for data: 60212800
I0418 16:30:54.291611  2203 layer_factory.hpp:77] Creating layer map16_1_relu_a
I0418 16:30:54.291617  2203 net.cpp:84] Creating Layer map16_1_relu_a
I0418 16:30:54.291620  2203 net.cpp:406] map16_1_relu_a <- map16_1_conv_a
I0418 16:30:54.291626  2203 net.cpp:367] map16_1_relu_a -> map16_1_conv_a (in-place)
I0418 16:30:54.291790  2203 net.cpp:122] Setting up map16_1_relu_a
I0418 16:30:54.291798  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.291801  2203 net.cpp:137] Memory required for data: 66766400
I0418 16:30:54.291805  2203 layer_factory.hpp:77] Creating layer map16_1_conv_b
I0418 16:30:54.291815  2203 net.cpp:84] Creating Layer map16_1_conv_b
I0418 16:30:54.291818  2203 net.cpp:406] map16_1_conv_b <- map16_1_conv_a
I0418 16:30:54.291826  2203 net.cpp:380] map16_1_conv_b -> map16_1_conv_b
I0418 16:30:54.292973  2203 net.cpp:122] Setting up map16_1_conv_b
I0418 16:30:54.292986  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.292990  2203 net.cpp:137] Memory required for data: 73320000
I0418 16:30:54.292996  2203 layer_factory.hpp:77] Creating layer map16_1_bn_b
I0418 16:30:54.293005  2203 net.cpp:84] Creating Layer map16_1_bn_b
I0418 16:30:54.293010  2203 net.cpp:406] map16_1_bn_b <- map16_1_conv_b
I0418 16:30:54.293015  2203 net.cpp:367] map16_1_bn_b -> map16_1_conv_b (in-place)
I0418 16:30:54.293203  2203 net.cpp:122] Setting up map16_1_bn_b
I0418 16:30:54.293211  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.293215  2203 net.cpp:137] Memory required for data: 79873600
I0418 16:30:54.293223  2203 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0418 16:30:54.293231  2203 net.cpp:84] Creating Layer map16_1_scale_b
I0418 16:30:54.293236  2203 net.cpp:406] map16_1_scale_b <- map16_1_conv_b
I0418 16:30:54.293244  2203 net.cpp:367] map16_1_scale_b -> map16_1_conv_b (in-place)
I0418 16:30:54.293305  2203 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0418 16:30:54.293411  2203 net.cpp:122] Setting up map16_1_scale_b
I0418 16:30:54.293418  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.293421  2203 net.cpp:137] Memory required for data: 86427200
I0418 16:30:54.293426  2203 layer_factory.hpp:77] Creating layer map16_1_eltsum
I0418 16:30:54.293432  2203 net.cpp:84] Creating Layer map16_1_eltsum
I0418 16:30:54.293437  2203 net.cpp:406] map16_1_eltsum <- conv1_relu_conv1_0_split_1
I0418 16:30:54.293440  2203 net.cpp:406] map16_1_eltsum <- map16_1_conv_b
I0418 16:30:54.293447  2203 net.cpp:380] map16_1_eltsum -> map16_1_eltsum
I0418 16:30:54.293470  2203 net.cpp:122] Setting up map16_1_eltsum
I0418 16:30:54.293478  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.293481  2203 net.cpp:137] Memory required for data: 92980800
I0418 16:30:54.293483  2203 layer_factory.hpp:77] Creating layer map16_1_relu_after_sum
I0418 16:30:54.293488  2203 net.cpp:84] Creating Layer map16_1_relu_after_sum
I0418 16:30:54.293491  2203 net.cpp:406] map16_1_relu_after_sum <- map16_1_eltsum
I0418 16:30:54.293495  2203 net.cpp:367] map16_1_relu_after_sum -> map16_1_eltsum (in-place)
I0418 16:30:54.293658  2203 net.cpp:122] Setting up map16_1_relu_after_sum
I0418 16:30:54.293668  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.293671  2203 net.cpp:137] Memory required for data: 99534400
I0418 16:30:54.293673  2203 layer_factory.hpp:77] Creating layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0418 16:30:54.293681  2203 net.cpp:84] Creating Layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0418 16:30:54.293684  2203 net.cpp:406] map16_1_eltsum_map16_1_relu_after_sum_0_split <- map16_1_eltsum
I0418 16:30:54.293689  2203 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0418 16:30:54.293697  2203 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0418 16:30:54.293736  2203 net.cpp:122] Setting up map16_1_eltsum_map16_1_relu_after_sum_0_split
I0418 16:30:54.293742  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.293746  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.293750  2203 net.cpp:137] Memory required for data: 112641600
I0418 16:30:54.293751  2203 layer_factory.hpp:77] Creating layer map16_2_conv_a
I0418 16:30:54.293762  2203 net.cpp:84] Creating Layer map16_2_conv_a
I0418 16:30:54.293766  2203 net.cpp:406] map16_2_conv_a <- map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0418 16:30:54.293771  2203 net.cpp:380] map16_2_conv_a -> map16_2_conv_a
I0418 16:30:54.294950  2203 net.cpp:122] Setting up map16_2_conv_a
I0418 16:30:54.294962  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.294966  2203 net.cpp:137] Memory required for data: 119195200
I0418 16:30:54.294972  2203 layer_factory.hpp:77] Creating layer map16_2_bn_a
I0418 16:30:54.294982  2203 net.cpp:84] Creating Layer map16_2_bn_a
I0418 16:30:54.294987  2203 net.cpp:406] map16_2_bn_a <- map16_2_conv_a
I0418 16:30:54.294992  2203 net.cpp:367] map16_2_bn_a -> map16_2_conv_a (in-place)
I0418 16:30:54.295205  2203 net.cpp:122] Setting up map16_2_bn_a
I0418 16:30:54.295213  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.295217  2203 net.cpp:137] Memory required for data: 125748800
I0418 16:30:54.295222  2203 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0418 16:30:54.295228  2203 net.cpp:84] Creating Layer map16_2_scale_a
I0418 16:30:54.295233  2203 net.cpp:406] map16_2_scale_a <- map16_2_conv_a
I0418 16:30:54.295243  2203 net.cpp:367] map16_2_scale_a -> map16_2_conv_a (in-place)
I0418 16:30:54.295282  2203 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0418 16:30:54.295387  2203 net.cpp:122] Setting up map16_2_scale_a
I0418 16:30:54.295402  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.295404  2203 net.cpp:137] Memory required for data: 132302400
I0418 16:30:54.295409  2203 layer_factory.hpp:77] Creating layer map16_2_relu_a
I0418 16:30:54.295431  2203 net.cpp:84] Creating Layer map16_2_relu_a
I0418 16:30:54.295435  2203 net.cpp:406] map16_2_relu_a <- map16_2_conv_a
I0418 16:30:54.295439  2203 net.cpp:367] map16_2_relu_a -> map16_2_conv_a (in-place)
I0418 16:30:54.295605  2203 net.cpp:122] Setting up map16_2_relu_a
I0418 16:30:54.295614  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.295619  2203 net.cpp:137] Memory required for data: 138856000
I0418 16:30:54.295621  2203 layer_factory.hpp:77] Creating layer map16_2_conv_b
I0418 16:30:54.295631  2203 net.cpp:84] Creating Layer map16_2_conv_b
I0418 16:30:54.295635  2203 net.cpp:406] map16_2_conv_b <- map16_2_conv_a
I0418 16:30:54.295640  2203 net.cpp:380] map16_2_conv_b -> map16_2_conv_b
I0418 16:30:54.296934  2203 net.cpp:122] Setting up map16_2_conv_b
I0418 16:30:54.296948  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.296952  2203 net.cpp:137] Memory required for data: 145409600
I0418 16:30:54.296959  2203 layer_factory.hpp:77] Creating layer map16_2_bn_b
I0418 16:30:54.296967  2203 net.cpp:84] Creating Layer map16_2_bn_b
I0418 16:30:54.296972  2203 net.cpp:406] map16_2_bn_b <- map16_2_conv_b
I0418 16:30:54.296979  2203 net.cpp:367] map16_2_bn_b -> map16_2_conv_b (in-place)
I0418 16:30:54.297168  2203 net.cpp:122] Setting up map16_2_bn_b
I0418 16:30:54.297174  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.297178  2203 net.cpp:137] Memory required for data: 151963200
I0418 16:30:54.297190  2203 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0418 16:30:54.297197  2203 net.cpp:84] Creating Layer map16_2_scale_b
I0418 16:30:54.297201  2203 net.cpp:406] map16_2_scale_b <- map16_2_conv_b
I0418 16:30:54.297205  2203 net.cpp:367] map16_2_scale_b -> map16_2_conv_b (in-place)
I0418 16:30:54.297269  2203 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0418 16:30:54.297380  2203 net.cpp:122] Setting up map16_2_scale_b
I0418 16:30:54.297387  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.297390  2203 net.cpp:137] Memory required for data: 158516800
I0418 16:30:54.297396  2203 layer_factory.hpp:77] Creating layer map16_2_eltsum
I0418 16:30:54.297402  2203 net.cpp:84] Creating Layer map16_2_eltsum
I0418 16:30:54.297406  2203 net.cpp:406] map16_2_eltsum <- map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0418 16:30:54.297410  2203 net.cpp:406] map16_2_eltsum <- map16_2_conv_b
I0418 16:30:54.297417  2203 net.cpp:380] map16_2_eltsum -> map16_2_eltsum
I0418 16:30:54.297441  2203 net.cpp:122] Setting up map16_2_eltsum
I0418 16:30:54.297446  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.297449  2203 net.cpp:137] Memory required for data: 165070400
I0418 16:30:54.297451  2203 layer_factory.hpp:77] Creating layer map16_2_relu_after_sum
I0418 16:30:54.297458  2203 net.cpp:84] Creating Layer map16_2_relu_after_sum
I0418 16:30:54.297462  2203 net.cpp:406] map16_2_relu_after_sum <- map16_2_eltsum
I0418 16:30:54.297466  2203 net.cpp:367] map16_2_relu_after_sum -> map16_2_eltsum (in-place)
I0418 16:30:54.297936  2203 net.cpp:122] Setting up map16_2_relu_after_sum
I0418 16:30:54.297948  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.297951  2203 net.cpp:137] Memory required for data: 171624000
I0418 16:30:54.297955  2203 layer_factory.hpp:77] Creating layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0418 16:30:54.297961  2203 net.cpp:84] Creating Layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0418 16:30:54.297966  2203 net.cpp:406] map16_2_eltsum_map16_2_relu_after_sum_0_split <- map16_2_eltsum
I0418 16:30:54.297971  2203 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0418 16:30:54.297981  2203 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0418 16:30:54.298023  2203 net.cpp:122] Setting up map16_2_eltsum_map16_2_relu_after_sum_0_split
I0418 16:30:54.298032  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.298058  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.298060  2203 net.cpp:137] Memory required for data: 184731200
I0418 16:30:54.298063  2203 layer_factory.hpp:77] Creating layer map16_3_conv_a
I0418 16:30:54.298074  2203 net.cpp:84] Creating Layer map16_3_conv_a
I0418 16:30:54.298079  2203 net.cpp:406] map16_3_conv_a <- map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0418 16:30:54.298084  2203 net.cpp:380] map16_3_conv_a -> map16_3_conv_a
I0418 16:30:54.298866  2203 net.cpp:122] Setting up map16_3_conv_a
I0418 16:30:54.298877  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.298880  2203 net.cpp:137] Memory required for data: 191284800
I0418 16:30:54.298887  2203 layer_factory.hpp:77] Creating layer map16_3_bn_a
I0418 16:30:54.298895  2203 net.cpp:84] Creating Layer map16_3_bn_a
I0418 16:30:54.298899  2203 net.cpp:406] map16_3_bn_a <- map16_3_conv_a
I0418 16:30:54.298904  2203 net.cpp:367] map16_3_bn_a -> map16_3_conv_a (in-place)
I0418 16:30:54.299096  2203 net.cpp:122] Setting up map16_3_bn_a
I0418 16:30:54.299103  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.299108  2203 net.cpp:137] Memory required for data: 197838400
I0418 16:30:54.299113  2203 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0418 16:30:54.299119  2203 net.cpp:84] Creating Layer map16_3_scale_a
I0418 16:30:54.299124  2203 net.cpp:406] map16_3_scale_a <- map16_3_conv_a
I0418 16:30:54.299129  2203 net.cpp:367] map16_3_scale_a -> map16_3_conv_a (in-place)
I0418 16:30:54.299173  2203 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0418 16:30:54.299293  2203 net.cpp:122] Setting up map16_3_scale_a
I0418 16:30:54.299301  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.299304  2203 net.cpp:137] Memory required for data: 204392000
I0418 16:30:54.299310  2203 layer_factory.hpp:77] Creating layer map16_3_relu_a
I0418 16:30:54.299319  2203 net.cpp:84] Creating Layer map16_3_relu_a
I0418 16:30:54.299324  2203 net.cpp:406] map16_3_relu_a <- map16_3_conv_a
I0418 16:30:54.299327  2203 net.cpp:367] map16_3_relu_a -> map16_3_conv_a (in-place)
I0418 16:30:54.300289  2203 net.cpp:122] Setting up map16_3_relu_a
I0418 16:30:54.300304  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.300308  2203 net.cpp:137] Memory required for data: 210945600
I0418 16:30:54.300312  2203 layer_factory.hpp:77] Creating layer map16_3_conv_b
I0418 16:30:54.300323  2203 net.cpp:84] Creating Layer map16_3_conv_b
I0418 16:30:54.300328  2203 net.cpp:406] map16_3_conv_b <- map16_3_conv_a
I0418 16:30:54.300335  2203 net.cpp:380] map16_3_conv_b -> map16_3_conv_b
I0418 16:30:54.301450  2203 net.cpp:122] Setting up map16_3_conv_b
I0418 16:30:54.301465  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.301468  2203 net.cpp:137] Memory required for data: 217499200
I0418 16:30:54.301476  2203 layer_factory.hpp:77] Creating layer map16_3_bn_b
I0418 16:30:54.301489  2203 net.cpp:84] Creating Layer map16_3_bn_b
I0418 16:30:54.301494  2203 net.cpp:406] map16_3_bn_b <- map16_3_conv_b
I0418 16:30:54.301499  2203 net.cpp:367] map16_3_bn_b -> map16_3_conv_b (in-place)
I0418 16:30:54.301692  2203 net.cpp:122] Setting up map16_3_bn_b
I0418 16:30:54.301700  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.301703  2203 net.cpp:137] Memory required for data: 224052800
I0418 16:30:54.301709  2203 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0418 16:30:54.301717  2203 net.cpp:84] Creating Layer map16_3_scale_b
I0418 16:30:54.301719  2203 net.cpp:406] map16_3_scale_b <- map16_3_conv_b
I0418 16:30:54.301725  2203 net.cpp:367] map16_3_scale_b -> map16_3_conv_b (in-place)
I0418 16:30:54.301766  2203 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0418 16:30:54.301877  2203 net.cpp:122] Setting up map16_3_scale_b
I0418 16:30:54.301887  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.301889  2203 net.cpp:137] Memory required for data: 230606400
I0418 16:30:54.301895  2203 layer_factory.hpp:77] Creating layer map16_3_eltsum
I0418 16:30:54.301919  2203 net.cpp:84] Creating Layer map16_3_eltsum
I0418 16:30:54.301924  2203 net.cpp:406] map16_3_eltsum <- map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0418 16:30:54.301929  2203 net.cpp:406] map16_3_eltsum <- map16_3_conv_b
I0418 16:30:54.301934  2203 net.cpp:380] map16_3_eltsum -> map16_3_eltsum
I0418 16:30:54.301964  2203 net.cpp:122] Setting up map16_3_eltsum
I0418 16:30:54.301970  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.301972  2203 net.cpp:137] Memory required for data: 237160000
I0418 16:30:54.301975  2203 layer_factory.hpp:77] Creating layer map16_3_relu_after_sum
I0418 16:30:54.301981  2203 net.cpp:84] Creating Layer map16_3_relu_after_sum
I0418 16:30:54.301985  2203 net.cpp:406] map16_3_relu_after_sum <- map16_3_eltsum
I0418 16:30:54.301990  2203 net.cpp:367] map16_3_relu_after_sum -> map16_3_eltsum (in-place)
I0418 16:30:54.302158  2203 net.cpp:122] Setting up map16_3_relu_after_sum
I0418 16:30:54.302166  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.302170  2203 net.cpp:137] Memory required for data: 243713600
I0418 16:30:54.302172  2203 layer_factory.hpp:77] Creating layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0418 16:30:54.302179  2203 net.cpp:84] Creating Layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0418 16:30:54.302183  2203 net.cpp:406] map16_3_eltsum_map16_3_relu_after_sum_0_split <- map16_3_eltsum
I0418 16:30:54.302189  2203 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0418 16:30:54.302196  2203 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0418 16:30:54.302237  2203 net.cpp:122] Setting up map16_3_eltsum_map16_3_relu_after_sum_0_split
I0418 16:30:54.302249  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.302253  2203 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 16:30:54.302255  2203 net.cpp:137] Memory required for data: 256820800
I0418 16:30:54.302259  2203 layer_factory.hpp:77] Creating layer map32_1_conv_proj
I0418 16:30:54.302268  2203 net.cpp:84] Creating Layer map32_1_conv_proj
I0418 16:30:54.302273  2203 net.cpp:406] map32_1_conv_proj <- map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0418 16:30:54.302278  2203 net.cpp:380] map32_1_conv_proj -> map32_1_conv_proj
I0418 16:30:54.303699  2203 net.cpp:122] Setting up map32_1_conv_proj
I0418 16:30:54.303712  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.303715  2203 net.cpp:137] Memory required for data: 260097600
I0418 16:30:54.303722  2203 layer_factory.hpp:77] Creating layer map32_1_bn_proj
I0418 16:30:54.303732  2203 net.cpp:84] Creating Layer map32_1_bn_proj
I0418 16:30:54.303737  2203 net.cpp:406] map32_1_bn_proj <- map32_1_conv_proj
I0418 16:30:54.303743  2203 net.cpp:367] map32_1_bn_proj -> map32_1_conv_proj (in-place)
I0418 16:30:54.303941  2203 net.cpp:122] Setting up map32_1_bn_proj
I0418 16:30:54.303948  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.303951  2203 net.cpp:137] Memory required for data: 263374400
I0418 16:30:54.303958  2203 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0418 16:30:54.303964  2203 net.cpp:84] Creating Layer map32_1_scale_proj
I0418 16:30:54.303968  2203 net.cpp:406] map32_1_scale_proj <- map32_1_conv_proj
I0418 16:30:54.303974  2203 net.cpp:367] map32_1_scale_proj -> map32_1_conv_proj (in-place)
I0418 16:30:54.304014  2203 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0418 16:30:54.304124  2203 net.cpp:122] Setting up map32_1_scale_proj
I0418 16:30:54.304136  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.304141  2203 net.cpp:137] Memory required for data: 266651200
I0418 16:30:54.304146  2203 layer_factory.hpp:77] Creating layer map32_1_conv_a
I0418 16:30:54.304157  2203 net.cpp:84] Creating Layer map32_1_conv_a
I0418 16:30:54.304160  2203 net.cpp:406] map32_1_conv_a <- map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0418 16:30:54.304167  2203 net.cpp:380] map32_1_conv_a -> map32_1_conv_a
I0418 16:30:54.305404  2203 net.cpp:122] Setting up map32_1_conv_a
I0418 16:30:54.305418  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.305421  2203 net.cpp:137] Memory required for data: 269928000
I0418 16:30:54.305428  2203 layer_factory.hpp:77] Creating layer map32_1_bn_a
I0418 16:30:54.305438  2203 net.cpp:84] Creating Layer map32_1_bn_a
I0418 16:30:54.305441  2203 net.cpp:406] map32_1_bn_a <- map32_1_conv_a
I0418 16:30:54.305449  2203 net.cpp:367] map32_1_bn_a -> map32_1_conv_a (in-place)
I0418 16:30:54.305644  2203 net.cpp:122] Setting up map32_1_bn_a
I0418 16:30:54.305650  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.305655  2203 net.cpp:137] Memory required for data: 273204800
I0418 16:30:54.305660  2203 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0418 16:30:54.305667  2203 net.cpp:84] Creating Layer map32_1_scale_a
I0418 16:30:54.305671  2203 net.cpp:406] map32_1_scale_a <- map32_1_conv_a
I0418 16:30:54.305675  2203 net.cpp:367] map32_1_scale_a -> map32_1_conv_a (in-place)
I0418 16:30:54.305717  2203 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0418 16:30:54.305829  2203 net.cpp:122] Setting up map32_1_scale_a
I0418 16:30:54.305835  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.305837  2203 net.cpp:137] Memory required for data: 276481600
I0418 16:30:54.305843  2203 layer_factory.hpp:77] Creating layer map32_1_relu_a
I0418 16:30:54.305850  2203 net.cpp:84] Creating Layer map32_1_relu_a
I0418 16:30:54.305853  2203 net.cpp:406] map32_1_relu_a <- map32_1_conv_a
I0418 16:30:54.305860  2203 net.cpp:367] map32_1_relu_a -> map32_1_conv_a (in-place)
I0418 16:30:54.306026  2203 net.cpp:122] Setting up map32_1_relu_a
I0418 16:30:54.306035  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.306040  2203 net.cpp:137] Memory required for data: 279758400
I0418 16:30:54.306042  2203 layer_factory.hpp:77] Creating layer map32_1_conv_b
I0418 16:30:54.306053  2203 net.cpp:84] Creating Layer map32_1_conv_b
I0418 16:30:54.306057  2203 net.cpp:406] map32_1_conv_b <- map32_1_conv_a
I0418 16:30:54.306066  2203 net.cpp:380] map32_1_conv_b -> map32_1_conv_b
I0418 16:30:54.307188  2203 net.cpp:122] Setting up map32_1_conv_b
I0418 16:30:54.307201  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.307204  2203 net.cpp:137] Memory required for data: 283035200
I0418 16:30:54.307224  2203 layer_factory.hpp:77] Creating layer map32_1_bn_b
I0418 16:30:54.307235  2203 net.cpp:84] Creating Layer map32_1_bn_b
I0418 16:30:54.307245  2203 net.cpp:406] map32_1_bn_b <- map32_1_conv_b
I0418 16:30:54.307251  2203 net.cpp:367] map32_1_bn_b -> map32_1_conv_b (in-place)
I0418 16:30:54.307441  2203 net.cpp:122] Setting up map32_1_bn_b
I0418 16:30:54.307448  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.307451  2203 net.cpp:137] Memory required for data: 286312000
I0418 16:30:54.307458  2203 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0418 16:30:54.307467  2203 net.cpp:84] Creating Layer map32_1_scale_b
I0418 16:30:54.307471  2203 net.cpp:406] map32_1_scale_b <- map32_1_conv_b
I0418 16:30:54.307476  2203 net.cpp:367] map32_1_scale_b -> map32_1_conv_b (in-place)
I0418 16:30:54.307518  2203 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0418 16:30:54.307627  2203 net.cpp:122] Setting up map32_1_scale_b
I0418 16:30:54.307634  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.307637  2203 net.cpp:137] Memory required for data: 289588800
I0418 16:30:54.307642  2203 layer_factory.hpp:77] Creating layer map32_1_eltsum
I0418 16:30:54.307649  2203 net.cpp:84] Creating Layer map32_1_eltsum
I0418 16:30:54.307653  2203 net.cpp:406] map32_1_eltsum <- map32_1_conv_proj
I0418 16:30:54.307657  2203 net.cpp:406] map32_1_eltsum <- map32_1_conv_b
I0418 16:30:54.307663  2203 net.cpp:380] map32_1_eltsum -> map32_1_eltsum
I0418 16:30:54.307715  2203 net.cpp:122] Setting up map32_1_eltsum
I0418 16:30:54.307724  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.307727  2203 net.cpp:137] Memory required for data: 292865600
I0418 16:30:54.307747  2203 layer_factory.hpp:77] Creating layer map32_1_relu_after_sum
I0418 16:30:54.307754  2203 net.cpp:84] Creating Layer map32_1_relu_after_sum
I0418 16:30:54.307759  2203 net.cpp:406] map32_1_relu_after_sum <- map32_1_eltsum
I0418 16:30:54.307762  2203 net.cpp:367] map32_1_relu_after_sum -> map32_1_eltsum (in-place)
I0418 16:30:54.307929  2203 net.cpp:122] Setting up map32_1_relu_after_sum
I0418 16:30:54.307942  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.307945  2203 net.cpp:137] Memory required for data: 296142400
I0418 16:30:54.307948  2203 layer_factory.hpp:77] Creating layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0418 16:30:54.307955  2203 net.cpp:84] Creating Layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0418 16:30:54.307960  2203 net.cpp:406] map32_1_eltsum_map32_1_relu_after_sum_0_split <- map32_1_eltsum
I0418 16:30:54.307965  2203 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0418 16:30:54.307971  2203 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0418 16:30:54.308014  2203 net.cpp:122] Setting up map32_1_eltsum_map32_1_relu_after_sum_0_split
I0418 16:30:54.308020  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.308024  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.308027  2203 net.cpp:137] Memory required for data: 302696000
I0418 16:30:54.308030  2203 layer_factory.hpp:77] Creating layer map32_2_conv_a
I0418 16:30:54.308039  2203 net.cpp:84] Creating Layer map32_2_conv_a
I0418 16:30:54.308043  2203 net.cpp:406] map32_2_conv_a <- map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0418 16:30:54.308050  2203 net.cpp:380] map32_2_conv_a -> map32_2_conv_a
I0418 16:30:54.309478  2203 net.cpp:122] Setting up map32_2_conv_a
I0418 16:30:54.309490  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.309494  2203 net.cpp:137] Memory required for data: 305972800
I0418 16:30:54.309500  2203 layer_factory.hpp:77] Creating layer map32_2_bn_a
I0418 16:30:54.309510  2203 net.cpp:84] Creating Layer map32_2_bn_a
I0418 16:30:54.309515  2203 net.cpp:406] map32_2_bn_a <- map32_2_conv_a
I0418 16:30:54.309520  2203 net.cpp:367] map32_2_bn_a -> map32_2_conv_a (in-place)
I0418 16:30:54.309705  2203 net.cpp:122] Setting up map32_2_bn_a
I0418 16:30:54.309712  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.309716  2203 net.cpp:137] Memory required for data: 309249600
I0418 16:30:54.309725  2203 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0418 16:30:54.309731  2203 net.cpp:84] Creating Layer map32_2_scale_a
I0418 16:30:54.309736  2203 net.cpp:406] map32_2_scale_a <- map32_2_conv_a
I0418 16:30:54.309739  2203 net.cpp:367] map32_2_scale_a -> map32_2_conv_a (in-place)
I0418 16:30:54.309782  2203 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0418 16:30:54.309890  2203 net.cpp:122] Setting up map32_2_scale_a
I0418 16:30:54.309897  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.309900  2203 net.cpp:137] Memory required for data: 312526400
I0418 16:30:54.309906  2203 layer_factory.hpp:77] Creating layer map32_2_relu_a
I0418 16:30:54.309914  2203 net.cpp:84] Creating Layer map32_2_relu_a
I0418 16:30:54.309917  2203 net.cpp:406] map32_2_relu_a <- map32_2_conv_a
I0418 16:30:54.309921  2203 net.cpp:367] map32_2_relu_a -> map32_2_conv_a (in-place)
I0418 16:30:54.310089  2203 net.cpp:122] Setting up map32_2_relu_a
I0418 16:30:54.310102  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.310106  2203 net.cpp:137] Memory required for data: 315803200
I0418 16:30:54.310108  2203 layer_factory.hpp:77] Creating layer map32_2_conv_b
I0418 16:30:54.310120  2203 net.cpp:84] Creating Layer map32_2_conv_b
I0418 16:30:54.310125  2203 net.cpp:406] map32_2_conv_b <- map32_2_conv_a
I0418 16:30:54.310130  2203 net.cpp:380] map32_2_conv_b -> map32_2_conv_b
I0418 16:30:54.311347  2203 net.cpp:122] Setting up map32_2_conv_b
I0418 16:30:54.311377  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.311379  2203 net.cpp:137] Memory required for data: 319080000
I0418 16:30:54.311386  2203 layer_factory.hpp:77] Creating layer map32_2_bn_b
I0418 16:30:54.311396  2203 net.cpp:84] Creating Layer map32_2_bn_b
I0418 16:30:54.311401  2203 net.cpp:406] map32_2_bn_b <- map32_2_conv_b
I0418 16:30:54.311408  2203 net.cpp:367] map32_2_bn_b -> map32_2_conv_b (in-place)
I0418 16:30:54.311595  2203 net.cpp:122] Setting up map32_2_bn_b
I0418 16:30:54.311604  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.311605  2203 net.cpp:137] Memory required for data: 322356800
I0418 16:30:54.311614  2203 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0418 16:30:54.311620  2203 net.cpp:84] Creating Layer map32_2_scale_b
I0418 16:30:54.311624  2203 net.cpp:406] map32_2_scale_b <- map32_2_conv_b
I0418 16:30:54.311631  2203 net.cpp:367] map32_2_scale_b -> map32_2_conv_b (in-place)
I0418 16:30:54.311672  2203 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0418 16:30:54.311789  2203 net.cpp:122] Setting up map32_2_scale_b
I0418 16:30:54.311796  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.311800  2203 net.cpp:137] Memory required for data: 325633600
I0418 16:30:54.311805  2203 layer_factory.hpp:77] Creating layer map32_2_eltsum
I0418 16:30:54.311811  2203 net.cpp:84] Creating Layer map32_2_eltsum
I0418 16:30:54.311815  2203 net.cpp:406] map32_2_eltsum <- map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0418 16:30:54.311820  2203 net.cpp:406] map32_2_eltsum <- map32_2_conv_b
I0418 16:30:54.311825  2203 net.cpp:380] map32_2_eltsum -> map32_2_eltsum
I0418 16:30:54.311847  2203 net.cpp:122] Setting up map32_2_eltsum
I0418 16:30:54.311853  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.311856  2203 net.cpp:137] Memory required for data: 328910400
I0418 16:30:54.311859  2203 layer_factory.hpp:77] Creating layer map32_2_relu_after_sum
I0418 16:30:54.311866  2203 net.cpp:84] Creating Layer map32_2_relu_after_sum
I0418 16:30:54.311868  2203 net.cpp:406] map32_2_relu_after_sum <- map32_2_eltsum
I0418 16:30:54.311874  2203 net.cpp:367] map32_2_relu_after_sum -> map32_2_eltsum (in-place)
I0418 16:30:54.312038  2203 net.cpp:122] Setting up map32_2_relu_after_sum
I0418 16:30:54.312047  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.312049  2203 net.cpp:137] Memory required for data: 332187200
I0418 16:30:54.312052  2203 layer_factory.hpp:77] Creating layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0418 16:30:54.312059  2203 net.cpp:84] Creating Layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0418 16:30:54.312065  2203 net.cpp:406] map32_2_eltsum_map32_2_relu_after_sum_0_split <- map32_2_eltsum
I0418 16:30:54.312070  2203 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0418 16:30:54.312081  2203 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0418 16:30:54.312126  2203 net.cpp:122] Setting up map32_2_eltsum_map32_2_relu_after_sum_0_split
I0418 16:30:54.312134  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.312136  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.312139  2203 net.cpp:137] Memory required for data: 338740800
I0418 16:30:54.312141  2203 layer_factory.hpp:77] Creating layer map32_3_conv_a
I0418 16:30:54.312152  2203 net.cpp:84] Creating Layer map32_3_conv_a
I0418 16:30:54.312156  2203 net.cpp:406] map32_3_conv_a <- map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0418 16:30:54.312163  2203 net.cpp:380] map32_3_conv_a -> map32_3_conv_a
I0418 16:30:54.313532  2203 net.cpp:122] Setting up map32_3_conv_a
I0418 16:30:54.313546  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.313549  2203 net.cpp:137] Memory required for data: 342017600
I0418 16:30:54.313556  2203 layer_factory.hpp:77] Creating layer map32_3_bn_a
I0418 16:30:54.313567  2203 net.cpp:84] Creating Layer map32_3_bn_a
I0418 16:30:54.313572  2203 net.cpp:406] map32_3_bn_a <- map32_3_conv_a
I0418 16:30:54.313594  2203 net.cpp:367] map32_3_bn_a -> map32_3_conv_a (in-place)
I0418 16:30:54.313782  2203 net.cpp:122] Setting up map32_3_bn_a
I0418 16:30:54.313791  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.313793  2203 net.cpp:137] Memory required for data: 345294400
I0418 16:30:54.313801  2203 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0418 16:30:54.313808  2203 net.cpp:84] Creating Layer map32_3_scale_a
I0418 16:30:54.313813  2203 net.cpp:406] map32_3_scale_a <- map32_3_conv_a
I0418 16:30:54.313817  2203 net.cpp:367] map32_3_scale_a -> map32_3_conv_a (in-place)
I0418 16:30:54.313858  2203 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0418 16:30:54.313971  2203 net.cpp:122] Setting up map32_3_scale_a
I0418 16:30:54.313978  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.313982  2203 net.cpp:137] Memory required for data: 348571200
I0418 16:30:54.313987  2203 layer_factory.hpp:77] Creating layer map32_3_relu_a
I0418 16:30:54.313993  2203 net.cpp:84] Creating Layer map32_3_relu_a
I0418 16:30:54.313997  2203 net.cpp:406] map32_3_relu_a <- map32_3_conv_a
I0418 16:30:54.314002  2203 net.cpp:367] map32_3_relu_a -> map32_3_conv_a (in-place)
I0418 16:30:54.314445  2203 net.cpp:122] Setting up map32_3_relu_a
I0418 16:30:54.314456  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.314460  2203 net.cpp:137] Memory required for data: 351848000
I0418 16:30:54.314463  2203 layer_factory.hpp:77] Creating layer map32_3_conv_b
I0418 16:30:54.314484  2203 net.cpp:84] Creating Layer map32_3_conv_b
I0418 16:30:54.314489  2203 net.cpp:406] map32_3_conv_b <- map32_3_conv_a
I0418 16:30:54.314496  2203 net.cpp:380] map32_3_conv_b -> map32_3_conv_b
I0418 16:30:54.315647  2203 net.cpp:122] Setting up map32_3_conv_b
I0418 16:30:54.315660  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.315665  2203 net.cpp:137] Memory required for data: 355124800
I0418 16:30:54.315671  2203 layer_factory.hpp:77] Creating layer map32_3_bn_b
I0418 16:30:54.315680  2203 net.cpp:84] Creating Layer map32_3_bn_b
I0418 16:30:54.315685  2203 net.cpp:406] map32_3_bn_b <- map32_3_conv_b
I0418 16:30:54.315692  2203 net.cpp:367] map32_3_bn_b -> map32_3_conv_b (in-place)
I0418 16:30:54.315882  2203 net.cpp:122] Setting up map32_3_bn_b
I0418 16:30:54.315891  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.315893  2203 net.cpp:137] Memory required for data: 358401600
I0418 16:30:54.315901  2203 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0418 16:30:54.315907  2203 net.cpp:84] Creating Layer map32_3_scale_b
I0418 16:30:54.315912  2203 net.cpp:406] map32_3_scale_b <- map32_3_conv_b
I0418 16:30:54.315915  2203 net.cpp:367] map32_3_scale_b -> map32_3_conv_b (in-place)
I0418 16:30:54.315958  2203 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0418 16:30:54.316073  2203 net.cpp:122] Setting up map32_3_scale_b
I0418 16:30:54.316081  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.316083  2203 net.cpp:137] Memory required for data: 361678400
I0418 16:30:54.316089  2203 layer_factory.hpp:77] Creating layer map32_3_eltsum
I0418 16:30:54.316097  2203 net.cpp:84] Creating Layer map32_3_eltsum
I0418 16:30:54.316100  2203 net.cpp:406] map32_3_eltsum <- map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0418 16:30:54.316105  2203 net.cpp:406] map32_3_eltsum <- map32_3_conv_b
I0418 16:30:54.316112  2203 net.cpp:380] map32_3_eltsum -> map32_3_eltsum
I0418 16:30:54.316133  2203 net.cpp:122] Setting up map32_3_eltsum
I0418 16:30:54.316138  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.316141  2203 net.cpp:137] Memory required for data: 364955200
I0418 16:30:54.316144  2203 layer_factory.hpp:77] Creating layer map32_3_relu_after_sum
I0418 16:30:54.316149  2203 net.cpp:84] Creating Layer map32_3_relu_after_sum
I0418 16:30:54.316154  2203 net.cpp:406] map32_3_relu_after_sum <- map32_3_eltsum
I0418 16:30:54.316159  2203 net.cpp:367] map32_3_relu_after_sum -> map32_3_eltsum (in-place)
I0418 16:30:54.316357  2203 net.cpp:122] Setting up map32_3_relu_after_sum
I0418 16:30:54.316366  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.316370  2203 net.cpp:137] Memory required for data: 368232000
I0418 16:30:54.316372  2203 layer_factory.hpp:77] Creating layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0418 16:30:54.316380  2203 net.cpp:84] Creating Layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0418 16:30:54.316383  2203 net.cpp:406] map32_3_eltsum_map32_3_relu_after_sum_0_split <- map32_3_eltsum
I0418 16:30:54.316390  2203 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0418 16:30:54.316396  2203 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0418 16:30:54.316438  2203 net.cpp:122] Setting up map32_3_eltsum_map32_3_relu_after_sum_0_split
I0418 16:30:54.316447  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.316450  2203 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 16:30:54.316452  2203 net.cpp:137] Memory required for data: 374785600
I0418 16:30:54.316457  2203 layer_factory.hpp:77] Creating layer map64_1_conv_proj
I0418 16:30:54.316467  2203 net.cpp:84] Creating Layer map64_1_conv_proj
I0418 16:30:54.316470  2203 net.cpp:406] map64_1_conv_proj <- map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0418 16:30:54.316475  2203 net.cpp:380] map64_1_conv_proj -> map64_1_conv_proj
I0418 16:30:54.317797  2203 net.cpp:122] Setting up map64_1_conv_proj
I0418 16:30:54.317811  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.317813  2203 net.cpp:137] Memory required for data: 376424000
I0418 16:30:54.317819  2203 layer_factory.hpp:77] Creating layer map64_1_bn_proj
I0418 16:30:54.317829  2203 net.cpp:84] Creating Layer map64_1_bn_proj
I0418 16:30:54.317834  2203 net.cpp:406] map64_1_bn_proj <- map64_1_conv_proj
I0418 16:30:54.317840  2203 net.cpp:367] map64_1_bn_proj -> map64_1_conv_proj (in-place)
I0418 16:30:54.318038  2203 net.cpp:122] Setting up map64_1_bn_proj
I0418 16:30:54.318047  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.318048  2203 net.cpp:137] Memory required for data: 378062400
I0418 16:30:54.318056  2203 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0418 16:30:54.318063  2203 net.cpp:84] Creating Layer map64_1_scale_proj
I0418 16:30:54.318066  2203 net.cpp:406] map64_1_scale_proj <- map64_1_conv_proj
I0418 16:30:54.318071  2203 net.cpp:367] map64_1_scale_proj -> map64_1_conv_proj (in-place)
I0418 16:30:54.318115  2203 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0418 16:30:54.318228  2203 net.cpp:122] Setting up map64_1_scale_proj
I0418 16:30:54.318236  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.318244  2203 net.cpp:137] Memory required for data: 379700800
I0418 16:30:54.318249  2203 layer_factory.hpp:77] Creating layer map64_1_conv_a
I0418 16:30:54.318259  2203 net.cpp:84] Creating Layer map64_1_conv_a
I0418 16:30:54.318264  2203 net.cpp:406] map64_1_conv_a <- map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0418 16:30:54.318271  2203 net.cpp:380] map64_1_conv_a -> map64_1_conv_a
I0418 16:30:54.319489  2203 net.cpp:122] Setting up map64_1_conv_a
I0418 16:30:54.319501  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.319504  2203 net.cpp:137] Memory required for data: 381339200
I0418 16:30:54.319512  2203 layer_factory.hpp:77] Creating layer map64_1_bn_a
I0418 16:30:54.319522  2203 net.cpp:84] Creating Layer map64_1_bn_a
I0418 16:30:54.319527  2203 net.cpp:406] map64_1_bn_a <- map64_1_conv_a
I0418 16:30:54.319533  2203 net.cpp:367] map64_1_bn_a -> map64_1_conv_a (in-place)
I0418 16:30:54.319730  2203 net.cpp:122] Setting up map64_1_bn_a
I0418 16:30:54.319737  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.319741  2203 net.cpp:137] Memory required for data: 382977600
I0418 16:30:54.319747  2203 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0418 16:30:54.319756  2203 net.cpp:84] Creating Layer map64_1_scale_a
I0418 16:30:54.319778  2203 net.cpp:406] map64_1_scale_a <- map64_1_conv_a
I0418 16:30:54.319784  2203 net.cpp:367] map64_1_scale_a -> map64_1_conv_a (in-place)
I0418 16:30:54.319828  2203 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0418 16:30:54.319942  2203 net.cpp:122] Setting up map64_1_scale_a
I0418 16:30:54.319949  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.319952  2203 net.cpp:137] Memory required for data: 384616000
I0418 16:30:54.319957  2203 layer_factory.hpp:77] Creating layer map64_1_relu_a
I0418 16:30:54.319963  2203 net.cpp:84] Creating Layer map64_1_relu_a
I0418 16:30:54.319967  2203 net.cpp:406] map64_1_relu_a <- map64_1_conv_a
I0418 16:30:54.319973  2203 net.cpp:367] map64_1_relu_a -> map64_1_conv_a (in-place)
I0418 16:30:54.320143  2203 net.cpp:122] Setting up map64_1_relu_a
I0418 16:30:54.320152  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.320155  2203 net.cpp:137] Memory required for data: 386254400
I0418 16:30:54.320158  2203 layer_factory.hpp:77] Creating layer map64_1_conv_b
I0418 16:30:54.320169  2203 net.cpp:84] Creating Layer map64_1_conv_b
I0418 16:30:54.320174  2203 net.cpp:406] map64_1_conv_b <- map64_1_conv_a
I0418 16:30:54.320180  2203 net.cpp:380] map64_1_conv_b -> map64_1_conv_b
I0418 16:30:54.321564  2203 net.cpp:122] Setting up map64_1_conv_b
I0418 16:30:54.321578  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.321583  2203 net.cpp:137] Memory required for data: 387892800
I0418 16:30:54.321588  2203 layer_factory.hpp:77] Creating layer map64_1_bn_b
I0418 16:30:54.321599  2203 net.cpp:84] Creating Layer map64_1_bn_b
I0418 16:30:54.321604  2203 net.cpp:406] map64_1_bn_b <- map64_1_conv_b
I0418 16:30:54.321612  2203 net.cpp:367] map64_1_bn_b -> map64_1_conv_b (in-place)
I0418 16:30:54.321807  2203 net.cpp:122] Setting up map64_1_bn_b
I0418 16:30:54.321815  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.321817  2203 net.cpp:137] Memory required for data: 389531200
I0418 16:30:54.321823  2203 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0418 16:30:54.321832  2203 net.cpp:84] Creating Layer map64_1_scale_b
I0418 16:30:54.321836  2203 net.cpp:406] map64_1_scale_b <- map64_1_conv_b
I0418 16:30:54.321841  2203 net.cpp:367] map64_1_scale_b -> map64_1_conv_b (in-place)
I0418 16:30:54.321883  2203 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0418 16:30:54.322002  2203 net.cpp:122] Setting up map64_1_scale_b
I0418 16:30:54.322008  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.322011  2203 net.cpp:137] Memory required for data: 391169600
I0418 16:30:54.322017  2203 layer_factory.hpp:77] Creating layer map64_1_eltsum
I0418 16:30:54.322026  2203 net.cpp:84] Creating Layer map64_1_eltsum
I0418 16:30:54.322029  2203 net.cpp:406] map64_1_eltsum <- map64_1_conv_proj
I0418 16:30:54.322033  2203 net.cpp:406] map64_1_eltsum <- map64_1_conv_b
I0418 16:30:54.322038  2203 net.cpp:380] map64_1_eltsum -> map64_1_eltsum
I0418 16:30:54.322065  2203 net.cpp:122] Setting up map64_1_eltsum
I0418 16:30:54.322072  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.322073  2203 net.cpp:137] Memory required for data: 392808000
I0418 16:30:54.322075  2203 layer_factory.hpp:77] Creating layer map64_1_relu_after_sum
I0418 16:30:54.322082  2203 net.cpp:84] Creating Layer map64_1_relu_after_sum
I0418 16:30:54.322085  2203 net.cpp:406] map64_1_relu_after_sum <- map64_1_eltsum
I0418 16:30:54.322090  2203 net.cpp:367] map64_1_relu_after_sum -> map64_1_eltsum (in-place)
I0418 16:30:54.322258  2203 net.cpp:122] Setting up map64_1_relu_after_sum
I0418 16:30:54.322268  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.322270  2203 net.cpp:137] Memory required for data: 394446400
I0418 16:30:54.322273  2203 layer_factory.hpp:77] Creating layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0418 16:30:54.322279  2203 net.cpp:84] Creating Layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0418 16:30:54.322283  2203 net.cpp:406] map64_1_eltsum_map64_1_relu_after_sum_0_split <- map64_1_eltsum
I0418 16:30:54.322317  2203 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0418 16:30:54.322325  2203 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0418 16:30:54.322369  2203 net.cpp:122] Setting up map64_1_eltsum_map64_1_relu_after_sum_0_split
I0418 16:30:54.322377  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.322381  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.322383  2203 net.cpp:137] Memory required for data: 397723200
I0418 16:30:54.322387  2203 layer_factory.hpp:77] Creating layer map64_2_conv_a
I0418 16:30:54.322397  2203 net.cpp:84] Creating Layer map64_2_conv_a
I0418 16:30:54.322402  2203 net.cpp:406] map64_2_conv_a <- map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0418 16:30:54.322407  2203 net.cpp:380] map64_2_conv_a -> map64_2_conv_a
I0418 16:30:54.323793  2203 net.cpp:122] Setting up map64_2_conv_a
I0418 16:30:54.323819  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.323823  2203 net.cpp:137] Memory required for data: 399361600
I0418 16:30:54.323830  2203 layer_factory.hpp:77] Creating layer map64_2_bn_a
I0418 16:30:54.323840  2203 net.cpp:84] Creating Layer map64_2_bn_a
I0418 16:30:54.323844  2203 net.cpp:406] map64_2_bn_a <- map64_2_conv_a
I0418 16:30:54.323850  2203 net.cpp:367] map64_2_bn_a -> map64_2_conv_a (in-place)
I0418 16:30:54.324048  2203 net.cpp:122] Setting up map64_2_bn_a
I0418 16:30:54.324054  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.324056  2203 net.cpp:137] Memory required for data: 401000000
I0418 16:30:54.324064  2203 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0418 16:30:54.324070  2203 net.cpp:84] Creating Layer map64_2_scale_a
I0418 16:30:54.324074  2203 net.cpp:406] map64_2_scale_a <- map64_2_conv_a
I0418 16:30:54.324079  2203 net.cpp:367] map64_2_scale_a -> map64_2_conv_a (in-place)
I0418 16:30:54.324126  2203 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0418 16:30:54.324249  2203 net.cpp:122] Setting up map64_2_scale_a
I0418 16:30:54.324256  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.324259  2203 net.cpp:137] Memory required for data: 402638400
I0418 16:30:54.324265  2203 layer_factory.hpp:77] Creating layer map64_2_relu_a
I0418 16:30:54.324271  2203 net.cpp:84] Creating Layer map64_2_relu_a
I0418 16:30:54.324275  2203 net.cpp:406] map64_2_relu_a <- map64_2_conv_a
I0418 16:30:54.324280  2203 net.cpp:367] map64_2_relu_a -> map64_2_conv_a (in-place)
I0418 16:30:54.324460  2203 net.cpp:122] Setting up map64_2_relu_a
I0418 16:30:54.324468  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.324470  2203 net.cpp:137] Memory required for data: 404276800
I0418 16:30:54.324473  2203 layer_factory.hpp:77] Creating layer map64_2_conv_b
I0418 16:30:54.324484  2203 net.cpp:84] Creating Layer map64_2_conv_b
I0418 16:30:54.324488  2203 net.cpp:406] map64_2_conv_b <- map64_2_conv_a
I0418 16:30:54.324496  2203 net.cpp:380] map64_2_conv_b -> map64_2_conv_b
I0418 16:30:54.325902  2203 net.cpp:122] Setting up map64_2_conv_b
I0418 16:30:54.325915  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.325922  2203 net.cpp:137] Memory required for data: 405915200
I0418 16:30:54.325928  2203 layer_factory.hpp:77] Creating layer map64_2_bn_b
I0418 16:30:54.325937  2203 net.cpp:84] Creating Layer map64_2_bn_b
I0418 16:30:54.325942  2203 net.cpp:406] map64_2_bn_b <- map64_2_conv_b
I0418 16:30:54.325949  2203 net.cpp:367] map64_2_bn_b -> map64_2_conv_b (in-place)
I0418 16:30:54.326145  2203 net.cpp:122] Setting up map64_2_bn_b
I0418 16:30:54.326153  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.326155  2203 net.cpp:137] Memory required for data: 407553600
I0418 16:30:54.326184  2203 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0418 16:30:54.326192  2203 net.cpp:84] Creating Layer map64_2_scale_b
I0418 16:30:54.326196  2203 net.cpp:406] map64_2_scale_b <- map64_2_conv_b
I0418 16:30:54.326200  2203 net.cpp:367] map64_2_scale_b -> map64_2_conv_b (in-place)
I0418 16:30:54.326272  2203 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0418 16:30:54.326390  2203 net.cpp:122] Setting up map64_2_scale_b
I0418 16:30:54.326397  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.326400  2203 net.cpp:137] Memory required for data: 409192000
I0418 16:30:54.326406  2203 layer_factory.hpp:77] Creating layer map64_2_eltsum
I0418 16:30:54.326412  2203 net.cpp:84] Creating Layer map64_2_eltsum
I0418 16:30:54.326416  2203 net.cpp:406] map64_2_eltsum <- map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0418 16:30:54.326422  2203 net.cpp:406] map64_2_eltsum <- map64_2_conv_b
I0418 16:30:54.326427  2203 net.cpp:380] map64_2_eltsum -> map64_2_eltsum
I0418 16:30:54.326457  2203 net.cpp:122] Setting up map64_2_eltsum
I0418 16:30:54.326462  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.326465  2203 net.cpp:137] Memory required for data: 410830400
I0418 16:30:54.326468  2203 layer_factory.hpp:77] Creating layer map64_2_relu_after_sum
I0418 16:30:54.326474  2203 net.cpp:84] Creating Layer map64_2_relu_after_sum
I0418 16:30:54.326478  2203 net.cpp:406] map64_2_relu_after_sum <- map64_2_eltsum
I0418 16:30:54.326484  2203 net.cpp:367] map64_2_relu_after_sum -> map64_2_eltsum (in-place)
I0418 16:30:54.326704  2203 net.cpp:122] Setting up map64_2_relu_after_sum
I0418 16:30:54.326714  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.326716  2203 net.cpp:137] Memory required for data: 412468800
I0418 16:30:54.326719  2203 layer_factory.hpp:77] Creating layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0418 16:30:54.326725  2203 net.cpp:84] Creating Layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0418 16:30:54.326730  2203 net.cpp:406] map64_2_eltsum_map64_2_relu_after_sum_0_split <- map64_2_eltsum
I0418 16:30:54.326736  2203 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0418 16:30:54.326743  2203 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0418 16:30:54.326794  2203 net.cpp:122] Setting up map64_2_eltsum_map64_2_relu_after_sum_0_split
I0418 16:30:54.326802  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.326807  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.326809  2203 net.cpp:137] Memory required for data: 415745600
I0418 16:30:54.326812  2203 layer_factory.hpp:77] Creating layer map64_3_conv_a
I0418 16:30:54.326824  2203 net.cpp:84] Creating Layer map64_3_conv_a
I0418 16:30:54.326828  2203 net.cpp:406] map64_3_conv_a <- map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0418 16:30:54.326835  2203 net.cpp:380] map64_3_conv_a -> map64_3_conv_a
I0418 16:30:54.328948  2203 net.cpp:122] Setting up map64_3_conv_a
I0418 16:30:54.328963  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.328965  2203 net.cpp:137] Memory required for data: 417384000
I0418 16:30:54.328972  2203 layer_factory.hpp:77] Creating layer map64_3_bn_a
I0418 16:30:54.328984  2203 net.cpp:84] Creating Layer map64_3_bn_a
I0418 16:30:54.328987  2203 net.cpp:406] map64_3_bn_a <- map64_3_conv_a
I0418 16:30:54.328994  2203 net.cpp:367] map64_3_bn_a -> map64_3_conv_a (in-place)
I0418 16:30:54.329203  2203 net.cpp:122] Setting up map64_3_bn_a
I0418 16:30:54.329211  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.329215  2203 net.cpp:137] Memory required for data: 419022400
I0418 16:30:54.329222  2203 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0418 16:30:54.329229  2203 net.cpp:84] Creating Layer map64_3_scale_a
I0418 16:30:54.329233  2203 net.cpp:406] map64_3_scale_a <- map64_3_conv_a
I0418 16:30:54.329242  2203 net.cpp:367] map64_3_scale_a -> map64_3_conv_a (in-place)
I0418 16:30:54.329286  2203 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0418 16:30:54.329406  2203 net.cpp:122] Setting up map64_3_scale_a
I0418 16:30:54.329413  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.329417  2203 net.cpp:137] Memory required for data: 420660800
I0418 16:30:54.329439  2203 layer_factory.hpp:77] Creating layer map64_3_relu_a
I0418 16:30:54.329447  2203 net.cpp:84] Creating Layer map64_3_relu_a
I0418 16:30:54.329450  2203 net.cpp:406] map64_3_relu_a <- map64_3_conv_a
I0418 16:30:54.329457  2203 net.cpp:367] map64_3_relu_a -> map64_3_conv_a (in-place)
I0418 16:30:54.329907  2203 net.cpp:122] Setting up map64_3_relu_a
I0418 16:30:54.329921  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.329926  2203 net.cpp:137] Memory required for data: 422299200
I0418 16:30:54.329928  2203 layer_factory.hpp:77] Creating layer map64_3_conv_b
I0418 16:30:54.329941  2203 net.cpp:84] Creating Layer map64_3_conv_b
I0418 16:30:54.329946  2203 net.cpp:406] map64_3_conv_b <- map64_3_conv_a
I0418 16:30:54.329953  2203 net.cpp:380] map64_3_conv_b -> map64_3_conv_b
I0418 16:30:54.331044  2203 net.cpp:122] Setting up map64_3_conv_b
I0418 16:30:54.331055  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.331058  2203 net.cpp:137] Memory required for data: 423937600
I0418 16:30:54.331064  2203 layer_factory.hpp:77] Creating layer map64_3_bn_b
I0418 16:30:54.331074  2203 net.cpp:84] Creating Layer map64_3_bn_b
I0418 16:30:54.331079  2203 net.cpp:406] map64_3_bn_b <- map64_3_conv_b
I0418 16:30:54.331085  2203 net.cpp:367] map64_3_bn_b -> map64_3_conv_b (in-place)
I0418 16:30:54.331298  2203 net.cpp:122] Setting up map64_3_bn_b
I0418 16:30:54.331307  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.331311  2203 net.cpp:137] Memory required for data: 425576000
I0418 16:30:54.331317  2203 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0418 16:30:54.331324  2203 net.cpp:84] Creating Layer map64_3_scale_b
I0418 16:30:54.331328  2203 net.cpp:406] map64_3_scale_b <- map64_3_conv_b
I0418 16:30:54.331332  2203 net.cpp:367] map64_3_scale_b -> map64_3_conv_b (in-place)
I0418 16:30:54.331377  2203 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0418 16:30:54.331490  2203 net.cpp:122] Setting up map64_3_scale_b
I0418 16:30:54.331499  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.331501  2203 net.cpp:137] Memory required for data: 427214400
I0418 16:30:54.331507  2203 layer_factory.hpp:77] Creating layer map64_3_eltsum
I0418 16:30:54.331514  2203 net.cpp:84] Creating Layer map64_3_eltsum
I0418 16:30:54.331518  2203 net.cpp:406] map64_3_eltsum <- map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0418 16:30:54.331522  2203 net.cpp:406] map64_3_eltsum <- map64_3_conv_b
I0418 16:30:54.331527  2203 net.cpp:380] map64_3_eltsum -> map64_3_eltsum
I0418 16:30:54.331555  2203 net.cpp:122] Setting up map64_3_eltsum
I0418 16:30:54.331562  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.331564  2203 net.cpp:137] Memory required for data: 428852800
I0418 16:30:54.331568  2203 layer_factory.hpp:77] Creating layer map64_3_relu_after_sum
I0418 16:30:54.331573  2203 net.cpp:84] Creating Layer map64_3_relu_after_sum
I0418 16:30:54.331576  2203 net.cpp:406] map64_3_relu_after_sum <- map64_3_eltsum
I0418 16:30:54.331586  2203 net.cpp:367] map64_3_relu_after_sum -> map64_3_eltsum (in-place)
I0418 16:30:54.332031  2203 net.cpp:122] Setting up map64_3_relu_after_sum
I0418 16:30:54.332044  2203 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 16:30:54.332047  2203 net.cpp:137] Memory required for data: 430491200
I0418 16:30:54.332051  2203 layer_factory.hpp:77] Creating layer pool_global
I0418 16:30:54.332059  2203 net.cpp:84] Creating Layer pool_global
I0418 16:30:54.332063  2203 net.cpp:406] pool_global <- map64_3_eltsum
I0418 16:30:54.332080  2203 net.cpp:380] pool_global -> pool_global
I0418 16:30:54.332285  2203 net.cpp:122] Setting up pool_global
I0418 16:30:54.332296  2203 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0418 16:30:54.332300  2203 net.cpp:137] Memory required for data: 430516800
I0418 16:30:54.332304  2203 layer_factory.hpp:77] Creating layer score
I0418 16:30:54.332311  2203 net.cpp:84] Creating Layer score
I0418 16:30:54.332315  2203 net.cpp:406] score <- pool_global
I0418 16:30:54.332324  2203 net.cpp:380] score -> score
I0418 16:30:54.332476  2203 net.cpp:122] Setting up score
I0418 16:30:54.332484  2203 net.cpp:129] Top shape: 100 10 (1000)
I0418 16:30:54.332487  2203 net.cpp:137] Memory required for data: 430520800
I0418 16:30:54.332494  2203 layer_factory.hpp:77] Creating layer score_score_0_split
I0418 16:30:54.332500  2203 net.cpp:84] Creating Layer score_score_0_split
I0418 16:30:54.332504  2203 net.cpp:406] score_score_0_split <- score
I0418 16:30:54.332510  2203 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0418 16:30:54.332516  2203 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0418 16:30:54.332523  2203 net.cpp:380] score_score_0_split -> score_score_0_split_2
I0418 16:30:54.332574  2203 net.cpp:122] Setting up score_score_0_split
I0418 16:30:54.332581  2203 net.cpp:129] Top shape: 100 10 (1000)
I0418 16:30:54.332584  2203 net.cpp:129] Top shape: 100 10 (1000)
I0418 16:30:54.332587  2203 net.cpp:129] Top shape: 100 10 (1000)
I0418 16:30:54.332589  2203 net.cpp:137] Memory required for data: 430532800
I0418 16:30:54.332592  2203 layer_factory.hpp:77] Creating layer loss
I0418 16:30:54.332598  2203 net.cpp:84] Creating Layer loss
I0418 16:30:54.332602  2203 net.cpp:406] loss <- score_score_0_split_0
I0418 16:30:54.332607  2203 net.cpp:406] loss <- label_data_1_split_0
I0418 16:30:54.332612  2203 net.cpp:380] loss -> loss
I0418 16:30:54.332622  2203 layer_factory.hpp:77] Creating layer loss
I0418 16:30:54.332875  2203 net.cpp:122] Setting up loss
I0418 16:30:54.332886  2203 net.cpp:129] Top shape: (1)
I0418 16:30:54.332890  2203 net.cpp:132]     with loss weight 1
I0418 16:30:54.332903  2203 net.cpp:137] Memory required for data: 430532804
I0418 16:30:54.332906  2203 layer_factory.hpp:77] Creating layer acc/top1
I0418 16:30:54.332913  2203 net.cpp:84] Creating Layer acc/top1
I0418 16:30:54.332917  2203 net.cpp:406] acc/top1 <- score_score_0_split_1
I0418 16:30:54.332921  2203 net.cpp:406] acc/top1 <- label_data_1_split_1
I0418 16:30:54.332926  2203 net.cpp:380] acc/top1 -> acctop1
I0418 16:30:54.332936  2203 net.cpp:122] Setting up acc/top1
I0418 16:30:54.332940  2203 net.cpp:129] Top shape: (1)
I0418 16:30:54.332942  2203 net.cpp:137] Memory required for data: 430532808
I0418 16:30:54.332945  2203 layer_factory.hpp:77] Creating layer acc/top5
I0418 16:30:54.332952  2203 net.cpp:84] Creating Layer acc/top5
I0418 16:30:54.332955  2203 net.cpp:406] acc/top5 <- score_score_0_split_2
I0418 16:30:54.332959  2203 net.cpp:406] acc/top5 <- label_data_1_split_2
I0418 16:30:54.332964  2203 net.cpp:380] acc/top5 -> acctop5
I0418 16:30:54.332972  2203 net.cpp:122] Setting up acc/top5
I0418 16:30:54.332975  2203 net.cpp:129] Top shape: (1)
I0418 16:30:54.332978  2203 net.cpp:137] Memory required for data: 430532812
I0418 16:30:54.332980  2203 net.cpp:200] acc/top5 does not need backward computation.
I0418 16:30:54.332984  2203 net.cpp:200] acc/top1 does not need backward computation.
I0418 16:30:54.332988  2203 net.cpp:198] loss needs backward computation.
I0418 16:30:54.332991  2203 net.cpp:198] score_score_0_split needs backward computation.
I0418 16:30:54.332994  2203 net.cpp:198] score needs backward computation.
I0418 16:30:54.332996  2203 net.cpp:198] pool_global needs backward computation.
I0418 16:30:54.332999  2203 net.cpp:198] map64_3_relu_after_sum needs backward computation.
I0418 16:30:54.333003  2203 net.cpp:198] map64_3_eltsum needs backward computation.
I0418 16:30:54.333005  2203 net.cpp:198] map64_3_scale_b needs backward computation.
I0418 16:30:54.333009  2203 net.cpp:198] map64_3_bn_b needs backward computation.
I0418 16:30:54.333010  2203 net.cpp:198] map64_3_conv_b needs backward computation.
I0418 16:30:54.333014  2203 net.cpp:198] map64_3_relu_a needs backward computation.
I0418 16:30:54.333016  2203 net.cpp:198] map64_3_scale_a needs backward computation.
I0418 16:30:54.333019  2203 net.cpp:198] map64_3_bn_a needs backward computation.
I0418 16:30:54.333024  2203 net.cpp:198] map64_3_conv_a needs backward computation.
I0418 16:30:54.333025  2203 net.cpp:198] map64_2_eltsum_map64_2_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.333041  2203 net.cpp:198] map64_2_relu_after_sum needs backward computation.
I0418 16:30:54.333045  2203 net.cpp:198] map64_2_eltsum needs backward computation.
I0418 16:30:54.333050  2203 net.cpp:198] map64_2_scale_b needs backward computation.
I0418 16:30:54.333052  2203 net.cpp:198] map64_2_bn_b needs backward computation.
I0418 16:30:54.333055  2203 net.cpp:198] map64_2_conv_b needs backward computation.
I0418 16:30:54.333057  2203 net.cpp:198] map64_2_relu_a needs backward computation.
I0418 16:30:54.333060  2203 net.cpp:198] map64_2_scale_a needs backward computation.
I0418 16:30:54.333063  2203 net.cpp:198] map64_2_bn_a needs backward computation.
I0418 16:30:54.333065  2203 net.cpp:198] map64_2_conv_a needs backward computation.
I0418 16:30:54.333068  2203 net.cpp:198] map64_1_eltsum_map64_1_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.333071  2203 net.cpp:198] map64_1_relu_after_sum needs backward computation.
I0418 16:30:54.333075  2203 net.cpp:198] map64_1_eltsum needs backward computation.
I0418 16:30:54.333081  2203 net.cpp:198] map64_1_scale_b needs backward computation.
I0418 16:30:54.333083  2203 net.cpp:198] map64_1_bn_b needs backward computation.
I0418 16:30:54.333086  2203 net.cpp:198] map64_1_conv_b needs backward computation.
I0418 16:30:54.333088  2203 net.cpp:198] map64_1_relu_a needs backward computation.
I0418 16:30:54.333091  2203 net.cpp:198] map64_1_scale_a needs backward computation.
I0418 16:30:54.333094  2203 net.cpp:198] map64_1_bn_a needs backward computation.
I0418 16:30:54.333097  2203 net.cpp:198] map64_1_conv_a needs backward computation.
I0418 16:30:54.333101  2203 net.cpp:198] map64_1_scale_proj needs backward computation.
I0418 16:30:54.333104  2203 net.cpp:198] map64_1_bn_proj needs backward computation.
I0418 16:30:54.333106  2203 net.cpp:198] map64_1_conv_proj needs backward computation.
I0418 16:30:54.333109  2203 net.cpp:198] map32_3_eltsum_map32_3_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.333112  2203 net.cpp:198] map32_3_relu_after_sum needs backward computation.
I0418 16:30:54.333115  2203 net.cpp:198] map32_3_eltsum needs backward computation.
I0418 16:30:54.333118  2203 net.cpp:198] map32_3_scale_b needs backward computation.
I0418 16:30:54.333122  2203 net.cpp:198] map32_3_bn_b needs backward computation.
I0418 16:30:54.333124  2203 net.cpp:198] map32_3_conv_b needs backward computation.
I0418 16:30:54.333127  2203 net.cpp:198] map32_3_relu_a needs backward computation.
I0418 16:30:54.333130  2203 net.cpp:198] map32_3_scale_a needs backward computation.
I0418 16:30:54.333133  2203 net.cpp:198] map32_3_bn_a needs backward computation.
I0418 16:30:54.333135  2203 net.cpp:198] map32_3_conv_a needs backward computation.
I0418 16:30:54.333139  2203 net.cpp:198] map32_2_eltsum_map32_2_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.333142  2203 net.cpp:198] map32_2_relu_after_sum needs backward computation.
I0418 16:30:54.333145  2203 net.cpp:198] map32_2_eltsum needs backward computation.
I0418 16:30:54.333148  2203 net.cpp:198] map32_2_scale_b needs backward computation.
I0418 16:30:54.333151  2203 net.cpp:198] map32_2_bn_b needs backward computation.
I0418 16:30:54.333153  2203 net.cpp:198] map32_2_conv_b needs backward computation.
I0418 16:30:54.333158  2203 net.cpp:198] map32_2_relu_a needs backward computation.
I0418 16:30:54.333159  2203 net.cpp:198] map32_2_scale_a needs backward computation.
I0418 16:30:54.333161  2203 net.cpp:198] map32_2_bn_a needs backward computation.
I0418 16:30:54.333163  2203 net.cpp:198] map32_2_conv_a needs backward computation.
I0418 16:30:54.333166  2203 net.cpp:198] map32_1_eltsum_map32_1_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.333170  2203 net.cpp:198] map32_1_relu_after_sum needs backward computation.
I0418 16:30:54.333173  2203 net.cpp:198] map32_1_eltsum needs backward computation.
I0418 16:30:54.333176  2203 net.cpp:198] map32_1_scale_b needs backward computation.
I0418 16:30:54.333180  2203 net.cpp:198] map32_1_bn_b needs backward computation.
I0418 16:30:54.333194  2203 net.cpp:198] map32_1_conv_b needs backward computation.
I0418 16:30:54.333197  2203 net.cpp:198] map32_1_relu_a needs backward computation.
I0418 16:30:54.333200  2203 net.cpp:198] map32_1_scale_a needs backward computation.
I0418 16:30:54.333204  2203 net.cpp:198] map32_1_bn_a needs backward computation.
I0418 16:30:54.333205  2203 net.cpp:198] map32_1_conv_a needs backward computation.
I0418 16:30:54.333209  2203 net.cpp:198] map32_1_scale_proj needs backward computation.
I0418 16:30:54.333211  2203 net.cpp:198] map32_1_bn_proj needs backward computation.
I0418 16:30:54.333214  2203 net.cpp:198] map32_1_conv_proj needs backward computation.
I0418 16:30:54.333217  2203 net.cpp:198] map16_3_eltsum_map16_3_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.333220  2203 net.cpp:198] map16_3_relu_after_sum needs backward computation.
I0418 16:30:54.333223  2203 net.cpp:198] map16_3_eltsum needs backward computation.
I0418 16:30:54.333227  2203 net.cpp:198] map16_3_scale_b needs backward computation.
I0418 16:30:54.333230  2203 net.cpp:198] map16_3_bn_b needs backward computation.
I0418 16:30:54.333233  2203 net.cpp:198] map16_3_conv_b needs backward computation.
I0418 16:30:54.333235  2203 net.cpp:198] map16_3_relu_a needs backward computation.
I0418 16:30:54.333243  2203 net.cpp:198] map16_3_scale_a needs backward computation.
I0418 16:30:54.333247  2203 net.cpp:198] map16_3_bn_a needs backward computation.
I0418 16:30:54.333250  2203 net.cpp:198] map16_3_conv_a needs backward computation.
I0418 16:30:54.333252  2203 net.cpp:198] map16_2_eltsum_map16_2_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.333256  2203 net.cpp:198] map16_2_relu_after_sum needs backward computation.
I0418 16:30:54.333258  2203 net.cpp:198] map16_2_eltsum needs backward computation.
I0418 16:30:54.333262  2203 net.cpp:198] map16_2_scale_b needs backward computation.
I0418 16:30:54.333266  2203 net.cpp:198] map16_2_bn_b needs backward computation.
I0418 16:30:54.333268  2203 net.cpp:198] map16_2_conv_b needs backward computation.
I0418 16:30:54.333271  2203 net.cpp:198] map16_2_relu_a needs backward computation.
I0418 16:30:54.333273  2203 net.cpp:198] map16_2_scale_a needs backward computation.
I0418 16:30:54.333276  2203 net.cpp:198] map16_2_bn_a needs backward computation.
I0418 16:30:54.333278  2203 net.cpp:198] map16_2_conv_a needs backward computation.
I0418 16:30:54.333281  2203 net.cpp:198] map16_1_eltsum_map16_1_relu_after_sum_0_split needs backward computation.
I0418 16:30:54.333284  2203 net.cpp:198] map16_1_relu_after_sum needs backward computation.
I0418 16:30:54.333287  2203 net.cpp:198] map16_1_eltsum needs backward computation.
I0418 16:30:54.333292  2203 net.cpp:198] map16_1_scale_b needs backward computation.
I0418 16:30:54.333294  2203 net.cpp:198] map16_1_bn_b needs backward computation.
I0418 16:30:54.333297  2203 net.cpp:198] map16_1_conv_b needs backward computation.
I0418 16:30:54.333299  2203 net.cpp:198] map16_1_relu_a needs backward computation.
I0418 16:30:54.333302  2203 net.cpp:198] map16_1_scale_a needs backward computation.
I0418 16:30:54.333305  2203 net.cpp:198] map16_1_bn_a needs backward computation.
I0418 16:30:54.333307  2203 net.cpp:198] map16_1_conv_a needs backward computation.
I0418 16:30:54.333312  2203 net.cpp:198] conv1_relu_conv1_0_split needs backward computation.
I0418 16:30:54.333315  2203 net.cpp:198] relu_conv1 needs backward computation.
I0418 16:30:54.333317  2203 net.cpp:198] scale_conv1 needs backward computation.
I0418 16:30:54.333320  2203 net.cpp:198] bn_conv1 needs backward computation.
I0418 16:30:54.333323  2203 net.cpp:198] conv1 needs backward computation.
I0418 16:30:54.333328  2203 net.cpp:200] label_data_1_split does not need backward computation.
I0418 16:30:54.333333  2203 net.cpp:200] data does not need backward computation.
I0418 16:30:54.333335  2203 net.cpp:242] This network produces output acctop1
I0418 16:30:54.333338  2203 net.cpp:242] This network produces output acctop5
I0418 16:30:54.333348  2203 net.cpp:242] This network produces output loss
I0418 16:30:54.333400  2203 net.cpp:255] Network initialization done.
I0418 16:30:54.333787  2203 solver.cpp:56] Solver scaffolding done.
I0418 16:30:54.338794  2203 caffe.cpp:248] Starting Optimization
I0418 16:30:54.338811  2203 solver.cpp:273] Solving 
I0418 16:30:54.338814  2203 solver.cpp:274] Learning Rate Policy: multistep
I0418 16:30:54.343114  2203 solver.cpp:331] Iteration 0, Testing net (#0)
I0418 16:30:56.720537  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:30:56.810645  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.1
I0418 16:30:56.810719  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.5
I0418 16:30:56.810737  2203 solver.cpp:398]     Test net output #2: loss = 87.3365 (* 1 = 87.3365 loss)
I0418 16:30:56.942926  2203 solver.cpp:219] Iteration 0 (-6.70429e-33 iter/s, 2.60387s/100 iters), loss = 2.29285
I0418 16:30:56.942989  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.15625
I0418 16:30:56.942996  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.4375
I0418 16:30:56.943004  2203 solver.cpp:238]     Train net output #2: loss = 2.29285 (* 1 = 2.29285 loss)
I0418 16:30:56.943027  2203 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0418 16:31:10.351104  2203 solver.cpp:219] Iteration 100 (7.45819 iter/s, 13.4081s/100 iters), loss = 1.70574
I0418 16:31:10.351178  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.335938
I0418 16:31:10.351187  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.867188
I0418 16:31:10.351196  2203 solver.cpp:238]     Train net output #2: loss = 1.70574 (* 1 = 1.70574 loss)
I0418 16:31:10.351204  2203 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0418 16:31:23.949461  2203 solver.cpp:219] Iteration 200 (7.35387 iter/s, 13.5983s/100 iters), loss = 1.6421
I0418 16:31:23.949664  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.367188
I0418 16:31:23.949672  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.875
I0418 16:31:23.949681  2203 solver.cpp:238]     Train net output #2: loss = 1.6421 (* 1 = 1.6421 loss)
I0418 16:31:23.949688  2203 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0418 16:31:35.770109  2203 solver.cpp:219] Iteration 300 (8.45995 iter/s, 11.8204s/100 iters), loss = 1.49296
I0418 16:31:35.770200  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.4375
I0418 16:31:35.770205  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.90625
I0418 16:31:35.770213  2203 solver.cpp:238]     Train net output #2: loss = 1.49296 (* 1 = 1.49296 loss)
I0418 16:31:35.770221  2203 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0418 16:31:49.144971  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:31:50.930080  2203 solver.cpp:219] Iteration 400 (6.59636 iter/s, 15.1599s/100 iters), loss = 1.43456
I0418 16:31:50.930186  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.539062
I0418 16:31:50.930196  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.929688
I0418 16:31:50.930207  2203 solver.cpp:238]     Train net output #2: loss = 1.43456 (* 1 = 1.43456 loss)
I0418 16:31:50.930218  2203 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0418 16:32:02.860783  2203 solver.cpp:219] Iteration 500 (8.38176 iter/s, 11.9307s/100 iters), loss = 1.16124
I0418 16:32:02.861325  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.546875
I0418 16:32:02.861333  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.96875
I0418 16:32:02.861341  2203 solver.cpp:238]     Train net output #2: loss = 1.16124 (* 1 = 1.16124 loss)
I0418 16:32:02.861348  2203 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0418 16:32:17.165877  2203 solver.cpp:219] Iteration 600 (6.99078 iter/s, 14.3046s/100 iters), loss = 1.24888
I0418 16:32:17.165966  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.5625
I0418 16:32:17.165973  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.953125
I0418 16:32:17.165982  2203 solver.cpp:238]     Train net output #2: loss = 1.24888 (* 1 = 1.24888 loss)
I0418 16:32:17.165989  2203 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0418 16:32:30.026074  2203 solver.cpp:219] Iteration 700 (7.77597 iter/s, 12.8601s/100 iters), loss = 1.15961
I0418 16:32:30.026140  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.5625
I0418 16:32:30.026146  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.953125
I0418 16:32:30.026154  2203 solver.cpp:238]     Train net output #2: loss = 1.15961 (* 1 = 1.15961 loss)
I0418 16:32:30.026161  2203 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0418 16:32:39.103571  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:32:42.332254  2203 solver.cpp:219] Iteration 800 (8.12605 iter/s, 12.3061s/100 iters), loss = 1.06459
I0418 16:32:42.332290  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.671875
I0418 16:32:42.332314  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.953125
I0418 16:32:42.332320  2203 solver.cpp:238]     Train net output #2: loss = 1.06459 (* 1 = 1.06459 loss)
I0418 16:32:42.332324  2203 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0418 16:32:56.808825  2203 solver.cpp:219] Iteration 900 (6.90769 iter/s, 14.4766s/100 iters), loss = 1.07045
I0418 16:32:56.808884  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.65625
I0418 16:32:56.808892  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0418 16:32:56.808898  2203 solver.cpp:238]     Train net output #2: loss = 1.07045 (* 1 = 1.07045 loss)
I0418 16:32:56.808904  2203 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0418 16:33:08.454207  2203 solver.cpp:331] Iteration 1000, Testing net (#0)
I0418 16:33:10.823035  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:33:10.918138  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.2094
I0418 16:33:10.918187  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.6815
I0418 16:33:10.918215  2203 solver.cpp:398]     Test net output #2: loss = 10.1502 (* 1 = 10.1502 loss)
I0418 16:33:11.030796  2203 solver.cpp:219] Iteration 1000 (7.03141 iter/s, 14.2219s/100 iters), loss = 1.02445
I0418 16:33:11.030871  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.625
I0418 16:33:11.030877  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.960938
I0418 16:33:11.030886  2203 solver.cpp:238]     Train net output #2: loss = 1.02445 (* 1 = 1.02445 loss)
I0418 16:33:11.030894  2203 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0418 16:33:26.213444  2203 solver.cpp:219] Iteration 1100 (6.5865 iter/s, 15.1826s/100 iters), loss = 1.06406
I0418 16:33:26.213527  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.664062
I0418 16:33:26.213536  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.96875
I0418 16:33:26.213546  2203 solver.cpp:238]     Train net output #2: loss = 1.06406 (* 1 = 1.06406 loss)
I0418 16:33:26.213554  2203 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0418 16:33:33.937901  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:33:37.818696  2203 solver.cpp:219] Iteration 1200 (8.61684 iter/s, 11.6052s/100 iters), loss = 0.775304
I0418 16:33:37.818783  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.710938
I0418 16:33:37.818789  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.96875
I0418 16:33:37.818796  2203 solver.cpp:238]     Train net output #2: loss = 0.775304 (* 1 = 0.775304 loss)
I0418 16:33:37.818804  2203 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0418 16:33:51.185290  2203 solver.cpp:219] Iteration 1300 (7.48139 iter/s, 13.3665s/100 iters), loss = 0.86747
I0418 16:33:51.186329  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.6875
I0418 16:33:51.186338  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.96875
I0418 16:33:51.186347  2203 solver.cpp:238]     Train net output #2: loss = 0.86747 (* 1 = 0.86747 loss)
I0418 16:33:51.186355  2203 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0418 16:34:04.700938  2203 solver.cpp:219] Iteration 1400 (7.39956 iter/s, 13.5143s/100 iters), loss = 0.746451
I0418 16:34:04.701023  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.734375
I0418 16:34:04.701030  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:34:04.701038  2203 solver.cpp:238]     Train net output #2: loss = 0.746451 (* 1 = 0.746451 loss)
I0418 16:34:04.701046  2203 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0418 16:34:16.512682  2203 solver.cpp:219] Iteration 1500 (8.46622 iter/s, 11.8117s/100 iters), loss = 0.843765
I0418 16:34:16.512768  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.648438
I0418 16:34:16.512774  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.953125
I0418 16:34:16.512783  2203 solver.cpp:238]     Train net output #2: loss = 0.843765 (* 1 = 0.843765 loss)
I0418 16:34:16.512790  2203 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0418 16:34:25.408018  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:34:31.662576  2203 solver.cpp:219] Iteration 1600 (6.60076 iter/s, 15.1498s/100 iters), loss = 0.92885
I0418 16:34:31.662673  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.65625
I0418 16:34:31.662681  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.96875
I0418 16:34:31.662689  2203 solver.cpp:238]     Train net output #2: loss = 0.92885 (* 1 = 0.92885 loss)
I0418 16:34:31.662709  2203 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0418 16:34:41.754488  2203 solver.cpp:219] Iteration 1700 (9.90897 iter/s, 10.0919s/100 iters), loss = 0.878435
I0418 16:34:41.754554  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.710938
I0418 16:34:41.754561  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.953125
I0418 16:34:41.754570  2203 solver.cpp:238]     Train net output #2: loss = 0.878435 (* 1 = 0.878435 loss)
I0418 16:34:41.754576  2203 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0418 16:34:51.827623  2203 solver.cpp:219] Iteration 1800 (9.92742 iter/s, 10.0731s/100 iters), loss = 0.850892
I0418 16:34:51.827713  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.6875
I0418 16:34:51.827721  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:34:51.827730  2203 solver.cpp:238]     Train net output #2: loss = 0.850892 (* 1 = 0.850892 loss)
I0418 16:34:51.827739  2203 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0418 16:35:01.904422  2203 solver.cpp:219] Iteration 1900 (9.92385 iter/s, 10.0767s/100 iters), loss = 0.862056
I0418 16:35:01.905306  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.6875
I0418 16:35:01.905316  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:35:01.905326  2203 solver.cpp:238]     Train net output #2: loss = 0.862056 (* 1 = 0.862056 loss)
I0418 16:35:01.905335  2203 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0418 16:35:06.847157  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:35:11.882964  2203 solver.cpp:331] Iteration 2000, Testing net (#0)
I0418 16:35:13.876287  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:35:13.957837  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.2624
I0418 16:35:13.957895  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.6967
I0418 16:35:13.957922  2203 solver.cpp:398]     Test net output #2: loss = 4.92661 (* 1 = 4.92661 loss)
I0418 16:35:14.056327  2203 solver.cpp:219] Iteration 2000 (8.22972 iter/s, 12.1511s/100 iters), loss = 0.82331
I0418 16:35:14.056416  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.710938
I0418 16:35:14.056424  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0418 16:35:14.056433  2203 solver.cpp:238]     Train net output #2: loss = 0.82331 (* 1 = 0.82331 loss)
I0418 16:35:14.056442  2203 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0418 16:35:24.128895  2203 solver.cpp:219] Iteration 2100 (9.92801 iter/s, 10.0725s/100 iters), loss = 0.560058
I0418 16:35:24.128988  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0418 16:35:24.128998  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:35:24.129006  2203 solver.cpp:238]     Train net output #2: loss = 0.560058 (* 1 = 0.560058 loss)
I0418 16:35:24.129014  2203 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0418 16:35:34.210186  2203 solver.cpp:219] Iteration 2200 (9.91943 iter/s, 10.0812s/100 iters), loss = 0.684344
I0418 16:35:34.211311  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.734375
I0418 16:35:34.211325  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:35:34.211335  2203 solver.cpp:238]     Train net output #2: loss = 0.684344 (* 1 = 0.684344 loss)
I0418 16:35:34.211345  2203 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0418 16:35:44.290593  2203 solver.cpp:219] Iteration 2300 (9.9213 iter/s, 10.0793s/100 iters), loss = 0.730958
I0418 16:35:44.290686  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.757812
I0418 16:35:44.290694  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:35:44.290704  2203 solver.cpp:238]     Train net output #2: loss = 0.730958 (* 1 = 0.730958 loss)
I0418 16:35:44.290711  2203 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0418 16:35:48.230095  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:35:54.377404  2203 solver.cpp:219] Iteration 2400 (9.91399 iter/s, 10.0868s/100 iters), loss = 0.61511
I0418 16:35:54.377496  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0418 16:35:54.377504  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:35:54.377513  2203 solver.cpp:238]     Train net output #2: loss = 0.61511 (* 1 = 0.61511 loss)
I0418 16:35:54.377522  2203 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0418 16:36:04.518537  2203 solver.cpp:219] Iteration 2500 (9.86088 iter/s, 10.1411s/100 iters), loss = 0.678284
I0418 16:36:04.519294  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.765625
I0418 16:36:04.519301  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:36:04.519310  2203 solver.cpp:238]     Train net output #2: loss = 0.678284 (* 1 = 0.678284 loss)
I0418 16:36:04.519327  2203 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0418 16:36:14.665513  2203 solver.cpp:219] Iteration 2600 (9.85585 iter/s, 10.1463s/100 iters), loss = 0.865955
I0418 16:36:14.665601  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.679688
I0418 16:36:14.665607  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0418 16:36:14.665616  2203 solver.cpp:238]     Train net output #2: loss = 0.865955 (* 1 = 0.865955 loss)
I0418 16:36:14.665623  2203 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0418 16:36:24.810686  2203 solver.cpp:219] Iteration 2700 (9.85695 iter/s, 10.1451s/100 iters), loss = 0.71575
I0418 16:36:24.810767  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.75
I0418 16:36:24.810775  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:36:24.810782  2203 solver.cpp:238]     Train net output #2: loss = 0.71575 (* 1 = 0.71575 loss)
I0418 16:36:24.810789  2203 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0418 16:36:27.853798  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:36:34.920090  2203 solver.cpp:219] Iteration 2800 (9.89181 iter/s, 10.1094s/100 iters), loss = 0.658464
I0418 16:36:34.920370  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.773438
I0418 16:36:34.920378  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:36:34.920387  2203 solver.cpp:238]     Train net output #2: loss = 0.658464 (* 1 = 0.658464 loss)
I0418 16:36:34.920394  2203 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0418 16:36:45.022112  2203 solver.cpp:219] Iteration 2900 (9.89924 iter/s, 10.1018s/100 iters), loss = 0.692433
I0418 16:36:45.022183  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0418 16:36:45.022192  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:36:45.022198  2203 solver.cpp:238]     Train net output #2: loss = 0.692433 (* 1 = 0.692433 loss)
I0418 16:36:45.022204  2203 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0418 16:36:55.029908  2203 solver.cpp:331] Iteration 3000, Testing net (#0)
I0418 16:36:57.007745  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:36:57.088495  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.6126
I0418 16:36:57.088531  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9521
I0418 16:36:57.088554  2203 solver.cpp:398]     Test net output #2: loss = 1.12605 (* 1 = 1.12605 loss)
I0418 16:36:57.187362  2203 solver.cpp:219] Iteration 3000 (8.22014 iter/s, 12.1652s/100 iters), loss = 0.620757
I0418 16:36:57.187427  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.78125
I0418 16:36:57.187434  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:36:57.187443  2203 solver.cpp:238]     Train net output #2: loss = 0.620757 (* 1 = 0.620757 loss)
I0418 16:36:57.187449  2203 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0418 16:37:07.297394  2203 solver.cpp:219] Iteration 3100 (9.89119 iter/s, 10.11s/100 iters), loss = 0.578771
I0418 16:37:07.298311  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.78125
I0418 16:37:07.298321  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:37:07.298329  2203 solver.cpp:238]     Train net output #2: loss = 0.578771 (* 1 = 0.578771 loss)
I0418 16:37:07.298336  2203 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0418 16:37:09.334659  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:37:17.443414  2203 solver.cpp:219] Iteration 3200 (9.85694 iter/s, 10.1451s/100 iters), loss = 0.59771
I0418 16:37:17.443495  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.757812
I0418 16:37:17.443501  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:37:17.443509  2203 solver.cpp:238]     Train net output #2: loss = 0.59771 (* 1 = 0.59771 loss)
I0418 16:37:17.443517  2203 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0418 16:37:27.589563  2203 solver.cpp:219] Iteration 3300 (9.85599 iter/s, 10.1461s/100 iters), loss = 0.664568
I0418 16:37:27.589643  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.742188
I0418 16:37:27.589649  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:37:27.589658  2203 solver.cpp:238]     Train net output #2: loss = 0.664568 (* 1 = 0.664568 loss)
I0418 16:37:27.589664  2203 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0418 16:37:37.736156  2203 solver.cpp:219] Iteration 3400 (9.85556 iter/s, 10.1466s/100 iters), loss = 0.610465
I0418 16:37:37.737294  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.75
I0418 16:37:37.737303  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:37:37.737310  2203 solver.cpp:238]     Train net output #2: loss = 0.610465 (* 1 = 0.610465 loss)
I0418 16:37:37.737318  2203 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0418 16:37:47.883942  2203 solver.cpp:219] Iteration 3500 (9.85543 iter/s, 10.1467s/100 iters), loss = 0.621796
I0418 16:37:47.884011  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.804688
I0418 16:37:47.884016  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:37:47.884023  2203 solver.cpp:238]     Train net output #2: loss = 0.621796 (* 1 = 0.621796 loss)
I0418 16:37:47.884030  2203 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0418 16:37:49.004431  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:37:58.031101  2203 solver.cpp:219] Iteration 3600 (9.855 iter/s, 10.1471s/100 iters), loss = 0.578351
I0418 16:37:58.031184  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.789062
I0418 16:37:58.031190  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:37:58.031199  2203 solver.cpp:238]     Train net output #2: loss = 0.578351 (* 1 = 0.578351 loss)
I0418 16:37:58.031205  2203 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0418 16:38:08.173378  2203 solver.cpp:219] Iteration 3700 (9.85976 iter/s, 10.1422s/100 iters), loss = 0.578621
I0418 16:38:08.174299  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0418 16:38:08.174307  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:38:08.174315  2203 solver.cpp:238]     Train net output #2: loss = 0.578621 (* 1 = 0.578621 loss)
I0418 16:38:08.174324  2203 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0418 16:38:18.319787  2203 solver.cpp:219] Iteration 3800 (9.85656 iter/s, 10.1455s/100 iters), loss = 0.688903
I0418 16:38:18.319874  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.757812
I0418 16:38:18.319880  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:38:18.319888  2203 solver.cpp:238]     Train net output #2: loss = 0.688903 (* 1 = 0.688903 loss)
I0418 16:38:18.319895  2203 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0418 16:38:33.714190  2203 solver.cpp:219] Iteration 3900 (6.49587 iter/s, 15.3944s/100 iters), loss = 0.568286
I0418 16:38:33.714258  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.804688
I0418 16:38:33.714264  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:38:33.714272  2203 solver.cpp:238]     Train net output #2: loss = 0.568286 (* 1 = 0.568286 loss)
I0418 16:38:33.714278  2203 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0418 16:38:34.176255  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:38:55.823807  2203 solver.cpp:331] Iteration 4000, Testing net (#0)
I0418 16:39:00.449869  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:39:00.622450  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7459
I0418 16:39:00.622512  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9788
I0418 16:39:00.622539  2203 solver.cpp:398]     Test net output #2: loss = 0.743556 (* 1 = 0.743556 loss)
I0418 16:39:00.821175  2203 solver.cpp:219] Iteration 4000 (3.68908 iter/s, 27.107s/100 iters), loss = 0.607158
I0418 16:39:00.821246  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.773438
I0418 16:39:00.821254  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:39:00.821262  2203 solver.cpp:238]     Train net output #2: loss = 0.607158 (* 1 = 0.607158 loss)
I0418 16:39:00.821270  2203 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0418 16:39:23.140007  2203 solver.cpp:219] Iteration 4100 (4.48052 iter/s, 22.3188s/100 iters), loss = 0.603245
I0418 16:39:23.140089  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.773438
I0418 16:39:23.140096  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:39:23.140105  2203 solver.cpp:238]     Train net output #2: loss = 0.603245 (* 1 = 0.603245 loss)
I0418 16:39:23.140112  2203 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0418 16:39:45.493906  2203 solver.cpp:219] Iteration 4200 (4.4739 iter/s, 22.3519s/100 iters), loss = 0.468029
I0418 16:39:45.494288  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 16:39:45.494297  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:39:45.494304  2203 solver.cpp:238]     Train net output #2: loss = 0.468029 (* 1 = 0.468029 loss)
I0418 16:39:45.494312  2203 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0418 16:40:06.115219  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:40:07.867625  2203 solver.cpp:219] Iteration 4300 (4.46994 iter/s, 22.3717s/100 iters), loss = 0.506185
I0418 16:40:07.867710  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.804688
I0418 16:40:07.867717  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:40:07.867725  2203 solver.cpp:238]     Train net output #2: loss = 0.506185 (* 1 = 0.506185 loss)
I0418 16:40:07.867733  2203 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0418 16:40:30.059191  2203 solver.cpp:219] Iteration 4400 (4.50653 iter/s, 22.19s/100 iters), loss = 0.584652
I0418 16:40:30.060315  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.765625
I0418 16:40:30.060323  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.960938
I0418 16:40:30.060331  2203 solver.cpp:238]     Train net output #2: loss = 0.584652 (* 1 = 0.584652 loss)
I0418 16:40:30.060338  2203 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0418 16:40:52.226274  2203 solver.cpp:219] Iteration 4500 (4.51161 iter/s, 22.165s/100 iters), loss = 0.38992
I0418 16:40:52.226302  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 16:40:52.226325  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:40:52.226331  2203 solver.cpp:238]     Train net output #2: loss = 0.38992 (* 1 = 0.38992 loss)
I0418 16:40:52.226336  2203 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0418 16:41:14.391890  2203 solver.cpp:219] Iteration 4600 (4.51191 iter/s, 22.1636s/100 iters), loss = 0.457522
I0418 16:41:14.392277  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0418 16:41:14.392285  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:41:14.392292  2203 solver.cpp:238]     Train net output #2: loss = 0.457522 (* 1 = 0.457522 loss)
I0418 16:41:14.392297  2203 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0418 16:41:32.792445  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:41:36.472323  2203 solver.cpp:219] Iteration 4700 (4.52932 iter/s, 22.0784s/100 iters), loss = 0.582716
I0418 16:41:36.472358  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0418 16:41:36.472363  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.96875
I0418 16:41:36.472370  2203 solver.cpp:238]     Train net output #2: loss = 0.582716 (* 1 = 0.582716 loss)
I0418 16:41:36.472374  2203 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0418 16:41:58.563266  2203 solver.cpp:219] Iteration 4800 (4.52674 iter/s, 22.091s/100 iters), loss = 0.496746
I0418 16:41:58.564290  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0418 16:41:58.564296  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:41:58.564302  2203 solver.cpp:238]     Train net output #2: loss = 0.496746 (* 1 = 0.496746 loss)
I0418 16:41:58.564307  2203 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0418 16:42:20.636947  2203 solver.cpp:219] Iteration 4900 (4.53048 iter/s, 22.0727s/100 iters), loss = 0.538195
I0418 16:42:20.636987  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.765625
I0418 16:42:20.636992  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:42:20.636998  2203 solver.cpp:238]     Train net output #2: loss = 0.538195 (* 1 = 0.538195 loss)
I0418 16:42:20.637002  2203 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0418 16:42:42.525571  2203 solver.cpp:331] Iteration 5000, Testing net (#0)
I0418 16:42:47.038416  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:42:47.254212  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.6739
I0418 16:42:47.254235  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9691
I0418 16:42:47.254262  2203 solver.cpp:398]     Test net output #2: loss = 1.01281 (* 1 = 1.01281 loss)
I0418 16:42:47.414556  2203 solver.cpp:219] Iteration 5000 (3.73474 iter/s, 26.7756s/100 iters), loss = 0.476671
I0418 16:42:47.414577  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0418 16:42:47.414599  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:42:47.414605  2203 solver.cpp:238]     Train net output #2: loss = 0.476671 (* 1 = 0.476671 loss)
I0418 16:42:47.414610  2203 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0418 16:43:03.868226  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:43:09.647462  2203 solver.cpp:219] Iteration 5100 (4.49784 iter/s, 22.2329s/100 iters), loss = 0.367731
I0418 16:43:09.647543  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 16:43:09.647550  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:43:09.647557  2203 solver.cpp:238]     Train net output #2: loss = 0.367731 (* 1 = 0.367731 loss)
I0418 16:43:09.647564  2203 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0418 16:43:31.989760  2203 solver.cpp:219] Iteration 5200 (4.47623 iter/s, 22.3402s/100 iters), loss = 0.524635
I0418 16:43:31.990332  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0418 16:43:31.990341  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:43:31.990350  2203 solver.cpp:238]     Train net output #2: loss = 0.524635 (* 1 = 0.524635 loss)
I0418 16:43:31.990356  2203 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0418 16:43:54.409487  2203 solver.cpp:219] Iteration 5300 (4.46054 iter/s, 22.4188s/100 iters), loss = 0.435884
I0418 16:43:54.409574  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 16:43:54.409580  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:43:54.409587  2203 solver.cpp:238]     Train net output #2: loss = 0.435884 (* 1 = 0.435884 loss)
I0418 16:43:54.409595  2203 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0418 16:44:16.821594  2203 solver.cpp:219] Iteration 5400 (4.4623 iter/s, 22.41s/100 iters), loss = 0.416452
I0418 16:44:16.822314  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 16:44:16.822321  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:44:16.822329  2203 solver.cpp:238]     Train net output #2: loss = 0.416452 (* 1 = 0.416452 loss)
I0418 16:44:16.822336  2203 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0418 16:44:31.298053  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:44:39.312660  2203 solver.cpp:219] Iteration 5500 (4.44634 iter/s, 22.4904s/100 iters), loss = 0.519965
I0418 16:44:39.312741  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0418 16:44:39.312748  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:44:39.312755  2203 solver.cpp:238]     Train net output #2: loss = 0.519965 (* 1 = 0.519965 loss)
I0418 16:44:39.312763  2203 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0418 16:45:01.776309  2203 solver.cpp:219] Iteration 5600 (4.45204 iter/s, 22.4616s/100 iters), loss = 0.533363
I0418 16:45:01.777312  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0418 16:45:01.777320  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:45:01.777328  2203 solver.cpp:238]     Train net output #2: loss = 0.533363 (* 1 = 0.533363 loss)
I0418 16:45:01.777334  2203 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0418 16:45:24.222807  2203 solver.cpp:219] Iteration 5700 (4.45546 iter/s, 22.4444s/100 iters), loss = 0.534626
I0418 16:45:24.222873  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0418 16:45:24.222880  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:45:24.222887  2203 solver.cpp:238]     Train net output #2: loss = 0.534626 (* 1 = 0.534626 loss)
I0418 16:45:24.222894  2203 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0418 16:45:46.550110  2203 solver.cpp:219] Iteration 5800 (4.47923 iter/s, 22.3253s/100 iters), loss = 0.533918
I0418 16:45:46.550290  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0418 16:45:46.550297  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:45:46.550304  2203 solver.cpp:238]     Train net output #2: loss = 0.533918 (* 1 = 0.533918 loss)
I0418 16:45:46.550312  2203 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0418 16:45:58.794651  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:46:08.723582  2203 solver.cpp:219] Iteration 5900 (4.51033 iter/s, 22.1713s/100 iters), loss = 0.444364
I0418 16:46:08.723654  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 16:46:08.723660  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:46:08.723667  2203 solver.cpp:238]     Train net output #2: loss = 0.444364 (* 1 = 0.444364 loss)
I0418 16:46:08.723675  2203 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0418 16:46:30.754057  2203 solver.cpp:331] Iteration 6000, Testing net (#0)
I0418 16:46:35.296968  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:46:35.467931  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7035
I0418 16:46:35.467988  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9628
I0418 16:46:35.468014  2203 solver.cpp:398]     Test net output #2: loss = 0.97881 (* 1 = 0.97881 loss)
I0418 16:46:35.670061  2203 solver.cpp:219] Iteration 6000 (3.71105 iter/s, 26.9465s/100 iters), loss = 0.449358
I0418 16:46:35.670141  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 16:46:35.670148  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:46:35.670157  2203 solver.cpp:238]     Train net output #2: loss = 0.449358 (* 1 = 0.449358 loss)
I0418 16:46:35.670166  2203 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0418 16:46:57.940481  2203 solver.cpp:219] Iteration 6100 (4.49026 iter/s, 22.2704s/100 iters), loss = 0.549606
I0418 16:46:57.940570  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0418 16:46:57.940577  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:46:57.940585  2203 solver.cpp:238]     Train net output #2: loss = 0.549606 (* 1 = 0.549606 loss)
I0418 16:46:57.940593  2203 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0418 16:47:20.338726  2203 solver.cpp:219] Iteration 6200 (4.46506 iter/s, 22.3961s/100 iters), loss = 0.532182
I0418 16:47:20.343467  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0418 16:47:20.343484  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:47:20.343493  2203 solver.cpp:238]     Train net output #2: loss = 0.532182 (* 1 = 0.532182 loss)
I0418 16:47:20.343502  2203 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0418 16:47:30.491672  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:47:42.798545  2203 solver.cpp:219] Iteration 6300 (4.45339 iter/s, 22.4548s/100 iters), loss = 0.432679
I0418 16:47:42.798637  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 16:47:42.798643  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:47:42.798651  2203 solver.cpp:238]     Train net output #2: loss = 0.432679 (* 1 = 0.432679 loss)
I0418 16:47:42.798660  2203 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0418 16:48:05.235484  2203 solver.cpp:219] Iteration 6400 (4.45735 iter/s, 22.4349s/100 iters), loss = 0.451646
I0418 16:48:05.236330  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 16:48:05.236343  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:48:05.236351  2203 solver.cpp:238]     Train net output #2: loss = 0.451646 (* 1 = 0.451646 loss)
I0418 16:48:05.236361  2203 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0418 16:48:27.444617  2203 solver.cpp:219] Iteration 6500 (4.50307 iter/s, 22.2071s/100 iters), loss = 0.459437
I0418 16:48:27.444691  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0418 16:48:27.444699  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:48:27.444706  2203 solver.cpp:238]     Train net output #2: loss = 0.459437 (* 1 = 0.459437 loss)
I0418 16:48:27.444713  2203 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0418 16:48:49.594514  2203 solver.cpp:219] Iteration 6600 (4.51469 iter/s, 22.1499s/100 iters), loss = 0.53133
I0418 16:48:49.595290  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0418 16:48:49.595297  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:48:49.595304  2203 solver.cpp:238]     Train net output #2: loss = 0.53133 (* 1 = 0.53133 loss)
I0418 16:48:49.595309  2203 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0418 16:48:57.617900  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:49:11.762516  2203 solver.cpp:219] Iteration 6700 (4.51144 iter/s, 22.1659s/100 iters), loss = 0.430812
I0418 16:49:11.762543  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0418 16:49:11.762565  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:49:11.762573  2203 solver.cpp:238]     Train net output #2: loss = 0.430812 (* 1 = 0.430812 loss)
I0418 16:49:11.762576  2203 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0418 16:49:33.935374  2203 solver.cpp:219] Iteration 6800 (4.51044 iter/s, 22.1708s/100 iters), loss = 0.367577
I0418 16:49:33.936305  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 16:49:33.936312  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:49:33.936318  2203 solver.cpp:238]     Train net output #2: loss = 0.367577 (* 1 = 0.367577 loss)
I0418 16:49:33.936323  2203 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0418 16:49:56.104676  2203 solver.cpp:219] Iteration 6900 (4.51116 iter/s, 22.1672s/100 iters), loss = 0.610834
I0418 16:49:56.104730  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.789062
I0418 16:49:56.104737  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:49:56.104743  2203 solver.cpp:238]     Train net output #2: loss = 0.610834 (* 1 = 0.610834 loss)
I0418 16:49:56.104746  2203 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0418 16:50:18.084520  2203 solver.cpp:331] Iteration 7000, Testing net (#0)
I0418 16:50:22.672608  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:50:22.853812  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7351
I0418 16:50:22.853837  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9793
I0418 16:50:22.853860  2203 solver.cpp:398]     Test net output #2: loss = 0.854027 (* 1 = 0.854027 loss)
I0418 16:50:23.052265  2203 solver.cpp:219] Iteration 7000 (3.7112 iter/s, 26.9455s/100 iters), loss = 0.455033
I0418 16:50:23.052289  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0418 16:50:23.052310  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:50:23.052316  2203 solver.cpp:238]     Train net output #2: loss = 0.455033 (* 1 = 0.455033 loss)
I0418 16:50:23.052322  2203 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0418 16:50:29.176359  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:50:45.301647  2203 solver.cpp:219] Iteration 7100 (4.49456 iter/s, 22.2491s/100 iters), loss = 0.4083
I0418 16:50:45.301700  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 16:50:45.301707  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:50:45.301712  2203 solver.cpp:238]     Train net output #2: loss = 0.4083 (* 1 = 0.4083 loss)
I0418 16:50:45.301717  2203 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0418 16:51:07.455373  2203 solver.cpp:219] Iteration 7200 (4.51435 iter/s, 22.1516s/100 iters), loss = 0.452471
I0418 16:51:07.456315  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 16:51:07.456321  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:51:07.456327  2203 solver.cpp:238]     Train net output #2: loss = 0.452471 (* 1 = 0.452471 loss)
I0418 16:51:07.456331  2203 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0418 16:51:29.661625  2203 solver.cpp:219] Iteration 7300 (4.50365 iter/s, 22.2042s/100 iters), loss = 0.429455
I0418 16:51:29.661679  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 16:51:29.661684  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:51:29.661690  2203 solver.cpp:238]     Train net output #2: loss = 0.429455 (* 1 = 0.429455 loss)
I0418 16:51:29.661695  2203 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0418 16:51:51.775288  2203 solver.cpp:219] Iteration 7400 (4.52209 iter/s, 22.1137s/100 iters), loss = 0.374731
I0418 16:51:51.776295  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 16:51:51.776302  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:51:51.776309  2203 solver.cpp:238]     Train net output #2: loss = 0.374731 (* 1 = 0.374731 loss)
I0418 16:51:51.776315  2203 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0418 16:51:55.589553  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:52:13.934469  2203 solver.cpp:219] Iteration 7500 (4.51307 iter/s, 22.1578s/100 iters), loss = 0.297218
I0418 16:52:13.934504  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 16:52:13.934525  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:52:13.934531  2203 solver.cpp:238]     Train net output #2: loss = 0.297218 (* 1 = 0.297218 loss)
I0418 16:52:13.934535  2203 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0418 16:52:36.148169  2203 solver.cpp:219] Iteration 7600 (4.50216 iter/s, 22.2116s/100 iters), loss = 0.470366
I0418 16:52:36.149297  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 16:52:36.149305  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:52:36.149312  2203 solver.cpp:238]     Train net output #2: loss = 0.470366 (* 1 = 0.470366 loss)
I0418 16:52:36.149317  2203 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0418 16:52:58.300150  2203 solver.cpp:219] Iteration 7700 (4.51471 iter/s, 22.1498s/100 iters), loss = 0.308878
I0418 16:52:58.300204  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 16:52:58.300211  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:52:58.300217  2203 solver.cpp:238]     Train net output #2: loss = 0.308878 (* 1 = 0.308878 loss)
I0418 16:52:58.300222  2203 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0418 16:53:20.476024  2203 solver.cpp:219] Iteration 7800 (4.5094 iter/s, 22.1759s/100 iters), loss = 0.371185
I0418 16:53:20.476271  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 16:53:20.476279  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:53:20.476285  2203 solver.cpp:238]     Train net output #2: loss = 0.371185 (* 1 = 0.371185 loss)
I0418 16:53:20.476289  2203 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0418 16:53:22.301669  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:53:42.643292  2203 solver.cpp:219] Iteration 7900 (4.51119 iter/s, 22.1671s/100 iters), loss = 0.380552
I0418 16:53:42.643348  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 16:53:42.643354  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:53:42.643362  2203 solver.cpp:238]     Train net output #2: loss = 0.380552 (* 1 = 0.380552 loss)
I0418 16:53:42.643365  2203 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0418 16:54:04.621696  2203 solver.cpp:331] Iteration 8000, Testing net (#0)
I0418 16:54:09.182766  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:54:09.353863  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7413
I0418 16:54:09.353888  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9812
I0418 16:54:09.353911  2203 solver.cpp:398]     Test net output #2: loss = 0.803769 (* 1 = 0.803769 loss)
I0418 16:54:09.552966  2203 solver.cpp:219] Iteration 8000 (3.71642 iter/s, 26.9076s/100 iters), loss = 0.343548
I0418 16:54:09.552987  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 16:54:09.553009  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:54:09.553014  2203 solver.cpp:238]     Train net output #2: loss = 0.343548 (* 1 = 0.343548 loss)
I0418 16:54:09.553020  2203 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0418 16:54:31.719723  2203 solver.cpp:219] Iteration 8100 (4.51126 iter/s, 22.1668s/100 iters), loss = 0.4508
I0418 16:54:31.719779  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0418 16:54:31.719785  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:54:31.719791  2203 solver.cpp:238]     Train net output #2: loss = 0.4508 (* 1 = 0.4508 loss)
I0418 16:54:31.719796  2203 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0418 16:54:53.696548  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:54:53.901620  2203 solver.cpp:219] Iteration 8200 (4.50817 iter/s, 22.1819s/100 iters), loss = 0.363289
I0418 16:54:53.901662  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 16:54:53.901667  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:54:53.901674  2203 solver.cpp:238]     Train net output #2: loss = 0.363289 (* 1 = 0.363289 loss)
I0418 16:54:53.901679  2203 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0418 16:55:16.057126  2203 solver.cpp:219] Iteration 8300 (4.51397 iter/s, 22.1534s/100 iters), loss = 0.388125
I0418 16:55:16.057181  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 16:55:16.057188  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:55:16.057195  2203 solver.cpp:238]     Train net output #2: loss = 0.388125 (* 1 = 0.388125 loss)
I0418 16:55:16.057199  2203 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0418 16:55:38.200122  2203 solver.cpp:219] Iteration 8400 (4.51652 iter/s, 22.1409s/100 iters), loss = 0.610644
I0418 16:55:38.201364  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0418 16:55:38.201390  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:55:38.201398  2203 solver.cpp:238]     Train net output #2: loss = 0.610644 (* 1 = 0.610644 loss)
I0418 16:55:38.201407  2203 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0418 16:56:00.343848  2203 solver.cpp:219] Iteration 8500 (4.51639 iter/s, 22.1416s/100 iters), loss = 0.605735
I0418 16:56:00.343888  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0418 16:56:00.343894  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0418 16:56:00.343901  2203 solver.cpp:238]     Train net output #2: loss = 0.605735 (* 1 = 0.605735 loss)
I0418 16:56:00.343905  2203 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0418 16:56:19.982800  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:56:22.370177  2203 solver.cpp:219] Iteration 8600 (4.54045 iter/s, 22.0243s/100 iters), loss = 0.478415
I0418 16:56:22.370219  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0418 16:56:22.370224  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:56:22.370230  2203 solver.cpp:238]     Train net output #2: loss = 0.478415 (* 1 = 0.478415 loss)
I0418 16:56:22.370235  2203 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0418 16:56:44.416335  2203 solver.cpp:219] Iteration 8700 (4.53636 iter/s, 22.0441s/100 iters), loss = 0.572375
I0418 16:56:44.416369  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.789062
I0418 16:56:44.416374  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:56:44.416380  2203 solver.cpp:238]     Train net output #2: loss = 0.572375 (* 1 = 0.572375 loss)
I0418 16:56:44.416384  2203 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0418 16:57:06.513486  2203 solver.cpp:219] Iteration 8800 (4.52591 iter/s, 22.095s/100 iters), loss = 0.391927
I0418 16:57:06.514328  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 16:57:06.514343  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:57:06.514358  2203 solver.cpp:238]     Train net output #2: loss = 0.391927 (* 1 = 0.391927 loss)
I0418 16:57:06.514367  2203 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0418 16:57:28.608855  2203 solver.cpp:219] Iteration 8900 (4.52626 iter/s, 22.0933s/100 iters), loss = 0.404246
I0418 16:57:28.608893  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 16:57:28.608899  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:57:28.608906  2203 solver.cpp:238]     Train net output #2: loss = 0.404246 (* 1 = 0.404246 loss)
I0418 16:57:28.608909  2203 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0418 16:57:46.357714  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:57:50.571761  2203 solver.cpp:331] Iteration 9000, Testing net (#0)
I0418 16:57:55.031194  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:57:55.237092  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.6166
I0418 16:57:55.237118  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9686
I0418 16:57:55.237141  2203 solver.cpp:398]     Test net output #2: loss = 1.52792 (* 1 = 1.52792 loss)
I0418 16:57:55.400182  2203 solver.cpp:219] Iteration 9000 (3.73283 iter/s, 26.7893s/100 iters), loss = 0.374361
I0418 16:57:55.400204  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 16:57:55.400225  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 16:57:55.400230  2203 solver.cpp:238]     Train net output #2: loss = 0.374361 (* 1 = 0.374361 loss)
I0418 16:57:55.400240  2203 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0418 16:58:17.558274  2203 solver.cpp:219] Iteration 9100 (4.51302 iter/s, 22.1581s/100 iters), loss = 0.405861
I0418 16:58:17.559294  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 16:58:17.559303  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:58:17.559309  2203 solver.cpp:238]     Train net output #2: loss = 0.405861 (* 1 = 0.405861 loss)
I0418 16:58:17.559312  2203 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0418 16:58:39.752317  2203 solver.cpp:219] Iteration 9200 (4.50614 iter/s, 22.1919s/100 iters), loss = 0.547242
I0418 16:58:39.752372  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0418 16:58:39.752377  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:58:39.752384  2203 solver.cpp:238]     Train net output #2: loss = 0.547242 (* 1 = 0.547242 loss)
I0418 16:58:39.752390  2203 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0418 16:59:02.098592  2203 solver.cpp:219] Iteration 9300 (4.47545 iter/s, 22.3441s/100 iters), loss = 0.432312
I0418 16:59:02.099315  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0418 16:59:02.099323  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:59:02.099331  2203 solver.cpp:238]     Train net output #2: loss = 0.432312 (* 1 = 0.432312 loss)
I0418 16:59:02.099339  2203 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0418 16:59:17.801259  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 16:59:24.474462  2203 solver.cpp:219] Iteration 9400 (4.46951 iter/s, 22.3738s/100 iters), loss = 0.274845
I0418 16:59:24.474539  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 16:59:24.474546  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 16:59:24.474553  2203 solver.cpp:238]     Train net output #2: loss = 0.274845 (* 1 = 0.274845 loss)
I0418 16:59:24.474560  2203 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0418 16:59:46.879865  2203 solver.cpp:219] Iteration 9500 (4.46362 iter/s, 22.4034s/100 iters), loss = 0.400926
I0418 16:59:46.880273  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 16:59:46.880280  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 16:59:46.880290  2203 solver.cpp:238]     Train net output #2: loss = 0.400926 (* 1 = 0.400926 loss)
I0418 16:59:46.880296  2203 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0418 17:00:09.305768  2203 solver.cpp:219] Iteration 9600 (4.45954 iter/s, 22.4238s/100 iters), loss = 0.37842
I0418 17:00:09.305856  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0418 17:00:09.305862  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:00:09.305871  2203 solver.cpp:238]     Train net output #2: loss = 0.37842 (* 1 = 0.37842 loss)
I0418 17:00:09.305878  2203 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0418 17:00:31.725185  2203 solver.cpp:219] Iteration 9700 (4.46084 iter/s, 22.4173s/100 iters), loss = 0.386358
I0418 17:00:31.726315  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 17:00:31.726322  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:00:31.726330  2203 solver.cpp:238]     Train net output #2: loss = 0.386358 (* 1 = 0.386358 loss)
I0418 17:00:31.726337  2203 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0418 17:00:45.482134  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:00:54.208344  2203 solver.cpp:219] Iteration 9800 (4.4482 iter/s, 22.481s/100 iters), loss = 0.386929
I0418 17:00:54.208432  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0418 17:00:54.208439  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:00:54.208446  2203 solver.cpp:238]     Train net output #2: loss = 0.386929 (* 1 = 0.386929 loss)
I0418 17:00:54.208454  2203 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0418 17:01:16.609084  2203 solver.cpp:219] Iteration 9900 (4.46414 iter/s, 22.4007s/100 iters), loss = 0.46171
I0418 17:01:16.609465  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 17:01:16.609493  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:01:16.609503  2203 solver.cpp:238]     Train net output #2: loss = 0.46171 (* 1 = 0.46171 loss)
I0418 17:01:16.609511  2203 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0418 17:01:38.633746  2203 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_highway_padded_data_iter_10000.caffemodel
I0418 17:01:38.734241  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_highway_padded_data_iter_10000.solverstate
I0418 17:01:38.798735  2203 solver.cpp:331] Iteration 10000, Testing net (#0)
I0418 17:01:43.343889  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:01:43.548930  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.6743
I0418 17:01:43.548969  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9591
I0418 17:01:43.548995  2203 solver.cpp:398]     Test net output #2: loss = 1.19487 (* 1 = 1.19487 loss)
I0418 17:01:43.721338  2203 solver.cpp:219] Iteration 10000 (3.68865 iter/s, 27.1102s/100 iters), loss = 0.386439
I0418 17:01:43.721400  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:01:43.721405  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:01:43.721413  2203 solver.cpp:238]     Train net output #2: loss = 0.386439 (* 1 = 0.386439 loss)
I0418 17:01:43.721421  2203 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0418 17:02:06.175190  2203 solver.cpp:219] Iteration 10100 (4.45358 iter/s, 22.4539s/100 iters), loss = 0.431709
I0418 17:02:06.176317  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0418 17:02:06.176326  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:02:06.176333  2203 solver.cpp:238]     Train net output #2: loss = 0.431709 (* 1 = 0.431709 loss)
I0418 17:02:06.176342  2203 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0418 17:02:17.867504  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:02:28.532743  2203 solver.cpp:219] Iteration 10200 (4.47297 iter/s, 22.3565s/100 iters), loss = 0.342105
I0418 17:02:28.532827  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:02:28.532835  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 17:02:28.532842  2203 solver.cpp:238]     Train net output #2: loss = 0.342105 (* 1 = 0.342105 loss)
I0418 17:02:28.532850  2203 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0418 17:02:50.978673  2203 solver.cpp:219] Iteration 10300 (4.45558 iter/s, 22.4438s/100 iters), loss = 0.417245
I0418 17:02:50.979310  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0418 17:02:50.979318  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:02:50.979326  2203 solver.cpp:238]     Train net output #2: loss = 0.417245 (* 1 = 0.417245 loss)
I0418 17:02:50.979334  2203 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0418 17:03:13.382688  2203 solver.cpp:219] Iteration 10400 (4.4639 iter/s, 22.4019s/100 iters), loss = 0.222294
I0418 17:03:13.382777  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 17:03:13.382784  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:03:13.382792  2203 solver.cpp:238]     Train net output #2: loss = 0.222294 (* 1 = 0.222294 loss)
I0418 17:03:13.382800  2203 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0418 17:03:35.816565  2203 solver.cpp:219] Iteration 10500 (4.45795 iter/s, 22.4318s/100 iters), loss = 0.390812
I0418 17:03:35.817308  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:03:35.817317  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:03:35.817325  2203 solver.cpp:238]     Train net output #2: loss = 0.390812 (* 1 = 0.390812 loss)
I0418 17:03:35.817332  2203 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0418 17:03:45.242566  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:03:58.122563  2203 solver.cpp:219] Iteration 10600 (4.48351 iter/s, 22.304s/100 iters), loss = 0.471443
I0418 17:03:58.122601  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 17:03:58.122606  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 17:03:58.122611  2203 solver.cpp:238]     Train net output #2: loss = 0.471443 (* 1 = 0.471443 loss)
I0418 17:03:58.122615  2203 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0418 17:04:20.401479  2203 solver.cpp:219] Iteration 10700 (4.48855 iter/s, 22.2789s/100 iters), loss = 0.292241
I0418 17:04:20.407367  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:04:20.407382  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:04:20.407389  2203 solver.cpp:238]     Train net output #2: loss = 0.292241 (* 1 = 0.292241 loss)
I0418 17:04:20.407397  2203 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0418 17:04:42.754376  2203 solver.cpp:219] Iteration 10800 (4.47495 iter/s, 22.3466s/100 iters), loss = 0.345328
I0418 17:04:42.754461  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0418 17:04:42.754467  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:04:42.754475  2203 solver.cpp:238]     Train net output #2: loss = 0.345328 (* 1 = 0.345328 loss)
I0418 17:04:42.754483  2203 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0418 17:05:05.177531  2203 solver.cpp:219] Iteration 10900 (4.46008 iter/s, 22.4211s/100 iters), loss = 0.445442
I0418 17:05:05.178313  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0418 17:05:05.178320  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:05:05.178329  2203 solver.cpp:238]     Train net output #2: loss = 0.445442 (* 1 = 0.445442 loss)
I0418 17:05:05.178336  2203 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0418 17:05:12.623642  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:05:27.466100  2203 solver.cpp:331] Iteration 11000, Testing net (#0)
I0418 17:05:32.031107  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:05:32.242676  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.6327
I0418 17:05:32.242749  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9264
I0418 17:05:32.242759  2203 solver.cpp:398]     Test net output #2: loss = 1.56578 (* 1 = 1.56578 loss)
I0418 17:05:32.418074  2203 solver.cpp:219] Iteration 11000 (3.67109 iter/s, 27.2399s/100 iters), loss = 0.407468
I0418 17:05:32.418157  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:05:32.418164  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:05:32.418171  2203 solver.cpp:238]     Train net output #2: loss = 0.407468 (* 1 = 0.407468 loss)
I0418 17:05:32.418179  2203 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0418 17:05:54.850926  2203 solver.cpp:219] Iteration 11100 (4.45816 iter/s, 22.4308s/100 iters), loss = 0.265275
I0418 17:05:54.851300  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:05:54.851307  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:05:54.851315  2203 solver.cpp:238]     Train net output #2: loss = 0.265275 (* 1 = 0.265275 loss)
I0418 17:05:54.851322  2203 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0418 17:06:17.274271  2203 solver.cpp:219] Iteration 11200 (4.46005 iter/s, 22.4213s/100 iters), loss = 0.516818
I0418 17:06:17.274353  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0418 17:06:17.274359  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:06:17.274368  2203 solver.cpp:238]     Train net output #2: loss = 0.516818 (* 1 = 0.516818 loss)
I0418 17:06:17.274374  2203 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0418 17:06:39.746984  2203 solver.cpp:219] Iteration 11300 (4.45027 iter/s, 22.4706s/100 iters), loss = 0.425055
I0418 17:06:39.747299  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0418 17:06:39.747309  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:06:39.747318  2203 solver.cpp:238]     Train net output #2: loss = 0.425055 (* 1 = 0.425055 loss)
I0418 17:06:39.747328  2203 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0418 17:06:45.208925  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:07:02.195607  2203 solver.cpp:219] Iteration 11400 (4.45467 iter/s, 22.4484s/100 iters), loss = 0.36556
I0418 17:07:02.195689  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:07:02.195698  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:07:02.195706  2203 solver.cpp:238]     Train net output #2: loss = 0.36556 (* 1 = 0.36556 loss)
I0418 17:07:02.195713  2203 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0418 17:07:24.652163  2203 solver.cpp:219] Iteration 11500 (4.45344 iter/s, 22.4545s/100 iters), loss = 0.305951
I0418 17:07:24.653321  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:07:24.653332  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:07:24.653342  2203 solver.cpp:238]     Train net output #2: loss = 0.305951 (* 1 = 0.305951 loss)
I0418 17:07:24.653348  2203 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0418 17:07:46.992187  2203 solver.cpp:219] Iteration 11600 (4.4767 iter/s, 22.3379s/100 iters), loss = 0.345893
I0418 17:07:46.992270  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:07:46.992278  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:07:46.992287  2203 solver.cpp:238]     Train net output #2: loss = 0.345893 (* 1 = 0.345893 loss)
I0418 17:07:46.992295  2203 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0418 17:08:09.199692  2203 solver.cpp:219] Iteration 11700 (4.50339 iter/s, 22.2055s/100 iters), loss = 0.353498
I0418 17:08:09.200353  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0418 17:08:09.200364  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:08:09.200373  2203 solver.cpp:238]     Train net output #2: loss = 0.353498 (* 1 = 0.353498 loss)
I0418 17:08:09.200381  2203 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0418 17:08:12.350457  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:08:31.487656  2203 solver.cpp:219] Iteration 11800 (4.48714 iter/s, 22.2859s/100 iters), loss = 0.556847
I0418 17:08:31.487740  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0418 17:08:31.487746  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:08:31.487754  2203 solver.cpp:238]     Train net output #2: loss = 0.556847 (* 1 = 0.556847 loss)
I0418 17:08:31.487762  2203 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0418 17:08:53.928581  2203 solver.cpp:219] Iteration 11900 (4.45657 iter/s, 22.4388s/100 iters), loss = 0.268659
I0418 17:08:53.929311  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:08:53.929319  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:08:53.929327  2203 solver.cpp:238]     Train net output #2: loss = 0.268659 (* 1 = 0.268659 loss)
I0418 17:08:53.929335  2203 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0418 17:09:16.159813  2203 solver.cpp:331] Iteration 12000, Testing net (#0)
I0418 17:09:20.744268  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:09:20.954522  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.693
I0418 17:09:20.954594  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9572
I0418 17:09:20.954603  2203 solver.cpp:398]     Test net output #2: loss = 1.23261 (* 1 = 1.23261 loss)
I0418 17:09:21.112790  2203 solver.cpp:219] Iteration 12000 (3.67889 iter/s, 27.1821s/100 iters), loss = 0.351896
I0418 17:09:21.112872  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:09:21.112879  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:09:21.112887  2203 solver.cpp:238]     Train net output #2: loss = 0.351896 (* 1 = 0.351896 loss)
I0418 17:09:21.112895  2203 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0418 17:09:43.553598  2203 solver.cpp:219] Iteration 12100 (4.45658 iter/s, 22.4387s/100 iters), loss = 0.263549
I0418 17:09:43.554319  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:09:43.554328  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:09:43.554337  2203 solver.cpp:238]     Train net output #2: loss = 0.263549 (* 1 = 0.263549 loss)
I0418 17:09:43.554344  2203 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0418 17:09:44.734482  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:10:05.992780  2203 solver.cpp:219] Iteration 12200 (4.4569 iter/s, 22.4371s/100 iters), loss = 0.340097
I0418 17:10:05.992861  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:10:05.992866  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:10:05.992875  2203 solver.cpp:238]     Train net output #2: loss = 0.340097 (* 1 = 0.340097 loss)
I0418 17:10:05.992882  2203 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0418 17:10:28.329226  2203 solver.cpp:219] Iteration 12300 (4.47742 iter/s, 22.3343s/100 iters), loss = 0.342312
I0418 17:10:28.330299  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:10:28.330307  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:10:28.330317  2203 solver.cpp:238]     Train net output #2: loss = 0.342312 (* 1 = 0.342312 loss)
I0418 17:10:28.330325  2203 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0418 17:10:50.525321  2203 solver.cpp:219] Iteration 12400 (4.50573 iter/s, 22.194s/100 iters), loss = 0.328411
I0418 17:10:50.525357  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:10:50.525362  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:10:50.525368  2203 solver.cpp:238]     Train net output #2: loss = 0.328411 (* 1 = 0.328411 loss)
I0418 17:10:50.525372  2203 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0418 17:11:11.606730  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:11:12.678764  2203 solver.cpp:219] Iteration 12500 (4.51439 iter/s, 22.1514s/100 iters), loss = 0.309955
I0418 17:11:12.678797  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:11:12.678802  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:11:12.678807  2203 solver.cpp:238]     Train net output #2: loss = 0.309955 (* 1 = 0.309955 loss)
I0418 17:11:12.678812  2203 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0418 17:11:34.755060  2203 solver.cpp:219] Iteration 12600 (4.53017 iter/s, 22.0742s/100 iters), loss = 0.330578
I0418 17:11:34.755095  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:11:34.755100  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:11:34.755106  2203 solver.cpp:238]     Train net output #2: loss = 0.330578 (* 1 = 0.330578 loss)
I0418 17:11:34.755110  2203 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0418 17:11:56.868578  2203 solver.cpp:219] Iteration 12700 (4.52254 iter/s, 22.1115s/100 iters), loss = 0.415427
I0418 17:11:56.869331  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0418 17:11:56.869354  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:11:56.869369  2203 solver.cpp:238]     Train net output #2: loss = 0.415427 (* 1 = 0.415427 loss)
I0418 17:11:56.869390  2203 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0418 17:12:18.955088  2203 solver.cpp:219] Iteration 12800 (4.52807 iter/s, 22.0844s/100 iters), loss = 0.458732
I0418 17:12:18.955154  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0418 17:12:18.955160  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:12:18.955168  2203 solver.cpp:238]     Train net output #2: loss = 0.458732 (* 1 = 0.458732 loss)
I0418 17:12:18.955175  2203 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0418 17:12:38.100785  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:12:41.183496  2203 solver.cpp:219] Iteration 12900 (4.49918 iter/s, 22.2263s/100 iters), loss = 0.277881
I0418 17:12:41.183598  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:12:41.183604  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:12:41.183611  2203 solver.cpp:238]     Train net output #2: loss = 0.277881 (* 1 = 0.277881 loss)
I0418 17:12:41.183619  2203 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0418 17:13:03.271605  2203 solver.cpp:331] Iteration 13000, Testing net (#0)
I0418 17:13:07.832126  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:13:08.042143  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7496
I0418 17:13:08.042202  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9788
I0418 17:13:08.042228  2203 solver.cpp:398]     Test net output #2: loss = 0.948279 (* 1 = 0.948279 loss)
I0418 17:13:08.214808  2203 solver.cpp:219] Iteration 13000 (3.69969 iter/s, 27.0293s/100 iters), loss = 0.372538
I0418 17:13:08.215332  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:13:08.215342  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:13:08.215353  2203 solver.cpp:238]     Train net output #2: loss = 0.372538 (* 1 = 0.372538 loss)
I0418 17:13:08.215363  2203 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0418 17:13:30.593071  2203 solver.cpp:219] Iteration 13100 (4.46903 iter/s, 22.3762s/100 iters), loss = 0.518571
I0418 17:13:30.593155  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0418 17:13:30.593161  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:13:30.593170  2203 solver.cpp:238]     Train net output #2: loss = 0.518571 (* 1 = 0.518571 loss)
I0418 17:13:30.593178  2203 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0418 17:13:52.976701  2203 solver.cpp:219] Iteration 13200 (4.46796 iter/s, 22.3816s/100 iters), loss = 0.32527
I0418 17:13:52.976927  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:13:52.976936  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:13:52.976944  2203 solver.cpp:238]     Train net output #2: loss = 0.32527 (* 1 = 0.32527 loss)
I0418 17:13:52.976953  2203 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0418 17:14:10.195333  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:14:15.268867  2203 solver.cpp:219] Iteration 13300 (4.48591 iter/s, 22.292s/100 iters), loss = 0.300127
I0418 17:14:15.268940  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:14:15.268946  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:14:15.268954  2203 solver.cpp:238]     Train net output #2: loss = 0.300127 (* 1 = 0.300127 loss)
I0418 17:14:15.268961  2203 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0418 17:14:37.441049  2203 solver.cpp:219] Iteration 13400 (4.51059 iter/s, 22.1701s/100 iters), loss = 0.437707
I0418 17:14:37.441269  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0418 17:14:37.441277  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:14:37.441283  2203 solver.cpp:238]     Train net output #2: loss = 0.437707 (* 1 = 0.437707 loss)
I0418 17:14:37.441290  2203 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0418 17:14:59.755646  2203 solver.cpp:219] Iteration 13500 (4.4818 iter/s, 22.3124s/100 iters), loss = 0.300573
I0418 17:14:59.755722  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:14:59.755728  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:14:59.755736  2203 solver.cpp:238]     Train net output #2: loss = 0.300573 (* 1 = 0.300573 loss)
I0418 17:14:59.755744  2203 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0418 17:15:22.199065  2203 solver.cpp:219] Iteration 13600 (4.45606 iter/s, 22.4414s/100 iters), loss = 0.380518
I0418 17:15:22.199290  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:15:22.199297  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:15:22.199306  2203 solver.cpp:238]     Train net output #2: loss = 0.380518 (* 1 = 0.380518 loss)
I0418 17:15:22.199312  2203 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0418 17:15:37.236140  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:15:44.575927  2203 solver.cpp:219] Iteration 13700 (4.46933 iter/s, 22.3747s/100 iters), loss = 0.355412
I0418 17:15:44.576010  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:15:44.576017  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:15:44.576025  2203 solver.cpp:238]     Train net output #2: loss = 0.355412 (* 1 = 0.355412 loss)
I0418 17:15:44.576032  2203 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0418 17:16:06.966235  2203 solver.cpp:219] Iteration 13800 (4.46663 iter/s, 22.3883s/100 iters), loss = 0.437584
I0418 17:16:06.967296  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0418 17:16:06.967305  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:16:06.967313  2203 solver.cpp:238]     Train net output #2: loss = 0.437584 (* 1 = 0.437584 loss)
I0418 17:16:06.967319  2203 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0418 17:16:29.423915  2203 solver.cpp:219] Iteration 13900 (4.45324 iter/s, 22.4555s/100 iters), loss = 0.316782
I0418 17:16:29.423991  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:16:29.423997  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:16:29.424005  2203 solver.cpp:238]     Train net output #2: loss = 0.316782 (* 1 = 0.316782 loss)
I0418 17:16:29.424013  2203 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0418 17:16:51.636910  2203 solver.cpp:331] Iteration 14000, Testing net (#0)
I0418 17:16:56.210005  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:16:56.416920  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7771
I0418 17:16:56.416976  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9802
I0418 17:16:56.417002  2203 solver.cpp:398]     Test net output #2: loss = 0.776348 (* 1 = 0.776348 loss)
I0418 17:16:56.584003  2203 solver.cpp:219] Iteration 14000 (3.68187 iter/s, 27.1601s/100 iters), loss = 0.252901
I0418 17:16:56.584089  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:16:56.584096  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:16:56.584105  2203 solver.cpp:238]     Train net output #2: loss = 0.252901 (* 1 = 0.252901 loss)
I0418 17:16:56.584113  2203 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0418 17:17:09.648669  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:17:19.028632  2203 solver.cpp:219] Iteration 14100 (4.45541 iter/s, 22.4446s/100 iters), loss = 0.310992
I0418 17:17:19.028718  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:17:19.028724  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:17:19.028733  2203 solver.cpp:238]     Train net output #2: loss = 0.310992 (* 1 = 0.310992 loss)
I0418 17:17:19.028740  2203 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0418 17:17:41.456583  2203 solver.cpp:219] Iteration 14200 (4.45872 iter/s, 22.4279s/100 iters), loss = 0.388741
I0418 17:17:41.457301  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:17:41.457309  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:17:41.457316  2203 solver.cpp:238]     Train net output #2: loss = 0.388741 (* 1 = 0.388741 loss)
I0418 17:17:41.457324  2203 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0418 17:18:03.775578  2203 solver.cpp:219] Iteration 14300 (4.48062 iter/s, 22.3184s/100 iters), loss = 0.376136
I0418 17:18:03.775650  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:18:03.775656  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:18:03.775663  2203 solver.cpp:238]     Train net output #2: loss = 0.376136 (* 1 = 0.376136 loss)
I0418 17:18:03.775671  2203 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0418 17:18:26.062701  2203 solver.cpp:219] Iteration 14400 (4.48731 iter/s, 22.2851s/100 iters), loss = 0.366143
I0418 17:18:26.063307  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:18:26.063314  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:18:26.063323  2203 solver.cpp:238]     Train net output #2: loss = 0.366143 (* 1 = 0.366143 loss)
I0418 17:18:26.063330  2203 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0418 17:18:37.107460  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:18:48.492240  2203 solver.cpp:219] Iteration 14500 (4.45883 iter/s, 22.4274s/100 iters), loss = 0.347283
I0418 17:18:48.492303  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:18:48.492308  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:18:48.492317  2203 solver.cpp:238]     Train net output #2: loss = 0.347283 (* 1 = 0.347283 loss)
I0418 17:18:48.492324  2203 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0418 17:19:10.942214  2203 solver.cpp:219] Iteration 14600 (4.45435 iter/s, 22.45s/100 iters), loss = 0.298824
I0418 17:19:10.943306  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:19:10.943315  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:19:10.943325  2203 solver.cpp:238]     Train net output #2: loss = 0.298824 (* 1 = 0.298824 loss)
I0418 17:19:10.943331  2203 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0418 17:19:33.390530  2203 solver.cpp:219] Iteration 14700 (4.45488 iter/s, 22.4473s/100 iters), loss = 0.344521
I0418 17:19:33.390611  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0418 17:19:33.390619  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:19:33.390626  2203 solver.cpp:238]     Train net output #2: loss = 0.344521 (* 1 = 0.344521 loss)
I0418 17:19:33.390635  2203 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0418 17:19:55.787019  2203 solver.cpp:219] Iteration 14800 (4.46499 iter/s, 22.3965s/100 iters), loss = 0.359935
I0418 17:19:55.787281  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:19:55.787291  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 17:19:55.787298  2203 solver.cpp:238]     Train net output #2: loss = 0.359935 (* 1 = 0.359935 loss)
I0418 17:19:55.787307  2203 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0418 17:20:04.590739  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:20:18.419481  2203 solver.cpp:219] Iteration 14900 (4.41883 iter/s, 22.6304s/100 iters), loss = 0.197923
I0418 17:20:18.419548  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 17:20:18.419553  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:20:18.419561  2203 solver.cpp:238]     Train net output #2: loss = 0.197923 (* 1 = 0.197923 loss)
I0418 17:20:18.419569  2203 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0418 17:20:40.597620  2203 solver.cpp:331] Iteration 15000, Testing net (#0)
I0418 17:20:45.061722  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:20:45.271925  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.5145
I0418 17:20:45.271975  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.8964
I0418 17:20:45.271997  2203 solver.cpp:398]     Test net output #2: loss = 2.74642 (* 1 = 2.74642 loss)
I0418 17:20:45.432226  2203 solver.cpp:219] Iteration 15000 (3.70223 iter/s, 27.0107s/100 iters), loss = 0.369299
I0418 17:20:45.432297  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:20:45.432303  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:20:45.432312  2203 solver.cpp:238]     Train net output #2: loss = 0.369299 (* 1 = 0.369299 loss)
I0418 17:20:45.432318  2203 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0418 17:21:07.718502  2203 solver.cpp:219] Iteration 15100 (4.48707 iter/s, 22.2863s/100 iters), loss = 0.546201
I0418 17:21:07.718590  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.78125
I0418 17:21:07.718597  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:21:07.718605  2203 solver.cpp:238]     Train net output #2: loss = 0.546201 (* 1 = 0.546201 loss)
I0418 17:21:07.718614  2203 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0418 17:21:30.088845  2203 solver.cpp:219] Iteration 15200 (4.47061 iter/s, 22.3683s/100 iters), loss = 0.42107
I0418 17:21:30.089310  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0418 17:21:30.089320  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:21:30.089340  2203 solver.cpp:238]     Train net output #2: loss = 0.42107 (* 1 = 0.42107 loss)
I0418 17:21:30.089347  2203 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0418 17:21:36.901162  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:21:52.567983  2203 solver.cpp:219] Iteration 15300 (4.44874 iter/s, 22.4783s/100 iters), loss = 0.317801
I0418 17:21:52.568070  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 17:21:52.568076  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:21:52.568085  2203 solver.cpp:238]     Train net output #2: loss = 0.317801 (* 1 = 0.317801 loss)
I0418 17:21:52.568092  2203 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0418 17:22:14.954156  2203 solver.cpp:219] Iteration 15400 (4.46745 iter/s, 22.3841s/100 iters), loss = 0.382452
I0418 17:22:14.955301  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:22:14.955308  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:22:14.955317  2203 solver.cpp:238]     Train net output #2: loss = 0.382452 (* 1 = 0.382452 loss)
I0418 17:22:14.955324  2203 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0418 17:22:37.424489  2203 solver.cpp:219] Iteration 15500 (4.45052 iter/s, 22.4693s/100 iters), loss = 0.296418
I0418 17:22:37.424576  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:22:37.424583  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:22:37.424592  2203 solver.cpp:238]     Train net output #2: loss = 0.296418 (* 1 = 0.296418 loss)
I0418 17:22:37.424599  2203 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0418 17:22:59.885375  2203 solver.cpp:219] Iteration 15600 (4.4526 iter/s, 22.4588s/100 iters), loss = 0.363888
I0418 17:22:59.886308  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:22:59.886315  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:22:59.886323  2203 solver.cpp:238]     Train net output #2: loss = 0.363888 (* 1 = 0.363888 loss)
I0418 17:22:59.886330  2203 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0418 17:23:04.428179  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:23:22.411800  2203 solver.cpp:219] Iteration 15700 (4.43964 iter/s, 22.5244s/100 iters), loss = 0.287882
I0418 17:23:22.411887  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:23:22.411895  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:23:22.411902  2203 solver.cpp:238]     Train net output #2: loss = 0.287882 (* 1 = 0.287882 loss)
I0418 17:23:22.411911  2203 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0418 17:23:44.870537  2203 solver.cpp:219] Iteration 15800 (4.45302 iter/s, 22.4567s/100 iters), loss = 0.224009
I0418 17:23:44.871310  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:23:44.871318  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:23:44.871325  2203 solver.cpp:238]     Train net output #2: loss = 0.224009 (* 1 = 0.224009 loss)
I0418 17:23:44.871333  2203 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0418 17:24:07.346225  2203 solver.cpp:219] Iteration 15900 (4.44967 iter/s, 22.4736s/100 iters), loss = 0.38031
I0418 17:24:07.346308  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:24:07.346315  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:24:07.346323  2203 solver.cpp:238]     Train net output #2: loss = 0.38031 (* 1 = 0.38031 loss)
I0418 17:24:07.346330  2203 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0418 17:24:29.629672  2203 solver.cpp:331] Iteration 16000, Testing net (#0)
I0418 17:24:34.203176  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:24:34.413997  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7544
I0418 17:24:34.414057  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9825
I0418 17:24:34.414082  2203 solver.cpp:398]     Test net output #2: loss = 0.833004 (* 1 = 0.833004 loss)
I0418 17:24:34.584496  2203 solver.cpp:219] Iteration 16000 (3.67158 iter/s, 27.2362s/100 iters), loss = 0.256647
I0418 17:24:34.584594  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:24:34.584600  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:24:34.584609  2203 solver.cpp:238]     Train net output #2: loss = 0.256647 (* 1 = 0.256647 loss)
I0418 17:24:34.584616  2203 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0418 17:24:37.104282  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:24:57.058328  2203 solver.cpp:219] Iteration 16100 (4.45003 iter/s, 22.4718s/100 iters), loss = 0.363675
I0418 17:24:57.058406  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 17:24:57.058413  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:24:57.058420  2203 solver.cpp:238]     Train net output #2: loss = 0.363675 (* 1 = 0.363675 loss)
I0418 17:24:57.058428  2203 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0418 17:25:19.347242  2203 solver.cpp:219] Iteration 16200 (4.48695 iter/s, 22.2869s/100 iters), loss = 0.326672
I0418 17:25:19.348307  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:25:19.348315  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:25:19.348323  2203 solver.cpp:238]     Train net output #2: loss = 0.326672 (* 1 = 0.326672 loss)
I0418 17:25:19.348331  2203 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0418 17:25:41.780905  2203 solver.cpp:219] Iteration 16300 (4.45778 iter/s, 22.4327s/100 iters), loss = 0.370775
I0418 17:25:41.780988  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:25:41.780994  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 17:25:41.781002  2203 solver.cpp:238]     Train net output #2: loss = 0.370775 (* 1 = 0.370775 loss)
I0418 17:25:41.781009  2203 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0418 17:26:04.193862  2203 solver.cpp:219] Iteration 16400 (4.46171 iter/s, 22.413s/100 iters), loss = 0.26175
I0418 17:26:04.194296  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:26:04.194319  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:26:04.194353  2203 solver.cpp:238]     Train net output #2: loss = 0.26175 (* 1 = 0.26175 loss)
I0418 17:26:04.194361  2203 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0418 17:26:04.679637  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:26:26.507249  2203 solver.cpp:219] Iteration 16500 (4.48203 iter/s, 22.3113s/100 iters), loss = 0.311978
I0418 17:26:26.507335  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:26:26.507344  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:26:26.507351  2203 solver.cpp:238]     Train net output #2: loss = 0.311978 (* 1 = 0.311978 loss)
I0418 17:26:26.507359  2203 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0418 17:26:48.989137  2203 solver.cpp:219] Iteration 16600 (4.44843 iter/s, 22.4798s/100 iters), loss = 0.264504
I0418 17:26:48.989364  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:26:48.989372  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:26:48.989380  2203 solver.cpp:238]     Train net output #2: loss = 0.264504 (* 1 = 0.264504 loss)
I0418 17:26:48.989388  2203 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0418 17:27:11.410636  2203 solver.cpp:219] Iteration 16700 (4.46041 iter/s, 22.4194s/100 iters), loss = 0.296002
I0418 17:27:11.410722  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:27:11.410729  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:27:11.410737  2203 solver.cpp:238]     Train net output #2: loss = 0.296003 (* 1 = 0.296003 loss)
I0418 17:27:11.410745  2203 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0418 17:27:32.086307  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:27:33.860318  2203 solver.cpp:219] Iteration 16800 (4.45483 iter/s, 22.4476s/100 iters), loss = 0.318563
I0418 17:27:33.860401  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:27:33.860407  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:27:33.860415  2203 solver.cpp:238]     Train net output #2: loss = 0.318563 (* 1 = 0.318563 loss)
I0418 17:27:33.860424  2203 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0418 17:27:56.310850  2203 solver.cpp:219] Iteration 16900 (4.45424 iter/s, 22.4505s/100 iters), loss = 0.315379
I0418 17:27:56.310937  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:27:56.310943  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:27:56.310951  2203 solver.cpp:238]     Train net output #2: loss = 0.315379 (* 1 = 0.315379 loss)
I0418 17:27:56.310958  2203 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0418 17:28:18.519798  2203 solver.cpp:331] Iteration 17000, Testing net (#0)
I0418 17:28:23.124864  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:28:23.301282  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.808
I0418 17:28:23.301339  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9893
I0418 17:28:23.301365  2203 solver.cpp:398]     Test net output #2: loss = 0.636549 (* 1 = 0.636549 loss)
I0418 17:28:23.498359  2203 solver.cpp:219] Iteration 17000 (3.67816 iter/s, 27.1875s/100 iters), loss = 0.224498
I0418 17:28:23.498438  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:28:23.498445  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:28:23.498452  2203 solver.cpp:238]     Train net output #2: loss = 0.224498 (* 1 = 0.224498 loss)
I0418 17:28:23.498461  2203 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0418 17:28:45.825834  2203 solver.cpp:219] Iteration 17100 (4.47879 iter/s, 22.3275s/100 iters), loss = 0.312082
I0418 17:28:45.825912  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:28:45.825918  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:28:45.825927  2203 solver.cpp:238]     Train net output #2: loss = 0.312082 (* 1 = 0.312082 loss)
I0418 17:28:45.825933  2203 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0418 17:29:04.312178  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:29:08.063422  2203 solver.cpp:219] Iteration 17200 (4.4973 iter/s, 22.2356s/100 iters), loss = 0.313251
I0418 17:29:08.063455  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:29:08.063460  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:29:08.063467  2203 solver.cpp:238]     Train net output #2: loss = 0.313251 (* 1 = 0.313251 loss)
I0418 17:29:08.063470  2203 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0418 17:29:30.187445  2203 solver.cpp:219] Iteration 17300 (4.51997 iter/s, 22.124s/100 iters), loss = 0.341557
I0418 17:29:30.187484  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:29:30.187489  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:29:30.187494  2203 solver.cpp:238]     Train net output #2: loss = 0.341557 (* 1 = 0.341557 loss)
I0418 17:29:30.187499  2203 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0418 17:29:52.378129  2203 solver.cpp:219] Iteration 17400 (4.50681 iter/s, 22.1886s/100 iters), loss = 0.28675
I0418 17:29:52.378314  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:29:52.378322  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:29:52.378329  2203 solver.cpp:238]     Train net output #2: loss = 0.28675 (* 1 = 0.28675 loss)
I0418 17:29:52.378334  2203 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0418 17:30:14.552470  2203 solver.cpp:219] Iteration 17500 (4.50975 iter/s, 22.1742s/100 iters), loss = 0.280487
I0418 17:30:14.552505  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:30:14.552510  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:30:14.552515  2203 solver.cpp:238]     Train net output #2: loss = 0.280487 (* 1 = 0.280487 loss)
I0418 17:30:14.552520  2203 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0418 17:30:30.996804  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:30:36.709333  2203 solver.cpp:219] Iteration 17600 (4.51327 iter/s, 22.1569s/100 iters), loss = 0.270117
I0418 17:30:36.709368  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:30:36.709372  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:30:36.709378  2203 solver.cpp:238]     Train net output #2: loss = 0.270117 (* 1 = 0.270117 loss)
I0418 17:30:36.709383  2203 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0418 17:30:58.857053  2203 solver.cpp:219] Iteration 17700 (4.51513 iter/s, 22.1477s/100 iters), loss = 0.29421
I0418 17:30:58.857091  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:30:58.857096  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:30:58.857102  2203 solver.cpp:238]     Train net output #2: loss = 0.29421 (* 1 = 0.29421 loss)
I0418 17:30:58.857106  2203 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0418 17:31:21.011605  2203 solver.cpp:219] Iteration 17800 (4.51374 iter/s, 22.1546s/100 iters), loss = 0.294185
I0418 17:31:21.012329  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:31:21.012339  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:31:21.012346  2203 solver.cpp:238]     Train net output #2: loss = 0.294185 (* 1 = 0.294185 loss)
I0418 17:31:21.012349  2203 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0418 17:31:43.212327  2203 solver.cpp:219] Iteration 17900 (4.50477 iter/s, 22.1987s/100 iters), loss = 0.215023
I0418 17:31:43.212363  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 17:31:43.212368  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:31:43.212373  2203 solver.cpp:238]     Train net output #2: loss = 0.215023 (* 1 = 0.215023 loss)
I0418 17:31:43.212376  2203 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0418 17:31:57.466675  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:32:05.231923  2203 solver.cpp:331] Iteration 18000, Testing net (#0)
I0418 17:32:09.764152  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:32:09.957175  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.8154
I0418 17:32:09.957200  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9894
I0418 17:32:09.957223  2203 solver.cpp:398]     Test net output #2: loss = 0.577337 (* 1 = 0.577337 loss)
I0418 17:32:10.141826  2203 solver.cpp:219] Iteration 18000 (3.71368 iter/s, 26.9275s/100 iters), loss = 0.377926
I0418 17:32:10.141847  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:32:10.141870  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 17:32:10.141875  2203 solver.cpp:238]     Train net output #2: loss = 0.377926 (* 1 = 0.377926 loss)
I0418 17:32:10.141880  2203 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0418 17:32:32.402326  2203 solver.cpp:219] Iteration 18100 (4.49268 iter/s, 22.2584s/100 iters), loss = 0.28031
I0418 17:32:32.403281  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 17:32:32.403288  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:32:32.403295  2203 solver.cpp:238]     Train net output #2: loss = 0.28031 (* 1 = 0.28031 loss)
I0418 17:32:32.403300  2203 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0418 17:32:54.529443  2203 solver.cpp:219] Iteration 18200 (4.51976 iter/s, 22.1251s/100 iters), loss = 0.279809
I0418 17:32:54.529497  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:32:54.529502  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:32:54.529510  2203 solver.cpp:238]     Train net output #2: loss = 0.279809 (* 1 = 0.279809 loss)
I0418 17:32:54.529513  2203 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0418 17:33:16.688256  2203 solver.cpp:219] Iteration 18300 (4.51287 iter/s, 22.1588s/100 iters), loss = 0.374124
I0418 17:33:16.689287  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 17:33:16.689296  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:33:16.689301  2203 solver.cpp:238]     Train net output #2: loss = 0.374124 (* 1 = 0.374124 loss)
I0418 17:33:16.689306  2203 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0418 17:33:28.940891  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:33:38.912370  2203 solver.cpp:219] Iteration 18400 (4.50003 iter/s, 22.2221s/100 iters), loss = 0.30431
I0418 17:33:38.912420  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:33:38.912425  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:33:38.912431  2203 solver.cpp:238]     Train net output #2: loss = 0.30431 (* 1 = 0.30431 loss)
I0418 17:33:38.912436  2203 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0418 17:34:01.077862  2203 solver.cpp:219] Iteration 18500 (4.51194 iter/s, 22.1634s/100 iters), loss = 0.336359
I0418 17:34:01.077939  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:34:01.077945  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:34:01.077952  2203 solver.cpp:238]     Train net output #2: loss = 0.336359 (* 1 = 0.336359 loss)
I0418 17:34:01.077956  2203 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0418 17:34:23.260944  2203 solver.cpp:219] Iteration 18600 (4.50837 iter/s, 22.181s/100 iters), loss = 0.425013
I0418 17:34:23.261003  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 17:34:23.261009  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:34:23.261016  2203 solver.cpp:238]     Train net output #2: loss = 0.425013 (* 1 = 0.425013 loss)
I0418 17:34:23.261021  2203 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0418 17:34:45.412111  2203 solver.cpp:219] Iteration 18700 (4.51486 iter/s, 22.1491s/100 iters), loss = 0.212789
I0418 17:34:45.412195  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 17:34:45.412202  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:34:45.412209  2203 solver.cpp:238]     Train net output #2: loss = 0.212789 (* 1 = 0.212789 loss)
I0418 17:34:45.412212  2203 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0418 17:34:55.435174  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:35:07.588650  2203 solver.cpp:219] Iteration 18800 (4.50927 iter/s, 22.1765s/100 iters), loss = 0.311812
I0418 17:35:07.588704  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:35:07.588709  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:35:07.588716  2203 solver.cpp:238]     Train net output #2: loss = 0.311812 (* 1 = 0.311812 loss)
I0418 17:35:07.588721  2203 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0418 17:35:29.786460  2203 solver.cpp:219] Iteration 18900 (4.50537 iter/s, 22.1958s/100 iters), loss = 0.298125
I0418 17:35:29.786623  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:35:29.786630  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:35:29.786638  2203 solver.cpp:238]     Train net output #2: loss = 0.298125 (* 1 = 0.298125 loss)
I0418 17:35:29.786641  2203 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0418 17:35:51.804553  2203 solver.cpp:331] Iteration 19000, Testing net (#0)
I0418 17:35:56.341845  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:35:56.524747  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7607
I0418 17:35:56.524775  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9838
I0418 17:35:56.524799  2203 solver.cpp:398]     Test net output #2: loss = 0.825251 (* 1 = 0.825251 loss)
I0418 17:35:56.728092  2203 solver.cpp:219] Iteration 19000 (3.71201 iter/s, 26.9396s/100 iters), loss = 0.340532
I0418 17:35:56.728116  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:35:56.728137  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:35:56.728143  2203 solver.cpp:238]     Train net output #2: loss = 0.340532 (* 1 = 0.340532 loss)
I0418 17:35:56.728149  2203 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0418 17:36:18.884528  2203 solver.cpp:219] Iteration 19100 (4.51378 iter/s, 22.1544s/100 iters), loss = 0.336806
I0418 17:36:18.884644  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:36:18.884650  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:36:18.884656  2203 solver.cpp:238]     Train net output #2: loss = 0.336806 (* 1 = 0.336806 loss)
I0418 17:36:18.884661  2203 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0418 17:36:26.905699  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:36:41.022964  2203 solver.cpp:219] Iteration 19200 (4.51745 iter/s, 22.1364s/100 iters), loss = 0.339668
I0418 17:36:41.023018  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0418 17:36:41.023023  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:36:41.023030  2203 solver.cpp:238]     Train net output #2: loss = 0.339668 (* 1 = 0.339668 loss)
I0418 17:36:41.023035  2203 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0418 17:37:03.204514  2203 solver.cpp:219] Iteration 19300 (4.50867 iter/s, 22.1795s/100 iters), loss = 0.345407
I0418 17:37:03.204679  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0418 17:37:03.204687  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:37:03.204694  2203 solver.cpp:238]     Train net output #2: loss = 0.345407 (* 1 = 0.345407 loss)
I0418 17:37:03.204699  2203 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0418 17:37:25.393200  2203 solver.cpp:219] Iteration 19400 (4.50722 iter/s, 22.1866s/100 iters), loss = 0.506054
I0418 17:37:25.393260  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0418 17:37:25.393265  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:37:25.393272  2203 solver.cpp:238]     Train net output #2: loss = 0.506054 (* 1 = 0.506054 loss)
I0418 17:37:25.393276  2203 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0418 17:37:47.580415  2203 solver.cpp:219] Iteration 19500 (4.5071 iter/s, 22.1872s/100 iters), loss = 0.311719
I0418 17:37:47.580615  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:37:47.580622  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:37:47.580628  2203 solver.cpp:238]     Train net output #2: loss = 0.311719 (* 1 = 0.311719 loss)
I0418 17:37:47.580633  2203 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0418 17:37:53.661072  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:38:09.563760  2203 solver.cpp:219] Iteration 19600 (4.54934 iter/s, 21.9812s/100 iters), loss = 0.209673
I0418 17:38:09.563810  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 17:38:09.563817  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:38:09.563822  2203 solver.cpp:238]     Train net output #2: loss = 0.209673 (* 1 = 0.209673 loss)
I0418 17:38:09.563827  2203 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0418 17:38:31.797061  2203 solver.cpp:219] Iteration 19700 (4.49819 iter/s, 22.2312s/100 iters), loss = 0.323311
I0418 17:38:31.797344  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:38:31.797350  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:38:31.797358  2203 solver.cpp:238]     Train net output #2: loss = 0.323311 (* 1 = 0.323311 loss)
I0418 17:38:31.797363  2203 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0418 17:38:53.997110  2203 solver.cpp:219] Iteration 19800 (4.50453 iter/s, 22.1999s/100 iters), loss = 0.384929
I0418 17:38:53.997164  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:38:53.997170  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:38:53.997176  2203 solver.cpp:238]     Train net output #2: loss = 0.384929 (* 1 = 0.384929 loss)
I0418 17:38:53.997181  2203 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0418 17:39:16.156626  2203 solver.cpp:219] Iteration 19900 (4.51315 iter/s, 22.1575s/100 iters), loss = 0.25491
I0418 17:39:16.156828  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:39:16.156836  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:39:16.156843  2203 solver.cpp:238]     Train net output #2: loss = 0.25491 (* 1 = 0.25491 loss)
I0418 17:39:16.156848  2203 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0418 17:39:19.961275  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:39:38.165987  2203 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_highway_padded_data_iter_20000.caffemodel
I0418 17:39:38.251380  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_highway_padded_data_iter_20000.solverstate
I0418 17:39:38.409787  2203 solver.cpp:331] Iteration 20000, Testing net (#0)
I0418 17:39:42.985407  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:39:43.158862  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.766
I0418 17:39:43.158887  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9842
I0418 17:39:43.158911  2203 solver.cpp:398]     Test net output #2: loss = 0.782319 (* 1 = 0.782319 loss)
I0418 17:39:43.357707  2203 solver.cpp:219] Iteration 20000 (3.6766 iter/s, 27.1991s/100 iters), loss = 0.294992
I0418 17:39:43.357728  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 17:39:43.357733  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:39:43.357753  2203 solver.cpp:238]     Train net output #2: loss = 0.294992 (* 1 = 0.294992 loss)
I0418 17:39:43.357760  2203 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0418 17:40:05.533092  2203 solver.cpp:219] Iteration 20100 (4.5095 iter/s, 22.1754s/100 iters), loss = 0.402562
I0418 17:40:05.533231  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:40:05.533242  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:40:05.533249  2203 solver.cpp:238]     Train net output #2: loss = 0.402562 (* 1 = 0.402562 loss)
I0418 17:40:05.533253  2203 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0418 17:40:27.726249  2203 solver.cpp:219] Iteration 20200 (4.50633 iter/s, 22.191s/100 iters), loss = 0.241705
I0418 17:40:27.726284  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:40:27.726289  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:40:27.726294  2203 solver.cpp:238]     Train net output #2: loss = 0.241705 (* 1 = 0.241705 loss)
I0418 17:40:27.726299  2203 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0418 17:40:49.908932  2203 solver.cpp:219] Iteration 20300 (4.50802 iter/s, 22.1827s/100 iters), loss = 0.286402
I0418 17:40:49.908996  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:40:49.909003  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:40:49.909008  2203 solver.cpp:238]     Train net output #2: loss = 0.286402 (* 1 = 0.286402 loss)
I0418 17:40:49.909013  2203 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0418 17:40:51.724097  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:41:12.102525  2203 solver.cpp:219] Iteration 20400 (4.5058 iter/s, 22.1936s/100 iters), loss = 0.31916
I0418 17:41:12.102562  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:41:12.102568  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:41:12.102574  2203 solver.cpp:238]     Train net output #2: loss = 0.31916 (* 1 = 0.31916 loss)
I0418 17:41:12.102578  2203 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0418 17:41:34.273718  2203 solver.cpp:219] Iteration 20500 (4.51079 iter/s, 22.1691s/100 iters), loss = 0.244167
I0418 17:41:34.274281  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:41:34.274294  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:41:34.274309  2203 solver.cpp:238]     Train net output #2: loss = 0.244167 (* 1 = 0.244167 loss)
I0418 17:41:34.274318  2203 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0418 17:41:56.500100  2203 solver.cpp:219] Iteration 20600 (4.49925 iter/s, 22.2259s/100 iters), loss = 0.439713
I0418 17:41:56.500152  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 17:41:56.500159  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:41:56.500164  2203 solver.cpp:238]     Train net output #2: loss = 0.439713 (* 1 = 0.439713 loss)
I0418 17:41:56.500169  2203 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0418 17:42:18.516952  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:42:18.730307  2203 solver.cpp:219] Iteration 20700 (4.49881 iter/s, 22.2281s/100 iters), loss = 0.278381
I0418 17:42:18.730351  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:42:18.730357  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:42:18.730363  2203 solver.cpp:238]     Train net output #2: loss = 0.278381 (* 1 = 0.278381 loss)
I0418 17:42:18.730367  2203 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0418 17:42:40.910748  2203 solver.cpp:219] Iteration 20800 (4.5089 iter/s, 22.1784s/100 iters), loss = 0.238119
I0418 17:42:40.910805  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:42:40.910812  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:42:40.910820  2203 solver.cpp:238]     Train net output #2: loss = 0.238119 (* 1 = 0.238119 loss)
I0418 17:42:40.910823  2203 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0418 17:43:03.097746  2203 solver.cpp:219] Iteration 20900 (4.50714 iter/s, 22.187s/100 iters), loss = 0.412005
I0418 17:43:03.097908  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 17:43:03.097914  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:43:03.097921  2203 solver.cpp:238]     Train net output #2: loss = 0.412005 (* 1 = 0.412005 loss)
I0418 17:43:03.097926  2203 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0418 17:43:25.014634  2203 solver.cpp:331] Iteration 21000, Testing net (#0)
I0418 17:43:29.593152  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:43:29.750365  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.775
I0418 17:43:29.750391  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9884
I0418 17:43:29.750414  2203 solver.cpp:398]     Test net output #2: loss = 0.761662 (* 1 = 0.761662 loss)
I0418 17:43:29.963259  2203 solver.cpp:219] Iteration 21000 (3.72253 iter/s, 26.8634s/100 iters), loss = 0.448456
I0418 17:43:29.963280  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0418 17:43:29.963302  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:43:29.963307  2203 solver.cpp:238]     Train net output #2: loss = 0.448456 (* 1 = 0.448456 loss)
I0418 17:43:29.963313  2203 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0418 17:43:49.686084  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:43:52.081985  2203 solver.cpp:219] Iteration 21100 (4.52148 iter/s, 22.1167s/100 iters), loss = 0.223392
I0418 17:43:52.082016  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:43:52.082021  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:43:52.082027  2203 solver.cpp:238]     Train net output #2: loss = 0.223392 (* 1 = 0.223392 loss)
I0418 17:43:52.082031  2203 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0418 17:44:14.369302  2203 solver.cpp:219] Iteration 21200 (4.48727 iter/s, 22.2853s/100 iters), loss = 0.358364
I0418 17:44:14.369333  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:44:14.369338  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:44:14.369344  2203 solver.cpp:238]     Train net output #2: loss = 0.358364 (* 1 = 0.358364 loss)
I0418 17:44:14.369349  2203 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0418 17:44:36.539511  2203 solver.cpp:219] Iteration 21300 (4.51055 iter/s, 22.1702s/100 iters), loss = 0.201575
I0418 17:44:36.539727  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:44:36.539736  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:44:36.539742  2203 solver.cpp:238]     Train net output #2: loss = 0.201575 (* 1 = 0.201575 loss)
I0418 17:44:36.539747  2203 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0418 17:44:58.727885  2203 solver.cpp:219] Iteration 21400 (4.50689 iter/s, 22.1882s/100 iters), loss = 0.274804
I0418 17:44:58.727922  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:44:58.727927  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:44:58.727933  2203 solver.cpp:238]     Train net output #2: loss = 0.274804 (* 1 = 0.274804 loss)
I0418 17:44:58.727937  2203 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0418 17:45:16.485401  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:45:20.918422  2203 solver.cpp:219] Iteration 21500 (4.50642 iter/s, 22.1906s/100 iters), loss = 0.23602
I0418 17:45:20.918460  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:45:20.918465  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:45:20.918470  2203 solver.cpp:238]     Train net output #2: loss = 0.23602 (* 1 = 0.23602 loss)
I0418 17:45:20.918475  2203 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0418 17:45:43.110999  2203 solver.cpp:219] Iteration 21600 (4.50601 iter/s, 22.1926s/100 iters), loss = 0.286764
I0418 17:45:43.111039  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:45:43.111044  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:45:43.111050  2203 solver.cpp:238]     Train net output #2: loss = 0.286764 (* 1 = 0.286764 loss)
I0418 17:45:43.111054  2203 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0418 17:46:05.296787  2203 solver.cpp:219] Iteration 21700 (4.50738 iter/s, 22.1858s/100 iters), loss = 0.227707
I0418 17:46:05.297268  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:46:05.297293  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:46:05.297299  2203 solver.cpp:238]     Train net output #2: loss = 0.227707 (* 1 = 0.227707 loss)
I0418 17:46:05.297303  2203 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0418 17:46:27.457604  2203 solver.cpp:219] Iteration 21800 (4.51255 iter/s, 22.1604s/100 iters), loss = 0.494711
I0418 17:46:27.457644  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0418 17:46:27.457649  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 17:46:27.457655  2203 solver.cpp:238]     Train net output #2: loss = 0.494711 (* 1 = 0.494711 loss)
I0418 17:46:27.457659  2203 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0418 17:46:42.985512  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:46:49.621914  2203 solver.cpp:219] Iteration 21900 (4.51175 iter/s, 22.1643s/100 iters), loss = 0.255507
I0418 17:46:49.621950  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:46:49.621955  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:46:49.621961  2203 solver.cpp:238]     Train net output #2: loss = 0.255507 (* 1 = 0.255507 loss)
I0418 17:46:49.621965  2203 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0418 17:47:11.609231  2203 solver.cpp:331] Iteration 22000, Testing net (#0)
I0418 17:47:16.172935  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:47:16.332226  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7074
I0418 17:47:16.332254  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9474
I0418 17:47:16.332278  2203 solver.cpp:398]     Test net output #2: loss = 1.09507 (* 1 = 1.09507 loss)
I0418 17:47:16.557108  2203 solver.cpp:219] Iteration 22000 (3.7126 iter/s, 26.9353s/100 iters), loss = 0.362401
I0418 17:47:16.557130  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:47:16.557135  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:47:16.557140  2203 solver.cpp:238]     Train net output #2: loss = 0.362401 (* 1 = 0.362401 loss)
I0418 17:47:16.557145  2203 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0418 17:47:38.739284  2203 solver.cpp:219] Iteration 22100 (4.50855 iter/s, 22.1801s/100 iters), loss = 0.181052
I0418 17:47:38.739318  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 17:47:38.739323  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:47:38.739328  2203 solver.cpp:238]     Train net output #2: loss = 0.181052 (* 1 = 0.181052 loss)
I0418 17:47:38.739333  2203 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0418 17:48:00.939406  2203 solver.cpp:219] Iteration 22200 (4.50491 iter/s, 22.198s/100 iters), loss = 0.341714
I0418 17:48:00.939640  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:48:00.939648  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:48:00.939656  2203 solver.cpp:238]     Train net output #2: loss = 0.341714 (* 1 = 0.341714 loss)
I0418 17:48:00.939661  2203 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0418 17:48:14.468384  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:48:23.104041  2203 solver.cpp:219] Iteration 22300 (4.51212 iter/s, 22.1625s/100 iters), loss = 0.309565
I0418 17:48:23.104096  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:48:23.104101  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:48:23.104109  2203 solver.cpp:238]     Train net output #2: loss = 0.309565 (* 1 = 0.309565 loss)
I0418 17:48:23.104112  2203 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0418 17:48:45.286664  2203 solver.cpp:219] Iteration 22400 (4.50845 iter/s, 22.1806s/100 iters), loss = 0.470965
I0418 17:48:45.286836  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0418 17:48:45.286844  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:48:45.286850  2203 solver.cpp:238]     Train net output #2: loss = 0.470965 (* 1 = 0.470965 loss)
I0418 17:48:45.286855  2203 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0418 17:49:07.482116  2203 solver.cpp:219] Iteration 22500 (4.50584 iter/s, 22.1934s/100 iters), loss = 0.222885
I0418 17:49:07.482151  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:49:07.482156  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:49:07.482161  2203 solver.cpp:238]     Train net output #2: loss = 0.222885 (* 1 = 0.222885 loss)
I0418 17:49:07.482165  2203 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0418 17:49:29.630200  2203 solver.cpp:219] Iteration 22600 (4.5155 iter/s, 22.1459s/100 iters), loss = 0.369861
I0418 17:49:29.630266  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:49:29.630272  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:49:29.630278  2203 solver.cpp:238]     Train net output #2: loss = 0.369861 (* 1 = 0.369861 loss)
I0418 17:49:29.630282  2203 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0418 17:49:41.168197  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:49:51.793673  2203 solver.cpp:219] Iteration 22700 (4.51234 iter/s, 22.1614s/100 iters), loss = 0.242925
I0418 17:49:51.793705  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:49:51.793710  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:49:51.793716  2203 solver.cpp:238]     Train net output #2: loss = 0.242925 (* 1 = 0.242925 loss)
I0418 17:49:51.793720  2203 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0418 17:50:13.974776  2203 solver.cpp:219] Iteration 22800 (4.50876 iter/s, 22.1791s/100 iters), loss = 0.395178
I0418 17:50:13.974947  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:50:13.974954  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:50:13.974961  2203 solver.cpp:238]     Train net output #2: loss = 0.395178 (* 1 = 0.395178 loss)
I0418 17:50:13.974967  2203 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0418 17:50:36.166925  2203 solver.cpp:219] Iteration 22900 (4.50652 iter/s, 22.1901s/100 iters), loss = 0.215548
I0418 17:50:36.166960  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 17:50:36.166965  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:50:36.166970  2203 solver.cpp:238]     Train net output #2: loss = 0.215548 (* 1 = 0.215548 loss)
I0418 17:50:36.166973  2203 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0418 17:50:58.105443  2203 solver.cpp:331] Iteration 23000, Testing net (#0)
I0418 17:51:02.728099  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:51:02.887630  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.8192
I0418 17:51:02.887655  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9883
I0418 17:51:02.887678  2203 solver.cpp:398]     Test net output #2: loss = 0.62516 (* 1 = 0.62516 loss)
I0418 17:51:03.111760  2203 solver.cpp:219] Iteration 23000 (3.71156 iter/s, 26.9428s/100 iters), loss = 0.226955
I0418 17:51:03.111779  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 17:51:03.111800  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:51:03.111807  2203 solver.cpp:238]     Train net output #2: loss = 0.226955 (* 1 = 0.226955 loss)
I0418 17:51:03.111812  2203 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0418 17:51:12.467214  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:51:25.297197  2203 solver.cpp:219] Iteration 23100 (4.50788 iter/s, 22.1834s/100 iters), loss = 0.360392
I0418 17:51:25.297233  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 17:51:25.297240  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:51:25.297246  2203 solver.cpp:238]     Train net output #2: loss = 0.360392 (* 1 = 0.360392 loss)
I0418 17:51:25.297251  2203 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0418 17:51:47.455366  2203 solver.cpp:219] Iteration 23200 (4.51343 iter/s, 22.1561s/100 iters), loss = 0.269901
I0418 17:51:47.455535  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:51:47.455543  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:51:47.455549  2203 solver.cpp:238]     Train net output #2: loss = 0.269901 (* 1 = 0.269901 loss)
I0418 17:51:47.455554  2203 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0418 17:52:09.666528  2203 solver.cpp:219] Iteration 23300 (4.50266 iter/s, 22.2091s/100 iters), loss = 0.256488
I0418 17:52:09.666563  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 17:52:09.666568  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:52:09.666574  2203 solver.cpp:238]     Train net output #2: loss = 0.256488 (* 1 = 0.256488 loss)
I0418 17:52:09.666577  2203 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0418 17:52:31.822571  2203 solver.cpp:219] Iteration 23400 (4.51388 iter/s, 22.1539s/100 iters), loss = 0.377343
I0418 17:52:31.822633  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:52:31.822638  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:52:31.822644  2203 solver.cpp:238]     Train net output #2: loss = 0.377343 (* 1 = 0.377343 loss)
I0418 17:52:31.822649  2203 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0418 17:52:39.170032  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:52:53.996034  2203 solver.cpp:219] Iteration 23500 (4.51031 iter/s, 22.1714s/100 iters), loss = 0.341363
I0418 17:52:53.996070  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:52:53.996075  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:52:53.996081  2203 solver.cpp:238]     Train net output #2: loss = 0.341363 (* 1 = 0.341363 loss)
I0418 17:52:53.996085  2203 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0418 17:53:16.196065  2203 solver.cpp:219] Iteration 23600 (4.50493 iter/s, 22.1979s/100 iters), loss = 0.182062
I0418 17:53:16.196218  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 17:53:16.196225  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:53:16.196233  2203 solver.cpp:238]     Train net output #2: loss = 0.182062 (* 1 = 0.182062 loss)
I0418 17:53:16.196240  2203 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0418 17:53:38.382266  2203 solver.cpp:219] Iteration 23700 (4.50772 iter/s, 22.1842s/100 iters), loss = 0.35865
I0418 17:53:38.382302  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 17:53:38.382306  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:53:38.382313  2203 solver.cpp:238]     Train net output #2: loss = 0.35865 (* 1 = 0.35865 loss)
I0418 17:53:38.382316  2203 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0418 17:54:00.576056  2203 solver.cpp:219] Iteration 23800 (4.50618 iter/s, 22.1917s/100 iters), loss = 0.442659
I0418 17:54:00.576295  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 17:54:00.576304  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:54:00.576311  2203 solver.cpp:238]     Train net output #2: loss = 0.442659 (* 1 = 0.442659 loss)
I0418 17:54:00.576315  2203 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0418 17:54:05.933053  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:54:22.768395  2203 solver.cpp:219] Iteration 23900 (4.50648 iter/s, 22.1903s/100 iters), loss = 0.351497
I0418 17:54:22.768435  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:54:22.768440  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:54:22.768445  2203 solver.cpp:238]     Train net output #2: loss = 0.351497 (* 1 = 0.351497 loss)
I0418 17:54:22.768450  2203 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0418 17:54:44.714967  2203 solver.cpp:331] Iteration 24000, Testing net (#0)
I0418 17:54:49.303761  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:54:49.463349  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7095
I0418 17:54:49.463376  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9737
I0418 17:54:49.463398  2203 solver.cpp:398]     Test net output #2: loss = 1.01617 (* 1 = 1.01617 loss)
I0418 17:54:49.679471  2203 solver.cpp:219] Iteration 24000 (3.71622 iter/s, 26.909s/100 iters), loss = 0.23504
I0418 17:54:49.679493  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 17:54:49.679497  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 17:54:49.679503  2203 solver.cpp:238]     Train net output #2: loss = 0.23504 (* 1 = 0.23504 loss)
I0418 17:54:49.679508  2203 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0418 17:55:11.852380  2203 solver.cpp:219] Iteration 24100 (4.51043 iter/s, 22.1709s/100 iters), loss = 0.288468
I0418 17:55:11.852414  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 17:55:11.852418  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:55:11.852424  2203 solver.cpp:238]     Train net output #2: loss = 0.288468 (* 1 = 0.288468 loss)
I0418 17:55:11.852428  2203 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0418 17:55:34.072757  2203 solver.cpp:219] Iteration 24200 (4.50081 iter/s, 22.2182s/100 iters), loss = 0.313485
I0418 17:55:34.072913  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:55:34.072921  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:55:34.072927  2203 solver.cpp:238]     Train net output #2: loss = 0.313485 (* 1 = 0.313485 loss)
I0418 17:55:34.072932  2203 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0418 17:55:37.216322  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:55:56.273535  2203 solver.cpp:219] Iteration 24300 (4.50478 iter/s, 22.1986s/100 iters), loss = 0.389734
I0418 17:55:56.273571  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 17:55:56.273576  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:55:56.273581  2203 solver.cpp:238]     Train net output #2: loss = 0.389734 (* 1 = 0.389734 loss)
I0418 17:55:56.273586  2203 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0418 17:56:18.437198  2203 solver.cpp:219] Iteration 24400 (4.51232 iter/s, 22.1615s/100 iters), loss = 0.180351
I0418 17:56:18.437433  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 17:56:18.437463  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 17:56:18.437469  2203 solver.cpp:238]     Train net output #2: loss = 0.180351 (* 1 = 0.180351 loss)
I0418 17:56:18.437475  2203 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0418 17:56:40.616650  2203 solver.cpp:219] Iteration 24500 (4.50871 iter/s, 22.1793s/100 iters), loss = 0.241302
I0418 17:56:40.616684  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 17:56:40.616689  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:56:40.616695  2203 solver.cpp:238]     Train net output #2: loss = 0.241302 (* 1 = 0.241302 loss)
I0418 17:56:40.616699  2203 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0418 17:57:02.755234  2203 solver.cpp:219] Iteration 24600 (4.517 iter/s, 22.1386s/100 iters), loss = 0.231475
I0418 17:57:02.755384  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:57:02.755391  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:57:02.755398  2203 solver.cpp:238]     Train net output #2: loss = 0.231475 (* 1 = 0.231475 loss)
I0418 17:57:02.755403  2203 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0418 17:57:03.885895  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:57:25.024832  2203 solver.cpp:219] Iteration 24700 (4.49086 iter/s, 22.2675s/100 iters), loss = 0.312547
I0418 17:57:25.024865  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 17:57:25.024870  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:57:25.024876  2203 solver.cpp:238]     Train net output #2: loss = 0.312547 (* 1 = 0.312547 loss)
I0418 17:57:25.024880  2203 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0418 17:57:47.264058  2203 solver.cpp:219] Iteration 24800 (4.49698 iter/s, 22.2372s/100 iters), loss = 0.483758
I0418 17:57:47.264189  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 17:57:47.264195  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0418 17:57:47.264202  2203 solver.cpp:238]     Train net output #2: loss = 0.483758 (* 1 = 0.483758 loss)
I0418 17:57:47.264206  2203 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0418 17:58:09.477797  2203 solver.cpp:219] Iteration 24900 (4.50173 iter/s, 22.2137s/100 iters), loss = 0.220113
I0418 17:58:09.477828  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 17:58:09.477833  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:58:09.477838  2203 solver.cpp:238]     Train net output #2: loss = 0.220113 (* 1 = 0.220113 loss)
I0418 17:58:09.477841  2203 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0418 17:58:30.621403  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:58:31.535938  2203 solver.cpp:331] Iteration 25000, Testing net (#0)
I0418 17:58:36.016634  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 17:58:36.177319  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.8171
I0418 17:58:36.177343  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9853
I0418 17:58:36.177367  2203 solver.cpp:398]     Test net output #2: loss = 0.679992 (* 1 = 0.679992 loss)
I0418 17:58:36.403470  2203 solver.cpp:219] Iteration 25000 (3.71422 iter/s, 26.9236s/100 iters), loss = 0.261733
I0418 17:58:36.403492  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 17:58:36.403514  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:58:36.403520  2203 solver.cpp:238]     Train net output #2: loss = 0.261733 (* 1 = 0.261733 loss)
I0418 17:58:36.403527  2203 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0418 17:58:58.598389  2203 solver.cpp:219] Iteration 25100 (4.50596 iter/s, 22.1928s/100 iters), loss = 0.180064
I0418 17:58:58.598423  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 17:58:58.598428  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:58:58.598434  2203 solver.cpp:238]     Train net output #2: loss = 0.180064 (* 1 = 0.180064 loss)
I0418 17:58:58.598438  2203 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0418 17:59:20.783627  2203 solver.cpp:219] Iteration 25200 (4.5075 iter/s, 22.1853s/100 iters), loss = 0.425502
I0418 17:59:20.783807  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0418 17:59:20.783830  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:59:20.783838  2203 solver.cpp:238]     Train net output #2: loss = 0.425502 (* 1 = 0.425502 loss)
I0418 17:59:20.783841  2203 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0418 17:59:42.986682  2203 solver.cpp:219] Iteration 25300 (4.5039 iter/s, 22.203s/100 iters), loss = 0.272579
I0418 17:59:42.986716  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 17:59:42.986721  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 17:59:42.986727  2203 solver.cpp:238]     Train net output #2: loss = 0.272579 (* 1 = 0.272579 loss)
I0418 17:59:42.986732  2203 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0418 18:00:02.174486  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:00:05.217753  2203 solver.cpp:219] Iteration 25400 (4.4982 iter/s, 22.2311s/100 iters), loss = 0.306166
I0418 18:00:05.217785  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 18:00:05.217790  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:00:05.217797  2203 solver.cpp:238]     Train net output #2: loss = 0.306166 (* 1 = 0.306166 loss)
I0418 18:00:05.217800  2203 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0418 18:00:27.433599  2203 solver.cpp:219] Iteration 25500 (4.50171 iter/s, 22.2138s/100 iters), loss = 0.221471
I0418 18:00:27.433632  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:00:27.433637  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:00:27.433645  2203 solver.cpp:238]     Train net output #2: loss = 0.221471 (* 1 = 0.221471 loss)
I0418 18:00:27.433648  2203 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0418 18:00:49.622331  2203 solver.cpp:219] Iteration 25600 (4.50678 iter/s, 22.1888s/100 iters), loss = 0.449521
I0418 18:00:49.622385  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 18:00:49.622391  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:00:49.622397  2203 solver.cpp:238]     Train net output #2: loss = 0.449521 (* 1 = 0.449521 loss)
I0418 18:00:49.622401  2203 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0418 18:01:11.835813  2203 solver.cpp:219] Iteration 25700 (4.50177 iter/s, 22.2135s/100 iters), loss = 0.230318
I0418 18:01:11.835850  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 18:01:11.835855  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:01:11.835861  2203 solver.cpp:238]     Train net output #2: loss = 0.230318 (* 1 = 0.230318 loss)
I0418 18:01:11.835865  2203 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0418 18:01:28.938551  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:01:34.013825  2203 solver.cpp:219] Iteration 25800 (4.50939 iter/s, 22.176s/100 iters), loss = 0.209468
I0418 18:01:34.013864  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 18:01:34.013869  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:01:34.013875  2203 solver.cpp:238]     Train net output #2: loss = 0.209468 (* 1 = 0.209468 loss)
I0418 18:01:34.013880  2203 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0418 18:01:56.246098  2203 solver.cpp:219] Iteration 25900 (4.49838 iter/s, 22.2302s/100 iters), loss = 0.347198
I0418 18:01:56.246124  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 18:01:56.246129  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:01:56.246135  2203 solver.cpp:238]     Train net output #2: loss = 0.347198 (* 1 = 0.347198 loss)
I0418 18:01:56.246140  2203 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0418 18:02:18.367501  2203 solver.cpp:331] Iteration 26000, Testing net (#0)
I0418 18:02:22.927754  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:02:23.135362  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7797
I0418 18:02:23.135388  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9894
I0418 18:02:23.135412  2203 solver.cpp:398]     Test net output #2: loss = 0.791025 (* 1 = 0.791025 loss)
I0418 18:02:23.307657  2203 solver.cpp:219] Iteration 26000 (3.69555 iter/s, 27.0595s/100 iters), loss = 0.24126
I0418 18:02:23.307677  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:02:23.307698  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:02:23.307703  2203 solver.cpp:238]     Train net output #2: loss = 0.24126 (* 1 = 0.24126 loss)
I0418 18:02:23.307709  2203 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0418 18:02:45.573005  2203 solver.cpp:219] Iteration 26100 (4.4917 iter/s, 22.2633s/100 iters), loss = 0.381002
I0418 18:02:45.573073  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:02:45.573081  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:02:45.573087  2203 solver.cpp:238]     Train net output #2: loss = 0.381002 (* 1 = 0.381002 loss)
I0418 18:02:45.573092  2203 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0418 18:03:00.537211  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:03:07.867156  2203 solver.cpp:219] Iteration 26200 (4.48548 iter/s, 22.2942s/100 iters), loss = 0.157918
I0418 18:03:07.867198  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 18:03:07.867204  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:03:07.867210  2203 solver.cpp:238]     Train net output #2: loss = 0.157918 (* 1 = 0.157918 loss)
I0418 18:03:07.867214  2203 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0418 18:03:30.153491  2203 solver.cpp:219] Iteration 26300 (4.48705 iter/s, 22.2864s/100 iters), loss = 0.377364
I0418 18:03:30.153529  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 18:03:30.153534  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 18:03:30.153540  2203 solver.cpp:238]     Train net output #2: loss = 0.377364 (* 1 = 0.377364 loss)
I0418 18:03:30.153545  2203 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0418 18:03:52.419646  2203 solver.cpp:219] Iteration 26400 (4.49112 iter/s, 22.2662s/100 iters), loss = 0.341761
I0418 18:03:52.419823  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 18:03:52.419831  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:03:52.419838  2203 solver.cpp:238]     Train net output #2: loss = 0.341761 (* 1 = 0.341761 loss)
I0418 18:03:52.419843  2203 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0418 18:04:14.725818  2203 solver.cpp:219] Iteration 26500 (4.48347 iter/s, 22.3041s/100 iters), loss = 0.253307
I0418 18:04:14.725852  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:04:14.725857  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:04:14.725863  2203 solver.cpp:238]     Train net output #2: loss = 0.253307 (* 1 = 0.253307 loss)
I0418 18:04:14.725867  2203 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0418 18:04:27.678326  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:04:37.019067  2203 solver.cpp:219] Iteration 26600 (4.48608 iter/s, 22.2912s/100 iters), loss = 0.294229
I0418 18:04:37.019124  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:04:37.019129  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:04:37.019135  2203 solver.cpp:238]     Train net output #2: loss = 0.294229 (* 1 = 0.294229 loss)
I0418 18:04:37.019140  2203 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0418 18:04:59.294101  2203 solver.cpp:219] Iteration 26700 (4.48933 iter/s, 22.2751s/100 iters), loss = 0.321069
I0418 18:04:59.297329  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:04:59.297353  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:04:59.297368  2203 solver.cpp:238]     Train net output #2: loss = 0.321069 (* 1 = 0.321069 loss)
I0418 18:04:59.297377  2203 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0418 18:05:21.533264  2203 solver.cpp:219] Iteration 26800 (4.49741 iter/s, 22.235s/100 iters), loss = 0.299357
I0418 18:05:21.533305  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 18:05:21.533311  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:05:21.533318  2203 solver.cpp:238]     Train net output #2: loss = 0.299357 (* 1 = 0.299357 loss)
I0418 18:05:21.533321  2203 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0418 18:05:43.824844  2203 solver.cpp:219] Iteration 26900 (4.48641 iter/s, 22.2895s/100 iters), loss = 0.330997
I0418 18:05:43.825011  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 18:05:43.825021  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:05:43.825029  2203 solver.cpp:238]     Train net output #2: loss = 0.330997 (* 1 = 0.330997 loss)
I0418 18:05:43.825037  2203 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0418 18:05:54.773756  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:06:05.892062  2203 solver.cpp:331] Iteration 27000, Testing net (#0)
I0418 18:06:10.499585  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:06:10.660547  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.709
I0418 18:06:10.660579  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9573
I0418 18:06:10.660586  2203 solver.cpp:398]     Test net output #2: loss = 1.0631 (* 1 = 1.0631 loss)
I0418 18:06:10.887054  2203 solver.cpp:219] Iteration 27000 (3.69548 iter/s, 27.0601s/100 iters), loss = 0.327052
I0418 18:06:10.887076  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:06:10.887081  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:06:10.887086  2203 solver.cpp:238]     Train net output #2: loss = 0.327052 (* 1 = 0.327052 loss)
I0418 18:06:10.887092  2203 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0418 18:06:33.177796  2203 solver.cpp:219] Iteration 27100 (4.4866 iter/s, 22.2886s/100 iters), loss = 0.160361
I0418 18:06:33.178336  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 18:06:33.178359  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:06:33.178375  2203 solver.cpp:238]     Train net output #2: loss = 0.160361 (* 1 = 0.160361 loss)
I0418 18:06:33.178385  2203 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0418 18:06:55.450698  2203 solver.cpp:219] Iteration 27200 (4.49018 iter/s, 22.2708s/100 iters), loss = 0.308839
I0418 18:06:55.450742  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:06:55.450747  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:06:55.450753  2203 solver.cpp:238]     Train net output #2: loss = 0.308839 (* 1 = 0.308839 loss)
I0418 18:06:55.450757  2203 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0418 18:07:17.696391  2203 solver.cpp:219] Iteration 27300 (4.49569 iter/s, 22.2435s/100 iters), loss = 0.248085
I0418 18:07:17.696619  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:07:17.696626  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:07:17.696633  2203 solver.cpp:238]     Train net output #2: loss = 0.248085 (* 1 = 0.248085 loss)
I0418 18:07:17.696637  2203 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0418 18:07:26.428050  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:07:39.935644  2203 solver.cpp:219] Iteration 27400 (4.49697 iter/s, 22.2372s/100 iters), loss = 0.168972
I0418 18:07:39.935683  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 18:07:39.935688  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:07:39.935693  2203 solver.cpp:238]     Train net output #2: loss = 0.168972 (* 1 = 0.168972 loss)
I0418 18:07:39.935698  2203 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0418 18:08:02.412353  2203 solver.cpp:219] Iteration 27500 (4.44946 iter/s, 22.4747s/100 iters), loss = 0.316541
I0418 18:08:02.412518  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 18:08:02.412526  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:08:02.412533  2203 solver.cpp:238]     Train net output #2: loss = 0.316541 (* 1 = 0.316541 loss)
I0418 18:08:02.412538  2203 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0418 18:08:24.658556  2203 solver.cpp:219] Iteration 27600 (4.49558 iter/s, 22.2441s/100 iters), loss = 0.378277
I0418 18:08:24.658597  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 18:08:24.658602  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:08:24.658608  2203 solver.cpp:238]     Train net output #2: loss = 0.378277 (* 1 = 0.378277 loss)
I0418 18:08:24.658613  2203 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0418 18:08:46.902062  2203 solver.cpp:219] Iteration 27700 (4.49613 iter/s, 22.2414s/100 iters), loss = 0.224414
I0418 18:08:46.902302  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 18:08:46.902308  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:08:46.902315  2203 solver.cpp:238]     Train net output #2: loss = 0.224414 (* 1 = 0.224414 loss)
I0418 18:08:46.902319  2203 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0418 18:08:53.653410  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:09:09.192785  2203 solver.cpp:219] Iteration 27800 (4.48658 iter/s, 22.2887s/100 iters), loss = 0.245438
I0418 18:09:09.192819  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:09:09.192824  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:09:09.192831  2203 solver.cpp:238]     Train net output #2: loss = 0.245438 (* 1 = 0.245438 loss)
I0418 18:09:09.192834  2203 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0418 18:09:31.439097  2203 solver.cpp:219] Iteration 27900 (4.49555 iter/s, 22.2442s/100 iters), loss = 0.325585
I0418 18:09:31.439301  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 18:09:31.439309  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:09:31.439316  2203 solver.cpp:238]     Train net output #2: loss = 0.325585 (* 1 = 0.325585 loss)
I0418 18:09:31.439321  2203 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0418 18:09:53.504233  2203 solver.cpp:331] Iteration 28000, Testing net (#0)
I0418 18:09:58.064265  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:09:58.271925  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7478
I0418 18:09:58.271960  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9835
I0418 18:09:58.271967  2203 solver.cpp:398]     Test net output #2: loss = 0.982746 (* 1 = 0.982746 loss)
I0418 18:09:58.435463  2203 solver.cpp:219] Iteration 28000 (3.70421 iter/s, 26.9963s/100 iters), loss = 0.2189
I0418 18:09:58.435487  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 18:09:58.435492  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:09:58.435497  2203 solver.cpp:238]     Train net output #2: loss = 0.2189 (* 1 = 0.2189 loss)
I0418 18:09:58.435503  2203 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0418 18:10:20.718708  2203 solver.cpp:219] Iteration 28100 (4.48767 iter/s, 22.2833s/100 iters), loss = 0.238907
I0418 18:10:20.718776  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:10:20.718782  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:10:20.718788  2203 solver.cpp:238]     Train net output #2: loss = 0.238907 (* 1 = 0.238907 loss)
I0418 18:10:20.718793  2203 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0418 18:10:25.222944  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:10:42.979976  2203 solver.cpp:219] Iteration 28200 (4.4921 iter/s, 22.2613s/100 iters), loss = 0.321596
I0418 18:10:42.980013  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 18:10:42.980018  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:10:42.980026  2203 solver.cpp:238]     Train net output #2: loss = 0.321596 (* 1 = 0.321596 loss)
I0418 18:10:42.980029  2203 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0418 18:11:05.241364  2203 solver.cpp:219] Iteration 28300 (4.49251 iter/s, 22.2593s/100 iters), loss = 0.318037
I0418 18:11:05.241508  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:11:05.241515  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:11:05.241523  2203 solver.cpp:238]     Train net output #2: loss = 0.318037 (* 1 = 0.318037 loss)
I0418 18:11:05.241526  2203 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0418 18:11:27.446192  2203 solver.cpp:219] Iteration 28400 (4.50394 iter/s, 22.2028s/100 iters), loss = 0.274211
I0418 18:11:27.446234  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 18:11:27.446244  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:11:27.446249  2203 solver.cpp:238]     Train net output #2: loss = 0.274211 (* 1 = 0.274211 loss)
I0418 18:11:27.446255  2203 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0418 18:11:49.717968  2203 solver.cpp:219] Iteration 28500 (4.49042 iter/s, 22.2696s/100 iters), loss = 0.276915
I0418 18:11:49.718154  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:11:49.718161  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:11:49.718168  2203 solver.cpp:238]     Train net output #2: loss = 0.276915 (* 1 = 0.276915 loss)
I0418 18:11:49.718173  2203 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0418 18:11:52.216680  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:12:12.022680  2203 solver.cpp:219] Iteration 28600 (4.48338 iter/s, 22.3046s/100 iters), loss = 0.181422
I0418 18:12:12.022718  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 18:12:12.022723  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:12:12.022729  2203 solver.cpp:238]     Train net output #2: loss = 0.181422 (* 1 = 0.181422 loss)
I0418 18:12:12.022733  2203 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0418 18:12:34.319504  2203 solver.cpp:219] Iteration 28700 (4.48494 iter/s, 22.2969s/100 iters), loss = 0.316163
I0418 18:12:34.319705  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 18:12:34.319713  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:12:34.319720  2203 solver.cpp:238]     Train net output #2: loss = 0.316163 (* 1 = 0.316163 loss)
I0418 18:12:34.319725  2203 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0418 18:12:56.610882  2203 solver.cpp:219] Iteration 28800 (4.48606 iter/s, 22.2913s/100 iters), loss = 0.315432
I0418 18:12:56.610922  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:12:56.610927  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:12:56.610934  2203 solver.cpp:238]     Train net output #2: loss = 0.315432 (* 1 = 0.315432 loss)
I0418 18:12:56.610937  2203 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0418 18:13:18.826019  2203 solver.cpp:219] Iteration 28900 (4.50143 iter/s, 22.2152s/100 iters), loss = 0.347474
I0418 18:13:18.826122  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:13:18.826128  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 18:13:18.826133  2203 solver.cpp:238]     Train net output #2: loss = 0.347474 (* 1 = 0.347474 loss)
I0418 18:13:18.826138  2203 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0418 18:13:19.278960  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:13:40.869230  2203 solver.cpp:331] Iteration 29000, Testing net (#0)
I0418 18:13:45.406692  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:13:45.585445  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7408
I0418 18:13:45.585477  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9838
I0418 18:13:45.585484  2203 solver.cpp:398]     Test net output #2: loss = 1.02956 (* 1 = 1.02956 loss)
I0418 18:13:45.792590  2203 solver.cpp:219] Iteration 29000 (3.70858 iter/s, 26.9645s/100 iters), loss = 0.258568
I0418 18:13:45.792614  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:13:45.792619  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:13:45.792624  2203 solver.cpp:238]     Train net output #2: loss = 0.258568 (* 1 = 0.258568 loss)
I0418 18:13:45.792630  2203 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0418 18:14:08.262549  2203 solver.cpp:219] Iteration 29100 (4.45079 iter/s, 22.4679s/100 iters), loss = 0.225878
I0418 18:14:08.262763  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 18:14:08.262771  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:14:08.262778  2203 solver.cpp:238]     Train net output #2: loss = 0.225878 (* 1 = 0.225878 loss)
I0418 18:14:08.262784  2203 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0418 18:14:30.528918  2203 solver.cpp:219] Iteration 29200 (4.49149 iter/s, 22.2643s/100 iters), loss = 0.252646
I0418 18:14:30.528960  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:14:30.528965  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:14:30.528971  2203 solver.cpp:238]     Train net output #2: loss = 0.252646 (* 1 = 0.252646 loss)
I0418 18:14:30.528975  2203 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0418 18:14:51.044936  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:14:52.782176  2203 solver.cpp:219] Iteration 29300 (4.49415 iter/s, 22.2511s/100 iters), loss = 0.22447
I0418 18:14:52.782217  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:14:52.782223  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:14:52.782228  2203 solver.cpp:238]     Train net output #2: loss = 0.22447 (* 1 = 0.22447 loss)
I0418 18:14:52.782233  2203 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0418 18:15:15.044019  2203 solver.cpp:219] Iteration 29400 (4.4924 iter/s, 22.2598s/100 iters), loss = 0.333188
I0418 18:15:15.044056  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0418 18:15:15.044061  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:15:15.044067  2203 solver.cpp:238]     Train net output #2: loss = 0.333188 (* 1 = 0.333188 loss)
I0418 18:15:15.044071  2203 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0418 18:15:37.289814  2203 solver.cpp:219] Iteration 29500 (4.49565 iter/s, 22.2437s/100 iters), loss = 0.242051
I0418 18:15:37.289986  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:15:37.289994  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:15:37.290000  2203 solver.cpp:238]     Train net output #2: loss = 0.242051 (* 1 = 0.242051 loss)
I0418 18:15:37.290004  2203 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0418 18:15:59.530467  2203 solver.cpp:219] Iteration 29600 (4.49669 iter/s, 22.2386s/100 iters), loss = 0.191743
I0418 18:15:59.530508  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 18:15:59.530513  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:15:59.530519  2203 solver.cpp:238]     Train net output #2: loss = 0.191743 (* 1 = 0.191743 loss)
I0418 18:15:59.530522  2203 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0418 18:16:18.034677  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:16:21.817939  2203 solver.cpp:219] Iteration 29700 (4.48682 iter/s, 22.2875s/100 iters), loss = 0.350125
I0418 18:16:21.817976  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 18:16:21.817981  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:16:21.817987  2203 solver.cpp:238]     Train net output #2: loss = 0.350125 (* 1 = 0.350125 loss)
I0418 18:16:21.817991  2203 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0418 18:16:44.110354  2203 solver.cpp:219] Iteration 29800 (4.48582 iter/s, 22.2925s/100 iters), loss = 0.320411
I0418 18:16:44.110389  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 18:16:44.110394  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:16:44.110400  2203 solver.cpp:238]     Train net output #2: loss = 0.320411 (* 1 = 0.320411 loss)
I0418 18:16:44.110404  2203 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0418 18:17:06.401654  2203 solver.cpp:219] Iteration 29900 (4.48605 iter/s, 22.2913s/100 iters), loss = 0.302405
I0418 18:17:06.401876  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 18:17:06.401885  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:17:06.401891  2203 solver.cpp:238]     Train net output #2: loss = 0.302405 (* 1 = 0.302405 loss)
I0418 18:17:06.401896  2203 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0418 18:17:28.482082  2203 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_highway_padded_data_iter_30000.caffemodel
I0418 18:17:28.562865  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_highway_padded_data_iter_30000.solverstate
I0418 18:17:28.670914  2203 solver.cpp:331] Iteration 30000, Testing net (#0)
I0418 18:17:33.243641  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:17:33.455206  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7635
I0418 18:17:33.455229  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9726
I0418 18:17:33.455235  2203 solver.cpp:398]     Test net output #2: loss = 0.844505 (* 1 = 0.844505 loss)
I0418 18:17:33.619880  2203 solver.cpp:219] Iteration 30000 (3.67402 iter/s, 27.2181s/100 iters), loss = 0.230579
I0418 18:17:33.619900  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:17:33.619905  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:17:33.619910  2203 solver.cpp:238]     Train net output #2: loss = 0.230579 (* 1 = 0.230579 loss)
I0418 18:17:33.619915  2203 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0418 18:17:50.170840  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:17:55.919153  2203 solver.cpp:219] Iteration 30100 (4.48486 iter/s, 22.2972s/100 iters), loss = 0.154781
I0418 18:17:55.919189  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:17:55.919195  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:17:55.919201  2203 solver.cpp:238]     Train net output #2: loss = 0.154781 (* 1 = 0.154781 loss)
I0418 18:17:55.919205  2203 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0418 18:18:18.193959  2203 solver.cpp:219] Iteration 30200 (4.4898 iter/s, 22.2727s/100 iters), loss = 0.310971
I0418 18:18:18.193995  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:18:18.194000  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:18:18.194006  2203 solver.cpp:238]     Train net output #2: loss = 0.310971 (* 1 = 0.310971 loss)
I0418 18:18:18.194010  2203 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0418 18:18:40.477170  2203 solver.cpp:219] Iteration 30300 (4.48811 iter/s, 22.2811s/100 iters), loss = 0.275354
I0418 18:18:40.477242  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:18:40.477249  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:18:40.477255  2203 solver.cpp:238]     Train net output #2: loss = 0.275354 (* 1 = 0.275354 loss)
I0418 18:18:40.477260  2203 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0418 18:19:02.782042  2203 solver.cpp:219] Iteration 30400 (4.48374 iter/s, 22.3028s/100 iters), loss = 0.297687
I0418 18:19:02.782083  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 18:19:02.782088  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:19:02.782094  2203 solver.cpp:238]     Train net output #2: loss = 0.297687 (* 1 = 0.297687 loss)
I0418 18:19:02.782099  2203 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0418 18:19:17.098754  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:19:25.062788  2203 solver.cpp:219] Iteration 30500 (4.48859 iter/s, 22.2787s/100 iters), loss = 0.296891
I0418 18:19:25.062827  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:19:25.062834  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:19:25.062839  2203 solver.cpp:238]     Train net output #2: loss = 0.296891 (* 1 = 0.296891 loss)
I0418 18:19:25.062844  2203 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0418 18:19:47.412374  2203 solver.cpp:219] Iteration 30600 (4.47476 iter/s, 22.3475s/100 iters), loss = 0.317217
I0418 18:19:47.412503  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0418 18:19:47.412509  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:19:47.412516  2203 solver.cpp:238]     Train net output #2: loss = 0.317217 (* 1 = 0.317217 loss)
I0418 18:19:47.412520  2203 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0418 18:20:09.871836  2203 solver.cpp:219] Iteration 30700 (4.45247 iter/s, 22.4594s/100 iters), loss = 0.19393
I0418 18:20:09.871876  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:20:09.871882  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:20:09.871888  2203 solver.cpp:238]     Train net output #2: loss = 0.19393 (* 1 = 0.19393 loss)
I0418 18:20:09.871892  2203 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0418 18:20:32.131563  2203 solver.cpp:219] Iteration 30800 (4.49284 iter/s, 22.2577s/100 iters), loss = 0.375176
I0418 18:20:32.131692  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 18:20:32.131700  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:20:32.131705  2203 solver.cpp:238]     Train net output #2: loss = 0.375176 (* 1 = 0.375176 loss)
I0418 18:20:32.131709  2203 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0418 18:20:44.406520  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:20:54.440217  2203 solver.cpp:219] Iteration 30900 (4.48299 iter/s, 22.3066s/100 iters), loss = 0.252956
I0418 18:20:54.440256  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 18:20:54.440263  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:20:54.440268  2203 solver.cpp:238]     Train net output #2: loss = 0.252956 (* 1 = 0.252956 loss)
I0418 18:20:54.440273  2203 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0418 18:21:16.498050  2203 solver.cpp:331] Iteration 31000, Testing net (#0)
I0418 18:21:21.078163  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:21:21.285691  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7647
I0418 18:21:21.285712  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9843
I0418 18:21:21.285718  2203 solver.cpp:398]     Test net output #2: loss = 1.06377 (* 1 = 1.06377 loss)
I0418 18:21:21.447288  2203 solver.cpp:219] Iteration 31000 (3.70301 iter/s, 27.005s/100 iters), loss = 0.204005
I0418 18:21:21.447307  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 18:21:21.447312  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:21:21.447317  2203 solver.cpp:238]     Train net output #2: loss = 0.204005 (* 1 = 0.204005 loss)
I0418 18:21:21.447321  2203 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0418 18:21:43.726047  2203 solver.cpp:219] Iteration 31100 (4.48858 iter/s, 22.2788s/100 iters), loss = 0.337295
I0418 18:21:43.726088  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 18:21:43.726094  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:21:43.726099  2203 solver.cpp:238]     Train net output #2: loss = 0.337295 (* 1 = 0.337295 loss)
I0418 18:21:43.726104  2203 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0418 18:22:06.031774  2203 solver.cpp:219] Iteration 31200 (4.48315 iter/s, 22.3058s/100 iters), loss = 0.344449
I0418 18:22:06.031924  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 18:22:06.031932  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:22:06.031939  2203 solver.cpp:238]     Train net output #2: loss = 0.344449 (* 1 = 0.344449 loss)
I0418 18:22:06.031944  2203 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0418 18:22:16.091969  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:22:28.294320  2203 solver.cpp:219] Iteration 31300 (4.49228 iter/s, 22.2604s/100 iters), loss = 0.28039
I0418 18:22:28.294356  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:22:28.294363  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:22:28.294368  2203 solver.cpp:238]     Train net output #2: loss = 0.28039 (* 1 = 0.28039 loss)
I0418 18:22:28.294371  2203 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0418 18:22:50.582073  2203 solver.cpp:219] Iteration 31400 (4.48676 iter/s, 22.2878s/100 iters), loss = 0.203892
I0418 18:22:50.582196  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:22:50.582204  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:22:50.582211  2203 solver.cpp:238]     Train net output #2: loss = 0.203892 (* 1 = 0.203892 loss)
I0418 18:22:50.582216  2203 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0418 18:23:12.873528  2203 solver.cpp:219] Iteration 31500 (4.48603 iter/s, 22.2914s/100 iters), loss = 0.372363
I0418 18:23:12.873566  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 18:23:12.873572  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:23:12.873577  2203 solver.cpp:238]     Train net output #2: loss = 0.372364 (* 1 = 0.372364 loss)
I0418 18:23:12.873582  2203 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0418 18:23:35.149158  2203 solver.cpp:219] Iteration 31600 (4.4892 iter/s, 22.2757s/100 iters), loss = 0.275269
I0418 18:23:35.149336  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:23:35.149343  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:23:35.149350  2203 solver.cpp:238]     Train net output #2: loss = 0.275269 (* 1 = 0.275269 loss)
I0418 18:23:35.149354  2203 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0418 18:23:43.200153  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:23:57.436113  2203 solver.cpp:219] Iteration 31700 (4.48695 iter/s, 22.2869s/100 iters), loss = 0.271703
I0418 18:23:57.436149  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:23:57.436154  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:23:57.436161  2203 solver.cpp:238]     Train net output #2: loss = 0.271703 (* 1 = 0.271703 loss)
I0418 18:23:57.436164  2203 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0418 18:24:19.719311  2203 solver.cpp:219] Iteration 31800 (4.48768 iter/s, 22.2832s/100 iters), loss = 0.309209
I0418 18:24:19.719480  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:24:19.719488  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:24:19.719496  2203 solver.cpp:238]     Train net output #2: loss = 0.309209 (* 1 = 0.309209 loss)
I0418 18:24:19.719501  2203 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0418 18:24:42.009222  2203 solver.cpp:219] Iteration 31900 (4.48635 iter/s, 22.2898s/100 iters), loss = 0.539544
I0418 18:24:42.009265  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.804688
I0418 18:24:42.009270  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:24:42.009276  2203 solver.cpp:238]     Train net output #2: loss = 0.539544 (* 1 = 0.539544 loss)
I0418 18:24:42.009280  2203 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0418 18:25:04.127821  2203 solver.cpp:331] Iteration 32000, Testing net (#0)
I0418 18:25:08.689990  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:25:08.900151  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7947
I0418 18:25:08.900173  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9863
I0418 18:25:08.900180  2203 solver.cpp:398]     Test net output #2: loss = 0.695031 (* 1 = 0.695031 loss)
I0418 18:25:09.067117  2203 solver.cpp:219] Iteration 32000 (3.69577 iter/s, 27.058s/100 iters), loss = 0.279522
I0418 18:25:09.067137  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:25:09.067142  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:25:09.067147  2203 solver.cpp:238]     Train net output #2: loss = 0.279522 (* 1 = 0.279522 loss)
I0418 18:25:09.067150  2203 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0418 18:25:15.135161  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:25:31.335343  2203 solver.cpp:219] Iteration 32100 (4.49112 iter/s, 22.2662s/100 iters), loss = 0.333879
I0418 18:25:31.335383  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 18:25:31.335389  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:25:31.335394  2203 solver.cpp:238]     Train net output #2: loss = 0.333879 (* 1 = 0.333879 loss)
I0418 18:25:31.335398  2203 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0418 18:25:53.866935  2203 solver.cpp:219] Iteration 32200 (4.43862 iter/s, 22.5295s/100 iters), loss = 0.258076
I0418 18:25:53.867136  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:25:53.867143  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:25:53.867149  2203 solver.cpp:238]     Train net output #2: loss = 0.258076 (* 1 = 0.258076 loss)
I0418 18:25:53.867154  2203 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0418 18:26:16.165877  2203 solver.cpp:219] Iteration 32300 (4.48454 iter/s, 22.2988s/100 iters), loss = 0.469779
I0418 18:26:16.165917  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 18:26:16.165922  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:26:16.165928  2203 solver.cpp:238]     Train net output #2: loss = 0.469779 (* 1 = 0.469779 loss)
I0418 18:26:16.165932  2203 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0418 18:26:38.449522  2203 solver.cpp:219] Iteration 32400 (4.48759 iter/s, 22.2837s/100 iters), loss = 0.263888
I0418 18:26:38.449676  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 18:26:38.449683  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:26:38.449689  2203 solver.cpp:238]     Train net output #2: loss = 0.263888 (* 1 = 0.263888 loss)
I0418 18:26:38.449693  2203 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0418 18:26:42.264356  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:27:00.736495  2203 solver.cpp:219] Iteration 32500 (4.48694 iter/s, 22.2869s/100 iters), loss = 0.248184
I0418 18:27:00.736533  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:27:00.736538  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:27:00.736544  2203 solver.cpp:238]     Train net output #2: loss = 0.248184 (* 1 = 0.248184 loss)
I0418 18:27:00.736548  2203 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0418 18:27:23.016471  2203 solver.cpp:219] Iteration 32600 (4.48833 iter/s, 22.28s/100 iters), loss = 0.334628
I0418 18:27:23.016618  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 18:27:23.016625  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:27:23.016633  2203 solver.cpp:238]     Train net output #2: loss = 0.334628 (* 1 = 0.334628 loss)
I0418 18:27:23.016638  2203 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0418 18:27:45.305426  2203 solver.cpp:219] Iteration 32700 (4.48654 iter/s, 22.2889s/100 iters), loss = 0.166032
I0418 18:27:45.305466  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 18:27:45.305472  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:27:45.305477  2203 solver.cpp:238]     Train net output #2: loss = 0.166032 (* 1 = 0.166032 loss)
I0418 18:27:45.305482  2203 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0418 18:28:07.594558  2203 solver.cpp:219] Iteration 32800 (4.48649 iter/s, 22.2892s/100 iters), loss = 0.216819
I0418 18:28:07.594674  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:28:07.594707  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:28:07.594712  2203 solver.cpp:238]     Train net output #2: loss = 0.216819 (* 1 = 0.216819 loss)
I0418 18:28:07.594717  2203 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0418 18:28:09.398900  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:28:29.878552  2203 solver.cpp:219] Iteration 32900 (4.48753 iter/s, 22.284s/100 iters), loss = 0.13548
I0418 18:28:29.878587  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 18:28:29.878593  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:28:29.878599  2203 solver.cpp:238]     Train net output #2: loss = 0.13548 (* 1 = 0.13548 loss)
I0418 18:28:29.878603  2203 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0418 18:28:51.945448  2203 solver.cpp:331] Iteration 33000, Testing net (#0)
I0418 18:28:56.505691  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:28:56.715004  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7729
I0418 18:28:56.715031  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9872
I0418 18:28:56.715039  2203 solver.cpp:398]     Test net output #2: loss = 0.814885 (* 1 = 0.814885 loss)
I0418 18:28:56.883565  2203 solver.cpp:219] Iteration 33000 (3.70301 iter/s, 27.0051s/100 iters), loss = 0.223233
I0418 18:28:56.883590  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:28:56.883595  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:28:56.883601  2203 solver.cpp:238]     Train net output #2: loss = 0.223233 (* 1 = 0.223233 loss)
I0418 18:28:56.883607  2203 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0418 18:29:19.161187  2203 solver.cpp:219] Iteration 33100 (4.48885 iter/s, 22.2774s/100 iters), loss = 0.389709
I0418 18:29:19.161226  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 18:29:19.161232  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:29:19.161240  2203 solver.cpp:238]     Train net output #2: loss = 0.389709 (* 1 = 0.389709 loss)
I0418 18:29:19.161245  2203 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0418 18:29:41.205554  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:29:41.426164  2203 solver.cpp:219] Iteration 33200 (4.49135 iter/s, 22.265s/100 iters), loss = 0.320208
I0418 18:29:41.426194  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:29:41.426199  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:29:41.426205  2203 solver.cpp:238]     Train net output #2: loss = 0.320208 (* 1 = 0.320208 loss)
I0418 18:29:41.426209  2203 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0418 18:30:03.715471  2203 solver.cpp:219] Iteration 33300 (4.48687 iter/s, 22.2872s/100 iters), loss = 0.230387
I0418 18:30:03.715509  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:30:03.715515  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:30:03.715522  2203 solver.cpp:238]     Train net output #2: loss = 0.230387 (* 1 = 0.230387 loss)
I0418 18:30:03.715525  2203 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0418 18:30:26.016582  2203 solver.cpp:219] Iteration 33400 (4.48449 iter/s, 22.2991s/100 iters), loss = 0.315921
I0418 18:30:26.016644  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:30:26.016650  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:30:26.016656  2203 solver.cpp:238]     Train net output #2: loss = 0.315921 (* 1 = 0.315921 loss)
I0418 18:30:26.016660  2203 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0418 18:30:48.294775  2203 solver.cpp:219] Iteration 33500 (4.48869 iter/s, 22.2782s/100 iters), loss = 0.490527
I0418 18:30:48.294816  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0418 18:30:48.294821  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:30:48.294827  2203 solver.cpp:238]     Train net output #2: loss = 0.490527 (* 1 = 0.490527 loss)
I0418 18:30:48.294831  2203 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0418 18:31:08.154539  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:31:10.593113  2203 solver.cpp:219] Iteration 33600 (4.48463 iter/s, 22.2984s/100 iters), loss = 0.390944
I0418 18:31:10.593150  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 18:31:10.593155  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:31:10.593161  2203 solver.cpp:238]     Train net output #2: loss = 0.390944 (* 1 = 0.390944 loss)
I0418 18:31:10.593166  2203 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0418 18:31:32.869202  2203 solver.cpp:219] Iteration 33700 (4.48911 iter/s, 22.2761s/100 iters), loss = 0.258109
I0418 18:31:32.869244  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:31:32.869251  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:31:32.869256  2203 solver.cpp:238]     Train net output #2: loss = 0.258109 (* 1 = 0.258109 loss)
I0418 18:31:32.869262  2203 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0418 18:31:55.337203  2203 solver.cpp:219] Iteration 33800 (4.45077 iter/s, 22.468s/100 iters), loss = 0.207621
I0418 18:31:55.337352  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:31:55.337359  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:31:55.337366  2203 solver.cpp:238]     Train net output #2: loss = 0.207621 (* 1 = 0.207621 loss)
I0418 18:31:55.337371  2203 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0418 18:32:17.655583  2203 solver.cpp:219] Iteration 33900 (4.48102 iter/s, 22.3163s/100 iters), loss = 0.325622
I0418 18:32:17.655622  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:32:17.655628  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:32:17.655634  2203 solver.cpp:238]     Train net output #2: loss = 0.325622 (* 1 = 0.325622 loss)
I0418 18:32:17.655638  2203 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0418 18:32:35.570904  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:32:39.791945  2203 solver.cpp:331] Iteration 34000, Testing net (#0)
I0418 18:32:44.401414  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:32:44.578027  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.785
I0418 18:32:44.578050  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9823
I0418 18:32:44.578058  2203 solver.cpp:398]     Test net output #2: loss = 0.834706 (* 1 = 0.834706 loss)
I0418 18:32:44.772783  2203 solver.cpp:219] Iteration 34000 (3.68797 iter/s, 27.1152s/100 iters), loss = 0.238007
I0418 18:32:44.772804  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 18:32:44.772809  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:32:44.772814  2203 solver.cpp:238]     Train net output #2: loss = 0.238007 (* 1 = 0.238007 loss)
I0418 18:32:44.772817  2203 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0418 18:33:07.066552  2203 solver.cpp:219] Iteration 34100 (4.48556 iter/s, 22.2938s/100 iters), loss = 0.325511
I0418 18:33:07.066732  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:33:07.066740  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 18:33:07.066746  2203 solver.cpp:238]     Train net output #2: loss = 0.325511 (* 1 = 0.325511 loss)
I0418 18:33:07.066751  2203 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0418 18:33:29.355382  2203 solver.cpp:219] Iteration 34200 (4.48657 iter/s, 22.2887s/100 iters), loss = 0.218178
I0418 18:33:29.355418  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:33:29.355423  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:33:29.355429  2203 solver.cpp:238]     Train net output #2: loss = 0.218178 (* 1 = 0.218178 loss)
I0418 18:33:29.355433  2203 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0418 18:33:51.651152  2203 solver.cpp:219] Iteration 34300 (4.48515 iter/s, 22.2958s/100 iters), loss = 0.363171
I0418 18:33:51.651320  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 18:33:51.651329  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:33:51.651335  2203 solver.cpp:238]     Train net output #2: loss = 0.363171 (* 1 = 0.363171 loss)
I0418 18:33:51.651340  2203 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0418 18:34:07.288594  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:34:13.947625  2203 solver.cpp:219] Iteration 34400 (4.48503 iter/s, 22.2964s/100 iters), loss = 0.224556
I0418 18:34:13.947679  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 18:34:13.947685  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:34:13.947690  2203 solver.cpp:238]     Train net output #2: loss = 0.224556 (* 1 = 0.224556 loss)
I0418 18:34:13.947695  2203 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0418 18:34:36.228209  2203 solver.cpp:219] Iteration 34500 (4.48821 iter/s, 22.2806s/100 iters), loss = 0.306674
I0418 18:34:36.228322  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:34:36.228328  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:34:36.228334  2203 solver.cpp:238]     Train net output #2: loss = 0.306673 (* 1 = 0.306673 loss)
I0418 18:34:36.228338  2203 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0418 18:34:58.519131  2203 solver.cpp:219] Iteration 34600 (4.48614 iter/s, 22.2909s/100 iters), loss = 0.280111
I0418 18:34:58.519165  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:34:58.519170  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:34:58.519176  2203 solver.cpp:238]     Train net output #2: loss = 0.280111 (* 1 = 0.280111 loss)
I0418 18:34:58.519181  2203 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0418 18:35:20.805896  2203 solver.cpp:219] Iteration 34700 (4.48696 iter/s, 22.2868s/100 iters), loss = 0.34748
I0418 18:35:20.805968  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 18:35:20.805974  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:35:20.805980  2203 solver.cpp:238]     Train net output #2: loss = 0.34748 (* 1 = 0.34748 loss)
I0418 18:35:20.805984  2203 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0418 18:35:34.402143  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:35:43.084950  2203 solver.cpp:219] Iteration 34800 (4.48852 iter/s, 22.2791s/100 iters), loss = 0.254061
I0418 18:35:43.084990  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 18:35:43.084996  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:35:43.085002  2203 solver.cpp:238]     Train net output #2: loss = 0.254061 (* 1 = 0.254061 loss)
I0418 18:35:43.085006  2203 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0418 18:36:05.377974  2203 solver.cpp:219] Iteration 34900 (4.48612 iter/s, 22.291s/100 iters), loss = 0.420138
I0418 18:36:05.378116  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0418 18:36:05.378124  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:36:05.378131  2203 solver.cpp:238]     Train net output #2: loss = 0.420138 (* 1 = 0.420138 loss)
I0418 18:36:05.378137  2203 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0418 18:36:27.458747  2203 solver.cpp:331] Iteration 35000, Testing net (#0)
I0418 18:36:32.033828  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:36:32.242851  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.809
I0418 18:36:32.242871  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9892
I0418 18:36:32.242877  2203 solver.cpp:398]     Test net output #2: loss = 0.650744 (* 1 = 0.650744 loss)
I0418 18:36:32.406662  2203 solver.cpp:219] Iteration 35000 (3.70006 iter/s, 27.0266s/100 iters), loss = 0.213645
I0418 18:36:32.406683  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:36:32.406687  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:36:32.406692  2203 solver.cpp:238]     Train net output #2: loss = 0.213645 (* 1 = 0.213645 loss)
I0418 18:36:32.406697  2203 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0418 18:36:54.686722  2203 solver.cpp:219] Iteration 35100 (4.48831 iter/s, 22.2801s/100 iters), loss = 0.258646
I0418 18:36:54.686859  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 18:36:54.686867  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:36:54.686873  2203 solver.cpp:238]     Train net output #2: loss = 0.258646 (* 1 = 0.258646 loss)
I0418 18:36:54.686878  2203 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0418 18:37:06.336848  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:37:16.973630  2203 solver.cpp:219] Iteration 35200 (4.48695 iter/s, 22.2869s/100 iters), loss = 0.254153
I0418 18:37:16.973670  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:37:16.973676  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:37:16.973682  2203 solver.cpp:238]     Train net output #2: loss = 0.254153 (* 1 = 0.254153 loss)
I0418 18:37:16.973686  2203 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0418 18:37:39.185984  2203 solver.cpp:219] Iteration 35300 (4.50199 iter/s, 22.2124s/100 iters), loss = 0.258017
I0418 18:37:39.186182  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 18:37:39.186189  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:37:39.186195  2203 solver.cpp:238]     Train net output #2: loss = 0.258016 (* 1 = 0.258016 loss)
I0418 18:37:39.186200  2203 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0418 18:38:01.471618  2203 solver.cpp:219] Iteration 35400 (4.48763 iter/s, 22.2835s/100 iters), loss = 0.216195
I0418 18:38:01.471655  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:38:01.471660  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:38:01.471667  2203 solver.cpp:238]     Train net output #2: loss = 0.216194 (* 1 = 0.216194 loss)
I0418 18:38:01.471670  2203 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0418 18:38:23.755537  2203 solver.cpp:219] Iteration 35500 (4.48754 iter/s, 22.2839s/100 iters), loss = 0.17919
I0418 18:38:23.755728  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:38:23.755735  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:38:23.755743  2203 solver.cpp:238]     Train net output #2: loss = 0.17919 (* 1 = 0.17919 loss)
I0418 18:38:23.755748  2203 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0418 18:38:33.139277  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:38:46.039153  2203 solver.cpp:219] Iteration 35600 (4.48762 iter/s, 22.2835s/100 iters), loss = 0.395187
I0418 18:38:46.039193  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:38:46.039198  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:38:46.039204  2203 solver.cpp:238]     Train net output #2: loss = 0.395187 (* 1 = 0.395187 loss)
I0418 18:38:46.039208  2203 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0418 18:39:08.324036  2203 solver.cpp:219] Iteration 35700 (4.48734 iter/s, 22.2849s/100 iters), loss = 0.261239
I0418 18:39:08.324196  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 18:39:08.324204  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:39:08.324210  2203 solver.cpp:238]     Train net output #2: loss = 0.261239 (* 1 = 0.261239 loss)
I0418 18:39:08.324215  2203 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0418 18:39:30.605757  2203 solver.cpp:219] Iteration 35800 (4.488 iter/s, 22.2817s/100 iters), loss = 0.248102
I0418 18:39:30.605793  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:39:30.605798  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:39:30.605804  2203 solver.cpp:238]     Train net output #2: loss = 0.248102 (* 1 = 0.248102 loss)
I0418 18:39:30.605808  2203 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0418 18:39:52.891990  2203 solver.cpp:219] Iteration 35900 (4.48707 iter/s, 22.2863s/100 iters), loss = 0.277574
I0418 18:39:52.892155  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 18:39:52.892163  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:39:52.892169  2203 solver.cpp:238]     Train net output #2: loss = 0.277574 (* 1 = 0.277574 loss)
I0418 18:39:52.892174  2203 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0418 18:40:00.236193  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:40:14.964170  2203 solver.cpp:331] Iteration 36000, Testing net (#0)
I0418 18:40:19.526938  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:40:19.735440  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7921
I0418 18:40:19.735462  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9827
I0418 18:40:19.735469  2203 solver.cpp:398]     Test net output #2: loss = 0.802981 (* 1 = 0.802981 loss)
I0418 18:40:19.899231  2203 solver.cpp:219] Iteration 36000 (3.70272 iter/s, 27.0072s/100 iters), loss = 0.285446
I0418 18:40:19.899255  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:40:19.899260  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:40:19.899265  2203 solver.cpp:238]     Train net output #2: loss = 0.285445 (* 1 = 0.285445 loss)
I0418 18:40:19.899269  2203 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0418 18:40:42.167829  2203 solver.cpp:219] Iteration 36100 (4.49062 iter/s, 22.2686s/100 iters), loss = 0.17861
I0418 18:40:42.167942  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:40:42.167948  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:40:42.167954  2203 solver.cpp:238]     Train net output #2: loss = 0.17861 (* 1 = 0.17861 loss)
I0418 18:40:42.167959  2203 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0418 18:41:04.451174  2203 solver.cpp:219] Iteration 36200 (4.48766 iter/s, 22.2833s/100 iters), loss = 0.314084
I0418 18:41:04.451210  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:41:04.451215  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:41:04.451220  2203 solver.cpp:238]     Train net output #2: loss = 0.314084 (* 1 = 0.314084 loss)
I0418 18:41:04.451225  2203 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0418 18:41:26.726681  2203 solver.cpp:219] Iteration 36300 (4.48923 iter/s, 22.2755s/100 iters), loss = 0.341897
I0418 18:41:26.726831  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:41:26.726838  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:41:26.726845  2203 solver.cpp:238]     Train net output #2: loss = 0.341897 (* 1 = 0.341897 loss)
I0418 18:41:26.726850  2203 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0418 18:41:32.078379  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:41:48.996781  2203 solver.cpp:219] Iteration 36400 (4.49074 iter/s, 22.268s/100 iters), loss = 0.296194
I0418 18:41:48.996819  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:41:48.996824  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:41:48.996830  2203 solver.cpp:238]     Train net output #2: loss = 0.296194 (* 1 = 0.296194 loss)
I0418 18:41:48.996835  2203 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0418 18:42:11.273186  2203 solver.cpp:219] Iteration 36500 (4.48947 iter/s, 22.2744s/100 iters), loss = 0.309448
I0418 18:42:11.273339  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:42:11.273345  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:42:11.273351  2203 solver.cpp:238]     Train net output #2: loss = 0.309448 (* 1 = 0.309448 loss)
I0418 18:42:11.273356  2203 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0418 18:42:33.511482  2203 solver.cpp:219] Iteration 36600 (4.49716 iter/s, 22.2362s/100 iters), loss = 0.317238
I0418 18:42:33.511518  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:42:33.511523  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:42:33.511529  2203 solver.cpp:238]     Train net output #2: loss = 0.317238 (* 1 = 0.317238 loss)
I0418 18:42:33.511533  2203 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0418 18:42:55.746886  2203 solver.cpp:219] Iteration 36700 (4.49775 iter/s, 22.2333s/100 iters), loss = 0.192288
I0418 18:42:55.747097  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 18:42:55.747104  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:42:55.747112  2203 solver.cpp:238]     Train net output #2: loss = 0.192288 (* 1 = 0.192288 loss)
I0418 18:42:55.747117  2203 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0418 18:42:58.919607  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:43:18.043942  2203 solver.cpp:219] Iteration 36800 (4.48533 iter/s, 22.2949s/100 iters), loss = 0.38239
I0418 18:43:18.043984  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 18:43:18.043989  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:43:18.043995  2203 solver.cpp:238]     Train net output #2: loss = 0.38239 (* 1 = 0.38239 loss)
I0418 18:43:18.043999  2203 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0418 18:43:40.540540  2203 solver.cpp:219] Iteration 36900 (4.44554 iter/s, 22.4945s/100 iters), loss = 0.170048
I0418 18:43:40.540705  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 18:43:40.540712  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:43:40.540719  2203 solver.cpp:238]     Train net output #2: loss = 0.170048 (* 1 = 0.170048 loss)
I0418 18:43:40.540724  2203 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0418 18:44:02.618484  2203 solver.cpp:331] Iteration 37000, Testing net (#0)
I0418 18:44:07.201122  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:44:07.363962  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7932
I0418 18:44:07.363986  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9861
I0418 18:44:07.363992  2203 solver.cpp:398]     Test net output #2: loss = 0.730792 (* 1 = 0.730792 loss)
I0418 18:44:07.580919  2203 solver.cpp:219] Iteration 37000 (3.69845 iter/s, 27.0384s/100 iters), loss = 0.277588
I0418 18:44:07.580938  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 18:44:07.580942  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:44:07.580947  2203 solver.cpp:238]     Train net output #2: loss = 0.277588 (* 1 = 0.277588 loss)
I0418 18:44:07.580952  2203 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0418 18:44:29.848417  2203 solver.cpp:219] Iteration 37100 (4.49127 iter/s, 22.2654s/100 iters), loss = 0.199349
I0418 18:44:29.848615  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 18:44:29.848623  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:44:29.848629  2203 solver.cpp:238]     Train net output #2: loss = 0.199349 (* 1 = 0.199349 loss)
I0418 18:44:29.848634  2203 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0418 18:44:30.992585  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:44:52.149186  2203 solver.cpp:219] Iteration 37200 (4.48457 iter/s, 22.2987s/100 iters), loss = 0.228412
I0418 18:44:52.149226  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:44:52.149231  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:44:52.149240  2203 solver.cpp:238]     Train net output #2: loss = 0.228412 (* 1 = 0.228412 loss)
I0418 18:44:52.149245  2203 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0418 18:45:14.433253  2203 solver.cpp:219] Iteration 37300 (4.48794 iter/s, 22.282s/100 iters), loss = 0.310555
I0418 18:45:14.433446  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:45:14.433454  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:45:14.433460  2203 solver.cpp:238]     Train net output #2: loss = 0.310555 (* 1 = 0.310555 loss)
I0418 18:45:14.433465  2203 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0418 18:45:36.724831  2203 solver.cpp:219] Iteration 37400 (4.48641 iter/s, 22.2895s/100 iters), loss = 0.282354
I0418 18:45:36.724865  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:45:36.724870  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:45:36.724876  2203 solver.cpp:238]     Train net output #2: loss = 0.282354 (* 1 = 0.282354 loss)
I0418 18:45:36.724880  2203 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0418 18:45:57.897299  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:45:58.977507  2203 solver.cpp:219] Iteration 37500 (4.49427 iter/s, 22.2506s/100 iters), loss = 0.214596
I0418 18:45:58.977537  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:45:58.977542  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:45:58.977548  2203 solver.cpp:238]     Train net output #2: loss = 0.214596 (* 1 = 0.214596 loss)
I0418 18:45:58.977552  2203 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0418 18:46:21.274113  2203 solver.cpp:219] Iteration 37600 (4.4854 iter/s, 22.2945s/100 iters), loss = 0.196637
I0418 18:46:21.274153  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 18:46:21.274158  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:46:21.274164  2203 solver.cpp:238]     Train net output #2: loss = 0.196637 (* 1 = 0.196637 loss)
I0418 18:46:21.274168  2203 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0418 18:46:43.552920  2203 solver.cpp:219] Iteration 37700 (4.48898 iter/s, 22.2768s/100 iters), loss = 0.334909
I0418 18:46:43.553067  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:46:43.553074  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:46:43.553081  2203 solver.cpp:238]     Train net output #2: loss = 0.334909 (* 1 = 0.334909 loss)
I0418 18:46:43.553086  2203 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0418 18:47:05.845348  2203 solver.cpp:219] Iteration 37800 (4.48624 iter/s, 22.2904s/100 iters), loss = 0.352891
I0418 18:47:05.845384  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0418 18:47:05.845389  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:47:05.845396  2203 solver.cpp:238]     Train net output #2: loss = 0.352891 (* 1 = 0.352891 loss)
I0418 18:47:05.845399  2203 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0418 18:47:25.060529  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:47:28.121947  2203 solver.cpp:219] Iteration 37900 (4.48943 iter/s, 22.2746s/100 iters), loss = 0.255007
I0418 18:47:28.121984  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 18:47:28.121989  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:47:28.121994  2203 solver.cpp:238]     Train net output #2: loss = 0.255007 (* 1 = 0.255007 loss)
I0418 18:47:28.121999  2203 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0418 18:47:50.225715  2203 solver.cpp:331] Iteration 38000, Testing net (#0)
I0418 18:47:54.801163  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:47:54.974550  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7342
I0418 18:47:54.974571  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9738
I0418 18:47:54.974578  2203 solver.cpp:398]     Test net output #2: loss = 1.11558 (* 1 = 1.11558 loss)
I0418 18:47:55.191836  2203 solver.cpp:219] Iteration 38000 (3.69441 iter/s, 27.0679s/100 iters), loss = 0.223334
I0418 18:47:55.191953  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:47:55.191961  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:47:55.191965  2203 solver.cpp:238]     Train net output #2: loss = 0.223334 (* 1 = 0.223334 loss)
I0418 18:47:55.191969  2203 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0418 18:48:17.504035  2203 solver.cpp:219] Iteration 38100 (4.48228 iter/s, 22.3101s/100 iters), loss = 0.350898
I0418 18:48:17.504076  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 18:48:17.504081  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:48:17.504087  2203 solver.cpp:238]     Train net output #2: loss = 0.350898 (* 1 = 0.350898 loss)
I0418 18:48:17.504091  2203 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0418 18:48:39.812702  2203 solver.cpp:219] Iteration 38200 (4.48299 iter/s, 22.3065s/100 iters), loss = 0.187886
I0418 18:48:39.812909  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:48:39.812917  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:48:39.812924  2203 solver.cpp:238]     Train net output #2: loss = 0.187886 (* 1 = 0.187886 loss)
I0418 18:48:39.812928  2203 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0418 18:48:57.003845  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:49:02.118706  2203 solver.cpp:219] Iteration 38300 (4.48312 iter/s, 22.3059s/100 iters), loss = 0.212897
I0418 18:49:02.118744  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:49:02.118749  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:49:02.118755  2203 solver.cpp:238]     Train net output #2: loss = 0.212897 (* 1 = 0.212897 loss)
I0418 18:49:02.118760  2203 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0418 18:49:24.488229  2203 solver.cpp:219] Iteration 38400 (4.47036 iter/s, 22.3696s/100 iters), loss = 0.340484
I0418 18:49:24.488322  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 18:49:24.488329  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:49:24.488335  2203 solver.cpp:238]     Train net output #2: loss = 0.340484 (* 1 = 0.340484 loss)
I0418 18:49:24.488340  2203 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0418 18:49:46.847162  2203 solver.cpp:219] Iteration 38500 (4.47289 iter/s, 22.3569s/100 iters), loss = 0.218669
I0418 18:49:46.847199  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 18:49:46.847205  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:49:46.847211  2203 solver.cpp:238]     Train net output #2: loss = 0.218669 (* 1 = 0.218669 loss)
I0418 18:49:46.847215  2203 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0418 18:50:09.158107  2203 solver.cpp:219] Iteration 38600 (4.48253 iter/s, 22.3088s/100 iters), loss = 0.279244
I0418 18:50:09.158203  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 18:50:09.158210  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:50:09.158216  2203 solver.cpp:238]     Train net output #2: loss = 0.279244 (* 1 = 0.279244 loss)
I0418 18:50:09.158221  2203 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0418 18:50:24.119390  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:50:31.438957  2203 solver.cpp:219] Iteration 38700 (4.48859 iter/s, 22.2787s/100 iters), loss = 0.238229
I0418 18:50:31.438995  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 18:50:31.439000  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:50:31.439007  2203 solver.cpp:238]     Train net output #2: loss = 0.238229 (* 1 = 0.238229 loss)
I0418 18:50:31.439010  2203 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0418 18:50:53.701342  2203 solver.cpp:219] Iteration 38800 (4.4923 iter/s, 22.2603s/100 iters), loss = 0.23502
I0418 18:50:53.701552  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:50:53.701560  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:50:53.701566  2203 solver.cpp:238]     Train net output #2: loss = 0.23502 (* 1 = 0.23502 loss)
I0418 18:50:53.701571  2203 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0418 18:51:16.013720  2203 solver.cpp:219] Iteration 38900 (4.48225 iter/s, 22.3102s/100 iters), loss = 0.238198
I0418 18:51:16.013756  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 18:51:16.013761  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 18:51:16.013767  2203 solver.cpp:238]     Train net output #2: loss = 0.238198 (* 1 = 0.238198 loss)
I0418 18:51:16.013772  2203 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0418 18:51:38.176806  2203 solver.cpp:331] Iteration 39000, Testing net (#0)
I0418 18:51:42.712872  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:51:42.886165  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7497
I0418 18:51:42.886188  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9685
I0418 18:51:42.886195  2203 solver.cpp:398]     Test net output #2: loss = 0.917441 (* 1 = 0.917441 loss)
I0418 18:51:43.093271  2203 solver.cpp:219] Iteration 39000 (3.6931 iter/s, 27.0775s/100 iters), loss = 0.276322
I0418 18:51:43.093291  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 18:51:43.093297  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:51:43.093302  2203 solver.cpp:238]     Train net output #2: loss = 0.276322 (* 1 = 0.276322 loss)
I0418 18:51:43.093305  2203 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0418 18:51:56.075472  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:52:05.370934  2203 solver.cpp:219] Iteration 39100 (4.48922 iter/s, 22.2756s/100 iters), loss = 0.229248
I0418 18:52:05.370973  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:52:05.370978  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:52:05.370985  2203 solver.cpp:238]     Train net output #2: loss = 0.229248 (* 1 = 0.229248 loss)
I0418 18:52:05.370988  2203 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0418 18:52:27.647125  2203 solver.cpp:219] Iteration 39200 (4.48951 iter/s, 22.2741s/100 iters), loss = 0.295775
I0418 18:52:27.647233  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:52:27.647244  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:52:27.647251  2203 solver.cpp:238]     Train net output #2: loss = 0.295775 (* 1 = 0.295775 loss)
I0418 18:52:27.647255  2203 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0418 18:52:49.956807  2203 solver.cpp:219] Iteration 39300 (4.48277 iter/s, 22.3076s/100 iters), loss = 0.227377
I0418 18:52:49.956847  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 18:52:49.956852  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:52:49.956858  2203 solver.cpp:238]     Train net output #2: loss = 0.227377 (* 1 = 0.227377 loss)
I0418 18:52:49.956862  2203 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0418 18:53:12.214241  2203 solver.cpp:219] Iteration 39400 (4.49329 iter/s, 22.2554s/100 iters), loss = 0.286641
I0418 18:53:12.214432  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:53:12.214439  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:53:12.214447  2203 solver.cpp:238]     Train net output #2: loss = 0.286641 (* 1 = 0.286641 loss)
I0418 18:53:12.214452  2203 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0418 18:53:23.179621  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:53:34.513386  2203 solver.cpp:219] Iteration 39500 (4.48489 iter/s, 22.2971s/100 iters), loss = 0.278158
I0418 18:53:34.513440  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:53:34.513447  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:53:34.513453  2203 solver.cpp:238]     Train net output #2: loss = 0.278158 (* 1 = 0.278158 loss)
I0418 18:53:34.513458  2203 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0418 18:53:56.796227  2203 solver.cpp:219] Iteration 39600 (4.48817 iter/s, 22.2808s/100 iters), loss = 0.158786
I0418 18:53:56.796417  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 18:53:56.796425  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:53:56.796432  2203 solver.cpp:238]     Train net output #2: loss = 0.158786 (* 1 = 0.158786 loss)
I0418 18:53:56.796437  2203 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0418 18:54:19.068557  2203 solver.cpp:219] Iteration 39700 (4.49029 iter/s, 22.2703s/100 iters), loss = 0.261481
I0418 18:54:19.068596  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:54:19.068601  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:54:19.068608  2203 solver.cpp:238]     Train net output #2: loss = 0.261481 (* 1 = 0.261481 loss)
I0418 18:54:19.068611  2203 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0418 18:54:41.393184  2203 solver.cpp:219] Iteration 39800 (4.47978 iter/s, 22.3225s/100 iters), loss = 0.244247
I0418 18:54:41.393293  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:54:41.393301  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:54:41.393307  2203 solver.cpp:238]     Train net output #2: loss = 0.244247 (* 1 = 0.244247 loss)
I0418 18:54:41.393312  2203 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0418 18:54:50.138514  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:55:03.691121  2203 solver.cpp:219] Iteration 39900 (4.48513 iter/s, 22.2959s/100 iters), loss = 0.244367
I0418 18:55:03.691159  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 18:55:03.691164  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:55:03.691170  2203 solver.cpp:238]     Train net output #2: loss = 0.244367 (* 1 = 0.244367 loss)
I0418 18:55:03.691174  2203 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0418 18:55:26.001260  2203 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_highway_padded_data_iter_40000.caffemodel
I0418 18:55:26.093917  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_highway_padded_data_iter_40000.solverstate
I0418 18:55:26.221868  2203 solver.cpp:331] Iteration 40000, Testing net (#0)
I0418 18:55:30.777686  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:55:30.954396  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7602
I0418 18:55:30.954418  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9835
I0418 18:55:30.954424  2203 solver.cpp:398]     Test net output #2: loss = 0.878485 (* 1 = 0.878485 loss)
I0418 18:55:31.161178  2203 solver.cpp:219] Iteration 40000 (3.64059 iter/s, 27.468s/100 iters), loss = 0.201176
I0418 18:55:31.161200  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 18:55:31.161203  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:55:31.161208  2203 solver.cpp:238]     Train net output #2: loss = 0.201176 (* 1 = 0.201176 loss)
I0418 18:55:31.161212  2203 sgd_solver.cpp:105] Iteration 40000, lr = 0.1
I0418 18:55:53.430132  2203 solver.cpp:219] Iteration 40100 (4.49097 iter/s, 22.2669s/100 iters), loss = 0.376454
I0418 18:55:53.430172  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 18:55:53.430178  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:55:53.430184  2203 solver.cpp:238]     Train net output #2: loss = 0.376454 (* 1 = 0.376454 loss)
I0418 18:55:53.430188  2203 sgd_solver.cpp:105] Iteration 40100, lr = 0.1
I0418 18:56:15.722389  2203 solver.cpp:219] Iteration 40200 (4.48628 iter/s, 22.2902s/100 iters), loss = 0.305515
I0418 18:56:15.722582  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 18:56:15.722590  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:56:15.722596  2203 solver.cpp:238]     Train net output #2: loss = 0.305515 (* 1 = 0.305515 loss)
I0418 18:56:15.722601  2203 sgd_solver.cpp:105] Iteration 40200, lr = 0.1
I0418 18:56:22.482913  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:56:38.027185  2203 solver.cpp:219] Iteration 40300 (4.48375 iter/s, 22.3027s/100 iters), loss = 0.189573
I0418 18:56:38.027225  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 18:56:38.027230  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 18:56:38.027235  2203 solver.cpp:238]     Train net output #2: loss = 0.189573 (* 1 = 0.189573 loss)
I0418 18:56:38.027242  2203 sgd_solver.cpp:105] Iteration 40300, lr = 0.1
I0418 18:57:00.287648  2203 solver.cpp:219] Iteration 40400 (4.49269 iter/s, 22.2584s/100 iters), loss = 0.329089
I0418 18:57:00.287827  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:57:00.287834  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:57:00.287842  2203 solver.cpp:238]     Train net output #2: loss = 0.329089 (* 1 = 0.329089 loss)
I0418 18:57:00.287845  2203 sgd_solver.cpp:105] Iteration 40400, lr = 0.1
I0418 18:57:22.555117  2203 solver.cpp:219] Iteration 40500 (4.49128 iter/s, 22.2653s/100 iters), loss = 0.220392
I0418 18:57:22.555155  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 18:57:22.555161  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:57:22.555167  2203 solver.cpp:238]     Train net output #2: loss = 0.220392 (* 1 = 0.220392 loss)
I0418 18:57:22.555171  2203 sgd_solver.cpp:105] Iteration 40500, lr = 0.1
I0418 18:57:44.831307  2203 solver.cpp:219] Iteration 40600 (4.48953 iter/s, 22.2741s/100 iters), loss = 0.311021
I0418 18:57:44.831451  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 18:57:44.831459  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:57:44.831485  2203 solver.cpp:238]     Train net output #2: loss = 0.311021 (* 1 = 0.311021 loss)
I0418 18:57:44.831490  2203 sgd_solver.cpp:105] Iteration 40600, lr = 0.1
I0418 18:57:49.339582  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:58:07.132488  2203 solver.cpp:219] Iteration 40700 (4.4845 iter/s, 22.2991s/100 iters), loss = 0.157449
I0418 18:58:07.132529  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 18:58:07.132534  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:58:07.132540  2203 solver.cpp:238]     Train net output #2: loss = 0.157449 (* 1 = 0.157449 loss)
I0418 18:58:07.132544  2203 sgd_solver.cpp:105] Iteration 40700, lr = 0.1
I0418 18:58:29.367573  2203 solver.cpp:219] Iteration 40800 (4.49781 iter/s, 22.233s/100 iters), loss = 0.23504
I0418 18:58:29.367705  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 18:58:29.367715  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 18:58:29.367727  2203 solver.cpp:238]     Train net output #2: loss = 0.23504 (* 1 = 0.23504 loss)
I0418 18:58:29.367732  2203 sgd_solver.cpp:105] Iteration 40800, lr = 0.1
I0418 18:58:51.655062  2203 solver.cpp:219] Iteration 40900 (4.48725 iter/s, 22.2853s/100 iters), loss = 0.276655
I0418 18:58:51.655099  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0418 18:58:51.655107  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:58:51.655117  2203 solver.cpp:238]     Train net output #2: loss = 0.276655 (* 1 = 0.276655 loss)
I0418 18:58:51.655122  2203 sgd_solver.cpp:105] Iteration 40900, lr = 0.1
I0418 18:59:13.816397  2203 solver.cpp:331] Iteration 41000, Testing net (#0)
I0418 18:59:18.360641  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:59:18.538204  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7762
I0418 18:59:18.538228  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9888
I0418 18:59:18.538234  2203 solver.cpp:398]     Test net output #2: loss = 0.822619 (* 1 = 0.822619 loss)
I0418 18:59:18.741772  2203 solver.cpp:219] Iteration 41000 (3.69213 iter/s, 27.0846s/100 iters), loss = 0.293653
I0418 18:59:18.741792  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 18:59:18.741797  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:59:18.741802  2203 solver.cpp:238]     Train net output #2: loss = 0.293653 (* 1 = 0.293653 loss)
I0418 18:59:18.741806  2203 sgd_solver.cpp:105] Iteration 41000, lr = 0.1
I0418 18:59:21.258276  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 18:59:41.055030  2203 solver.cpp:219] Iteration 41100 (4.48206 iter/s, 22.3112s/100 iters), loss = 0.293601
I0418 18:59:41.055070  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 18:59:41.055076  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 18:59:41.055081  2203 solver.cpp:238]     Train net output #2: loss = 0.293601 (* 1 = 0.293601 loss)
I0418 18:59:41.055085  2203 sgd_solver.cpp:105] Iteration 41100, lr = 0.1
I0418 19:00:03.356358  2203 solver.cpp:219] Iteration 41200 (4.48445 iter/s, 22.2993s/100 iters), loss = 0.204534
I0418 19:00:03.356514  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 19:00:03.356523  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:00:03.356530  2203 solver.cpp:238]     Train net output #2: loss = 0.204534 (* 1 = 0.204534 loss)
I0418 19:00:03.356534  2203 sgd_solver.cpp:105] Iteration 41200, lr = 0.1
I0418 19:00:25.671221  2203 solver.cpp:219] Iteration 41300 (4.48174 iter/s, 22.3127s/100 iters), loss = 0.350748
I0418 19:00:25.671264  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 19:00:25.671270  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:00:25.671277  2203 solver.cpp:238]     Train net output #2: loss = 0.350748 (* 1 = 0.350748 loss)
I0418 19:00:25.671280  2203 sgd_solver.cpp:105] Iteration 41300, lr = 0.1
I0418 19:00:47.987393  2203 solver.cpp:219] Iteration 41400 (4.48147 iter/s, 22.3141s/100 iters), loss = 0.272775
I0418 19:00:47.987534  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0418 19:00:47.987542  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:00:47.987547  2203 solver.cpp:238]     Train net output #2: loss = 0.272775 (* 1 = 0.272775 loss)
I0418 19:00:47.987553  2203 sgd_solver.cpp:105] Iteration 41400, lr = 0.1
I0418 19:00:48.434609  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:01:10.277735  2203 solver.cpp:219] Iteration 41500 (4.48666 iter/s, 22.2883s/100 iters), loss = 0.242789
I0418 19:01:10.277792  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:01:10.277797  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:01:10.277804  2203 solver.cpp:238]     Train net output #2: loss = 0.242789 (* 1 = 0.242789 loss)
I0418 19:01:10.277808  2203 sgd_solver.cpp:105] Iteration 41500, lr = 0.1
I0418 19:01:32.723304  2203 solver.cpp:219] Iteration 41600 (4.45564 iter/s, 22.4435s/100 iters), loss = 0.226639
I0418 19:01:32.723474  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 19:01:32.723482  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:01:32.723489  2203 solver.cpp:238]     Train net output #2: loss = 0.226639 (* 1 = 0.226639 loss)
I0418 19:01:32.723495  2203 sgd_solver.cpp:105] Iteration 41600, lr = 0.1
I0418 19:01:55.031033  2203 solver.cpp:219] Iteration 41700 (4.48317 iter/s, 22.3057s/100 iters), loss = 0.210029
I0418 19:01:55.031076  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:01:55.031082  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:01:55.031088  2203 solver.cpp:238]     Train net output #2: loss = 0.210029 (* 1 = 0.210029 loss)
I0418 19:01:55.031093  2203 sgd_solver.cpp:105] Iteration 41700, lr = 0.1
I0418 19:02:15.614120  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:02:17.352370  2203 solver.cpp:219] Iteration 41800 (4.48044 iter/s, 22.3192s/100 iters), loss = 0.298219
I0418 19:02:17.352398  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 19:02:17.352404  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:02:17.352411  2203 solver.cpp:238]     Train net output #2: loss = 0.298219 (* 1 = 0.298219 loss)
I0418 19:02:17.352414  2203 sgd_solver.cpp:105] Iteration 41800, lr = 0.1
I0418 19:02:39.734725  2203 solver.cpp:219] Iteration 41900 (4.4678 iter/s, 22.3824s/100 iters), loss = 0.256257
I0418 19:02:39.734767  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 19:02:39.734773  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:02:39.734779  2203 solver.cpp:238]     Train net output #2: loss = 0.256257 (* 1 = 0.256257 loss)
I0418 19:02:39.734783  2203 sgd_solver.cpp:105] Iteration 41900, lr = 0.1
I0418 19:03:01.870666  2203 solver.cpp:331] Iteration 42000, Testing net (#0)
I0418 19:03:06.440924  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:03:06.653182  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7692
I0418 19:03:06.653205  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9864
I0418 19:03:06.653213  2203 solver.cpp:398]     Test net output #2: loss = 0.822939 (* 1 = 0.822939 loss)
I0418 19:03:06.812678  2203 solver.cpp:219] Iteration 42000 (3.69333 iter/s, 27.0758s/100 iters), loss = 0.184716
I0418 19:03:06.812698  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 19:03:06.812702  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:03:06.812707  2203 solver.cpp:238]     Train net output #2: loss = 0.184716 (* 1 = 0.184716 loss)
I0418 19:03:06.812711  2203 sgd_solver.cpp:105] Iteration 42000, lr = 0.1
I0418 19:03:29.189103  2203 solver.cpp:219] Iteration 42100 (4.46942 iter/s, 22.3743s/100 iters), loss = 0.227027
I0418 19:03:29.189127  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:03:29.189132  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:03:29.189137  2203 solver.cpp:238]     Train net output #2: loss = 0.227027 (* 1 = 0.227027 loss)
I0418 19:03:29.189141  2203 sgd_solver.cpp:105] Iteration 42100, lr = 0.1
I0418 19:03:47.787936  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:03:51.542587  2203 solver.cpp:219] Iteration 42200 (4.47399 iter/s, 22.3514s/100 iters), loss = 0.164139
I0418 19:03:51.542621  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 19:03:51.542626  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:03:51.542632  2203 solver.cpp:238]     Train net output #2: loss = 0.164139 (* 1 = 0.164139 loss)
I0418 19:03:51.542636  2203 sgd_solver.cpp:105] Iteration 42200, lr = 0.1
I0418 19:04:13.887714  2203 solver.cpp:219] Iteration 42300 (4.47525 iter/s, 22.3451s/100 iters), loss = 0.242537
I0418 19:04:13.887753  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 19:04:13.887758  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:04:13.887764  2203 solver.cpp:238]     Train net output #2: loss = 0.242537 (* 1 = 0.242537 loss)
I0418 19:04:13.887768  2203 sgd_solver.cpp:105] Iteration 42300, lr = 0.1
I0418 19:04:36.253587  2203 solver.cpp:219] Iteration 42400 (4.47152 iter/s, 22.3638s/100 iters), loss = 0.288762
I0418 19:04:36.253727  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 19:04:36.253734  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:04:36.253741  2203 solver.cpp:238]     Train net output #2: loss = 0.288762 (* 1 = 0.288762 loss)
I0418 19:04:36.253746  2203 sgd_solver.cpp:105] Iteration 42400, lr = 0.1
I0418 19:04:58.582746  2203 solver.cpp:219] Iteration 42500 (4.47886 iter/s, 22.3271s/100 iters), loss = 0.232346
I0418 19:04:58.582782  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 19:04:58.582787  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:04:58.582792  2203 solver.cpp:238]     Train net output #2: loss = 0.232345 (* 1 = 0.232345 loss)
I0418 19:04:58.582797  2203 sgd_solver.cpp:105] Iteration 42500, lr = 0.1
I0418 19:05:15.186038  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:05:20.953619  2203 solver.cpp:219] Iteration 42600 (4.47052 iter/s, 22.3687s/100 iters), loss = 0.242342
I0418 19:05:20.953645  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 19:05:20.953650  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:05:20.953656  2203 solver.cpp:238]     Train net output #2: loss = 0.242342 (* 1 = 0.242342 loss)
I0418 19:05:20.953660  2203 sgd_solver.cpp:105] Iteration 42600, lr = 0.1
I0418 19:05:43.306913  2203 solver.cpp:219] Iteration 42700 (4.47404 iter/s, 22.3512s/100 iters), loss = 0.40316
I0418 19:05:43.306948  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 19:05:43.306954  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:05:43.306960  2203 solver.cpp:238]     Train net output #2: loss = 0.40316 (* 1 = 0.40316 loss)
I0418 19:05:43.306964  2203 sgd_solver.cpp:105] Iteration 42700, lr = 0.1
I0418 19:06:05.668671  2203 solver.cpp:219] Iteration 42800 (4.47234 iter/s, 22.3596s/100 iters), loss = 0.223725
I0418 19:06:05.668799  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 19:06:05.668807  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:06:05.668813  2203 solver.cpp:238]     Train net output #2: loss = 0.223725 (* 1 = 0.223725 loss)
I0418 19:06:05.668817  2203 sgd_solver.cpp:105] Iteration 42800, lr = 0.1
I0418 19:06:28.024821  2203 solver.cpp:219] Iteration 42900 (4.47347 iter/s, 22.354s/100 iters), loss = 0.251254
I0418 19:06:28.024852  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:06:28.024857  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:06:28.024863  2203 solver.cpp:238]     Train net output #2: loss = 0.251254 (* 1 = 0.251254 loss)
I0418 19:06:28.024868  2203 sgd_solver.cpp:105] Iteration 42900, lr = 0.1
I0418 19:06:42.364029  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:06:50.128303  2203 solver.cpp:331] Iteration 43000, Testing net (#0)
I0418 19:06:54.719864  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:06:54.893625  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7516
I0418 19:06:54.893652  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9757
I0418 19:06:54.893659  2203 solver.cpp:398]     Test net output #2: loss = 0.917404 (* 1 = 0.917404 loss)
I0418 19:06:55.089422  2203 solver.cpp:219] Iteration 43000 (3.69514 iter/s, 27.0626s/100 iters), loss = 0.303865
I0418 19:06:55.089442  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 19:06:55.089447  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:06:55.089452  2203 solver.cpp:238]     Train net output #2: loss = 0.303865 (* 1 = 0.303865 loss)
I0418 19:06:55.089457  2203 sgd_solver.cpp:105] Iteration 43000, lr = 0.1
I0418 19:07:17.494910  2203 solver.cpp:219] Iteration 43100 (4.46319 iter/s, 22.4055s/100 iters), loss = 0.238125
I0418 19:07:17.495065  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 19:07:17.495074  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0418 19:07:17.495079  2203 solver.cpp:238]     Train net output #2: loss = 0.238125 (* 1 = 0.238125 loss)
I0418 19:07:17.495084  2203 sgd_solver.cpp:105] Iteration 43100, lr = 0.1
I0418 19:07:39.786648  2203 solver.cpp:219] Iteration 43200 (4.48598 iter/s, 22.2917s/100 iters), loss = 0.283282
I0418 19:07:39.786686  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0418 19:07:39.786692  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:07:39.786698  2203 solver.cpp:238]     Train net output #2: loss = 0.283282 (* 1 = 0.283282 loss)
I0418 19:07:39.786702  2203 sgd_solver.cpp:105] Iteration 43200, lr = 0.1
I0418 19:08:02.067353  2203 solver.cpp:219] Iteration 43300 (4.48818 iter/s, 22.2807s/100 iters), loss = 0.228696
I0418 19:08:02.067509  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 19:08:02.067517  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:08:02.067523  2203 solver.cpp:238]     Train net output #2: loss = 0.228696 (* 1 = 0.228696 loss)
I0418 19:08:02.067529  2203 sgd_solver.cpp:105] Iteration 43300, lr = 0.1
I0418 19:08:14.348497  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:08:24.358551  2203 solver.cpp:219] Iteration 43400 (4.48609 iter/s, 22.2911s/100 iters), loss = 0.311139
I0418 19:08:24.358587  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 19:08:24.358592  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:08:24.358597  2203 solver.cpp:238]     Train net output #2: loss = 0.311139 (* 1 = 0.311139 loss)
I0418 19:08:24.358602  2203 sgd_solver.cpp:105] Iteration 43400, lr = 0.1
I0418 19:08:46.629825  2203 solver.cpp:219] Iteration 43500 (4.49009 iter/s, 22.2713s/100 iters), loss = 0.254845
I0418 19:08:46.629974  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 19:08:46.629982  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:08:46.629988  2203 solver.cpp:238]     Train net output #2: loss = 0.254845 (* 1 = 0.254845 loss)
I0418 19:08:46.629993  2203 sgd_solver.cpp:105] Iteration 43500, lr = 0.1
I0418 19:09:08.916573  2203 solver.cpp:219] Iteration 43600 (4.48739 iter/s, 22.2847s/100 iters), loss = 0.302278
I0418 19:09:08.916611  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:09:08.916616  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:09:08.916622  2203 solver.cpp:238]     Train net output #2: loss = 0.302278 (* 1 = 0.302278 loss)
I0418 19:09:08.916626  2203 sgd_solver.cpp:105] Iteration 43600, lr = 0.1
I0418 19:09:31.154039  2203 solver.cpp:219] Iteration 43700 (4.49733 iter/s, 22.2354s/100 iters), loss = 0.263147
I0418 19:09:31.154181  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:09:31.154188  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:09:31.154194  2203 solver.cpp:238]     Train net output #2: loss = 0.263147 (* 1 = 0.263147 loss)
I0418 19:09:31.154198  2203 sgd_solver.cpp:105] Iteration 43700, lr = 0.1
I0418 19:09:41.213394  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:09:53.434739  2203 solver.cpp:219] Iteration 43800 (4.48862 iter/s, 22.2786s/100 iters), loss = 0.291257
I0418 19:09:53.434779  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 19:09:53.434784  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:09:53.434792  2203 solver.cpp:238]     Train net output #2: loss = 0.291258 (* 1 = 0.291258 loss)
I0418 19:09:53.434795  2203 sgd_solver.cpp:105] Iteration 43800, lr = 0.1
I0418 19:10:15.724752  2203 solver.cpp:219] Iteration 43900 (4.48673 iter/s, 22.288s/100 iters), loss = 0.305849
I0418 19:10:15.724906  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 19:10:15.724913  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:10:15.724920  2203 solver.cpp:238]     Train net output #2: loss = 0.305849 (* 1 = 0.305849 loss)
I0418 19:10:15.724925  2203 sgd_solver.cpp:105] Iteration 43900, lr = 0.1
I0418 19:10:37.764813  2203 solver.cpp:331] Iteration 44000, Testing net (#0)
I0418 19:10:42.368554  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:10:42.529527  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7331
I0418 19:10:42.529551  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9751
I0418 19:10:42.529558  2203 solver.cpp:398]     Test net output #2: loss = 0.968504 (* 1 = 0.968504 loss)
I0418 19:10:42.755616  2203 solver.cpp:219] Iteration 44000 (3.69975 iter/s, 27.0288s/100 iters), loss = 0.277734
I0418 19:10:42.755636  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 19:10:42.755641  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:10:42.755646  2203 solver.cpp:238]     Train net output #2: loss = 0.277734 (* 1 = 0.277734 loss)
I0418 19:10:42.755650  2203 sgd_solver.cpp:105] Iteration 44000, lr = 0.1
I0418 19:11:05.007036  2203 solver.cpp:219] Iteration 44100 (4.49452 iter/s, 22.2493s/100 iters), loss = 0.24137
I0418 19:11:05.007262  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:11:05.007271  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:11:05.007277  2203 solver.cpp:238]     Train net output #2: loss = 0.24137 (* 1 = 0.24137 loss)
I0418 19:11:05.007282  2203 sgd_solver.cpp:105] Iteration 44100, lr = 0.1
I0418 19:11:13.073480  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:11:27.285993  2203 solver.cpp:219] Iteration 44200 (4.48896 iter/s, 22.2769s/100 iters), loss = 0.205361
I0418 19:11:27.286031  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 19:11:27.286036  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:11:27.286041  2203 solver.cpp:238]     Train net output #2: loss = 0.205361 (* 1 = 0.205361 loss)
I0418 19:11:27.286046  2203 sgd_solver.cpp:105] Iteration 44200, lr = 0.1
I0418 19:11:49.549768  2203 solver.cpp:219] Iteration 44300 (4.49203 iter/s, 22.2616s/100 iters), loss = 0.296355
I0418 19:11:49.549829  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 19:11:49.549835  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:11:49.549841  2203 solver.cpp:238]     Train net output #2: loss = 0.296355 (* 1 = 0.296355 loss)
I0418 19:11:49.549845  2203 sgd_solver.cpp:105] Iteration 44300, lr = 0.1
I0418 19:12:11.840827  2203 solver.cpp:219] Iteration 44400 (4.48652 iter/s, 22.289s/100 iters), loss = 0.287869
I0418 19:12:11.840867  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 19:12:11.840873  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:12:11.840878  2203 solver.cpp:238]     Train net output #2: loss = 0.287869 (* 1 = 0.287869 loss)
I0418 19:12:11.840883  2203 sgd_solver.cpp:105] Iteration 44400, lr = 0.1
I0418 19:12:34.131736  2203 solver.cpp:219] Iteration 44500 (4.48655 iter/s, 22.2888s/100 iters), loss = 0.281451
I0418 19:12:34.131930  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:12:34.131942  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:12:34.131952  2203 solver.cpp:238]     Train net output #2: loss = 0.281451 (* 1 = 0.281451 loss)
I0418 19:12:34.131958  2203 sgd_solver.cpp:105] Iteration 44500, lr = 0.1
I0418 19:12:40.164827  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:12:56.442281  2203 solver.cpp:219] Iteration 44600 (4.4826 iter/s, 22.3085s/100 iters), loss = 0.240386
I0418 19:12:56.442319  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:12:56.442327  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:12:56.442335  2203 solver.cpp:238]     Train net output #2: loss = 0.240386 (* 1 = 0.240386 loss)
I0418 19:12:56.442342  2203 sgd_solver.cpp:105] Iteration 44600, lr = 0.1
I0418 19:13:18.820413  2203 solver.cpp:219] Iteration 44700 (4.46906 iter/s, 22.3761s/100 iters), loss = 0.219701
I0418 19:13:18.820549  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 19:13:18.820557  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:13:18.820566  2203 solver.cpp:238]     Train net output #2: loss = 0.219701 (* 1 = 0.219701 loss)
I0418 19:13:18.820574  2203 sgd_solver.cpp:105] Iteration 44700, lr = 0.1
I0418 19:13:41.098673  2203 solver.cpp:219] Iteration 44800 (4.4891 iter/s, 22.2762s/100 iters), loss = 0.342472
I0418 19:13:41.098716  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 19:13:41.098723  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:13:41.098732  2203 solver.cpp:238]     Train net output #2: loss = 0.342472 (* 1 = 0.342472 loss)
I0418 19:13:41.098739  2203 sgd_solver.cpp:105] Iteration 44800, lr = 0.1
I0418 19:14:03.426808  2203 solver.cpp:219] Iteration 44900 (4.47907 iter/s, 22.3261s/100 iters), loss = 0.201602
I0418 19:14:03.426954  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 19:14:03.426964  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:14:03.426975  2203 solver.cpp:238]     Train net output #2: loss = 0.201602 (* 1 = 0.201602 loss)
I0418 19:14:03.426981  2203 sgd_solver.cpp:105] Iteration 44900, lr = 0.1
I0418 19:14:07.273852  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:14:25.510926  2203 solver.cpp:331] Iteration 45000, Testing net (#0)
I0418 19:14:30.104809  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:14:30.281553  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7727
I0418 19:14:30.281577  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9858
I0418 19:14:30.281584  2203 solver.cpp:398]     Test net output #2: loss = 0.870757 (* 1 = 0.870757 loss)
I0418 19:14:30.475661  2203 solver.cpp:219] Iteration 45000 (3.69729 iter/s, 27.0468s/100 iters), loss = 0.220748
I0418 19:14:30.475679  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 19:14:30.475683  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:14:30.475688  2203 solver.cpp:238]     Train net output #2: loss = 0.220748 (* 1 = 0.220748 loss)
I0418 19:14:30.475693  2203 sgd_solver.cpp:105] Iteration 45000, lr = 0.1
I0418 19:14:52.762904  2203 solver.cpp:219] Iteration 45100 (4.48687 iter/s, 22.2873s/100 iters), loss = 0.315076
I0418 19:14:52.763018  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:14:52.763026  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:14:52.763032  2203 solver.cpp:238]     Train net output #2: loss = 0.315076 (* 1 = 0.315076 loss)
I0418 19:14:52.763037  2203 sgd_solver.cpp:105] Iteration 45100, lr = 0.1
I0418 19:15:15.055995  2203 solver.cpp:219] Iteration 45200 (4.4857 iter/s, 22.293s/100 iters), loss = 0.15492
I0418 19:15:15.056032  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 19:15:15.056038  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:15:15.056043  2203 solver.cpp:238]     Train net output #2: loss = 0.15492 (* 1 = 0.15492 loss)
I0418 19:15:15.056048  2203 sgd_solver.cpp:105] Iteration 45200, lr = 0.1
I0418 19:15:37.356966  2203 solver.cpp:219] Iteration 45300 (4.48411 iter/s, 22.301s/100 iters), loss = 0.271489
I0418 19:15:37.357122  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:15:37.357130  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:15:37.357136  2203 solver.cpp:238]     Train net output #2: loss = 0.271489 (* 1 = 0.271489 loss)
I0418 19:15:37.357141  2203 sgd_solver.cpp:105] Iteration 45300, lr = 0.1
I0418 19:15:39.180907  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:15:59.658757  2203 solver.cpp:219] Iteration 45400 (4.48396 iter/s, 22.3017s/100 iters), loss = 0.225995
I0418 19:15:59.658793  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 19:15:59.658798  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:15:59.658804  2203 solver.cpp:238]     Train net output #2: loss = 0.225995 (* 1 = 0.225995 loss)
I0418 19:15:59.658808  2203 sgd_solver.cpp:105] Iteration 45400, lr = 0.1
I0418 19:16:21.958242  2203 solver.cpp:219] Iteration 45500 (4.48441 iter/s, 22.2995s/100 iters), loss = 0.149672
I0418 19:16:21.958423  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:16:21.958431  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:16:21.958437  2203 solver.cpp:238]     Train net output #2: loss = 0.149673 (* 1 = 0.149673 loss)
I0418 19:16:21.958442  2203 sgd_solver.cpp:105] Iteration 45500, lr = 0.1
I0418 19:16:44.239614  2203 solver.cpp:219] Iteration 45600 (4.48808 iter/s, 22.2813s/100 iters), loss = 0.298858
I0418 19:16:44.239652  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 19:16:44.239657  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:16:44.239663  2203 solver.cpp:238]     Train net output #2: loss = 0.298858 (* 1 = 0.298858 loss)
I0418 19:16:44.239668  2203 sgd_solver.cpp:105] Iteration 45600, lr = 0.1
I0418 19:17:06.358203  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:17:06.530521  2203 solver.cpp:219] Iteration 45700 (4.48613 iter/s, 22.2909s/100 iters), loss = 0.23975
I0418 19:17:06.530549  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 19:17:06.530553  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:17:06.530558  2203 solver.cpp:238]     Train net output #2: loss = 0.23975 (* 1 = 0.23975 loss)
I0418 19:17:06.530563  2203 sgd_solver.cpp:105] Iteration 45700, lr = 0.1
I0418 19:17:28.836982  2203 solver.cpp:219] Iteration 45800 (4.483 iter/s, 22.3065s/100 iters), loss = 0.255157
I0418 19:17:28.837023  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 19:17:28.837028  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:17:28.837033  2203 solver.cpp:238]     Train net output #2: loss = 0.255157 (* 1 = 0.255157 loss)
I0418 19:17:28.837038  2203 sgd_solver.cpp:105] Iteration 45800, lr = 0.1
I0418 19:17:51.113940  2203 solver.cpp:219] Iteration 45900 (4.48936 iter/s, 22.2749s/100 iters), loss = 0.390275
I0418 19:17:51.114084  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 19:17:51.114092  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:17:51.114099  2203 solver.cpp:238]     Train net output #2: loss = 0.390275 (* 1 = 0.390275 loss)
I0418 19:17:51.114104  2203 sgd_solver.cpp:105] Iteration 45900, lr = 0.1
I0418 19:18:13.251646  2203 solver.cpp:331] Iteration 46000, Testing net (#0)
I0418 19:18:17.812964  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:18:18.023897  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.8002
I0418 19:18:18.023919  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9805
I0418 19:18:18.023926  2203 solver.cpp:398]     Test net output #2: loss = 0.802014 (* 1 = 0.802014 loss)
I0418 19:18:18.197427  2203 solver.cpp:219] Iteration 46000 (3.69229 iter/s, 27.0835s/100 iters), loss = 0.362578
I0418 19:18:18.197448  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 19:18:18.197451  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:18:18.197456  2203 solver.cpp:238]     Train net output #2: loss = 0.362578 (* 1 = 0.362578 loss)
I0418 19:18:18.197461  2203 sgd_solver.cpp:105] Iteration 46000, lr = 0.1
I0418 19:18:38.079784  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:18:40.473662  2203 solver.cpp:219] Iteration 46100 (4.48951 iter/s, 22.2741s/100 iters), loss = 0.301626
I0418 19:18:40.473701  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 19:18:40.473708  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:18:40.473717  2203 solver.cpp:238]     Train net output #2: loss = 0.301626 (* 1 = 0.301626 loss)
I0418 19:18:40.473724  2203 sgd_solver.cpp:105] Iteration 46100, lr = 0.1
I0418 19:19:02.823894  2203 solver.cpp:219] Iteration 46200 (4.47465 iter/s, 22.3481s/100 iters), loss = 0.337023
I0418 19:19:02.823932  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 19:19:02.823940  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:19:02.823947  2203 solver.cpp:238]     Train net output #2: loss = 0.337023 (* 1 = 0.337023 loss)
I0418 19:19:02.823954  2203 sgd_solver.cpp:105] Iteration 46200, lr = 0.1
I0418 19:19:25.118475  2203 solver.cpp:219] Iteration 46300 (4.48583 iter/s, 22.2924s/100 iters), loss = 0.225757
I0418 19:19:25.118647  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 19:19:25.118657  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:19:25.118667  2203 solver.cpp:238]     Train net output #2: loss = 0.225757 (* 1 = 0.225757 loss)
I0418 19:19:25.118674  2203 sgd_solver.cpp:105] Iteration 46300, lr = 0.1
I0418 19:19:47.397069  2203 solver.cpp:219] Iteration 46400 (4.48903 iter/s, 22.2765s/100 iters), loss = 0.126499
I0418 19:19:47.397111  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 19:19:47.397119  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:19:47.397127  2203 solver.cpp:238]     Train net output #2: loss = 0.126499 (* 1 = 0.126499 loss)
I0418 19:19:47.397135  2203 sgd_solver.cpp:105] Iteration 46400, lr = 0.1
I0418 19:20:05.284368  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:20:09.696542  2203 solver.cpp:219] Iteration 46500 (4.48441 iter/s, 22.2995s/100 iters), loss = 0.195981
I0418 19:20:09.696578  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:20:09.696585  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:20:09.696593  2203 solver.cpp:238]     Train net output #2: loss = 0.195981 (* 1 = 0.195981 loss)
I0418 19:20:09.696599  2203 sgd_solver.cpp:105] Iteration 46500, lr = 0.1
I0418 19:20:31.991508  2203 solver.cpp:219] Iteration 46600 (4.48544 iter/s, 22.2944s/100 iters), loss = 0.260338
I0418 19:20:31.991550  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 19:20:31.991557  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:20:31.991566  2203 solver.cpp:238]     Train net output #2: loss = 0.260338 (* 1 = 0.260338 loss)
I0418 19:20:31.991572  2203 sgd_solver.cpp:105] Iteration 46600, lr = 0.1
I0418 19:20:54.275065  2203 solver.cpp:219] Iteration 46700 (4.48761 iter/s, 22.2836s/100 iters), loss = 0.195717
I0418 19:20:54.275259  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:20:54.275269  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:20:54.275280  2203 solver.cpp:238]     Train net output #2: loss = 0.195717 (* 1 = 0.195717 loss)
I0418 19:20:54.275287  2203 sgd_solver.cpp:105] Iteration 46700, lr = 0.1
I0418 19:21:16.567735  2203 solver.cpp:219] Iteration 46800 (4.4858 iter/s, 22.2926s/100 iters), loss = 0.262945
I0418 19:21:16.567776  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 19:21:16.567783  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:21:16.567793  2203 solver.cpp:238]     Train net output #2: loss = 0.262945 (* 1 = 0.262945 loss)
I0418 19:21:16.567800  2203 sgd_solver.cpp:105] Iteration 46800, lr = 0.1
I0418 19:21:32.208111  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:21:38.857453  2203 solver.cpp:219] Iteration 46900 (4.48637 iter/s, 22.2897s/100 iters), loss = 0.269926
I0418 19:21:38.857489  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:21:38.857496  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:21:38.857506  2203 solver.cpp:238]     Train net output #2: loss = 0.269927 (* 1 = 0.269927 loss)
I0418 19:21:38.857512  2203 sgd_solver.cpp:105] Iteration 46900, lr = 0.1
I0418 19:22:00.968430  2203 solver.cpp:331] Iteration 47000, Testing net (#0)
I0418 19:22:05.531922  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:22:05.741724  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.7644
I0418 19:22:05.741750  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9763
I0418 19:22:05.741756  2203 solver.cpp:398]     Test net output #2: loss = 0.894067 (* 1 = 0.894067 loss)
I0418 19:22:05.900208  2203 solver.cpp:219] Iteration 47000 (3.69784 iter/s, 27.0428s/100 iters), loss = 0.276485
I0418 19:22:05.900228  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 19:22:05.900233  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:22:05.900241  2203 solver.cpp:238]     Train net output #2: loss = 0.276485 (* 1 = 0.276485 loss)
I0418 19:22:05.900245  2203 sgd_solver.cpp:105] Iteration 47000, lr = 0.1
I0418 19:22:28.170598  2203 solver.cpp:219] Iteration 47100 (4.49069 iter/s, 22.2683s/100 iters), loss = 0.165822
I0418 19:22:28.170639  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:22:28.170644  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:22:28.170650  2203 solver.cpp:238]     Train net output #2: loss = 0.165822 (* 1 = 0.165822 loss)
I0418 19:22:28.170653  2203 sgd_solver.cpp:105] Iteration 47100, lr = 0.1
I0418 19:22:50.454399  2203 solver.cpp:219] Iteration 47200 (4.488 iter/s, 22.2817s/100 iters), loss = 0.246601
I0418 19:22:50.454466  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:22:50.454473  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:22:50.454478  2203 solver.cpp:238]     Train net output #2: loss = 0.246601 (* 1 = 0.246601 loss)
I0418 19:22:50.454483  2203 sgd_solver.cpp:105] Iteration 47200, lr = 0.1
I0418 19:23:04.107801  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:23:12.739646  2203 solver.cpp:219] Iteration 47300 (4.48769 iter/s, 22.2832s/100 iters), loss = 0.177723
I0418 19:23:12.739684  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 19:23:12.739689  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:23:12.739696  2203 solver.cpp:238]     Train net output #2: loss = 0.177723 (* 1 = 0.177723 loss)
I0418 19:23:12.739699  2203 sgd_solver.cpp:105] Iteration 47300, lr = 0.1
I0418 19:23:35.032224  2203 solver.cpp:219] Iteration 47400 (4.48579 iter/s, 22.2926s/100 iters), loss = 0.500217
I0418 19:23:35.032405  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0418 19:23:35.032413  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:23:35.032419  2203 solver.cpp:238]     Train net output #2: loss = 0.500218 (* 1 = 0.500218 loss)
I0418 19:23:35.032423  2203 sgd_solver.cpp:105] Iteration 47400, lr = 0.1
I0418 19:23:57.319180  2203 solver.cpp:219] Iteration 47500 (4.48706 iter/s, 22.2863s/100 iters), loss = 0.189357
I0418 19:23:57.319216  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:23:57.319221  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:23:57.319226  2203 solver.cpp:238]     Train net output #2: loss = 0.189357 (* 1 = 0.189357 loss)
I0418 19:23:57.319231  2203 sgd_solver.cpp:105] Iteration 47500, lr = 0.1
I0418 19:24:19.612231  2203 solver.cpp:219] Iteration 47600 (4.4857 iter/s, 22.2931s/100 iters), loss = 0.328181
I0418 19:24:19.612342  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 19:24:19.612350  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:24:19.612356  2203 solver.cpp:238]     Train net output #2: loss = 0.328181 (* 1 = 0.328181 loss)
I0418 19:24:19.612360  2203 sgd_solver.cpp:105] Iteration 47600, lr = 0.1
I0418 19:24:31.273941  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:24:41.926149  2203 solver.cpp:219] Iteration 47700 (4.48151 iter/s, 22.3139s/100 iters), loss = 0.285339
I0418 19:24:41.926187  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0418 19:24:41.926192  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:24:41.926198  2203 solver.cpp:238]     Train net output #2: loss = 0.285339 (* 1 = 0.285339 loss)
I0418 19:24:41.926201  2203 sgd_solver.cpp:105] Iteration 47700, lr = 0.1
I0418 19:25:04.306398  2203 solver.cpp:219] Iteration 47800 (4.46866 iter/s, 22.3781s/100 iters), loss = 0.305551
I0418 19:25:04.306581  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:25:04.306588  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:25:04.306594  2203 solver.cpp:238]     Train net output #2: loss = 0.305551 (* 1 = 0.305551 loss)
I0418 19:25:04.306599  2203 sgd_solver.cpp:105] Iteration 47800, lr = 0.1
I0418 19:25:26.594730  2203 solver.cpp:219] Iteration 47900 (4.48667 iter/s, 22.2882s/100 iters), loss = 0.148969
I0418 19:25:26.594768  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 19:25:26.594774  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:25:26.594779  2203 solver.cpp:238]     Train net output #2: loss = 0.148969 (* 1 = 0.148969 loss)
I0418 19:25:26.594784  2203 sgd_solver.cpp:105] Iteration 47900, lr = 0.1
I0418 19:25:48.669440  2203 solver.cpp:331] Iteration 48000, Testing net (#0)
I0418 19:25:53.231581  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:25:53.440505  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.8058
I0418 19:25:53.440526  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9814
I0418 19:25:53.440533  2203 solver.cpp:398]     Test net output #2: loss = 0.671456 (* 1 = 0.671456 loss)
I0418 19:25:53.602429  2203 solver.cpp:219] Iteration 48000 (3.70264 iter/s, 27.0078s/100 iters), loss = 0.330053
I0418 19:25:53.602450  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0418 19:25:53.602454  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:25:53.602459  2203 solver.cpp:238]     Train net output #2: loss = 0.330053 (* 1 = 0.330053 loss)
I0418 19:25:53.602463  2203 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 1
I0418 19:25:53.602465  2203 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0418 19:26:02.992434  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:26:15.892540  2203 solver.cpp:219] Iteration 48100 (4.48629 iter/s, 22.2901s/100 iters), loss = 0.266154
I0418 19:26:15.892576  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0418 19:26:15.892581  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:26:15.892587  2203 solver.cpp:238]     Train net output #2: loss = 0.266154 (* 1 = 0.266154 loss)
I0418 19:26:15.892591  2203 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0418 19:26:38.173840  2203 solver.cpp:219] Iteration 48200 (4.4885 iter/s, 22.2792s/100 iters), loss = 0.112832
I0418 19:26:38.174072  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 19:26:38.174080  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:26:38.174087  2203 solver.cpp:238]     Train net output #2: loss = 0.112832 (* 1 = 0.112832 loss)
I0418 19:26:38.174091  2203 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0418 19:27:00.473294  2203 solver.cpp:219] Iteration 48300 (4.48454 iter/s, 22.2988s/100 iters), loss = 0.111735
I0418 19:27:00.473333  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:27:00.473338  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:27:00.473345  2203 solver.cpp:238]     Train net output #2: loss = 0.111735 (* 1 = 0.111735 loss)
I0418 19:27:00.473348  2203 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0418 19:27:22.794457  2203 solver.cpp:219] Iteration 48400 (4.48005 iter/s, 22.3212s/100 iters), loss = 0.173269
I0418 19:27:22.794530  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 19:27:22.794536  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:27:22.794543  2203 solver.cpp:238]     Train net output #2: loss = 0.173269 (* 1 = 0.173269 loss)
I0418 19:27:22.794546  2203 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0418 19:27:30.172700  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:27:45.057886  2203 solver.cpp:219] Iteration 48500 (4.49209 iter/s, 22.2614s/100 iters), loss = 0.22103
I0418 19:27:45.057922  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 19:27:45.057927  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:27:45.057934  2203 solver.cpp:238]     Train net output #2: loss = 0.221031 (* 1 = 0.221031 loss)
I0418 19:27:45.057937  2203 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0418 19:28:07.367848  2203 solver.cpp:219] Iteration 48600 (4.4823 iter/s, 22.31s/100 iters), loss = 0.0850687
I0418 19:28:07.367974  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 19:28:07.367981  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:28:07.367988  2203 solver.cpp:238]     Train net output #2: loss = 0.0850688 (* 1 = 0.0850688 loss)
I0418 19:28:07.367992  2203 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0418 19:28:29.680560  2203 solver.cpp:219] Iteration 48700 (4.48216 iter/s, 22.3107s/100 iters), loss = 0.145624
I0418 19:28:29.680599  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:28:29.680604  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:28:29.680610  2203 solver.cpp:238]     Train net output #2: loss = 0.145624 (* 1 = 0.145624 loss)
I0418 19:28:29.680614  2203 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0418 19:28:51.979537  2203 solver.cpp:219] Iteration 48800 (4.48469 iter/s, 22.2981s/100 iters), loss = 0.222057
I0418 19:28:51.979681  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 19:28:51.979687  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:28:51.979694  2203 solver.cpp:238]     Train net output #2: loss = 0.222058 (* 1 = 0.222058 loss)
I0418 19:28:51.979698  2203 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0418 19:28:57.393635  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:29:14.261729  2203 solver.cpp:219] Iteration 48900 (4.48832 iter/s, 22.2801s/100 iters), loss = 0.110901
I0418 19:29:14.261765  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 19:29:14.261770  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:29:14.261775  2203 solver.cpp:238]     Train net output #2: loss = 0.110901 (* 1 = 0.110901 loss)
I0418 19:29:14.261780  2203 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0418 19:29:36.411846  2203 solver.cpp:331] Iteration 49000, Testing net (#0)
I0418 19:29:40.983494  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:29:41.154381  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.9003
I0418 19:29:41.154403  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9963
I0418 19:29:41.154410  2203 solver.cpp:398]     Test net output #2: loss = 0.327484 (* 1 = 0.327484 loss)
I0418 19:29:41.371084  2203 solver.cpp:219] Iteration 49000 (3.68887 iter/s, 27.1085s/100 iters), loss = 0.118192
I0418 19:29:41.371104  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:29:41.371109  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:29:41.371114  2203 solver.cpp:238]     Train net output #2: loss = 0.118192 (* 1 = 0.118192 loss)
I0418 19:29:41.371119  2203 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0418 19:30:03.647768  2203 solver.cpp:219] Iteration 49100 (4.48944 iter/s, 22.2745s/100 iters), loss = 0.0847126
I0418 19:30:03.647806  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 19:30:03.647812  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:30:03.647819  2203 solver.cpp:238]     Train net output #2: loss = 0.0847127 (* 1 = 0.0847127 loss)
I0418 19:30:03.647822  2203 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0418 19:30:25.949856  2203 solver.cpp:219] Iteration 49200 (4.48431 iter/s, 22.2999s/100 iters), loss = 0.0819377
I0418 19:30:25.950021  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 19:30:25.950027  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:30:25.950034  2203 solver.cpp:238]     Train net output #2: loss = 0.0819378 (* 1 = 0.0819378 loss)
I0418 19:30:25.950039  2203 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0418 19:30:29.114923  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:30:48.271714  2203 solver.cpp:219] Iteration 49300 (4.48033 iter/s, 22.3198s/100 iters), loss = 0.211628
I0418 19:30:48.271752  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0418 19:30:48.271757  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:30:48.271764  2203 solver.cpp:238]     Train net output #2: loss = 0.211628 (* 1 = 0.211628 loss)
I0418 19:30:48.271767  2203 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0418 19:31:10.631583  2203 solver.cpp:219] Iteration 49400 (4.47271 iter/s, 22.3578s/100 iters), loss = 0.0665759
I0418 19:31:10.631757  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 19:31:10.631765  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:31:10.631772  2203 solver.cpp:238]     Train net output #2: loss = 0.066576 (* 1 = 0.066576 loss)
I0418 19:31:10.631777  2203 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0418 19:31:32.927961  2203 solver.cpp:219] Iteration 49500 (4.48545 iter/s, 22.2943s/100 iters), loss = 0.132374
I0418 19:31:32.928000  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 19:31:32.928006  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:31:32.928012  2203 solver.cpp:238]     Train net output #2: loss = 0.132375 (* 1 = 0.132375 loss)
I0418 19:31:32.928016  2203 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0418 19:31:55.239504  2203 solver.cpp:219] Iteration 49600 (4.4824 iter/s, 22.3095s/100 iters), loss = 0.0702735
I0418 19:31:55.239665  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 19:31:55.239672  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:31:55.239679  2203 solver.cpp:238]     Train net output #2: loss = 0.0702736 (* 1 = 0.0702736 loss)
I0418 19:31:55.239684  2203 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0418 19:31:56.360101  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:32:17.557081  2203 solver.cpp:219] Iteration 49700 (4.48119 iter/s, 22.3155s/100 iters), loss = 0.0889995
I0418 19:32:17.557117  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 19:32:17.557122  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:32:17.557128  2203 solver.cpp:238]     Train net output #2: loss = 0.0889996 (* 1 = 0.0889996 loss)
I0418 19:32:17.557132  2203 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0418 19:32:39.902499  2203 solver.cpp:219] Iteration 49800 (4.4756 iter/s, 22.3434s/100 iters), loss = 0.199345
I0418 19:32:39.902595  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 19:32:39.902603  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:32:39.902609  2203 solver.cpp:238]     Train net output #2: loss = 0.199345 (* 1 = 0.199345 loss)
I0418 19:32:39.902616  2203 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0418 19:33:02.274912  2203 solver.cpp:219] Iteration 49900 (4.46979 iter/s, 22.3724s/100 iters), loss = 0.107505
I0418 19:33:02.274950  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 19:33:02.274955  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:33:02.274961  2203 solver.cpp:238]     Train net output #2: loss = 0.107505 (* 1 = 0.107505 loss)
I0418 19:33:02.274966  2203 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0418 19:33:23.590592  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:33:24.440058  2203 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_highway_padded_data_iter_50000.caffemodel
I0418 19:33:24.555781  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_highway_padded_data_iter_50000.solverstate
I0418 19:33:24.613402  2203 solver.cpp:331] Iteration 50000, Testing net (#0)
I0418 19:33:29.176640  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:33:29.386054  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.9004
I0418 19:33:29.386075  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.997
I0418 19:33:29.386080  2203 solver.cpp:398]     Test net output #2: loss = 0.325487 (* 1 = 0.325487 loss)
I0418 19:33:29.549289  2203 solver.cpp:219] Iteration 50000 (3.66672 iter/s, 27.2724s/100 iters), loss = 0.131915
I0418 19:33:29.549309  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 19:33:29.549314  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:33:29.549319  2203 solver.cpp:238]     Train net output #2: loss = 0.131915 (* 1 = 0.131915 loss)
I0418 19:33:29.549322  2203 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0418 19:33:51.902247  2203 solver.cpp:219] Iteration 50100 (4.47368 iter/s, 22.353s/100 iters), loss = 0.0624469
I0418 19:33:51.902285  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 19:33:51.902290  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:33:51.902297  2203 solver.cpp:238]     Train net output #2: loss = 0.062447 (* 1 = 0.062447 loss)
I0418 19:33:51.902300  2203 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0418 19:34:14.249300  2203 solver.cpp:219] Iteration 50200 (4.47527 iter/s, 22.345s/100 iters), loss = 0.23851
I0418 19:34:14.249452  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0418 19:34:14.249459  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:34:14.249466  2203 solver.cpp:238]     Train net output #2: loss = 0.23851 (* 1 = 0.23851 loss)
I0418 19:34:14.249470  2203 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0418 19:34:36.591748  2203 solver.cpp:219] Iteration 50300 (4.4762 iter/s, 22.3404s/100 iters), loss = 0.0994517
I0418 19:34:36.591773  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 19:34:36.591778  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:34:36.591783  2203 solver.cpp:238]     Train net output #2: loss = 0.0994518 (* 1 = 0.0994518 loss)
I0418 19:34:36.591786  2203 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0418 19:34:55.809583  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:34:58.897724  2203 solver.cpp:219] Iteration 50400 (4.4831 iter/s, 22.306s/100 iters), loss = 0.161116
I0418 19:34:58.897756  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 19:34:58.897763  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:34:58.897768  2203 solver.cpp:238]     Train net output #2: loss = 0.161116 (* 1 = 0.161116 loss)
I0418 19:34:58.897773  2203 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0418 19:35:21.259999  2203 solver.cpp:219] Iteration 50500 (4.47224 iter/s, 22.3601s/100 iters), loss = 0.10495
I0418 19:35:21.260025  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 19:35:21.260030  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:35:21.260036  2203 solver.cpp:238]     Train net output #2: loss = 0.10495 (* 1 = 0.10495 loss)
I0418 19:35:21.260040  2203 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0418 19:35:43.603504  2203 solver.cpp:219] Iteration 50600 (4.47599 iter/s, 22.3414s/100 iters), loss = 0.149694
I0418 19:35:43.603713  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 19:35:43.603721  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:35:43.603729  2203 solver.cpp:238]     Train net output #2: loss = 0.149694 (* 1 = 0.149694 loss)
I0418 19:35:43.603732  2203 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0418 19:36:05.904404  2203 solver.cpp:219] Iteration 50700 (4.48447 iter/s, 22.2992s/100 iters), loss = 0.0569862
I0418 19:36:05.904435  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 19:36:05.904441  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:36:05.904446  2203 solver.cpp:238]     Train net output #2: loss = 0.0569862 (* 1 = 0.0569862 loss)
I0418 19:36:05.904450  2203 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0418 19:36:23.178624  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:36:28.250103  2203 solver.cpp:219] Iteration 50800 (4.47513 iter/s, 22.3457s/100 iters), loss = 0.120266
I0418 19:36:28.250138  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:36:28.250143  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:36:28.250149  2203 solver.cpp:238]     Train net output #2: loss = 0.120266 (* 1 = 0.120266 loss)
I0418 19:36:28.250154  2203 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0418 19:36:50.386216  2203 solver.cpp:219] Iteration 50900 (4.51792 iter/s, 22.1341s/100 iters), loss = 0.158819
I0418 19:36:50.386243  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 19:36:50.386248  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:36:50.386253  2203 solver.cpp:238]     Train net output #2: loss = 0.158819 (* 1 = 0.158819 loss)
I0418 19:36:50.386257  2203 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0418 19:37:12.594522  2203 solver.cpp:331] Iteration 51000, Testing net (#0)
I0418 19:37:17.194686  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:37:17.353899  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.9047
I0418 19:37:17.353919  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9965
I0418 19:37:17.353927  2203 solver.cpp:398]     Test net output #2: loss = 0.326873 (* 1 = 0.326873 loss)
I0418 19:37:17.580368  2203 solver.cpp:219] Iteration 51000 (3.67755 iter/s, 27.192s/100 iters), loss = 0.0683285
I0418 19:37:17.580387  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 19:37:17.580392  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:37:17.580397  2203 solver.cpp:238]     Train net output #2: loss = 0.0683286 (* 1 = 0.0683286 loss)
I0418 19:37:17.580401  2203 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0418 19:37:39.875701  2203 solver.cpp:219] Iteration 51100 (4.48566 iter/s, 22.2933s/100 iters), loss = 0.102077
I0418 19:37:39.875740  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 19:37:39.875746  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:37:39.875751  2203 solver.cpp:238]     Train net output #2: loss = 0.102077 (* 1 = 0.102077 loss)
I0418 19:37:39.875756  2203 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0418 19:37:54.892556  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:38:02.245466  2203 solver.cpp:219] Iteration 51200 (4.47075 iter/s, 22.3676s/100 iters), loss = 0.101555
I0418 19:38:02.245491  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 19:38:02.245496  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:38:02.245501  2203 solver.cpp:238]     Train net output #2: loss = 0.101555 (* 1 = 0.101555 loss)
I0418 19:38:02.245506  2203 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0418 19:38:24.591295  2203 solver.cpp:219] Iteration 51300 (4.47554 iter/s, 22.3437s/100 iters), loss = 0.150526
I0418 19:38:24.591346  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 19:38:24.591352  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:38:24.591359  2203 solver.cpp:238]     Train net output #2: loss = 0.150527 (* 1 = 0.150527 loss)
I0418 19:38:24.591363  2203 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0418 19:38:46.896761  2203 solver.cpp:219] Iteration 51400 (4.48362 iter/s, 22.3034s/100 iters), loss = 0.0797025
I0418 19:38:46.896814  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 19:38:46.896821  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:38:46.896826  2203 solver.cpp:238]     Train net output #2: loss = 0.0797026 (* 1 = 0.0797026 loss)
I0418 19:38:46.896831  2203 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0418 19:39:09.205648  2203 solver.cpp:219] Iteration 51500 (4.48251 iter/s, 22.3089s/100 iters), loss = 0.036419
I0418 19:39:09.205684  2203 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 19:39:09.205689  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:39:09.205696  2203 solver.cpp:238]     Train net output #2: loss = 0.0364191 (* 1 = 0.0364191 loss)
I0418 19:39:09.205700  2203 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0418 19:39:22.213810  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:39:31.542753  2203 solver.cpp:219] Iteration 51600 (4.47728 iter/s, 22.335s/100 iters), loss = 0.0971599
I0418 19:39:31.542776  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 19:39:31.542798  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:39:31.542804  2203 solver.cpp:238]     Train net output #2: loss = 0.09716 (* 1 = 0.09716 loss)
I0418 19:39:31.542809  2203 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0418 19:39:53.895627  2203 solver.cpp:219] Iteration 51700 (4.47413 iter/s, 22.3507s/100 iters), loss = 0.12264
I0418 19:39:53.895761  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 19:39:53.895768  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:39:53.895776  2203 solver.cpp:238]     Train net output #2: loss = 0.12264 (* 1 = 0.12264 loss)
I0418 19:39:53.895779  2203 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0418 19:40:16.224710  2203 solver.cpp:219] Iteration 51800 (4.47888 iter/s, 22.327s/100 iters), loss = 0.150619
I0418 19:40:16.224748  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 19:40:16.224755  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:40:16.224761  2203 solver.cpp:238]     Train net output #2: loss = 0.15062 (* 1 = 0.15062 loss)
I0418 19:40:16.224764  2203 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0418 19:40:38.528348  2203 solver.cpp:219] Iteration 51900 (4.48357 iter/s, 22.3037s/100 iters), loss = 0.118582
I0418 19:40:38.528471  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 19:40:38.528478  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:40:38.528484  2203 solver.cpp:238]     Train net output #2: loss = 0.118582 (* 1 = 0.118582 loss)
I0418 19:40:38.528488  2203 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0418 19:40:49.552593  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:41:00.706110  2203 solver.cpp:331] Iteration 52000, Testing net (#0)
I0418 19:41:05.311661  2447 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:41:05.471657  2203 solver.cpp:398]     Test net output #0: acctop1 = 0.9009
I0418 19:41:05.471676  2203 solver.cpp:398]     Test net output #1: acctop5 = 0.9971
I0418 19:41:05.471683  2203 solver.cpp:398]     Test net output #2: loss = 0.350182 (* 1 = 0.350182 loss)
I0418 19:41:05.697294  2203 solver.cpp:219] Iteration 52000 (3.68096 iter/s, 27.1668s/100 iters), loss = 0.0936472
I0418 19:41:05.697315  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 19:41:05.697319  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:41:05.697324  2203 solver.cpp:238]     Train net output #2: loss = 0.0936473 (* 1 = 0.0936473 loss)
I0418 19:41:05.697329  2203 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0418 19:41:28.015450  2203 solver.cpp:219] Iteration 52100 (4.48109 iter/s, 22.316s/100 iters), loss = 0.073793
I0418 19:41:28.015527  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 19:41:28.015533  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:41:28.015538  2203 solver.cpp:238]     Train net output #2: loss = 0.0737931 (* 1 = 0.0737931 loss)
I0418 19:41:28.015542  2203 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0418 19:41:50.402341  2203 solver.cpp:219] Iteration 52200 (4.46733 iter/s, 22.3847s/100 iters), loss = 0.115102
I0418 19:41:50.402377  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:41:50.402384  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:41:50.402390  2203 solver.cpp:238]     Train net output #2: loss = 0.115102 (* 1 = 0.115102 loss)
I0418 19:41:50.402393  2203 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0418 19:42:12.748042  2203 solver.cpp:219] Iteration 52300 (4.47554 iter/s, 22.3436s/100 iters), loss = 0.128787
I0418 19:42:12.748095  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 19:42:12.748100  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:42:12.748106  2203 solver.cpp:238]     Train net output #2: loss = 0.128787 (* 1 = 0.128787 loss)
I0418 19:42:12.748109  2203 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0418 19:42:21.471968  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:42:35.144043  2203 solver.cpp:219] Iteration 52400 (4.46549 iter/s, 22.3939s/100 iters), loss = 0.0817518
I0418 19:42:35.144073  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 19:42:35.144078  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:42:35.144083  2203 solver.cpp:238]     Train net output #2: loss = 0.0817519 (* 1 = 0.0817519 loss)
I0418 19:42:35.144088  2203 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0418 19:42:57.605523  2203 solver.cpp:219] Iteration 52500 (4.45215 iter/s, 22.4611s/100 iters), loss = 0.115827
I0418 19:42:57.605664  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:42:57.605670  2203 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 19:42:57.605677  2203 solver.cpp:238]     Train net output #2: loss = 0.115828 (* 1 = 0.115828 loss)
I0418 19:42:57.605684  2203 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0418 19:43:19.947568  2203 solver.cpp:219] Iteration 52600 (4.47629 iter/s, 22.3399s/100 iters), loss = 0.160799
I0418 19:43:19.947593  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 19:43:19.947598  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:43:19.947603  2203 solver.cpp:238]     Train net output #2: loss = 0.160799 (* 1 = 0.160799 loss)
I0418 19:43:19.947607  2203 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0418 19:43:42.290760  2203 solver.cpp:219] Iteration 52700 (4.47563 iter/s, 22.3432s/100 iters), loss = 0.10548
I0418 19:43:42.290961  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:43:42.290968  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:43:42.290977  2203 solver.cpp:238]     Train net output #2: loss = 0.10548 (* 1 = 0.10548 loss)
I0418 19:43:42.290980  2203 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0418 19:43:49.049335  2208 data_layer.cpp:73] Restarting data prefetching from start.
I0418 19:44:04.655164  2203 solver.cpp:219] Iteration 52800 (4.47141 iter/s, 22.3643s/100 iters), loss = 0.0505863
I0418 19:44:04.655190  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 19:44:04.655195  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:44:04.655201  2203 solver.cpp:238]     Train net output #2: loss = 0.0505863 (* 1 = 0.0505863 loss)
I0418 19:44:04.655205  2203 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0418 19:44:26.997386  2203 solver.cpp:219] Iteration 52900 (4.47625 iter/s, 22.3401s/100 iters), loss = 0.141429
I0418 19:44:26.997483  2203 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 19:44:26.997489  2203 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 19:44:26.997496  2203 solver.cpp:238]     Train net output #2: loss = 0.141429 (* 1 = 0.141429 loss)
I0418 19:44:26.997500  2203 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
/opt/sge/default/spool/argon-mm-p100-compute-1-37/job_scripts/1743604: line 22: /caffe: No such file or directory
I0418 20:35:07.014148 50350 caffe.cpp:218] Using GPUs 0
I0418 20:35:07.732686 50350 caffe.cpp:223] GPU 0: Tesla P100-PCIE-16GB
I0418 20:35:09.415657 50350 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "model/ResNet20_highway_padded_data"
solver_mode: GPU
device_id: 0
net: "resnet20_relu_msra_cifar10.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 48000
stepvalue: 64000
I0418 20:35:09.418438 50350 solver.cpp:87] Creating training net from net file: resnet20_relu_msra_cifar10.prototxt
I0418 20:35:09.421430 50350 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet20_relu_msra_cifar10.prototxt
I0418 20:35:09.421468 50350 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0418 20:35:09.421766 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0418 20:35:09.421795 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv1
I0418 20:35:09.421820 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_1_bn_a
I0418 20:35:09.421844 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_1_bn_b
I0418 20:35:09.421849 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_2_bn_a
I0418 20:35:09.421854 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_2_bn_b
I0418 20:35:09.421859 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_3_bn_a
I0418 20:35:09.421864 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_3_bn_b
I0418 20:35:09.421869 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_proj
I0418 20:35:09.421874 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_a
I0418 20:35:09.421878 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_b
I0418 20:35:09.421885 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_2_bn_a
I0418 20:35:09.421890 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_2_bn_b
I0418 20:35:09.421896 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_3_bn_a
I0418 20:35:09.421902 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_3_bn_b
I0418 20:35:09.421907 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_proj
I0418 20:35:09.421912 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_a
I0418 20:35:09.421918 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_b
I0418 20:35:09.421923 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_2_bn_a
I0418 20:35:09.421929 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_2_bn_b
I0418 20:35:09.421936 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_3_bn_a
I0418 20:35:09.421941 50350 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_3_bn_b
I0418 20:35:09.422459 50350 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
    mean_file: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/paddedmean.binaryproto"
  }
  data_param {
    source: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_full_train_leveldb_padded/"
    batch_size: 128
    backend: LEVELDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "map16_1_conv_a"
  type: "Convolution"
  bottom: "conv1"
  top: "map16_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_a"
  type: "BatchNorm"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_1_scale_a"
  type: "Scale"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_relu_a"
  type: "ReLU"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
}
layer {
  name: "map16_1_conv_b"
  type: "Convolution"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_b"
  type: "BatchNorm"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_1_scale_b"
  type: "Scale"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_eltsum"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "map16_1_conv_b"
  top: "map16_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_1_relu_after_sum"
  type: "ReLU"
  bottom: "map16_1_eltsum"
  top: "map16_1_eltsum"
}
layer {
  name: "map16_2_conv_a"
  type: "Convolution"
  bottom: "map16_1_eltsum"
  top: "map16_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_a"
  type: "BatchNorm"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_2_scale_a"
  type: "Scale"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_relu_a"
  type: "ReLU"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
}
layer {
  name: "map16_2_conv_b"
  type: "Convolution"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_b"
  type: "BatchNorm"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_2_scale_b"
  type: "Scale"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_eltsum"
  type: "Eltwise"
  bottom: "map16_1_eltsum"
  bottom: "map16_2_conv_b"
  top: "map16_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_2_relu_after_sum"
  type: "ReLU"
  bottom: "map16_2_eltsum"
  top: "map16_2_eltsum"
}
layer {
  name: "map16_3_conv_a"
  type: "Convolution"
  bottom: "map16_2_eltsum"
  top: "map16_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_a"
  type: "BatchNorm"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_3_scale_a"
  type: "Scale"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_relu_a"
  type: "ReLU"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
}
layer {
  name: "map16_3_conv_b"
  type: "Convolution"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_b"
  type: "BatchNorm"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_3_scale_b"
  type: "Scale"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_eltsum"
  type: "Eltwise"
  bottom: "map16_2_eltsum"
  bottom: "map16_3_conv_b"
  top: "map16_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_3_relu_after_sum"
  type: "ReLU"
  bottom: "map16_3_eltsum"
  top: "map16_3_eltsum"
}
layer {
  name: "map32_1_conv_proj"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_proj"
  type: "BatchNorm"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_proj"
  type: "Scale"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_conv_a"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_a"
  type: "BatchNorm"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_a"
  type: "Scale"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_relu_a"
  type: "ReLU"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
}
layer {
  name: "map32_1_conv_b"
  type: "Convolution"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_b"
  type: "BatchNorm"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_b"
  type: "Scale"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_eltsum"
  type: "Eltwise"
  bottom: "map32_1_conv_proj"
  bottom: "map32_1_conv_b"
  top: "map32_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_1_relu_after_sum"
  type: "ReLU"
  bottom: "map32_1_eltsum"
  top: "map32_1_eltsum"
}
layer {
  name: "map32_2_conv_a"
  type: "Convolution"
  bottom: "map32_1_eltsum"
  top: "map32_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_a"
  type: "BatchNorm"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_2_scale_a"
  type: "Scale"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_relu_a"
  type: "ReLU"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
}
layer {
  name: "map32_2_conv_b"
  type: "Convolution"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_b"
  type: "BatchNorm"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_2_scale_b"
  type: "Scale"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_eltsum"
  type: "Eltwise"
  bottom: "map32_1_eltsum"
  bottom: "map32_2_conv_b"
  top: "map32_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_2_relu_after_sum"
  type: "ReLU"
  bottom: "map32_2_eltsum"
  top: "map32_2_eltsum"
}
layer {
  name: "map32_3_conv_a"
  type: "Convolution"
  bottom: "map32_2_eltsum"
  top: "map32_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_a"
  type: "BatchNorm"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_3_scale_a"
  type: "Scale"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_relu_a"
  type: "ReLU"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
}
layer {
  name: "map32_3_conv_b"
  type: "Convolution"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_b"
  type: "BatchNorm"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_3_scale_b"
  type: "Scale"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_eltsum"
  type: "Eltwise"
  bottom: "map32_2_eltsum"
  bottom: "map32_3_conv_b"
  top: "map32_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_3_relu_after_sum"
  type: "ReLU"
  bottom: "map32_3_eltsum"
  top: "map32_3_eltsum"
}
layer {
  name: "map64_1_conv_proj"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_proj"
  type: "BatchNorm"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_proj"
  type: "Scale"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_conv_a"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_a"
  type: "BatchNorm"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_a"
  type: "Scale"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_relu_a"
  type: "ReLU"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
}
layer {
  name: "map64_1_conv_b"
  type: "Convolution"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_b"
  type: "BatchNorm"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_b"
  type: "Scale"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_eltsum"
  type: "Eltwise"
  bottom: "map64_1_conv_proj"
  bottom: "map64_1_conv_b"
  top: "map64_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_1_relu_after_sum"
  type: "ReLU"
  bottom: "map64_1_eltsum"
  top: "map64_1_eltsum"
}
layer {
  name: "map64_2_conv_a"
  type: "Convolution"
  bottom: "map64_1_eltsum"
  top: "map64_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_a"
  type: "BatchNorm"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_2_scale_a"
  type: "Scale"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_relu_a"
  type: "ReLU"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
}
layer {
  name: "map64_2_conv_b"
  type: "Convolution"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_b"
  type: "BatchNorm"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_2_scale_b"
  type: "Scale"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_eltsum"
  type: "Eltwise"
  bottom: "map64_1_eltsum"
  bottom: "map64_2_conv_b"
  top: "map64_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_2_relu_after_sum"
  type: "ReLU"
  bottom: "map64_2_eltsum"
  top: "map64_2_eltsum"
}
layer {
  name: "map64_3_conv_a"
  type: "Convolution"
  bottom: "map64_2_eltsum"
  top: "map64_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_a"
  type: "BatchNorm"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_3_scale_a"
  type: "Scale"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_relu_a"
  type: "ReLU"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
}
layer {
  name: "map64_3_conv_b"
  type: "Convolution"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_b"
  type: "BatchNorm"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_3_scale_b"
  type: "Scale"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_eltsum"
  type: "Eltwise"
  bottom: "map64_2_eltsum"
  bottom: "map64_3_conv_b"
  top: "map64_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_3_relu_after_sum"
  type: "ReLU"
  bottom: "map64_3_eltsum"
  top: "map64_3_eltsum"
}
layer {
  name: "pool_global"
  type: "Pooling"
  bottom: "map64_3_eltsum"
  top: "pool_global"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_global"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc/top1"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc/top5"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop5"
  accuracy_param {
    top_k: 5
  }
}
I0418 20:35:09.422968 50350 layer_factory.hpp:77] Creating layer data
I0418 20:35:09.488593 50350 db_leveldb.cpp:18] Opened leveldb /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_full_train_leveldb_padded/
I0418 20:35:09.568109 50350 net.cpp:84] Creating Layer data
I0418 20:35:09.568146 50350 net.cpp:380] data -> data
I0418 20:35:09.568189 50350 net.cpp:380] data -> label
I0418 20:35:09.568214 50350 data_transformer.cpp:25] Loading mean file from: /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/paddedmean.binaryproto
I0418 20:35:09.575696 50350 data_layer.cpp:45] output data size: 128,3,32,32
I0418 20:35:09.582712 50350 net.cpp:122] Setting up data
I0418 20:35:09.582746 50350 net.cpp:129] Top shape: 128 3 32 32 (393216)
I0418 20:35:09.582751 50350 net.cpp:129] Top shape: 128 (128)
I0418 20:35:09.582752 50350 net.cpp:137] Memory required for data: 1573376
I0418 20:35:09.582762 50350 layer_factory.hpp:77] Creating layer label_data_1_split
I0418 20:35:09.582788 50350 net.cpp:84] Creating Layer label_data_1_split
I0418 20:35:09.582794 50350 net.cpp:406] label_data_1_split <- label
I0418 20:35:09.582806 50350 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0418 20:35:09.582814 50350 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0418 20:35:09.582821 50350 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0418 20:35:09.582954 50350 net.cpp:122] Setting up label_data_1_split
I0418 20:35:09.582960 50350 net.cpp:129] Top shape: 128 (128)
I0418 20:35:09.582964 50350 net.cpp:129] Top shape: 128 (128)
I0418 20:35:09.582967 50350 net.cpp:129] Top shape: 128 (128)
I0418 20:35:09.582986 50350 net.cpp:137] Memory required for data: 1574912
I0418 20:35:09.582991 50350 layer_factory.hpp:77] Creating layer conv1
I0418 20:35:09.583010 50350 net.cpp:84] Creating Layer conv1
I0418 20:35:09.583014 50350 net.cpp:406] conv1 <- data
I0418 20:35:09.583019 50350 net.cpp:380] conv1 -> conv1
I0418 20:35:14.136071 50350 net.cpp:122] Setting up conv1
I0418 20:35:14.136126 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.136129 50350 net.cpp:137] Memory required for data: 9963520
I0418 20:35:14.136160 50350 layer_factory.hpp:77] Creating layer bn_conv1
I0418 20:35:14.136181 50350 net.cpp:84] Creating Layer bn_conv1
I0418 20:35:14.136188 50350 net.cpp:406] bn_conv1 <- conv1
I0418 20:35:14.136194 50350 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0418 20:35:14.136358 50350 net.cpp:122] Setting up bn_conv1
I0418 20:35:14.136364 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.136368 50350 net.cpp:137] Memory required for data: 18352128
I0418 20:35:14.136376 50350 layer_factory.hpp:77] Creating layer scale_conv1
I0418 20:35:14.136389 50350 net.cpp:84] Creating Layer scale_conv1
I0418 20:35:14.136394 50350 net.cpp:406] scale_conv1 <- conv1
I0418 20:35:14.136397 50350 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0418 20:35:14.136435 50350 layer_factory.hpp:77] Creating layer scale_conv1
I0418 20:35:14.136554 50350 net.cpp:122] Setting up scale_conv1
I0418 20:35:14.136560 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.136564 50350 net.cpp:137] Memory required for data: 26740736
I0418 20:35:14.136570 50350 layer_factory.hpp:77] Creating layer relu_conv1
I0418 20:35:14.136577 50350 net.cpp:84] Creating Layer relu_conv1
I0418 20:35:14.136580 50350 net.cpp:406] relu_conv1 <- conv1
I0418 20:35:14.136584 50350 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0418 20:35:14.136755 50350 net.cpp:122] Setting up relu_conv1
I0418 20:35:14.136762 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.136765 50350 net.cpp:137] Memory required for data: 35129344
I0418 20:35:14.136768 50350 layer_factory.hpp:77] Creating layer conv1_relu_conv1_0_split
I0418 20:35:14.136775 50350 net.cpp:84] Creating Layer conv1_relu_conv1_0_split
I0418 20:35:14.136778 50350 net.cpp:406] conv1_relu_conv1_0_split <- conv1
I0418 20:35:14.136783 50350 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_0
I0418 20:35:14.136790 50350 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_1
I0418 20:35:14.136821 50350 net.cpp:122] Setting up conv1_relu_conv1_0_split
I0418 20:35:14.136826 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.136831 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.136832 50350 net.cpp:137] Memory required for data: 51906560
I0418 20:35:14.136837 50350 layer_factory.hpp:77] Creating layer map16_1_conv_a
I0418 20:35:14.136845 50350 net.cpp:84] Creating Layer map16_1_conv_a
I0418 20:35:14.136849 50350 net.cpp:406] map16_1_conv_a <- conv1_relu_conv1_0_split_0
I0418 20:35:14.136853 50350 net.cpp:380] map16_1_conv_a -> map16_1_conv_a
I0418 20:35:14.138871 50350 net.cpp:122] Setting up map16_1_conv_a
I0418 20:35:14.138885 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.138888 50350 net.cpp:137] Memory required for data: 60295168
I0418 20:35:14.138896 50350 layer_factory.hpp:77] Creating layer map16_1_bn_a
I0418 20:35:14.138906 50350 net.cpp:84] Creating Layer map16_1_bn_a
I0418 20:35:14.138909 50350 net.cpp:406] map16_1_bn_a <- map16_1_conv_a
I0418 20:35:14.138916 50350 net.cpp:367] map16_1_bn_a -> map16_1_conv_a (in-place)
I0418 20:35:14.139058 50350 net.cpp:122] Setting up map16_1_bn_a
I0418 20:35:14.139065 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.139067 50350 net.cpp:137] Memory required for data: 68683776
I0418 20:35:14.139073 50350 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0418 20:35:14.139080 50350 net.cpp:84] Creating Layer map16_1_scale_a
I0418 20:35:14.139082 50350 net.cpp:406] map16_1_scale_a <- map16_1_conv_a
I0418 20:35:14.139117 50350 net.cpp:367] map16_1_scale_a -> map16_1_conv_a (in-place)
I0418 20:35:14.139145 50350 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0418 20:35:14.139225 50350 net.cpp:122] Setting up map16_1_scale_a
I0418 20:35:14.139230 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.139233 50350 net.cpp:137] Memory required for data: 77072384
I0418 20:35:14.139238 50350 layer_factory.hpp:77] Creating layer map16_1_relu_a
I0418 20:35:14.139243 50350 net.cpp:84] Creating Layer map16_1_relu_a
I0418 20:35:14.139246 50350 net.cpp:406] map16_1_relu_a <- map16_1_conv_a
I0418 20:35:14.139250 50350 net.cpp:367] map16_1_relu_a -> map16_1_conv_a (in-place)
I0418 20:35:14.139611 50350 net.cpp:122] Setting up map16_1_relu_a
I0418 20:35:14.139621 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.139624 50350 net.cpp:137] Memory required for data: 85460992
I0418 20:35:14.139627 50350 layer_factory.hpp:77] Creating layer map16_1_conv_b
I0418 20:35:14.139637 50350 net.cpp:84] Creating Layer map16_1_conv_b
I0418 20:35:14.139642 50350 net.cpp:406] map16_1_conv_b <- map16_1_conv_a
I0418 20:35:14.139647 50350 net.cpp:380] map16_1_conv_b -> map16_1_conv_b
I0418 20:35:14.140234 50350 net.cpp:122] Setting up map16_1_conv_b
I0418 20:35:14.140244 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.140246 50350 net.cpp:137] Memory required for data: 93849600
I0418 20:35:14.140252 50350 layer_factory.hpp:77] Creating layer map16_1_bn_b
I0418 20:35:14.140259 50350 net.cpp:84] Creating Layer map16_1_bn_b
I0418 20:35:14.140264 50350 net.cpp:406] map16_1_bn_b <- map16_1_conv_b
I0418 20:35:14.140269 50350 net.cpp:367] map16_1_bn_b -> map16_1_conv_b (in-place)
I0418 20:35:14.140405 50350 net.cpp:122] Setting up map16_1_bn_b
I0418 20:35:14.140410 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.140413 50350 net.cpp:137] Memory required for data: 102238208
I0418 20:35:14.140422 50350 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0418 20:35:14.140429 50350 net.cpp:84] Creating Layer map16_1_scale_b
I0418 20:35:14.140431 50350 net.cpp:406] map16_1_scale_b <- map16_1_conv_b
I0418 20:35:14.140435 50350 net.cpp:367] map16_1_scale_b -> map16_1_conv_b (in-place)
I0418 20:35:14.140485 50350 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0418 20:35:14.140566 50350 net.cpp:122] Setting up map16_1_scale_b
I0418 20:35:14.140573 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.140575 50350 net.cpp:137] Memory required for data: 110626816
I0418 20:35:14.140580 50350 layer_factory.hpp:77] Creating layer map16_1_eltsum
I0418 20:35:14.141875 50350 net.cpp:84] Creating Layer map16_1_eltsum
I0418 20:35:14.141883 50350 net.cpp:406] map16_1_eltsum <- conv1_relu_conv1_0_split_1
I0418 20:35:14.141888 50350 net.cpp:406] map16_1_eltsum <- map16_1_conv_b
I0418 20:35:14.141892 50350 net.cpp:380] map16_1_eltsum -> map16_1_eltsum
I0418 20:35:14.141924 50350 net.cpp:122] Setting up map16_1_eltsum
I0418 20:35:14.141930 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.141933 50350 net.cpp:137] Memory required for data: 119015424
I0418 20:35:14.141935 50350 layer_factory.hpp:77] Creating layer map16_1_relu_after_sum
I0418 20:35:14.141940 50350 net.cpp:84] Creating Layer map16_1_relu_after_sum
I0418 20:35:14.141943 50350 net.cpp:406] map16_1_relu_after_sum <- map16_1_eltsum
I0418 20:35:14.141947 50350 net.cpp:367] map16_1_relu_after_sum -> map16_1_eltsum (in-place)
I0418 20:35:14.142310 50350 net.cpp:122] Setting up map16_1_relu_after_sum
I0418 20:35:14.142320 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.142324 50350 net.cpp:137] Memory required for data: 127404032
I0418 20:35:14.142328 50350 layer_factory.hpp:77] Creating layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0418 20:35:14.142335 50350 net.cpp:84] Creating Layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0418 20:35:14.142338 50350 net.cpp:406] map16_1_eltsum_map16_1_relu_after_sum_0_split <- map16_1_eltsum
I0418 20:35:14.142343 50350 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0418 20:35:14.142361 50350 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0418 20:35:14.142395 50350 net.cpp:122] Setting up map16_1_eltsum_map16_1_relu_after_sum_0_split
I0418 20:35:14.142400 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.142405 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.142406 50350 net.cpp:137] Memory required for data: 144181248
I0418 20:35:14.142410 50350 layer_factory.hpp:77] Creating layer map16_2_conv_a
I0418 20:35:14.142417 50350 net.cpp:84] Creating Layer map16_2_conv_a
I0418 20:35:14.142421 50350 net.cpp:406] map16_2_conv_a <- map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0418 20:35:14.142426 50350 net.cpp:380] map16_2_conv_a -> map16_2_conv_a
I0418 20:35:14.143261 50350 net.cpp:122] Setting up map16_2_conv_a
I0418 20:35:14.143272 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.143275 50350 net.cpp:137] Memory required for data: 152569856
I0418 20:35:14.143281 50350 layer_factory.hpp:77] Creating layer map16_2_bn_a
I0418 20:35:14.143290 50350 net.cpp:84] Creating Layer map16_2_bn_a
I0418 20:35:14.143292 50350 net.cpp:406] map16_2_bn_a <- map16_2_conv_a
I0418 20:35:14.143297 50350 net.cpp:367] map16_2_bn_a -> map16_2_conv_a (in-place)
I0418 20:35:14.143445 50350 net.cpp:122] Setting up map16_2_bn_a
I0418 20:35:14.143467 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.143471 50350 net.cpp:137] Memory required for data: 160958464
I0418 20:35:14.143476 50350 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0418 20:35:14.143482 50350 net.cpp:84] Creating Layer map16_2_scale_a
I0418 20:35:14.143486 50350 net.cpp:406] map16_2_scale_a <- map16_2_conv_a
I0418 20:35:14.143491 50350 net.cpp:367] map16_2_scale_a -> map16_2_conv_a (in-place)
I0418 20:35:14.143518 50350 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0418 20:35:14.143602 50350 net.cpp:122] Setting up map16_2_scale_a
I0418 20:35:14.143609 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.143611 50350 net.cpp:137] Memory required for data: 169347072
I0418 20:35:14.143616 50350 layer_factory.hpp:77] Creating layer map16_2_relu_a
I0418 20:35:14.143621 50350 net.cpp:84] Creating Layer map16_2_relu_a
I0418 20:35:14.143625 50350 net.cpp:406] map16_2_relu_a <- map16_2_conv_a
I0418 20:35:14.143628 50350 net.cpp:367] map16_2_relu_a -> map16_2_conv_a (in-place)
I0418 20:35:14.143800 50350 net.cpp:122] Setting up map16_2_relu_a
I0418 20:35:14.143806 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.143810 50350 net.cpp:137] Memory required for data: 177735680
I0418 20:35:14.143812 50350 layer_factory.hpp:77] Creating layer map16_2_conv_b
I0418 20:35:14.143821 50350 net.cpp:84] Creating Layer map16_2_conv_b
I0418 20:35:14.143826 50350 net.cpp:406] map16_2_conv_b <- map16_2_conv_a
I0418 20:35:14.143829 50350 net.cpp:380] map16_2_conv_b -> map16_2_conv_b
I0418 20:35:14.144675 50350 net.cpp:122] Setting up map16_2_conv_b
I0418 20:35:14.144685 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.144688 50350 net.cpp:137] Memory required for data: 186124288
I0418 20:35:14.144695 50350 layer_factory.hpp:77] Creating layer map16_2_bn_b
I0418 20:35:14.144702 50350 net.cpp:84] Creating Layer map16_2_bn_b
I0418 20:35:14.144706 50350 net.cpp:406] map16_2_bn_b <- map16_2_conv_b
I0418 20:35:14.144711 50350 net.cpp:367] map16_2_bn_b -> map16_2_conv_b (in-place)
I0418 20:35:14.144856 50350 net.cpp:122] Setting up map16_2_bn_b
I0418 20:35:14.144861 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.144865 50350 net.cpp:137] Memory required for data: 194512896
I0418 20:35:14.144875 50350 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0418 20:35:14.144881 50350 net.cpp:84] Creating Layer map16_2_scale_b
I0418 20:35:14.144883 50350 net.cpp:406] map16_2_scale_b <- map16_2_conv_b
I0418 20:35:14.144887 50350 net.cpp:367] map16_2_scale_b -> map16_2_conv_b (in-place)
I0418 20:35:14.144927 50350 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0418 20:35:14.145009 50350 net.cpp:122] Setting up map16_2_scale_b
I0418 20:35:14.145015 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.145018 50350 net.cpp:137] Memory required for data: 202901504
I0418 20:35:14.145022 50350 layer_factory.hpp:77] Creating layer map16_2_eltsum
I0418 20:35:14.145028 50350 net.cpp:84] Creating Layer map16_2_eltsum
I0418 20:35:14.145032 50350 net.cpp:406] map16_2_eltsum <- map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0418 20:35:14.145036 50350 net.cpp:406] map16_2_eltsum <- map16_2_conv_b
I0418 20:35:14.145040 50350 net.cpp:380] map16_2_eltsum -> map16_2_eltsum
I0418 20:35:14.145058 50350 net.cpp:122] Setting up map16_2_eltsum
I0418 20:35:14.145063 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.145066 50350 net.cpp:137] Memory required for data: 211290112
I0418 20:35:14.145068 50350 layer_factory.hpp:77] Creating layer map16_2_relu_after_sum
I0418 20:35:14.145073 50350 net.cpp:84] Creating Layer map16_2_relu_after_sum
I0418 20:35:14.145076 50350 net.cpp:406] map16_2_relu_after_sum <- map16_2_eltsum
I0418 20:35:14.145079 50350 net.cpp:367] map16_2_relu_after_sum -> map16_2_eltsum (in-place)
I0418 20:35:14.145213 50350 net.cpp:122] Setting up map16_2_relu_after_sum
I0418 20:35:14.145220 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.145223 50350 net.cpp:137] Memory required for data: 219678720
I0418 20:35:14.145226 50350 layer_factory.hpp:77] Creating layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0418 20:35:14.145231 50350 net.cpp:84] Creating Layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0418 20:35:14.145234 50350 net.cpp:406] map16_2_eltsum_map16_2_relu_after_sum_0_split <- map16_2_eltsum
I0418 20:35:14.145238 50350 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0418 20:35:14.145244 50350 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0418 20:35:14.145274 50350 net.cpp:122] Setting up map16_2_eltsum_map16_2_relu_after_sum_0_split
I0418 20:35:14.145279 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.145283 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.145285 50350 net.cpp:137] Memory required for data: 236455936
I0418 20:35:14.145289 50350 layer_factory.hpp:77] Creating layer map16_3_conv_a
I0418 20:35:14.145297 50350 net.cpp:84] Creating Layer map16_3_conv_a
I0418 20:35:14.145299 50350 net.cpp:406] map16_3_conv_a <- map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0418 20:35:14.145303 50350 net.cpp:380] map16_3_conv_a -> map16_3_conv_a
I0418 20:35:14.146133 50350 net.cpp:122] Setting up map16_3_conv_a
I0418 20:35:14.146144 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.146147 50350 net.cpp:137] Memory required for data: 244844544
I0418 20:35:14.146153 50350 layer_factory.hpp:77] Creating layer map16_3_bn_a
I0418 20:35:14.146160 50350 net.cpp:84] Creating Layer map16_3_bn_a
I0418 20:35:14.146164 50350 net.cpp:406] map16_3_bn_a <- map16_3_conv_a
I0418 20:35:14.146169 50350 net.cpp:367] map16_3_bn_a -> map16_3_conv_a (in-place)
I0418 20:35:14.146314 50350 net.cpp:122] Setting up map16_3_bn_a
I0418 20:35:14.146320 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.146323 50350 net.cpp:137] Memory required for data: 253233152
I0418 20:35:14.146328 50350 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0418 20:35:14.146334 50350 net.cpp:84] Creating Layer map16_3_scale_a
I0418 20:35:14.146338 50350 net.cpp:406] map16_3_scale_a <- map16_3_conv_a
I0418 20:35:14.146342 50350 net.cpp:367] map16_3_scale_a -> map16_3_conv_a (in-place)
I0418 20:35:14.146368 50350 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0418 20:35:14.146473 50350 net.cpp:122] Setting up map16_3_scale_a
I0418 20:35:14.146479 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.146482 50350 net.cpp:137] Memory required for data: 261621760
I0418 20:35:14.146499 50350 layer_factory.hpp:77] Creating layer map16_3_relu_a
I0418 20:35:14.146505 50350 net.cpp:84] Creating Layer map16_3_relu_a
I0418 20:35:14.146509 50350 net.cpp:406] map16_3_relu_a <- map16_3_conv_a
I0418 20:35:14.146513 50350 net.cpp:367] map16_3_relu_a -> map16_3_conv_a (in-place)
I0418 20:35:14.146656 50350 net.cpp:122] Setting up map16_3_relu_a
I0418 20:35:14.146662 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.146666 50350 net.cpp:137] Memory required for data: 270010368
I0418 20:35:14.146667 50350 layer_factory.hpp:77] Creating layer map16_3_conv_b
I0418 20:35:14.146677 50350 net.cpp:84] Creating Layer map16_3_conv_b
I0418 20:35:14.146680 50350 net.cpp:406] map16_3_conv_b <- map16_3_conv_a
I0418 20:35:14.146684 50350 net.cpp:380] map16_3_conv_b -> map16_3_conv_b
I0418 20:35:14.147544 50350 net.cpp:122] Setting up map16_3_conv_b
I0418 20:35:14.147557 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.147559 50350 net.cpp:137] Memory required for data: 278398976
I0418 20:35:14.147565 50350 layer_factory.hpp:77] Creating layer map16_3_bn_b
I0418 20:35:14.147574 50350 net.cpp:84] Creating Layer map16_3_bn_b
I0418 20:35:14.147578 50350 net.cpp:406] map16_3_bn_b <- map16_3_conv_b
I0418 20:35:14.147584 50350 net.cpp:367] map16_3_bn_b -> map16_3_conv_b (in-place)
I0418 20:35:14.147733 50350 net.cpp:122] Setting up map16_3_bn_b
I0418 20:35:14.147739 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.147742 50350 net.cpp:137] Memory required for data: 286787584
I0418 20:35:14.147747 50350 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0418 20:35:14.147753 50350 net.cpp:84] Creating Layer map16_3_scale_b
I0418 20:35:14.147756 50350 net.cpp:406] map16_3_scale_b <- map16_3_conv_b
I0418 20:35:14.147760 50350 net.cpp:367] map16_3_scale_b -> map16_3_conv_b (in-place)
I0418 20:35:14.147788 50350 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0418 20:35:14.147869 50350 net.cpp:122] Setting up map16_3_scale_b
I0418 20:35:14.147874 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.147877 50350 net.cpp:137] Memory required for data: 295176192
I0418 20:35:14.147882 50350 layer_factory.hpp:77] Creating layer map16_3_eltsum
I0418 20:35:14.147888 50350 net.cpp:84] Creating Layer map16_3_eltsum
I0418 20:35:14.147892 50350 net.cpp:406] map16_3_eltsum <- map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0418 20:35:14.147897 50350 net.cpp:406] map16_3_eltsum <- map16_3_conv_b
I0418 20:35:14.147900 50350 net.cpp:380] map16_3_eltsum -> map16_3_eltsum
I0418 20:35:14.147919 50350 net.cpp:122] Setting up map16_3_eltsum
I0418 20:35:14.147923 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.147927 50350 net.cpp:137] Memory required for data: 303564800
I0418 20:35:14.147929 50350 layer_factory.hpp:77] Creating layer map16_3_relu_after_sum
I0418 20:35:14.147933 50350 net.cpp:84] Creating Layer map16_3_relu_after_sum
I0418 20:35:14.147936 50350 net.cpp:406] map16_3_relu_after_sum <- map16_3_eltsum
I0418 20:35:14.147939 50350 net.cpp:367] map16_3_relu_after_sum -> map16_3_eltsum (in-place)
I0418 20:35:14.148075 50350 net.cpp:122] Setting up map16_3_relu_after_sum
I0418 20:35:14.148082 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.148085 50350 net.cpp:137] Memory required for data: 311953408
I0418 20:35:14.148087 50350 layer_factory.hpp:77] Creating layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0418 20:35:14.148093 50350 net.cpp:84] Creating Layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0418 20:35:14.148097 50350 net.cpp:406] map16_3_eltsum_map16_3_relu_after_sum_0_split <- map16_3_eltsum
I0418 20:35:14.148100 50350 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0418 20:35:14.148106 50350 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0418 20:35:14.148138 50350 net.cpp:122] Setting up map16_3_eltsum_map16_3_relu_after_sum_0_split
I0418 20:35:14.148141 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.148156 50350 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0418 20:35:14.148159 50350 net.cpp:137] Memory required for data: 328730624
I0418 20:35:14.148161 50350 layer_factory.hpp:77] Creating layer map32_1_conv_proj
I0418 20:35:14.148169 50350 net.cpp:84] Creating Layer map32_1_conv_proj
I0418 20:35:14.148174 50350 net.cpp:406] map32_1_conv_proj <- map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0418 20:35:14.148177 50350 net.cpp:380] map32_1_conv_proj -> map32_1_conv_proj
I0418 20:35:14.149256 50350 net.cpp:122] Setting up map32_1_conv_proj
I0418 20:35:14.149268 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.149271 50350 net.cpp:137] Memory required for data: 332924928
I0418 20:35:14.149277 50350 layer_factory.hpp:77] Creating layer map32_1_bn_proj
I0418 20:35:14.149286 50350 net.cpp:84] Creating Layer map32_1_bn_proj
I0418 20:35:14.149289 50350 net.cpp:406] map32_1_bn_proj <- map32_1_conv_proj
I0418 20:35:14.149294 50350 net.cpp:367] map32_1_bn_proj -> map32_1_conv_proj (in-place)
I0418 20:35:14.149448 50350 net.cpp:122] Setting up map32_1_bn_proj
I0418 20:35:14.149471 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.149474 50350 net.cpp:137] Memory required for data: 337119232
I0418 20:35:14.149480 50350 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0418 20:35:14.149487 50350 net.cpp:84] Creating Layer map32_1_scale_proj
I0418 20:35:14.149490 50350 net.cpp:406] map32_1_scale_proj <- map32_1_conv_proj
I0418 20:35:14.149494 50350 net.cpp:367] map32_1_scale_proj -> map32_1_conv_proj (in-place)
I0418 20:35:14.149523 50350 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0418 20:35:14.149606 50350 net.cpp:122] Setting up map32_1_scale_proj
I0418 20:35:14.149612 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.149615 50350 net.cpp:137] Memory required for data: 341313536
I0418 20:35:14.149619 50350 layer_factory.hpp:77] Creating layer map32_1_conv_a
I0418 20:35:14.149627 50350 net.cpp:84] Creating Layer map32_1_conv_a
I0418 20:35:14.149631 50350 net.cpp:406] map32_1_conv_a <- map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0418 20:35:14.149636 50350 net.cpp:380] map32_1_conv_a -> map32_1_conv_a
I0418 20:35:14.150509 50350 net.cpp:122] Setting up map32_1_conv_a
I0418 20:35:14.150521 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.150524 50350 net.cpp:137] Memory required for data: 345507840
I0418 20:35:14.150530 50350 layer_factory.hpp:77] Creating layer map32_1_bn_a
I0418 20:35:14.150537 50350 net.cpp:84] Creating Layer map32_1_bn_a
I0418 20:35:14.150542 50350 net.cpp:406] map32_1_bn_a <- map32_1_conv_a
I0418 20:35:14.150547 50350 net.cpp:367] map32_1_bn_a -> map32_1_conv_a (in-place)
I0418 20:35:14.150693 50350 net.cpp:122] Setting up map32_1_bn_a
I0418 20:35:14.150699 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.150702 50350 net.cpp:137] Memory required for data: 349702144
I0418 20:35:14.150708 50350 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0418 20:35:14.150713 50350 net.cpp:84] Creating Layer map32_1_scale_a
I0418 20:35:14.150717 50350 net.cpp:406] map32_1_scale_a <- map32_1_conv_a
I0418 20:35:14.150720 50350 net.cpp:367] map32_1_scale_a -> map32_1_conv_a (in-place)
I0418 20:35:14.150748 50350 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0418 20:35:14.150828 50350 net.cpp:122] Setting up map32_1_scale_a
I0418 20:35:14.150835 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.150837 50350 net.cpp:137] Memory required for data: 353896448
I0418 20:35:14.150841 50350 layer_factory.hpp:77] Creating layer map32_1_relu_a
I0418 20:35:14.150846 50350 net.cpp:84] Creating Layer map32_1_relu_a
I0418 20:35:14.150851 50350 net.cpp:406] map32_1_relu_a <- map32_1_conv_a
I0418 20:35:14.150853 50350 net.cpp:367] map32_1_relu_a -> map32_1_conv_a (in-place)
I0418 20:35:14.150992 50350 net.cpp:122] Setting up map32_1_relu_a
I0418 20:35:14.151000 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.151002 50350 net.cpp:137] Memory required for data: 358090752
I0418 20:35:14.151015 50350 layer_factory.hpp:77] Creating layer map32_1_conv_b
I0418 20:35:14.151026 50350 net.cpp:84] Creating Layer map32_1_conv_b
I0418 20:35:14.151028 50350 net.cpp:406] map32_1_conv_b <- map32_1_conv_a
I0418 20:35:14.151033 50350 net.cpp:380] map32_1_conv_b -> map32_1_conv_b
I0418 20:35:14.151938 50350 net.cpp:122] Setting up map32_1_conv_b
I0418 20:35:14.151949 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.151953 50350 net.cpp:137] Memory required for data: 362285056
I0418 20:35:14.151964 50350 layer_factory.hpp:77] Creating layer map32_1_bn_b
I0418 20:35:14.151971 50350 net.cpp:84] Creating Layer map32_1_bn_b
I0418 20:35:14.151975 50350 net.cpp:406] map32_1_bn_b <- map32_1_conv_b
I0418 20:35:14.151980 50350 net.cpp:367] map32_1_bn_b -> map32_1_conv_b (in-place)
I0418 20:35:14.152127 50350 net.cpp:122] Setting up map32_1_bn_b
I0418 20:35:14.152132 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.152135 50350 net.cpp:137] Memory required for data: 366479360
I0418 20:35:14.152142 50350 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0418 20:35:14.152148 50350 net.cpp:84] Creating Layer map32_1_scale_b
I0418 20:35:14.152151 50350 net.cpp:406] map32_1_scale_b <- map32_1_conv_b
I0418 20:35:14.152154 50350 net.cpp:367] map32_1_scale_b -> map32_1_conv_b (in-place)
I0418 20:35:14.152181 50350 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0418 20:35:14.152264 50350 net.cpp:122] Setting up map32_1_scale_b
I0418 20:35:14.152269 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.152272 50350 net.cpp:137] Memory required for data: 370673664
I0418 20:35:14.152277 50350 layer_factory.hpp:77] Creating layer map32_1_eltsum
I0418 20:35:14.152281 50350 net.cpp:84] Creating Layer map32_1_eltsum
I0418 20:35:14.152285 50350 net.cpp:406] map32_1_eltsum <- map32_1_conv_proj
I0418 20:35:14.152289 50350 net.cpp:406] map32_1_eltsum <- map32_1_conv_b
I0418 20:35:14.152293 50350 net.cpp:380] map32_1_eltsum -> map32_1_eltsum
I0418 20:35:14.152308 50350 net.cpp:122] Setting up map32_1_eltsum
I0418 20:35:14.152313 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.152317 50350 net.cpp:137] Memory required for data: 374867968
I0418 20:35:14.152318 50350 layer_factory.hpp:77] Creating layer map32_1_relu_after_sum
I0418 20:35:14.152323 50350 net.cpp:84] Creating Layer map32_1_relu_after_sum
I0418 20:35:14.152326 50350 net.cpp:406] map32_1_relu_after_sum <- map32_1_eltsum
I0418 20:35:14.152330 50350 net.cpp:367] map32_1_relu_after_sum -> map32_1_eltsum (in-place)
I0418 20:35:14.152714 50350 net.cpp:122] Setting up map32_1_relu_after_sum
I0418 20:35:14.152724 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.152729 50350 net.cpp:137] Memory required for data: 379062272
I0418 20:35:14.152731 50350 layer_factory.hpp:77] Creating layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0418 20:35:14.152737 50350 net.cpp:84] Creating Layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0418 20:35:14.152756 50350 net.cpp:406] map32_1_eltsum_map32_1_relu_after_sum_0_split <- map32_1_eltsum
I0418 20:35:14.152761 50350 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0418 20:35:14.152766 50350 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0418 20:35:14.152801 50350 net.cpp:122] Setting up map32_1_eltsum_map32_1_relu_after_sum_0_split
I0418 20:35:14.152806 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.152809 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.152812 50350 net.cpp:137] Memory required for data: 387450880
I0418 20:35:14.152814 50350 layer_factory.hpp:77] Creating layer map32_2_conv_a
I0418 20:35:14.152822 50350 net.cpp:84] Creating Layer map32_2_conv_a
I0418 20:35:14.152825 50350 net.cpp:406] map32_2_conv_a <- map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0418 20:35:14.152830 50350 net.cpp:380] map32_2_conv_a -> map32_2_conv_a
I0418 20:35:14.153540 50350 net.cpp:122] Setting up map32_2_conv_a
I0418 20:35:14.153549 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.153553 50350 net.cpp:137] Memory required for data: 391645184
I0418 20:35:14.153558 50350 layer_factory.hpp:77] Creating layer map32_2_bn_a
I0418 20:35:14.153565 50350 net.cpp:84] Creating Layer map32_2_bn_a
I0418 20:35:14.153568 50350 net.cpp:406] map32_2_bn_a <- map32_2_conv_a
I0418 20:35:14.153573 50350 net.cpp:367] map32_2_bn_a -> map32_2_conv_a (in-place)
I0418 20:35:14.153717 50350 net.cpp:122] Setting up map32_2_bn_a
I0418 20:35:14.153723 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.153726 50350 net.cpp:137] Memory required for data: 395839488
I0418 20:35:14.153731 50350 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0418 20:35:14.153738 50350 net.cpp:84] Creating Layer map32_2_scale_a
I0418 20:35:14.153740 50350 net.cpp:406] map32_2_scale_a <- map32_2_conv_a
I0418 20:35:14.153744 50350 net.cpp:367] map32_2_scale_a -> map32_2_conv_a (in-place)
I0418 20:35:14.153770 50350 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0418 20:35:14.153854 50350 net.cpp:122] Setting up map32_2_scale_a
I0418 20:35:14.153859 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.153862 50350 net.cpp:137] Memory required for data: 400033792
I0418 20:35:14.153867 50350 layer_factory.hpp:77] Creating layer map32_2_relu_a
I0418 20:35:14.153872 50350 net.cpp:84] Creating Layer map32_2_relu_a
I0418 20:35:14.153875 50350 net.cpp:406] map32_2_relu_a <- map32_2_conv_a
I0418 20:35:14.153878 50350 net.cpp:367] map32_2_relu_a -> map32_2_conv_a (in-place)
I0418 20:35:14.154243 50350 net.cpp:122] Setting up map32_2_relu_a
I0418 20:35:14.154254 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.154258 50350 net.cpp:137] Memory required for data: 404228096
I0418 20:35:14.154260 50350 layer_factory.hpp:77] Creating layer map32_2_conv_b
I0418 20:35:14.154269 50350 net.cpp:84] Creating Layer map32_2_conv_b
I0418 20:35:14.154273 50350 net.cpp:406] map32_2_conv_b <- map32_2_conv_a
I0418 20:35:14.154278 50350 net.cpp:380] map32_2_conv_b -> map32_2_conv_b
I0418 20:35:14.155215 50350 net.cpp:122] Setting up map32_2_conv_b
I0418 20:35:14.155225 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.155230 50350 net.cpp:137] Memory required for data: 408422400
I0418 20:35:14.155234 50350 layer_factory.hpp:77] Creating layer map32_2_bn_b
I0418 20:35:14.155242 50350 net.cpp:84] Creating Layer map32_2_bn_b
I0418 20:35:14.155246 50350 net.cpp:406] map32_2_bn_b <- map32_2_conv_b
I0418 20:35:14.155251 50350 net.cpp:367] map32_2_bn_b -> map32_2_conv_b (in-place)
I0418 20:35:14.155424 50350 net.cpp:122] Setting up map32_2_bn_b
I0418 20:35:14.155431 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.155433 50350 net.cpp:137] Memory required for data: 412616704
I0418 20:35:14.155438 50350 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0418 20:35:14.155450 50350 net.cpp:84] Creating Layer map32_2_scale_b
I0418 20:35:14.155454 50350 net.cpp:406] map32_2_scale_b <- map32_2_conv_b
I0418 20:35:14.155458 50350 net.cpp:367] map32_2_scale_b -> map32_2_conv_b (in-place)
I0418 20:35:14.155491 50350 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0418 20:35:14.155580 50350 net.cpp:122] Setting up map32_2_scale_b
I0418 20:35:14.155586 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.155588 50350 net.cpp:137] Memory required for data: 416811008
I0418 20:35:14.155593 50350 layer_factory.hpp:77] Creating layer map32_2_eltsum
I0418 20:35:14.155599 50350 net.cpp:84] Creating Layer map32_2_eltsum
I0418 20:35:14.155603 50350 net.cpp:406] map32_2_eltsum <- map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0418 20:35:14.155607 50350 net.cpp:406] map32_2_eltsum <- map32_2_conv_b
I0418 20:35:14.155611 50350 net.cpp:380] map32_2_eltsum -> map32_2_eltsum
I0418 20:35:14.155627 50350 net.cpp:122] Setting up map32_2_eltsum
I0418 20:35:14.155632 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.155647 50350 net.cpp:137] Memory required for data: 421005312
I0418 20:35:14.155649 50350 layer_factory.hpp:77] Creating layer map32_2_relu_after_sum
I0418 20:35:14.155655 50350 net.cpp:84] Creating Layer map32_2_relu_after_sum
I0418 20:35:14.155658 50350 net.cpp:406] map32_2_relu_after_sum <- map32_2_eltsum
I0418 20:35:14.155663 50350 net.cpp:367] map32_2_relu_after_sum -> map32_2_eltsum (in-place)
I0418 20:35:14.155824 50350 net.cpp:122] Setting up map32_2_relu_after_sum
I0418 20:35:14.155830 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.155833 50350 net.cpp:137] Memory required for data: 425199616
I0418 20:35:14.155836 50350 layer_factory.hpp:77] Creating layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0418 20:35:14.155841 50350 net.cpp:84] Creating Layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0418 20:35:14.155845 50350 net.cpp:406] map32_2_eltsum_map32_2_relu_after_sum_0_split <- map32_2_eltsum
I0418 20:35:14.155849 50350 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0418 20:35:14.155858 50350 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0418 20:35:14.155907 50350 net.cpp:122] Setting up map32_2_eltsum_map32_2_relu_after_sum_0_split
I0418 20:35:14.155915 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.155918 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.155920 50350 net.cpp:137] Memory required for data: 433588224
I0418 20:35:14.155923 50350 layer_factory.hpp:77] Creating layer map32_3_conv_a
I0418 20:35:14.155931 50350 net.cpp:84] Creating Layer map32_3_conv_a
I0418 20:35:14.155935 50350 net.cpp:406] map32_3_conv_a <- map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0418 20:35:14.155939 50350 net.cpp:380] map32_3_conv_a -> map32_3_conv_a
I0418 20:35:14.156904 50350 net.cpp:122] Setting up map32_3_conv_a
I0418 20:35:14.156916 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.156920 50350 net.cpp:137] Memory required for data: 437782528
I0418 20:35:14.156925 50350 layer_factory.hpp:77] Creating layer map32_3_bn_a
I0418 20:35:14.156934 50350 net.cpp:84] Creating Layer map32_3_bn_a
I0418 20:35:14.156937 50350 net.cpp:406] map32_3_bn_a <- map32_3_conv_a
I0418 20:35:14.156942 50350 net.cpp:367] map32_3_bn_a -> map32_3_conv_a (in-place)
I0418 20:35:14.157100 50350 net.cpp:122] Setting up map32_3_bn_a
I0418 20:35:14.157106 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.157109 50350 net.cpp:137] Memory required for data: 441976832
I0418 20:35:14.157115 50350 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0418 20:35:14.157121 50350 net.cpp:84] Creating Layer map32_3_scale_a
I0418 20:35:14.157124 50350 net.cpp:406] map32_3_scale_a <- map32_3_conv_a
I0418 20:35:14.157129 50350 net.cpp:367] map32_3_scale_a -> map32_3_conv_a (in-place)
I0418 20:35:14.157156 50350 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0418 20:35:14.157246 50350 net.cpp:122] Setting up map32_3_scale_a
I0418 20:35:14.157253 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.157254 50350 net.cpp:137] Memory required for data: 446171136
I0418 20:35:14.157259 50350 layer_factory.hpp:77] Creating layer map32_3_relu_a
I0418 20:35:14.157264 50350 net.cpp:84] Creating Layer map32_3_relu_a
I0418 20:35:14.157269 50350 net.cpp:406] map32_3_relu_a <- map32_3_conv_a
I0418 20:35:14.157271 50350 net.cpp:367] map32_3_relu_a -> map32_3_conv_a (in-place)
I0418 20:35:14.157423 50350 net.cpp:122] Setting up map32_3_relu_a
I0418 20:35:14.157429 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.157433 50350 net.cpp:137] Memory required for data: 450365440
I0418 20:35:14.157435 50350 layer_factory.hpp:77] Creating layer map32_3_conv_b
I0418 20:35:14.157454 50350 net.cpp:84] Creating Layer map32_3_conv_b
I0418 20:35:14.157459 50350 net.cpp:406] map32_3_conv_b <- map32_3_conv_a
I0418 20:35:14.157464 50350 net.cpp:380] map32_3_conv_b -> map32_3_conv_b
I0418 20:35:14.158421 50350 net.cpp:122] Setting up map32_3_conv_b
I0418 20:35:14.158450 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.158470 50350 net.cpp:137] Memory required for data: 454559744
I0418 20:35:14.158478 50350 layer_factory.hpp:77] Creating layer map32_3_bn_b
I0418 20:35:14.158485 50350 net.cpp:84] Creating Layer map32_3_bn_b
I0418 20:35:14.158489 50350 net.cpp:406] map32_3_bn_b <- map32_3_conv_b
I0418 20:35:14.158495 50350 net.cpp:367] map32_3_bn_b -> map32_3_conv_b (in-place)
I0418 20:35:14.158653 50350 net.cpp:122] Setting up map32_3_bn_b
I0418 20:35:14.158659 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.158663 50350 net.cpp:137] Memory required for data: 458754048
I0418 20:35:14.158668 50350 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0418 20:35:14.158674 50350 net.cpp:84] Creating Layer map32_3_scale_b
I0418 20:35:14.158677 50350 net.cpp:406] map32_3_scale_b <- map32_3_conv_b
I0418 20:35:14.158681 50350 net.cpp:367] map32_3_scale_b -> map32_3_conv_b (in-place)
I0418 20:35:14.158710 50350 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0418 20:35:14.158812 50350 net.cpp:122] Setting up map32_3_scale_b
I0418 20:35:14.158818 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.158820 50350 net.cpp:137] Memory required for data: 462948352
I0418 20:35:14.158824 50350 layer_factory.hpp:77] Creating layer map32_3_eltsum
I0418 20:35:14.158830 50350 net.cpp:84] Creating Layer map32_3_eltsum
I0418 20:35:14.158834 50350 net.cpp:406] map32_3_eltsum <- map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0418 20:35:14.158839 50350 net.cpp:406] map32_3_eltsum <- map32_3_conv_b
I0418 20:35:14.158843 50350 net.cpp:380] map32_3_eltsum -> map32_3_eltsum
I0418 20:35:14.158859 50350 net.cpp:122] Setting up map32_3_eltsum
I0418 20:35:14.158862 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.158865 50350 net.cpp:137] Memory required for data: 467142656
I0418 20:35:14.158869 50350 layer_factory.hpp:77] Creating layer map32_3_relu_after_sum
I0418 20:35:14.158872 50350 net.cpp:84] Creating Layer map32_3_relu_after_sum
I0418 20:35:14.158876 50350 net.cpp:406] map32_3_relu_after_sum <- map32_3_eltsum
I0418 20:35:14.158879 50350 net.cpp:367] map32_3_relu_after_sum -> map32_3_eltsum (in-place)
I0418 20:35:14.159023 50350 net.cpp:122] Setting up map32_3_relu_after_sum
I0418 20:35:14.159029 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.159034 50350 net.cpp:137] Memory required for data: 471336960
I0418 20:35:14.159035 50350 layer_factory.hpp:77] Creating layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0418 20:35:14.159041 50350 net.cpp:84] Creating Layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0418 20:35:14.159044 50350 net.cpp:406] map32_3_eltsum_map32_3_relu_after_sum_0_split <- map32_3_eltsum
I0418 20:35:14.159049 50350 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0418 20:35:14.159054 50350 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0418 20:35:14.159086 50350 net.cpp:122] Setting up map32_3_eltsum_map32_3_relu_after_sum_0_split
I0418 20:35:14.159091 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.159096 50350 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0418 20:35:14.159098 50350 net.cpp:137] Memory required for data: 479725568
I0418 20:35:14.159101 50350 layer_factory.hpp:77] Creating layer map64_1_conv_proj
I0418 20:35:14.159108 50350 net.cpp:84] Creating Layer map64_1_conv_proj
I0418 20:35:14.159111 50350 net.cpp:406] map64_1_conv_proj <- map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0418 20:35:14.159116 50350 net.cpp:380] map64_1_conv_proj -> map64_1_conv_proj
I0418 20:35:14.161360 50350 net.cpp:122] Setting up map64_1_conv_proj
I0418 20:35:14.161372 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.161376 50350 net.cpp:137] Memory required for data: 481822720
I0418 20:35:14.161382 50350 layer_factory.hpp:77] Creating layer map64_1_bn_proj
I0418 20:35:14.161401 50350 net.cpp:84] Creating Layer map64_1_bn_proj
I0418 20:35:14.161406 50350 net.cpp:406] map64_1_bn_proj <- map64_1_conv_proj
I0418 20:35:14.161412 50350 net.cpp:367] map64_1_bn_proj -> map64_1_conv_proj (in-place)
I0418 20:35:14.161615 50350 net.cpp:122] Setting up map64_1_bn_proj
I0418 20:35:14.161623 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.161625 50350 net.cpp:137] Memory required for data: 483919872
I0418 20:35:14.161631 50350 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0418 20:35:14.161640 50350 net.cpp:84] Creating Layer map64_1_scale_proj
I0418 20:35:14.161643 50350 net.cpp:406] map64_1_scale_proj <- map64_1_conv_proj
I0418 20:35:14.161648 50350 net.cpp:367] map64_1_scale_proj -> map64_1_conv_proj (in-place)
I0418 20:35:14.161677 50350 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0418 20:35:14.161794 50350 net.cpp:122] Setting up map64_1_scale_proj
I0418 20:35:14.161800 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.161803 50350 net.cpp:137] Memory required for data: 486017024
I0418 20:35:14.161808 50350 layer_factory.hpp:77] Creating layer map64_1_conv_a
I0418 20:35:14.161818 50350 net.cpp:84] Creating Layer map64_1_conv_a
I0418 20:35:14.161821 50350 net.cpp:406] map64_1_conv_a <- map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0418 20:35:14.161829 50350 net.cpp:380] map64_1_conv_a -> map64_1_conv_a
I0418 20:35:14.162966 50350 net.cpp:122] Setting up map64_1_conv_a
I0418 20:35:14.162977 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.162981 50350 net.cpp:137] Memory required for data: 488114176
I0418 20:35:14.162986 50350 layer_factory.hpp:77] Creating layer map64_1_bn_a
I0418 20:35:14.162997 50350 net.cpp:84] Creating Layer map64_1_bn_a
I0418 20:35:14.163000 50350 net.cpp:406] map64_1_bn_a <- map64_1_conv_a
I0418 20:35:14.163007 50350 net.cpp:367] map64_1_bn_a -> map64_1_conv_a (in-place)
I0418 20:35:14.163185 50350 net.cpp:122] Setting up map64_1_bn_a
I0418 20:35:14.163192 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.163194 50350 net.cpp:137] Memory required for data: 490211328
I0418 20:35:14.163200 50350 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0418 20:35:14.163208 50350 net.cpp:84] Creating Layer map64_1_scale_a
I0418 20:35:14.163211 50350 net.cpp:406] map64_1_scale_a <- map64_1_conv_a
I0418 20:35:14.163215 50350 net.cpp:367] map64_1_scale_a -> map64_1_conv_a (in-place)
I0418 20:35:14.163244 50350 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0418 20:35:14.163344 50350 net.cpp:122] Setting up map64_1_scale_a
I0418 20:35:14.163349 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.163352 50350 net.cpp:137] Memory required for data: 492308480
I0418 20:35:14.163357 50350 layer_factory.hpp:77] Creating layer map64_1_relu_a
I0418 20:35:14.163362 50350 net.cpp:84] Creating Layer map64_1_relu_a
I0418 20:35:14.163367 50350 net.cpp:406] map64_1_relu_a <- map64_1_conv_a
I0418 20:35:14.163372 50350 net.cpp:367] map64_1_relu_a -> map64_1_conv_a (in-place)
I0418 20:35:14.163549 50350 net.cpp:122] Setting up map64_1_relu_a
I0418 20:35:14.163558 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.163560 50350 net.cpp:137] Memory required for data: 494405632
I0418 20:35:14.163563 50350 layer_factory.hpp:77] Creating layer map64_1_conv_b
I0418 20:35:14.163573 50350 net.cpp:84] Creating Layer map64_1_conv_b
I0418 20:35:14.163578 50350 net.cpp:406] map64_1_conv_b <- map64_1_conv_a
I0418 20:35:14.163584 50350 net.cpp:380] map64_1_conv_b -> map64_1_conv_b
I0418 20:35:14.165349 50350 net.cpp:122] Setting up map64_1_conv_b
I0418 20:35:14.165361 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.165365 50350 net.cpp:137] Memory required for data: 496502784
I0418 20:35:14.165371 50350 layer_factory.hpp:77] Creating layer map64_1_bn_b
I0418 20:35:14.165380 50350 net.cpp:84] Creating Layer map64_1_bn_b
I0418 20:35:14.165385 50350 net.cpp:406] map64_1_bn_b <- map64_1_conv_b
I0418 20:35:14.165390 50350 net.cpp:367] map64_1_bn_b -> map64_1_conv_b (in-place)
I0418 20:35:14.165621 50350 net.cpp:122] Setting up map64_1_bn_b
I0418 20:35:14.165627 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.165630 50350 net.cpp:137] Memory required for data: 498599936
I0418 20:35:14.165637 50350 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0418 20:35:14.165644 50350 net.cpp:84] Creating Layer map64_1_scale_b
I0418 20:35:14.165648 50350 net.cpp:406] map64_1_scale_b <- map64_1_conv_b
I0418 20:35:14.165652 50350 net.cpp:367] map64_1_scale_b -> map64_1_conv_b (in-place)
I0418 20:35:14.165683 50350 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0418 20:35:14.165801 50350 net.cpp:122] Setting up map64_1_scale_b
I0418 20:35:14.165805 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.165808 50350 net.cpp:137] Memory required for data: 500697088
I0418 20:35:14.165813 50350 layer_factory.hpp:77] Creating layer map64_1_eltsum
I0418 20:35:14.165819 50350 net.cpp:84] Creating Layer map64_1_eltsum
I0418 20:35:14.165822 50350 net.cpp:406] map64_1_eltsum <- map64_1_conv_proj
I0418 20:35:14.165827 50350 net.cpp:406] map64_1_eltsum <- map64_1_conv_b
I0418 20:35:14.165834 50350 net.cpp:380] map64_1_eltsum -> map64_1_eltsum
I0418 20:35:14.165850 50350 net.cpp:122] Setting up map64_1_eltsum
I0418 20:35:14.165855 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.165858 50350 net.cpp:137] Memory required for data: 502794240
I0418 20:35:14.165861 50350 layer_factory.hpp:77] Creating layer map64_1_relu_after_sum
I0418 20:35:14.165868 50350 net.cpp:84] Creating Layer map64_1_relu_after_sum
I0418 20:35:14.165870 50350 net.cpp:406] map64_1_relu_after_sum <- map64_1_eltsum
I0418 20:35:14.165874 50350 net.cpp:367] map64_1_relu_after_sum -> map64_1_eltsum (in-place)
I0418 20:35:14.166038 50350 net.cpp:122] Setting up map64_1_relu_after_sum
I0418 20:35:14.166046 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.166049 50350 net.cpp:137] Memory required for data: 504891392
I0418 20:35:14.166051 50350 layer_factory.hpp:77] Creating layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0418 20:35:14.166057 50350 net.cpp:84] Creating Layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0418 20:35:14.166060 50350 net.cpp:406] map64_1_eltsum_map64_1_relu_after_sum_0_split <- map64_1_eltsum
I0418 20:35:14.166065 50350 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0418 20:35:14.166070 50350 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0418 20:35:14.166110 50350 net.cpp:122] Setting up map64_1_eltsum_map64_1_relu_after_sum_0_split
I0418 20:35:14.166115 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.166117 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.166119 50350 net.cpp:137] Memory required for data: 509085696
I0418 20:35:14.166123 50350 layer_factory.hpp:77] Creating layer map64_2_conv_a
I0418 20:35:14.166133 50350 net.cpp:84] Creating Layer map64_2_conv_a
I0418 20:35:14.166136 50350 net.cpp:406] map64_2_conv_a <- map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0418 20:35:14.166143 50350 net.cpp:380] map64_2_conv_a -> map64_2_conv_a
I0418 20:35:14.167423 50350 net.cpp:122] Setting up map64_2_conv_a
I0418 20:35:14.167435 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.167438 50350 net.cpp:137] Memory required for data: 511182848
I0418 20:35:14.167450 50350 layer_factory.hpp:77] Creating layer map64_2_bn_a
I0418 20:35:14.167477 50350 net.cpp:84] Creating Layer map64_2_bn_a
I0418 20:35:14.167481 50350 net.cpp:406] map64_2_bn_a <- map64_2_conv_a
I0418 20:35:14.167488 50350 net.cpp:367] map64_2_bn_a -> map64_2_conv_a (in-place)
I0418 20:35:14.167672 50350 net.cpp:122] Setting up map64_2_bn_a
I0418 20:35:14.167680 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.167682 50350 net.cpp:137] Memory required for data: 513280000
I0418 20:35:14.167688 50350 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0418 20:35:14.167696 50350 net.cpp:84] Creating Layer map64_2_scale_a
I0418 20:35:14.167711 50350 net.cpp:406] map64_2_scale_a <- map64_2_conv_a
I0418 20:35:14.167716 50350 net.cpp:367] map64_2_scale_a -> map64_2_conv_a (in-place)
I0418 20:35:14.167763 50350 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0418 20:35:14.167866 50350 net.cpp:122] Setting up map64_2_scale_a
I0418 20:35:14.167872 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.167876 50350 net.cpp:137] Memory required for data: 515377152
I0418 20:35:14.167881 50350 layer_factory.hpp:77] Creating layer map64_2_relu_a
I0418 20:35:14.167886 50350 net.cpp:84] Creating Layer map64_2_relu_a
I0418 20:35:14.167888 50350 net.cpp:406] map64_2_relu_a <- map64_2_conv_a
I0418 20:35:14.167894 50350 net.cpp:367] map64_2_relu_a -> map64_2_conv_a (in-place)
I0418 20:35:14.168278 50350 net.cpp:122] Setting up map64_2_relu_a
I0418 20:35:14.168288 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.168292 50350 net.cpp:137] Memory required for data: 517474304
I0418 20:35:14.168295 50350 layer_factory.hpp:77] Creating layer map64_2_conv_b
I0418 20:35:14.168305 50350 net.cpp:84] Creating Layer map64_2_conv_b
I0418 20:35:14.168310 50350 net.cpp:406] map64_2_conv_b <- map64_2_conv_a
I0418 20:35:14.168318 50350 net.cpp:380] map64_2_conv_b -> map64_2_conv_b
I0418 20:35:14.169869 50350 net.cpp:122] Setting up map64_2_conv_b
I0418 20:35:14.169881 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.169884 50350 net.cpp:137] Memory required for data: 519571456
I0418 20:35:14.169890 50350 layer_factory.hpp:77] Creating layer map64_2_bn_b
I0418 20:35:14.169900 50350 net.cpp:84] Creating Layer map64_2_bn_b
I0418 20:35:14.169904 50350 net.cpp:406] map64_2_bn_b <- map64_2_conv_b
I0418 20:35:14.169911 50350 net.cpp:367] map64_2_bn_b -> map64_2_conv_b (in-place)
I0418 20:35:14.170094 50350 net.cpp:122] Setting up map64_2_bn_b
I0418 20:35:14.170100 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.170104 50350 net.cpp:137] Memory required for data: 521668608
I0418 20:35:14.170122 50350 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0418 20:35:14.170130 50350 net.cpp:84] Creating Layer map64_2_scale_b
I0418 20:35:14.170135 50350 net.cpp:406] map64_2_scale_b <- map64_2_conv_b
I0418 20:35:14.170138 50350 net.cpp:367] map64_2_scale_b -> map64_2_conv_b (in-place)
I0418 20:35:14.170171 50350 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0418 20:35:14.170272 50350 net.cpp:122] Setting up map64_2_scale_b
I0418 20:35:14.170277 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.170280 50350 net.cpp:137] Memory required for data: 523765760
I0418 20:35:14.170285 50350 layer_factory.hpp:77] Creating layer map64_2_eltsum
I0418 20:35:14.170290 50350 net.cpp:84] Creating Layer map64_2_eltsum
I0418 20:35:14.170295 50350 net.cpp:406] map64_2_eltsum <- map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0418 20:35:14.170300 50350 net.cpp:406] map64_2_eltsum <- map64_2_conv_b
I0418 20:35:14.170306 50350 net.cpp:380] map64_2_eltsum -> map64_2_eltsum
I0418 20:35:14.170322 50350 net.cpp:122] Setting up map64_2_eltsum
I0418 20:35:14.170327 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.170330 50350 net.cpp:137] Memory required for data: 525862912
I0418 20:35:14.170332 50350 layer_factory.hpp:77] Creating layer map64_2_relu_after_sum
I0418 20:35:14.170339 50350 net.cpp:84] Creating Layer map64_2_relu_after_sum
I0418 20:35:14.170342 50350 net.cpp:406] map64_2_relu_after_sum <- map64_2_eltsum
I0418 20:35:14.170346 50350 net.cpp:367] map64_2_relu_after_sum -> map64_2_eltsum (in-place)
I0418 20:35:14.170517 50350 net.cpp:122] Setting up map64_2_relu_after_sum
I0418 20:35:14.170526 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.170529 50350 net.cpp:137] Memory required for data: 527960064
I0418 20:35:14.170531 50350 layer_factory.hpp:77] Creating layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0418 20:35:14.170539 50350 net.cpp:84] Creating Layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0418 20:35:14.170542 50350 net.cpp:406] map64_2_eltsum_map64_2_relu_after_sum_0_split <- map64_2_eltsum
I0418 20:35:14.170558 50350 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0418 20:35:14.170565 50350 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0418 20:35:14.170605 50350 net.cpp:122] Setting up map64_2_eltsum_map64_2_relu_after_sum_0_split
I0418 20:35:14.170611 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.170615 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.170617 50350 net.cpp:137] Memory required for data: 532154368
I0418 20:35:14.170620 50350 layer_factory.hpp:77] Creating layer map64_3_conv_a
I0418 20:35:14.170630 50350 net.cpp:84] Creating Layer map64_3_conv_a
I0418 20:35:14.170634 50350 net.cpp:406] map64_3_conv_a <- map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0418 20:35:14.170640 50350 net.cpp:380] map64_3_conv_a -> map64_3_conv_a
I0418 20:35:14.171967 50350 net.cpp:122] Setting up map64_3_conv_a
I0418 20:35:14.171978 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.171983 50350 net.cpp:137] Memory required for data: 534251520
I0418 20:35:14.171988 50350 layer_factory.hpp:77] Creating layer map64_3_bn_a
I0418 20:35:14.171995 50350 net.cpp:84] Creating Layer map64_3_bn_a
I0418 20:35:14.171999 50350 net.cpp:406] map64_3_bn_a <- map64_3_conv_a
I0418 20:35:14.172008 50350 net.cpp:367] map64_3_bn_a -> map64_3_conv_a (in-place)
I0418 20:35:14.172195 50350 net.cpp:122] Setting up map64_3_bn_a
I0418 20:35:14.172202 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.172205 50350 net.cpp:137] Memory required for data: 536348672
I0418 20:35:14.172210 50350 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0418 20:35:14.172216 50350 net.cpp:84] Creating Layer map64_3_scale_a
I0418 20:35:14.172220 50350 net.cpp:406] map64_3_scale_a <- map64_3_conv_a
I0418 20:35:14.172226 50350 net.cpp:367] map64_3_scale_a -> map64_3_conv_a (in-place)
I0418 20:35:14.172257 50350 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0418 20:35:14.172363 50350 net.cpp:122] Setting up map64_3_scale_a
I0418 20:35:14.172368 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.172370 50350 net.cpp:137] Memory required for data: 538445824
I0418 20:35:14.172375 50350 layer_factory.hpp:77] Creating layer map64_3_relu_a
I0418 20:35:14.172381 50350 net.cpp:84] Creating Layer map64_3_relu_a
I0418 20:35:14.172384 50350 net.cpp:406] map64_3_relu_a <- map64_3_conv_a
I0418 20:35:14.172389 50350 net.cpp:367] map64_3_relu_a -> map64_3_conv_a (in-place)
I0418 20:35:14.172557 50350 net.cpp:122] Setting up map64_3_relu_a
I0418 20:35:14.172564 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.172569 50350 net.cpp:137] Memory required for data: 540542976
I0418 20:35:14.172571 50350 layer_factory.hpp:77] Creating layer map64_3_conv_b
I0418 20:35:14.172581 50350 net.cpp:84] Creating Layer map64_3_conv_b
I0418 20:35:14.172585 50350 net.cpp:406] map64_3_conv_b <- map64_3_conv_a
I0418 20:35:14.172592 50350 net.cpp:380] map64_3_conv_b -> map64_3_conv_b
I0418 20:35:14.174124 50350 net.cpp:122] Setting up map64_3_conv_b
I0418 20:35:14.174135 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.174139 50350 net.cpp:137] Memory required for data: 542640128
I0418 20:35:14.174144 50350 layer_factory.hpp:77] Creating layer map64_3_bn_b
I0418 20:35:14.174154 50350 net.cpp:84] Creating Layer map64_3_bn_b
I0418 20:35:14.174159 50350 net.cpp:406] map64_3_bn_b <- map64_3_conv_b
I0418 20:35:14.174165 50350 net.cpp:367] map64_3_bn_b -> map64_3_conv_b (in-place)
I0418 20:35:14.174341 50350 net.cpp:122] Setting up map64_3_bn_b
I0418 20:35:14.174347 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.174350 50350 net.cpp:137] Memory required for data: 544737280
I0418 20:35:14.174355 50350 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0418 20:35:14.174361 50350 net.cpp:84] Creating Layer map64_3_scale_b
I0418 20:35:14.174365 50350 net.cpp:406] map64_3_scale_b <- map64_3_conv_b
I0418 20:35:14.174379 50350 net.cpp:367] map64_3_scale_b -> map64_3_conv_b (in-place)
I0418 20:35:14.174415 50350 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0418 20:35:14.174547 50350 net.cpp:122] Setting up map64_3_scale_b
I0418 20:35:14.174553 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.174556 50350 net.cpp:137] Memory required for data: 546834432
I0418 20:35:14.174562 50350 layer_factory.hpp:77] Creating layer map64_3_eltsum
I0418 20:35:14.174567 50350 net.cpp:84] Creating Layer map64_3_eltsum
I0418 20:35:14.174571 50350 net.cpp:406] map64_3_eltsum <- map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0418 20:35:14.174576 50350 net.cpp:406] map64_3_eltsum <- map64_3_conv_b
I0418 20:35:14.174582 50350 net.cpp:380] map64_3_eltsum -> map64_3_eltsum
I0418 20:35:14.174599 50350 net.cpp:122] Setting up map64_3_eltsum
I0418 20:35:14.174604 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.174607 50350 net.cpp:137] Memory required for data: 548931584
I0418 20:35:14.174610 50350 layer_factory.hpp:77] Creating layer map64_3_relu_after_sum
I0418 20:35:14.174616 50350 net.cpp:84] Creating Layer map64_3_relu_after_sum
I0418 20:35:14.174619 50350 net.cpp:406] map64_3_relu_after_sum <- map64_3_eltsum
I0418 20:35:14.174623 50350 net.cpp:367] map64_3_relu_after_sum -> map64_3_eltsum (in-place)
I0418 20:35:14.174808 50350 net.cpp:122] Setting up map64_3_relu_after_sum
I0418 20:35:14.174814 50350 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0418 20:35:14.174818 50350 net.cpp:137] Memory required for data: 551028736
I0418 20:35:14.174820 50350 layer_factory.hpp:77] Creating layer pool_global
I0418 20:35:14.174831 50350 net.cpp:84] Creating Layer pool_global
I0418 20:35:14.174835 50350 net.cpp:406] pool_global <- map64_3_eltsum
I0418 20:35:14.174839 50350 net.cpp:380] pool_global -> pool_global
I0418 20:35:14.175032 50350 net.cpp:122] Setting up pool_global
I0418 20:35:14.175040 50350 net.cpp:129] Top shape: 128 64 1 1 (8192)
I0418 20:35:14.175042 50350 net.cpp:137] Memory required for data: 551061504
I0418 20:35:14.175045 50350 layer_factory.hpp:77] Creating layer score
I0418 20:35:14.175055 50350 net.cpp:84] Creating Layer score
I0418 20:35:14.175057 50350 net.cpp:406] score <- pool_global
I0418 20:35:14.175063 50350 net.cpp:380] score -> score
I0418 20:35:14.175174 50350 net.cpp:122] Setting up score
I0418 20:35:14.175180 50350 net.cpp:129] Top shape: 128 10 (1280)
I0418 20:35:14.175184 50350 net.cpp:137] Memory required for data: 551066624
I0418 20:35:14.175189 50350 layer_factory.hpp:77] Creating layer score_score_0_split
I0418 20:35:14.175195 50350 net.cpp:84] Creating Layer score_score_0_split
I0418 20:35:14.175199 50350 net.cpp:406] score_score_0_split <- score
I0418 20:35:14.175202 50350 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0418 20:35:14.175209 50350 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0418 20:35:14.175215 50350 net.cpp:380] score_score_0_split -> score_score_0_split_2
I0418 20:35:14.175256 50350 net.cpp:122] Setting up score_score_0_split
I0418 20:35:14.175261 50350 net.cpp:129] Top shape: 128 10 (1280)
I0418 20:35:14.175263 50350 net.cpp:129] Top shape: 128 10 (1280)
I0418 20:35:14.175266 50350 net.cpp:129] Top shape: 128 10 (1280)
I0418 20:35:14.175269 50350 net.cpp:137] Memory required for data: 551081984
I0418 20:35:14.175271 50350 layer_factory.hpp:77] Creating layer loss
I0418 20:35:14.175277 50350 net.cpp:84] Creating Layer loss
I0418 20:35:14.175282 50350 net.cpp:406] loss <- score_score_0_split_0
I0418 20:35:14.175284 50350 net.cpp:406] loss <- label_data_1_split_0
I0418 20:35:14.175289 50350 net.cpp:380] loss -> loss
I0418 20:35:14.175302 50350 layer_factory.hpp:77] Creating layer loss
I0418 20:35:14.175835 50350 net.cpp:122] Setting up loss
I0418 20:35:14.175846 50350 net.cpp:129] Top shape: (1)
I0418 20:35:14.175849 50350 net.cpp:132]     with loss weight 1
I0418 20:35:14.175879 50350 net.cpp:137] Memory required for data: 551081988
I0418 20:35:14.175881 50350 layer_factory.hpp:77] Creating layer acc/top1
I0418 20:35:14.175891 50350 net.cpp:84] Creating Layer acc/top1
I0418 20:35:14.175904 50350 net.cpp:406] acc/top1 <- score_score_0_split_1
I0418 20:35:14.175910 50350 net.cpp:406] acc/top1 <- label_data_1_split_1
I0418 20:35:14.175915 50350 net.cpp:380] acc/top1 -> acctop1
I0418 20:35:14.175928 50350 net.cpp:122] Setting up acc/top1
I0418 20:35:14.175935 50350 net.cpp:129] Top shape: (1)
I0418 20:35:14.175937 50350 net.cpp:137] Memory required for data: 551081992
I0418 20:35:14.175940 50350 layer_factory.hpp:77] Creating layer acc/top5
I0418 20:35:14.175943 50350 net.cpp:84] Creating Layer acc/top5
I0418 20:35:14.175947 50350 net.cpp:406] acc/top5 <- score_score_0_split_2
I0418 20:35:14.175951 50350 net.cpp:406] acc/top5 <- label_data_1_split_2
I0418 20:35:14.175954 50350 net.cpp:380] acc/top5 -> acctop5
I0418 20:35:14.175961 50350 net.cpp:122] Setting up acc/top5
I0418 20:35:14.175964 50350 net.cpp:129] Top shape: (1)
I0418 20:35:14.175966 50350 net.cpp:137] Memory required for data: 551081996
I0418 20:35:14.175971 50350 net.cpp:200] acc/top5 does not need backward computation.
I0418 20:35:14.175974 50350 net.cpp:200] acc/top1 does not need backward computation.
I0418 20:35:14.175976 50350 net.cpp:198] loss needs backward computation.
I0418 20:35:14.175981 50350 net.cpp:198] score_score_0_split needs backward computation.
I0418 20:35:14.175982 50350 net.cpp:198] score needs backward computation.
I0418 20:35:14.175986 50350 net.cpp:198] pool_global needs backward computation.
I0418 20:35:14.175988 50350 net.cpp:198] map64_3_relu_after_sum needs backward computation.
I0418 20:35:14.175992 50350 net.cpp:198] map64_3_eltsum needs backward computation.
I0418 20:35:14.175993 50350 net.cpp:198] map64_3_scale_b needs backward computation.
I0418 20:35:14.175995 50350 net.cpp:198] map64_3_bn_b needs backward computation.
I0418 20:35:14.175998 50350 net.cpp:198] map64_3_conv_b needs backward computation.
I0418 20:35:14.176000 50350 net.cpp:198] map64_3_relu_a needs backward computation.
I0418 20:35:14.176002 50350 net.cpp:198] map64_3_scale_a needs backward computation.
I0418 20:35:14.176005 50350 net.cpp:198] map64_3_bn_a needs backward computation.
I0418 20:35:14.176007 50350 net.cpp:198] map64_3_conv_a needs backward computation.
I0418 20:35:14.176010 50350 net.cpp:198] map64_2_eltsum_map64_2_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.176013 50350 net.cpp:198] map64_2_relu_after_sum needs backward computation.
I0418 20:35:14.176015 50350 net.cpp:198] map64_2_eltsum needs backward computation.
I0418 20:35:14.176018 50350 net.cpp:198] map64_2_scale_b needs backward computation.
I0418 20:35:14.176021 50350 net.cpp:198] map64_2_bn_b needs backward computation.
I0418 20:35:14.176023 50350 net.cpp:198] map64_2_conv_b needs backward computation.
I0418 20:35:14.176026 50350 net.cpp:198] map64_2_relu_a needs backward computation.
I0418 20:35:14.176029 50350 net.cpp:198] map64_2_scale_a needs backward computation.
I0418 20:35:14.176031 50350 net.cpp:198] map64_2_bn_a needs backward computation.
I0418 20:35:14.176033 50350 net.cpp:198] map64_2_conv_a needs backward computation.
I0418 20:35:14.176036 50350 net.cpp:198] map64_1_eltsum_map64_1_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.176039 50350 net.cpp:198] map64_1_relu_after_sum needs backward computation.
I0418 20:35:14.176041 50350 net.cpp:198] map64_1_eltsum needs backward computation.
I0418 20:35:14.176043 50350 net.cpp:198] map64_1_scale_b needs backward computation.
I0418 20:35:14.176046 50350 net.cpp:198] map64_1_bn_b needs backward computation.
I0418 20:35:14.176050 50350 net.cpp:198] map64_1_conv_b needs backward computation.
I0418 20:35:14.176053 50350 net.cpp:198] map64_1_relu_a needs backward computation.
I0418 20:35:14.176054 50350 net.cpp:198] map64_1_scale_a needs backward computation.
I0418 20:35:14.176057 50350 net.cpp:198] map64_1_bn_a needs backward computation.
I0418 20:35:14.176059 50350 net.cpp:198] map64_1_conv_a needs backward computation.
I0418 20:35:14.176062 50350 net.cpp:198] map64_1_scale_proj needs backward computation.
I0418 20:35:14.176064 50350 net.cpp:198] map64_1_bn_proj needs backward computation.
I0418 20:35:14.176074 50350 net.cpp:198] map64_1_conv_proj needs backward computation.
I0418 20:35:14.176076 50350 net.cpp:198] map32_3_eltsum_map32_3_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.176079 50350 net.cpp:198] map32_3_relu_after_sum needs backward computation.
I0418 20:35:14.176081 50350 net.cpp:198] map32_3_eltsum needs backward computation.
I0418 20:35:14.176085 50350 net.cpp:198] map32_3_scale_b needs backward computation.
I0418 20:35:14.176089 50350 net.cpp:198] map32_3_bn_b needs backward computation.
I0418 20:35:14.176090 50350 net.cpp:198] map32_3_conv_b needs backward computation.
I0418 20:35:14.176093 50350 net.cpp:198] map32_3_relu_a needs backward computation.
I0418 20:35:14.176095 50350 net.cpp:198] map32_3_scale_a needs backward computation.
I0418 20:35:14.176098 50350 net.cpp:198] map32_3_bn_a needs backward computation.
I0418 20:35:14.176100 50350 net.cpp:198] map32_3_conv_a needs backward computation.
I0418 20:35:14.176102 50350 net.cpp:198] map32_2_eltsum_map32_2_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.176105 50350 net.cpp:198] map32_2_relu_after_sum needs backward computation.
I0418 20:35:14.176107 50350 net.cpp:198] map32_2_eltsum needs backward computation.
I0418 20:35:14.176110 50350 net.cpp:198] map32_2_scale_b needs backward computation.
I0418 20:35:14.176113 50350 net.cpp:198] map32_2_bn_b needs backward computation.
I0418 20:35:14.176115 50350 net.cpp:198] map32_2_conv_b needs backward computation.
I0418 20:35:14.176117 50350 net.cpp:198] map32_2_relu_a needs backward computation.
I0418 20:35:14.176120 50350 net.cpp:198] map32_2_scale_a needs backward computation.
I0418 20:35:14.176122 50350 net.cpp:198] map32_2_bn_a needs backward computation.
I0418 20:35:14.176125 50350 net.cpp:198] map32_2_conv_a needs backward computation.
I0418 20:35:14.176127 50350 net.cpp:198] map32_1_eltsum_map32_1_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.176129 50350 net.cpp:198] map32_1_relu_after_sum needs backward computation.
I0418 20:35:14.176132 50350 net.cpp:198] map32_1_eltsum needs backward computation.
I0418 20:35:14.176136 50350 net.cpp:198] map32_1_scale_b needs backward computation.
I0418 20:35:14.176138 50350 net.cpp:198] map32_1_bn_b needs backward computation.
I0418 20:35:14.176141 50350 net.cpp:198] map32_1_conv_b needs backward computation.
I0418 20:35:14.176143 50350 net.cpp:198] map32_1_relu_a needs backward computation.
I0418 20:35:14.176146 50350 net.cpp:198] map32_1_scale_a needs backward computation.
I0418 20:35:14.176148 50350 net.cpp:198] map32_1_bn_a needs backward computation.
I0418 20:35:14.176151 50350 net.cpp:198] map32_1_conv_a needs backward computation.
I0418 20:35:14.176153 50350 net.cpp:198] map32_1_scale_proj needs backward computation.
I0418 20:35:14.176156 50350 net.cpp:198] map32_1_bn_proj needs backward computation.
I0418 20:35:14.176158 50350 net.cpp:198] map32_1_conv_proj needs backward computation.
I0418 20:35:14.176161 50350 net.cpp:198] map16_3_eltsum_map16_3_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.176163 50350 net.cpp:198] map16_3_relu_after_sum needs backward computation.
I0418 20:35:14.176167 50350 net.cpp:198] map16_3_eltsum needs backward computation.
I0418 20:35:14.176168 50350 net.cpp:198] map16_3_scale_b needs backward computation.
I0418 20:35:14.176172 50350 net.cpp:198] map16_3_bn_b needs backward computation.
I0418 20:35:14.176173 50350 net.cpp:198] map16_3_conv_b needs backward computation.
I0418 20:35:14.176177 50350 net.cpp:198] map16_3_relu_a needs backward computation.
I0418 20:35:14.176178 50350 net.cpp:198] map16_3_scale_a needs backward computation.
I0418 20:35:14.176180 50350 net.cpp:198] map16_3_bn_a needs backward computation.
I0418 20:35:14.176183 50350 net.cpp:198] map16_3_conv_a needs backward computation.
I0418 20:35:14.176187 50350 net.cpp:198] map16_2_eltsum_map16_2_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.176188 50350 net.cpp:198] map16_2_relu_after_sum needs backward computation.
I0418 20:35:14.176195 50350 net.cpp:198] map16_2_eltsum needs backward computation.
I0418 20:35:14.176198 50350 net.cpp:198] map16_2_scale_b needs backward computation.
I0418 20:35:14.176201 50350 net.cpp:198] map16_2_bn_b needs backward computation.
I0418 20:35:14.176203 50350 net.cpp:198] map16_2_conv_b needs backward computation.
I0418 20:35:14.176206 50350 net.cpp:198] map16_2_relu_a needs backward computation.
I0418 20:35:14.176209 50350 net.cpp:198] map16_2_scale_a needs backward computation.
I0418 20:35:14.176211 50350 net.cpp:198] map16_2_bn_a needs backward computation.
I0418 20:35:14.176213 50350 net.cpp:198] map16_2_conv_a needs backward computation.
I0418 20:35:14.176215 50350 net.cpp:198] map16_1_eltsum_map16_1_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.176219 50350 net.cpp:198] map16_1_relu_after_sum needs backward computation.
I0418 20:35:14.176221 50350 net.cpp:198] map16_1_eltsum needs backward computation.
I0418 20:35:14.176224 50350 net.cpp:198] map16_1_scale_b needs backward computation.
I0418 20:35:14.176228 50350 net.cpp:198] map16_1_bn_b needs backward computation.
I0418 20:35:14.176229 50350 net.cpp:198] map16_1_conv_b needs backward computation.
I0418 20:35:14.176231 50350 net.cpp:198] map16_1_relu_a needs backward computation.
I0418 20:35:14.176234 50350 net.cpp:198] map16_1_scale_a needs backward computation.
I0418 20:35:14.176236 50350 net.cpp:198] map16_1_bn_a needs backward computation.
I0418 20:35:14.176239 50350 net.cpp:198] map16_1_conv_a needs backward computation.
I0418 20:35:14.176241 50350 net.cpp:198] conv1_relu_conv1_0_split needs backward computation.
I0418 20:35:14.176244 50350 net.cpp:198] relu_conv1 needs backward computation.
I0418 20:35:14.176247 50350 net.cpp:198] scale_conv1 needs backward computation.
I0418 20:35:14.176249 50350 net.cpp:198] bn_conv1 needs backward computation.
I0418 20:35:14.176252 50350 net.cpp:198] conv1 needs backward computation.
I0418 20:35:14.176255 50350 net.cpp:200] label_data_1_split does not need backward computation.
I0418 20:35:14.176259 50350 net.cpp:200] data does not need backward computation.
I0418 20:35:14.176262 50350 net.cpp:242] This network produces output acctop1
I0418 20:35:14.176265 50350 net.cpp:242] This network produces output acctop5
I0418 20:35:14.176268 50350 net.cpp:242] This network produces output loss
I0418 20:35:14.176318 50350 net.cpp:255] Network initialization done.
I0418 20:35:14.179045 50350 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet20_relu_msra_cifar10.prototxt
I0418 20:35:14.179059 50350 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0418 20:35:14.179066 50350 solver.cpp:173] Creating test net (#0) specified by net file: resnet20_relu_msra_cifar10.prototxt
I0418 20:35:14.179181 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0418 20:35:14.179188 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv1
I0418 20:35:14.179194 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_1_bn_a
I0418 20:35:14.179199 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_1_bn_b
I0418 20:35:14.179205 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_2_bn_a
I0418 20:35:14.179210 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_2_bn_b
I0418 20:35:14.179215 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_3_bn_a
I0418 20:35:14.179221 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_3_bn_b
I0418 20:35:14.179226 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_proj
I0418 20:35:14.179231 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_a
I0418 20:35:14.179245 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_b
I0418 20:35:14.179251 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_2_bn_a
I0418 20:35:14.179256 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_2_bn_b
I0418 20:35:14.179262 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_3_bn_a
I0418 20:35:14.179267 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_3_bn_b
I0418 20:35:14.179272 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_proj
I0418 20:35:14.179277 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_a
I0418 20:35:14.179282 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_b
I0418 20:35:14.179287 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_2_bn_a
I0418 20:35:14.179293 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_2_bn_b
I0418 20:35:14.179298 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_3_bn_a
I0418 20:35:14.179303 50350 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_3_bn_b
I0418 20:35:14.179837 50350 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 32
    mean_file: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/mean.binaryproto"
  }
  data_param {
    source: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_test_leveldb_copy/"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "map16_1_conv_a"
  type: "Convolution"
  bottom: "conv1"
  top: "map16_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_a"
  type: "BatchNorm"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_1_scale_a"
  type: "Scale"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_relu_a"
  type: "ReLU"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
}
layer {
  name: "map16_1_conv_b"
  type: "Convolution"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_b"
  type: "BatchNorm"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_1_scale_b"
  type: "Scale"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_eltsum"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "map16_1_conv_b"
  top: "map16_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_1_relu_after_sum"
  type: "ReLU"
  bottom: "map16_1_eltsum"
  top: "map16_1_eltsum"
}
layer {
  name: "map16_2_conv_a"
  type: "Convolution"
  bottom: "map16_1_eltsum"
  top: "map16_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_a"
  type: "BatchNorm"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_2_scale_a"
  type: "Scale"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_relu_a"
  type: "ReLU"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
}
layer {
  name: "map16_2_conv_b"
  type: "Convolution"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_b"
  type: "BatchNorm"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_2_scale_b"
  type: "Scale"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_eltsum"
  type: "Eltwise"
  bottom: "map16_1_eltsum"
  bottom: "map16_2_conv_b"
  top: "map16_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_2_relu_after_sum"
  type: "ReLU"
  bottom: "map16_2_eltsum"
  top: "map16_2_eltsum"
}
layer {
  name: "map16_3_conv_a"
  type: "Convolution"
  bottom: "map16_2_eltsum"
  top: "map16_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_a"
  type: "BatchNorm"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_3_scale_a"
  type: "Scale"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_relu_a"
  type: "ReLU"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
}
layer {
  name: "map16_3_conv_b"
  type: "Convolution"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_b"
  type: "BatchNorm"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_3_scale_b"
  type: "Scale"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_eltsum"
  type: "Eltwise"
  bottom: "map16_2_eltsum"
  bottom: "map16_3_conv_b"
  top: "map16_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_3_relu_after_sum"
  type: "ReLU"
  bottom: "map16_3_eltsum"
  top: "map16_3_eltsum"
}
layer {
  name: "map32_1_conv_proj"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_proj"
  type: "BatchNorm"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_proj"
  type: "Scale"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_conv_a"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_a"
  type: "BatchNorm"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_a"
  type: "Scale"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_relu_a"
  type: "ReLU"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
}
layer {
  name: "map32_1_conv_b"
  type: "Convolution"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_b"
  type: "BatchNorm"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_b"
  type: "Scale"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_eltsum"
  type: "Eltwise"
  bottom: "map32_1_conv_proj"
  bottom: "map32_1_conv_b"
  top: "map32_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_1_relu_after_sum"
  type: "ReLU"
  bottom: "map32_1_eltsum"
  top: "map32_1_eltsum"
}
layer {
  name: "map32_2_conv_a"
  type: "Convolution"
  bottom: "map32_1_eltsum"
  top: "map32_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_a"
  type: "BatchNorm"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_2_scale_a"
  type: "Scale"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_relu_a"
  type: "ReLU"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
}
layer {
  name: "map32_2_conv_b"
  type: "Convolution"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_b"
  type: "BatchNorm"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_2_scale_b"
  type: "Scale"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_eltsum"
  type: "Eltwise"
  bottom: "map32_1_eltsum"
  bottom: "map32_2_conv_b"
  top: "map32_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_2_relu_after_sum"
  type: "ReLU"
  bottom: "map32_2_eltsum"
  top: "map32_2_eltsum"
}
layer {
  name: "map32_3_conv_a"
  type: "Convolution"
  bottom: "map32_2_eltsum"
  top: "map32_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_a"
  type: "BatchNorm"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_3_scale_a"
  type: "Scale"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_relu_a"
  type: "ReLU"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
}
layer {
  name: "map32_3_conv_b"
  type: "Convolution"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_b"
  type: "BatchNorm"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_3_scale_b"
  type: "Scale"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_eltsum"
  type: "Eltwise"
  bottom: "map32_2_eltsum"
  bottom: "map32_3_conv_b"
  top: "map32_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_3_relu_after_sum"
  type: "ReLU"
  bottom: "map32_3_eltsum"
  top: "map32_3_eltsum"
}
layer {
  name: "map64_1_conv_proj"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_proj"
  type: "BatchNorm"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_proj"
  type: "Scale"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_conv_a"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_a"
  type: "BatchNorm"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_a"
  type: "Scale"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_relu_a"
  type: "ReLU"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
}
layer {
  name: "map64_1_conv_b"
  type: "Convolution"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_b"
  type: "BatchNorm"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_b"
  type: "Scale"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_eltsum"
  type: "Eltwise"
  bottom: "map64_1_conv_proj"
  bottom: "map64_1_conv_b"
  top: "map64_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_1_relu_after_sum"
  type: "ReLU"
  bottom: "map64_1_eltsum"
  top: "map64_1_eltsum"
}
layer {
  name: "map64_2_conv_a"
  type: "Convolution"
  bottom: "map64_1_eltsum"
  top: "map64_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_a"
  type: "BatchNorm"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_2_scale_a"
  type: "Scale"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_relu_a"
  type: "ReLU"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
}
layer {
  name: "map64_2_conv_b"
  type: "Convolution"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_b"
  type: "BatchNorm"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_2_scale_b"
  type: "Scale"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_eltsum"
  type: "Eltwise"
  bottom: "map64_1_eltsum"
  bottom: "map64_2_conv_b"
  top: "map64_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_2_relu_after_sum"
  type: "ReLU"
  bottom: "map64_2_eltsum"
  top: "map64_2_eltsum"
}
layer {
  name: "map64_3_conv_a"
  type: "Convolution"
  bottom: "map64_2_eltsum"
  top: "map64_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_a"
  type: "BatchNorm"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_3_scale_a"
  type: "Scale"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_relu_a"
  type: "ReLU"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
}
layer {
  name: "map64_3_conv_b"
  type: "Convolution"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_b"
  type: "BatchNorm"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_3_scale_b"
  type: "Scale"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_eltsum"
  type: "Eltwise"
  bottom: "map64_2_eltsum"
  bottom: "map64_3_conv_b"
  top: "map64_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_3_relu_after_sum"
  type: "ReLU"
  bottom: "map64_3_eltsum"
  top: "map64_3_eltsum"
}
layer {
  name: "pool_global"
  type: "Pooling"
  bottom: "map64_3_eltsum"
  top: "pool_global"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_global"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc/top1"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc/top5"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop5"
  accuracy_param {
    top_k: 5
  }
}
I0418 20:35:14.180176 50350 layer_factory.hpp:77] Creating layer data
I0418 20:35:14.213505 50350 db_leveldb.cpp:18] Opened leveldb /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_test_leveldb_copy/
I0418 20:35:14.253515 50350 net.cpp:84] Creating Layer data
I0418 20:35:14.253545 50350 net.cpp:380] data -> data
I0418 20:35:14.253566 50350 net.cpp:380] data -> label
I0418 20:35:14.253582 50350 data_transformer.cpp:25] Loading mean file from: /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/mean.binaryproto
I0418 20:35:14.258404 50350 data_layer.cpp:45] output data size: 100,3,32,32
I0418 20:35:14.264343 50350 net.cpp:122] Setting up data
I0418 20:35:14.264354 50350 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0418 20:35:14.264374 50350 net.cpp:129] Top shape: 100 (100)
I0418 20:35:14.264376 50350 net.cpp:137] Memory required for data: 1229200
I0418 20:35:14.264380 50350 layer_factory.hpp:77] Creating layer label_data_1_split
I0418 20:35:14.264386 50350 net.cpp:84] Creating Layer label_data_1_split
I0418 20:35:14.264389 50350 net.cpp:406] label_data_1_split <- label
I0418 20:35:14.264394 50350 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0418 20:35:14.264433 50350 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0418 20:35:14.264446 50350 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0418 20:35:14.264513 50350 net.cpp:122] Setting up label_data_1_split
I0418 20:35:14.264520 50350 net.cpp:129] Top shape: 100 (100)
I0418 20:35:14.264523 50350 net.cpp:129] Top shape: 100 (100)
I0418 20:35:14.264528 50350 net.cpp:129] Top shape: 100 (100)
I0418 20:35:14.264530 50350 net.cpp:137] Memory required for data: 1230400
I0418 20:35:14.264533 50350 layer_factory.hpp:77] Creating layer conv1
I0418 20:35:14.264544 50350 net.cpp:84] Creating Layer conv1
I0418 20:35:14.264547 50350 net.cpp:406] conv1 <- data
I0418 20:35:14.264552 50350 net.cpp:380] conv1 -> conv1
I0418 20:35:14.265827 50350 net.cpp:122] Setting up conv1
I0418 20:35:14.265839 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.265846 50350 net.cpp:137] Memory required for data: 7784000
I0418 20:35:14.265854 50350 layer_factory.hpp:77] Creating layer bn_conv1
I0418 20:35:14.265861 50350 net.cpp:84] Creating Layer bn_conv1
I0418 20:35:14.265866 50350 net.cpp:406] bn_conv1 <- conv1
I0418 20:35:14.265872 50350 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0418 20:35:14.266103 50350 net.cpp:122] Setting up bn_conv1
I0418 20:35:14.266110 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.266113 50350 net.cpp:137] Memory required for data: 14337600
I0418 20:35:14.266121 50350 layer_factory.hpp:77] Creating layer scale_conv1
I0418 20:35:14.266129 50350 net.cpp:84] Creating Layer scale_conv1
I0418 20:35:14.266131 50350 net.cpp:406] scale_conv1 <- conv1
I0418 20:35:14.266135 50350 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0418 20:35:14.266294 50350 layer_factory.hpp:77] Creating layer scale_conv1
I0418 20:35:14.266412 50350 net.cpp:122] Setting up scale_conv1
I0418 20:35:14.266417 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.266420 50350 net.cpp:137] Memory required for data: 20891200
I0418 20:35:14.266427 50350 layer_factory.hpp:77] Creating layer relu_conv1
I0418 20:35:14.266433 50350 net.cpp:84] Creating Layer relu_conv1
I0418 20:35:14.266435 50350 net.cpp:406] relu_conv1 <- conv1
I0418 20:35:14.266448 50350 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0418 20:35:14.266641 50350 net.cpp:122] Setting up relu_conv1
I0418 20:35:14.266649 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.266652 50350 net.cpp:137] Memory required for data: 27444800
I0418 20:35:14.266655 50350 layer_factory.hpp:77] Creating layer conv1_relu_conv1_0_split
I0418 20:35:14.266660 50350 net.cpp:84] Creating Layer conv1_relu_conv1_0_split
I0418 20:35:14.266679 50350 net.cpp:406] conv1_relu_conv1_0_split <- conv1
I0418 20:35:14.266685 50350 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_0
I0418 20:35:14.266691 50350 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_1
I0418 20:35:14.266732 50350 net.cpp:122] Setting up conv1_relu_conv1_0_split
I0418 20:35:14.266737 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.266741 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.266743 50350 net.cpp:137] Memory required for data: 40552000
I0418 20:35:14.266746 50350 layer_factory.hpp:77] Creating layer map16_1_conv_a
I0418 20:35:14.266754 50350 net.cpp:84] Creating Layer map16_1_conv_a
I0418 20:35:14.266758 50350 net.cpp:406] map16_1_conv_a <- conv1_relu_conv1_0_split_0
I0418 20:35:14.266769 50350 net.cpp:380] map16_1_conv_a -> map16_1_conv_a
I0418 20:35:14.267802 50350 net.cpp:122] Setting up map16_1_conv_a
I0418 20:35:14.267813 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.267817 50350 net.cpp:137] Memory required for data: 47105600
I0418 20:35:14.267825 50350 layer_factory.hpp:77] Creating layer map16_1_bn_a
I0418 20:35:14.267834 50350 net.cpp:84] Creating Layer map16_1_bn_a
I0418 20:35:14.267838 50350 net.cpp:406] map16_1_bn_a <- map16_1_conv_a
I0418 20:35:14.267844 50350 net.cpp:367] map16_1_bn_a -> map16_1_conv_a (in-place)
I0418 20:35:14.268020 50350 net.cpp:122] Setting up map16_1_bn_a
I0418 20:35:14.268026 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.268029 50350 net.cpp:137] Memory required for data: 53659200
I0418 20:35:14.268034 50350 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0418 20:35:14.268040 50350 net.cpp:84] Creating Layer map16_1_scale_a
I0418 20:35:14.268043 50350 net.cpp:406] map16_1_scale_a <- map16_1_conv_a
I0418 20:35:14.268049 50350 net.cpp:367] map16_1_scale_a -> map16_1_conv_a (in-place)
I0418 20:35:14.268082 50350 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0418 20:35:14.268183 50350 net.cpp:122] Setting up map16_1_scale_a
I0418 20:35:14.268191 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.268194 50350 net.cpp:137] Memory required for data: 60212800
I0418 20:35:14.268198 50350 layer_factory.hpp:77] Creating layer map16_1_relu_a
I0418 20:35:14.268203 50350 net.cpp:84] Creating Layer map16_1_relu_a
I0418 20:35:14.268206 50350 net.cpp:406] map16_1_relu_a <- map16_1_conv_a
I0418 20:35:14.268210 50350 net.cpp:367] map16_1_relu_a -> map16_1_conv_a (in-place)
I0418 20:35:14.268365 50350 net.cpp:122] Setting up map16_1_relu_a
I0418 20:35:14.268375 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.268378 50350 net.cpp:137] Memory required for data: 66766400
I0418 20:35:14.268381 50350 layer_factory.hpp:77] Creating layer map16_1_conv_b
I0418 20:35:14.268393 50350 net.cpp:84] Creating Layer map16_1_conv_b
I0418 20:35:14.268396 50350 net.cpp:406] map16_1_conv_b <- map16_1_conv_a
I0418 20:35:14.268401 50350 net.cpp:380] map16_1_conv_b -> map16_1_conv_b
I0418 20:35:14.269379 50350 net.cpp:122] Setting up map16_1_conv_b
I0418 20:35:14.269392 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.269397 50350 net.cpp:137] Memory required for data: 73320000
I0418 20:35:14.269402 50350 layer_factory.hpp:77] Creating layer map16_1_bn_b
I0418 20:35:14.269409 50350 net.cpp:84] Creating Layer map16_1_bn_b
I0418 20:35:14.269412 50350 net.cpp:406] map16_1_bn_b <- map16_1_conv_b
I0418 20:35:14.269424 50350 net.cpp:367] map16_1_bn_b -> map16_1_conv_b (in-place)
I0418 20:35:14.269610 50350 net.cpp:122] Setting up map16_1_bn_b
I0418 20:35:14.269618 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.269620 50350 net.cpp:137] Memory required for data: 79873600
I0418 20:35:14.269629 50350 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0418 20:35:14.269637 50350 net.cpp:84] Creating Layer map16_1_scale_b
I0418 20:35:14.269641 50350 net.cpp:406] map16_1_scale_b <- map16_1_conv_b
I0418 20:35:14.269645 50350 net.cpp:367] map16_1_scale_b -> map16_1_conv_b (in-place)
I0418 20:35:14.269711 50350 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0418 20:35:14.269814 50350 net.cpp:122] Setting up map16_1_scale_b
I0418 20:35:14.269821 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.269824 50350 net.cpp:137] Memory required for data: 86427200
I0418 20:35:14.269829 50350 layer_factory.hpp:77] Creating layer map16_1_eltsum
I0418 20:35:14.269834 50350 net.cpp:84] Creating Layer map16_1_eltsum
I0418 20:35:14.269839 50350 net.cpp:406] map16_1_eltsum <- conv1_relu_conv1_0_split_1
I0418 20:35:14.269842 50350 net.cpp:406] map16_1_eltsum <- map16_1_conv_b
I0418 20:35:14.269846 50350 net.cpp:380] map16_1_eltsum -> map16_1_eltsum
I0418 20:35:14.269868 50350 net.cpp:122] Setting up map16_1_eltsum
I0418 20:35:14.269873 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.269876 50350 net.cpp:137] Memory required for data: 92980800
I0418 20:35:14.269878 50350 layer_factory.hpp:77] Creating layer map16_1_relu_after_sum
I0418 20:35:14.269882 50350 net.cpp:84] Creating Layer map16_1_relu_after_sum
I0418 20:35:14.269886 50350 net.cpp:406] map16_1_relu_after_sum <- map16_1_eltsum
I0418 20:35:14.269891 50350 net.cpp:367] map16_1_relu_after_sum -> map16_1_eltsum (in-place)
I0418 20:35:14.270064 50350 net.cpp:122] Setting up map16_1_relu_after_sum
I0418 20:35:14.270071 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.270074 50350 net.cpp:137] Memory required for data: 99534400
I0418 20:35:14.270077 50350 layer_factory.hpp:77] Creating layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0418 20:35:14.270086 50350 net.cpp:84] Creating Layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0418 20:35:14.270089 50350 net.cpp:406] map16_1_eltsum_map16_1_relu_after_sum_0_split <- map16_1_eltsum
I0418 20:35:14.270093 50350 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0418 20:35:14.270098 50350 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0418 20:35:14.270135 50350 net.cpp:122] Setting up map16_1_eltsum_map16_1_relu_after_sum_0_split
I0418 20:35:14.270140 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.270144 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.270146 50350 net.cpp:137] Memory required for data: 112641600
I0418 20:35:14.270149 50350 layer_factory.hpp:77] Creating layer map16_2_conv_a
I0418 20:35:14.270157 50350 net.cpp:84] Creating Layer map16_2_conv_a
I0418 20:35:14.270160 50350 net.cpp:406] map16_2_conv_a <- map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0418 20:35:14.270166 50350 net.cpp:380] map16_2_conv_a -> map16_2_conv_a
I0418 20:35:14.271152 50350 net.cpp:122] Setting up map16_2_conv_a
I0418 20:35:14.271165 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.271169 50350 net.cpp:137] Memory required for data: 119195200
I0418 20:35:14.271175 50350 layer_factory.hpp:77] Creating layer map16_2_bn_a
I0418 20:35:14.271183 50350 net.cpp:84] Creating Layer map16_2_bn_a
I0418 20:35:14.271186 50350 net.cpp:406] map16_2_bn_a <- map16_2_conv_a
I0418 20:35:14.271198 50350 net.cpp:367] map16_2_bn_a -> map16_2_conv_a (in-place)
I0418 20:35:14.271383 50350 net.cpp:122] Setting up map16_2_bn_a
I0418 20:35:14.271389 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.271391 50350 net.cpp:137] Memory required for data: 125748800
I0418 20:35:14.271397 50350 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0418 20:35:14.271402 50350 net.cpp:84] Creating Layer map16_2_scale_a
I0418 20:35:14.271406 50350 net.cpp:406] map16_2_scale_a <- map16_2_conv_a
I0418 20:35:14.271409 50350 net.cpp:367] map16_2_scale_a -> map16_2_conv_a (in-place)
I0418 20:35:14.271451 50350 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0418 20:35:14.271554 50350 net.cpp:122] Setting up map16_2_scale_a
I0418 20:35:14.271560 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.271564 50350 net.cpp:137] Memory required for data: 132302400
I0418 20:35:14.271569 50350 layer_factory.hpp:77] Creating layer map16_2_relu_a
I0418 20:35:14.271584 50350 net.cpp:84] Creating Layer map16_2_relu_a
I0418 20:35:14.271587 50350 net.cpp:406] map16_2_relu_a <- map16_2_conv_a
I0418 20:35:14.271594 50350 net.cpp:367] map16_2_relu_a -> map16_2_conv_a (in-place)
I0418 20:35:14.271755 50350 net.cpp:122] Setting up map16_2_relu_a
I0418 20:35:14.271762 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.271766 50350 net.cpp:137] Memory required for data: 138856000
I0418 20:35:14.271769 50350 layer_factory.hpp:77] Creating layer map16_2_conv_b
I0418 20:35:14.271777 50350 net.cpp:84] Creating Layer map16_2_conv_b
I0418 20:35:14.271781 50350 net.cpp:406] map16_2_conv_b <- map16_2_conv_a
I0418 20:35:14.271787 50350 net.cpp:380] map16_2_conv_b -> map16_2_conv_b
I0418 20:35:14.273077 50350 net.cpp:122] Setting up map16_2_conv_b
I0418 20:35:14.273088 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.273092 50350 net.cpp:137] Memory required for data: 145409600
I0418 20:35:14.273098 50350 layer_factory.hpp:77] Creating layer map16_2_bn_b
I0418 20:35:14.273106 50350 net.cpp:84] Creating Layer map16_2_bn_b
I0418 20:35:14.273110 50350 net.cpp:406] map16_2_bn_b <- map16_2_conv_b
I0418 20:35:14.273118 50350 net.cpp:367] map16_2_bn_b -> map16_2_conv_b (in-place)
I0418 20:35:14.273304 50350 net.cpp:122] Setting up map16_2_bn_b
I0418 20:35:14.273310 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.273313 50350 net.cpp:137] Memory required for data: 151963200
I0418 20:35:14.273324 50350 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0418 20:35:14.273329 50350 net.cpp:84] Creating Layer map16_2_scale_b
I0418 20:35:14.273334 50350 net.cpp:406] map16_2_scale_b <- map16_2_conv_b
I0418 20:35:14.273336 50350 net.cpp:367] map16_2_scale_b -> map16_2_conv_b (in-place)
I0418 20:35:14.273372 50350 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0418 20:35:14.273483 50350 net.cpp:122] Setting up map16_2_scale_b
I0418 20:35:14.273489 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.273493 50350 net.cpp:137] Memory required for data: 158516800
I0418 20:35:14.273497 50350 layer_factory.hpp:77] Creating layer map16_2_eltsum
I0418 20:35:14.273504 50350 net.cpp:84] Creating Layer map16_2_eltsum
I0418 20:35:14.273507 50350 net.cpp:406] map16_2_eltsum <- map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0418 20:35:14.273512 50350 net.cpp:406] map16_2_eltsum <- map16_2_conv_b
I0418 20:35:14.273516 50350 net.cpp:380] map16_2_eltsum -> map16_2_eltsum
I0418 20:35:14.273538 50350 net.cpp:122] Setting up map16_2_eltsum
I0418 20:35:14.273543 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.273546 50350 net.cpp:137] Memory required for data: 165070400
I0418 20:35:14.273548 50350 layer_factory.hpp:77] Creating layer map16_2_relu_after_sum
I0418 20:35:14.273552 50350 net.cpp:84] Creating Layer map16_2_relu_after_sum
I0418 20:35:14.273555 50350 net.cpp:406] map16_2_relu_after_sum <- map16_2_eltsum
I0418 20:35:14.273561 50350 net.cpp:367] map16_2_relu_after_sum -> map16_2_eltsum (in-place)
I0418 20:35:14.273959 50350 net.cpp:122] Setting up map16_2_relu_after_sum
I0418 20:35:14.273969 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.273972 50350 net.cpp:137] Memory required for data: 171624000
I0418 20:35:14.273975 50350 layer_factory.hpp:77] Creating layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0418 20:35:14.273983 50350 net.cpp:84] Creating Layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0418 20:35:14.273988 50350 net.cpp:406] map16_2_eltsum_map16_2_relu_after_sum_0_split <- map16_2_eltsum
I0418 20:35:14.273991 50350 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0418 20:35:14.273999 50350 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0418 20:35:14.274039 50350 net.cpp:122] Setting up map16_2_eltsum_map16_2_relu_after_sum_0_split
I0418 20:35:14.274045 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.274060 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.274062 50350 net.cpp:137] Memory required for data: 184731200
I0418 20:35:14.274065 50350 layer_factory.hpp:77] Creating layer map16_3_conv_a
I0418 20:35:14.274075 50350 net.cpp:84] Creating Layer map16_3_conv_a
I0418 20:35:14.274078 50350 net.cpp:406] map16_3_conv_a <- map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0418 20:35:14.274085 50350 net.cpp:380] map16_3_conv_a -> map16_3_conv_a
I0418 20:35:14.274830 50350 net.cpp:122] Setting up map16_3_conv_a
I0418 20:35:14.274842 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.274845 50350 net.cpp:137] Memory required for data: 191284800
I0418 20:35:14.274850 50350 layer_factory.hpp:77] Creating layer map16_3_bn_a
I0418 20:35:14.274857 50350 net.cpp:84] Creating Layer map16_3_bn_a
I0418 20:35:14.274860 50350 net.cpp:406] map16_3_bn_a <- map16_3_conv_a
I0418 20:35:14.274866 50350 net.cpp:367] map16_3_bn_a -> map16_3_conv_a (in-place)
I0418 20:35:14.275051 50350 net.cpp:122] Setting up map16_3_bn_a
I0418 20:35:14.275058 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.275060 50350 net.cpp:137] Memory required for data: 197838400
I0418 20:35:14.275068 50350 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0418 20:35:14.275073 50350 net.cpp:84] Creating Layer map16_3_scale_a
I0418 20:35:14.275075 50350 net.cpp:406] map16_3_scale_a <- map16_3_conv_a
I0418 20:35:14.275079 50350 net.cpp:367] map16_3_scale_a -> map16_3_conv_a (in-place)
I0418 20:35:14.275115 50350 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0418 20:35:14.275218 50350 net.cpp:122] Setting up map16_3_scale_a
I0418 20:35:14.275223 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.275225 50350 net.cpp:137] Memory required for data: 204392000
I0418 20:35:14.275230 50350 layer_factory.hpp:77] Creating layer map16_3_relu_a
I0418 20:35:14.275234 50350 net.cpp:84] Creating Layer map16_3_relu_a
I0418 20:35:14.275238 50350 net.cpp:406] map16_3_relu_a <- map16_3_conv_a
I0418 20:35:14.275243 50350 net.cpp:367] map16_3_relu_a -> map16_3_conv_a (in-place)
I0418 20:35:14.275687 50350 net.cpp:122] Setting up map16_3_relu_a
I0418 20:35:14.275709 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.275713 50350 net.cpp:137] Memory required for data: 210945600
I0418 20:35:14.275723 50350 layer_factory.hpp:77] Creating layer map16_3_conv_b
I0418 20:35:14.275734 50350 net.cpp:84] Creating Layer map16_3_conv_b
I0418 20:35:14.275738 50350 net.cpp:406] map16_3_conv_b <- map16_3_conv_a
I0418 20:35:14.275746 50350 net.cpp:380] map16_3_conv_b -> map16_3_conv_b
I0418 20:35:14.276836 50350 net.cpp:122] Setting up map16_3_conv_b
I0418 20:35:14.276849 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.276852 50350 net.cpp:137] Memory required for data: 217499200
I0418 20:35:14.276859 50350 layer_factory.hpp:77] Creating layer map16_3_bn_b
I0418 20:35:14.276870 50350 net.cpp:84] Creating Layer map16_3_bn_b
I0418 20:35:14.276875 50350 net.cpp:406] map16_3_bn_b <- map16_3_conv_b
I0418 20:35:14.276881 50350 net.cpp:367] map16_3_bn_b -> map16_3_conv_b (in-place)
I0418 20:35:14.277218 50350 net.cpp:122] Setting up map16_3_bn_b
I0418 20:35:14.277225 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.277228 50350 net.cpp:137] Memory required for data: 224052800
I0418 20:35:14.277235 50350 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0418 20:35:14.277240 50350 net.cpp:84] Creating Layer map16_3_scale_b
I0418 20:35:14.277243 50350 net.cpp:406] map16_3_scale_b <- map16_3_conv_b
I0418 20:35:14.277246 50350 net.cpp:367] map16_3_scale_b -> map16_3_conv_b (in-place)
I0418 20:35:14.277283 50350 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0418 20:35:14.277390 50350 net.cpp:122] Setting up map16_3_scale_b
I0418 20:35:14.277395 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.277398 50350 net.cpp:137] Memory required for data: 230606400
I0418 20:35:14.277402 50350 layer_factory.hpp:77] Creating layer map16_3_eltsum
I0418 20:35:14.277418 50350 net.cpp:84] Creating Layer map16_3_eltsum
I0418 20:35:14.277423 50350 net.cpp:406] map16_3_eltsum <- map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0418 20:35:14.277426 50350 net.cpp:406] map16_3_eltsum <- map16_3_conv_b
I0418 20:35:14.277433 50350 net.cpp:380] map16_3_eltsum -> map16_3_eltsum
I0418 20:35:14.277463 50350 net.cpp:122] Setting up map16_3_eltsum
I0418 20:35:14.277469 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.277472 50350 net.cpp:137] Memory required for data: 237160000
I0418 20:35:14.277474 50350 layer_factory.hpp:77] Creating layer map16_3_relu_after_sum
I0418 20:35:14.277480 50350 net.cpp:84] Creating Layer map16_3_relu_after_sum
I0418 20:35:14.277483 50350 net.cpp:406] map16_3_relu_after_sum <- map16_3_eltsum
I0418 20:35:14.277487 50350 net.cpp:367] map16_3_relu_after_sum -> map16_3_eltsum (in-place)
I0418 20:35:14.277650 50350 net.cpp:122] Setting up map16_3_relu_after_sum
I0418 20:35:14.277658 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.277662 50350 net.cpp:137] Memory required for data: 243713600
I0418 20:35:14.277664 50350 layer_factory.hpp:77] Creating layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0418 20:35:14.277669 50350 net.cpp:84] Creating Layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0418 20:35:14.277673 50350 net.cpp:406] map16_3_eltsum_map16_3_relu_after_sum_0_split <- map16_3_eltsum
I0418 20:35:14.277678 50350 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0418 20:35:14.277684 50350 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0418 20:35:14.277719 50350 net.cpp:122] Setting up map16_3_eltsum_map16_3_relu_after_sum_0_split
I0418 20:35:14.277724 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.277729 50350 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0418 20:35:14.277730 50350 net.cpp:137] Memory required for data: 256820800
I0418 20:35:14.277732 50350 layer_factory.hpp:77] Creating layer map32_1_conv_proj
I0418 20:35:14.277741 50350 net.cpp:84] Creating Layer map32_1_conv_proj
I0418 20:35:14.277745 50350 net.cpp:406] map32_1_conv_proj <- map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0418 20:35:14.277750 50350 net.cpp:380] map32_1_conv_proj -> map32_1_conv_proj
I0418 20:35:14.278841 50350 net.cpp:122] Setting up map32_1_conv_proj
I0418 20:35:14.278856 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.278858 50350 net.cpp:137] Memory required for data: 260097600
I0418 20:35:14.278864 50350 layer_factory.hpp:77] Creating layer map32_1_bn_proj
I0418 20:35:14.278872 50350 net.cpp:84] Creating Layer map32_1_bn_proj
I0418 20:35:14.278875 50350 net.cpp:406] map32_1_bn_proj <- map32_1_conv_proj
I0418 20:35:14.278882 50350 net.cpp:367] map32_1_bn_proj -> map32_1_conv_proj (in-place)
I0418 20:35:14.279065 50350 net.cpp:122] Setting up map32_1_bn_proj
I0418 20:35:14.279072 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.279075 50350 net.cpp:137] Memory required for data: 263374400
I0418 20:35:14.279080 50350 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0418 20:35:14.279085 50350 net.cpp:84] Creating Layer map32_1_scale_proj
I0418 20:35:14.279088 50350 net.cpp:406] map32_1_scale_proj <- map32_1_conv_proj
I0418 20:35:14.279093 50350 net.cpp:367] map32_1_scale_proj -> map32_1_conv_proj (in-place)
I0418 20:35:14.279130 50350 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0418 20:35:14.279232 50350 net.cpp:122] Setting up map32_1_scale_proj
I0418 20:35:14.279238 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.279242 50350 net.cpp:137] Memory required for data: 266651200
I0418 20:35:14.279247 50350 layer_factory.hpp:77] Creating layer map32_1_conv_a
I0418 20:35:14.279255 50350 net.cpp:84] Creating Layer map32_1_conv_a
I0418 20:35:14.279259 50350 net.cpp:406] map32_1_conv_a <- map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0418 20:35:14.279268 50350 net.cpp:380] map32_1_conv_a -> map32_1_conv_a
I0418 20:35:14.280539 50350 net.cpp:122] Setting up map32_1_conv_a
I0418 20:35:14.280550 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.280553 50350 net.cpp:137] Memory required for data: 269928000
I0418 20:35:14.280560 50350 layer_factory.hpp:77] Creating layer map32_1_bn_a
I0418 20:35:14.280568 50350 net.cpp:84] Creating Layer map32_1_bn_a
I0418 20:35:14.280572 50350 net.cpp:406] map32_1_bn_a <- map32_1_conv_a
I0418 20:35:14.280578 50350 net.cpp:367] map32_1_bn_a -> map32_1_conv_a (in-place)
I0418 20:35:14.280757 50350 net.cpp:122] Setting up map32_1_bn_a
I0418 20:35:14.280763 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.280766 50350 net.cpp:137] Memory required for data: 273204800
I0418 20:35:14.280771 50350 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0418 20:35:14.280779 50350 net.cpp:84] Creating Layer map32_1_scale_a
I0418 20:35:14.280783 50350 net.cpp:406] map32_1_scale_a <- map32_1_conv_a
I0418 20:35:14.280787 50350 net.cpp:367] map32_1_scale_a -> map32_1_conv_a (in-place)
I0418 20:35:14.280824 50350 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0418 20:35:14.280930 50350 net.cpp:122] Setting up map32_1_scale_a
I0418 20:35:14.280936 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.280939 50350 net.cpp:137] Memory required for data: 276481600
I0418 20:35:14.280943 50350 layer_factory.hpp:77] Creating layer map32_1_relu_a
I0418 20:35:14.280951 50350 net.cpp:84] Creating Layer map32_1_relu_a
I0418 20:35:14.280954 50350 net.cpp:406] map32_1_relu_a <- map32_1_conv_a
I0418 20:35:14.280957 50350 net.cpp:367] map32_1_relu_a -> map32_1_conv_a (in-place)
I0418 20:35:14.281132 50350 net.cpp:122] Setting up map32_1_relu_a
I0418 20:35:14.281139 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.281142 50350 net.cpp:137] Memory required for data: 279758400
I0418 20:35:14.281144 50350 layer_factory.hpp:77] Creating layer map32_1_conv_b
I0418 20:35:14.281158 50350 net.cpp:84] Creating Layer map32_1_conv_b
I0418 20:35:14.281162 50350 net.cpp:406] map32_1_conv_b <- map32_1_conv_a
I0418 20:35:14.281167 50350 net.cpp:380] map32_1_conv_b -> map32_1_conv_b
I0418 20:35:14.282260 50350 net.cpp:122] Setting up map32_1_conv_b
I0418 20:35:14.282271 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.282274 50350 net.cpp:137] Memory required for data: 283035200
I0418 20:35:14.282290 50350 layer_factory.hpp:77] Creating layer map32_1_bn_b
I0418 20:35:14.282299 50350 net.cpp:84] Creating Layer map32_1_bn_b
I0418 20:35:14.282304 50350 net.cpp:406] map32_1_bn_b <- map32_1_conv_b
I0418 20:35:14.282312 50350 net.cpp:367] map32_1_bn_b -> map32_1_conv_b (in-place)
I0418 20:35:14.282497 50350 net.cpp:122] Setting up map32_1_bn_b
I0418 20:35:14.282503 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.282506 50350 net.cpp:137] Memory required for data: 286312000
I0418 20:35:14.282512 50350 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0418 20:35:14.282518 50350 net.cpp:84] Creating Layer map32_1_scale_b
I0418 20:35:14.282521 50350 net.cpp:406] map32_1_scale_b <- map32_1_conv_b
I0418 20:35:14.282527 50350 net.cpp:367] map32_1_scale_b -> map32_1_conv_b (in-place)
I0418 20:35:14.282563 50350 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0418 20:35:14.282665 50350 net.cpp:122] Setting up map32_1_scale_b
I0418 20:35:14.282672 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.282675 50350 net.cpp:137] Memory required for data: 289588800
I0418 20:35:14.282680 50350 layer_factory.hpp:77] Creating layer map32_1_eltsum
I0418 20:35:14.282685 50350 net.cpp:84] Creating Layer map32_1_eltsum
I0418 20:35:14.282690 50350 net.cpp:406] map32_1_eltsum <- map32_1_conv_proj
I0418 20:35:14.282692 50350 net.cpp:406] map32_1_eltsum <- map32_1_conv_b
I0418 20:35:14.282697 50350 net.cpp:380] map32_1_eltsum -> map32_1_eltsum
I0418 20:35:14.282721 50350 net.cpp:122] Setting up map32_1_eltsum
I0418 20:35:14.282726 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.282728 50350 net.cpp:137] Memory required for data: 292865600
I0418 20:35:14.282742 50350 layer_factory.hpp:77] Creating layer map32_1_relu_after_sum
I0418 20:35:14.282747 50350 net.cpp:84] Creating Layer map32_1_relu_after_sum
I0418 20:35:14.282752 50350 net.cpp:406] map32_1_relu_after_sum <- map32_1_eltsum
I0418 20:35:14.282757 50350 net.cpp:367] map32_1_relu_after_sum -> map32_1_eltsum (in-place)
I0418 20:35:14.282933 50350 net.cpp:122] Setting up map32_1_relu_after_sum
I0418 20:35:14.282940 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.282944 50350 net.cpp:137] Memory required for data: 296142400
I0418 20:35:14.282948 50350 layer_factory.hpp:77] Creating layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0418 20:35:14.282953 50350 net.cpp:84] Creating Layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0418 20:35:14.282956 50350 net.cpp:406] map32_1_eltsum_map32_1_relu_after_sum_0_split <- map32_1_eltsum
I0418 20:35:14.282963 50350 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0418 20:35:14.282969 50350 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0418 20:35:14.283006 50350 net.cpp:122] Setting up map32_1_eltsum_map32_1_relu_after_sum_0_split
I0418 20:35:14.283013 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.283017 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.283020 50350 net.cpp:137] Memory required for data: 302696000
I0418 20:35:14.283022 50350 layer_factory.hpp:77] Creating layer map32_2_conv_a
I0418 20:35:14.283030 50350 net.cpp:84] Creating Layer map32_2_conv_a
I0418 20:35:14.283035 50350 net.cpp:406] map32_2_conv_a <- map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0418 20:35:14.283038 50350 net.cpp:380] map32_2_conv_a -> map32_2_conv_a
I0418 20:35:14.284525 50350 net.cpp:122] Setting up map32_2_conv_a
I0418 20:35:14.284538 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.284543 50350 net.cpp:137] Memory required for data: 305972800
I0418 20:35:14.284548 50350 layer_factory.hpp:77] Creating layer map32_2_bn_a
I0418 20:35:14.284554 50350 net.cpp:84] Creating Layer map32_2_bn_a
I0418 20:35:14.284559 50350 net.cpp:406] map32_2_bn_a <- map32_2_conv_a
I0418 20:35:14.284566 50350 net.cpp:367] map32_2_bn_a -> map32_2_conv_a (in-place)
I0418 20:35:14.284746 50350 net.cpp:122] Setting up map32_2_bn_a
I0418 20:35:14.284754 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.284756 50350 net.cpp:137] Memory required for data: 309249600
I0418 20:35:14.284762 50350 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0418 20:35:14.284770 50350 net.cpp:84] Creating Layer map32_2_scale_a
I0418 20:35:14.284773 50350 net.cpp:406] map32_2_scale_a <- map32_2_conv_a
I0418 20:35:14.284777 50350 net.cpp:367] map32_2_scale_a -> map32_2_conv_a (in-place)
I0418 20:35:14.284814 50350 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0418 20:35:14.284916 50350 net.cpp:122] Setting up map32_2_scale_a
I0418 20:35:14.284921 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.284924 50350 net.cpp:137] Memory required for data: 312526400
I0418 20:35:14.284929 50350 layer_factory.hpp:77] Creating layer map32_2_relu_a
I0418 20:35:14.284934 50350 net.cpp:84] Creating Layer map32_2_relu_a
I0418 20:35:14.284937 50350 net.cpp:406] map32_2_relu_a <- map32_2_conv_a
I0418 20:35:14.284946 50350 net.cpp:367] map32_2_relu_a -> map32_2_conv_a (in-place)
I0418 20:35:14.285107 50350 net.cpp:122] Setting up map32_2_relu_a
I0418 20:35:14.285115 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.285117 50350 net.cpp:137] Memory required for data: 315803200
I0418 20:35:14.285120 50350 layer_factory.hpp:77] Creating layer map32_2_conv_b
I0418 20:35:14.285130 50350 net.cpp:84] Creating Layer map32_2_conv_b
I0418 20:35:14.285132 50350 net.cpp:406] map32_2_conv_b <- map32_2_conv_a
I0418 20:35:14.285140 50350 net.cpp:380] map32_2_conv_b -> map32_2_conv_b
I0418 20:35:14.286211 50350 net.cpp:122] Setting up map32_2_conv_b
I0418 20:35:14.286233 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.286237 50350 net.cpp:137] Memory required for data: 319080000
I0418 20:35:14.286243 50350 layer_factory.hpp:77] Creating layer map32_2_bn_b
I0418 20:35:14.286250 50350 net.cpp:84] Creating Layer map32_2_bn_b
I0418 20:35:14.286253 50350 net.cpp:406] map32_2_bn_b <- map32_2_conv_b
I0418 20:35:14.286260 50350 net.cpp:367] map32_2_bn_b -> map32_2_conv_b (in-place)
I0418 20:35:14.286445 50350 net.cpp:122] Setting up map32_2_bn_b
I0418 20:35:14.286453 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.286455 50350 net.cpp:137] Memory required for data: 322356800
I0418 20:35:14.286461 50350 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0418 20:35:14.286466 50350 net.cpp:84] Creating Layer map32_2_scale_b
I0418 20:35:14.286470 50350 net.cpp:406] map32_2_scale_b <- map32_2_conv_b
I0418 20:35:14.286474 50350 net.cpp:367] map32_2_scale_b -> map32_2_conv_b (in-place)
I0418 20:35:14.286521 50350 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0418 20:35:14.286630 50350 net.cpp:122] Setting up map32_2_scale_b
I0418 20:35:14.286635 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.286640 50350 net.cpp:137] Memory required for data: 325633600
I0418 20:35:14.286646 50350 layer_factory.hpp:77] Creating layer map32_2_eltsum
I0418 20:35:14.286653 50350 net.cpp:84] Creating Layer map32_2_eltsum
I0418 20:35:14.286658 50350 net.cpp:406] map32_2_eltsum <- map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0418 20:35:14.286662 50350 net.cpp:406] map32_2_eltsum <- map32_2_conv_b
I0418 20:35:14.286667 50350 net.cpp:380] map32_2_eltsum -> map32_2_eltsum
I0418 20:35:14.286684 50350 net.cpp:122] Setting up map32_2_eltsum
I0418 20:35:14.286689 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.286708 50350 net.cpp:137] Memory required for data: 328910400
I0418 20:35:14.286711 50350 layer_factory.hpp:77] Creating layer map32_2_relu_after_sum
I0418 20:35:14.286717 50350 net.cpp:84] Creating Layer map32_2_relu_after_sum
I0418 20:35:14.286721 50350 net.cpp:406] map32_2_relu_after_sum <- map32_2_eltsum
I0418 20:35:14.286725 50350 net.cpp:367] map32_2_relu_after_sum -> map32_2_eltsum (in-place)
I0418 20:35:14.286896 50350 net.cpp:122] Setting up map32_2_relu_after_sum
I0418 20:35:14.286906 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.286908 50350 net.cpp:137] Memory required for data: 332187200
I0418 20:35:14.286911 50350 layer_factory.hpp:77] Creating layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0418 20:35:14.286916 50350 net.cpp:84] Creating Layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0418 20:35:14.286919 50350 net.cpp:406] map32_2_eltsum_map32_2_relu_after_sum_0_split <- map32_2_eltsum
I0418 20:35:14.286923 50350 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0418 20:35:14.286933 50350 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0418 20:35:14.286972 50350 net.cpp:122] Setting up map32_2_eltsum_map32_2_relu_after_sum_0_split
I0418 20:35:14.286979 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.286999 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.287001 50350 net.cpp:137] Memory required for data: 338740800
I0418 20:35:14.287004 50350 layer_factory.hpp:77] Creating layer map32_3_conv_a
I0418 20:35:14.287014 50350 net.cpp:84] Creating Layer map32_3_conv_a
I0418 20:35:14.287016 50350 net.cpp:406] map32_3_conv_a <- map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0418 20:35:14.287022 50350 net.cpp:380] map32_3_conv_a -> map32_3_conv_a
I0418 20:35:14.288070 50350 net.cpp:122] Setting up map32_3_conv_a
I0418 20:35:14.288081 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.288085 50350 net.cpp:137] Memory required for data: 342017600
I0418 20:35:14.288090 50350 layer_factory.hpp:77] Creating layer map32_3_bn_a
I0418 20:35:14.288100 50350 net.cpp:84] Creating Layer map32_3_bn_a
I0418 20:35:14.288103 50350 net.cpp:406] map32_3_bn_a <- map32_3_conv_a
I0418 20:35:14.288120 50350 net.cpp:367] map32_3_bn_a -> map32_3_conv_a (in-place)
I0418 20:35:14.288302 50350 net.cpp:122] Setting up map32_3_bn_a
I0418 20:35:14.288308 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.288311 50350 net.cpp:137] Memory required for data: 345294400
I0418 20:35:14.288317 50350 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0418 20:35:14.288322 50350 net.cpp:84] Creating Layer map32_3_scale_a
I0418 20:35:14.288326 50350 net.cpp:406] map32_3_scale_a <- map32_3_conv_a
I0418 20:35:14.288329 50350 net.cpp:367] map32_3_scale_a -> map32_3_conv_a (in-place)
I0418 20:35:14.288367 50350 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0418 20:35:14.288480 50350 net.cpp:122] Setting up map32_3_scale_a
I0418 20:35:14.288487 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.288491 50350 net.cpp:137] Memory required for data: 348571200
I0418 20:35:14.288496 50350 layer_factory.hpp:77] Creating layer map32_3_relu_a
I0418 20:35:14.288501 50350 net.cpp:84] Creating Layer map32_3_relu_a
I0418 20:35:14.288504 50350 net.cpp:406] map32_3_relu_a <- map32_3_conv_a
I0418 20:35:14.288509 50350 net.cpp:367] map32_3_relu_a -> map32_3_conv_a (in-place)
I0418 20:35:14.288926 50350 net.cpp:122] Setting up map32_3_relu_a
I0418 20:35:14.288936 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.288940 50350 net.cpp:137] Memory required for data: 351848000
I0418 20:35:14.288944 50350 layer_factory.hpp:77] Creating layer map32_3_conv_b
I0418 20:35:14.288959 50350 net.cpp:84] Creating Layer map32_3_conv_b
I0418 20:35:14.288964 50350 net.cpp:406] map32_3_conv_b <- map32_3_conv_a
I0418 20:35:14.288969 50350 net.cpp:380] map32_3_conv_b -> map32_3_conv_b
I0418 20:35:14.290350 50350 net.cpp:122] Setting up map32_3_conv_b
I0418 20:35:14.290364 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.290367 50350 net.cpp:137] Memory required for data: 355124800
I0418 20:35:14.290374 50350 layer_factory.hpp:77] Creating layer map32_3_bn_b
I0418 20:35:14.290381 50350 net.cpp:84] Creating Layer map32_3_bn_b
I0418 20:35:14.290385 50350 net.cpp:406] map32_3_bn_b <- map32_3_conv_b
I0418 20:35:14.290390 50350 net.cpp:367] map32_3_bn_b -> map32_3_conv_b (in-place)
I0418 20:35:14.290604 50350 net.cpp:122] Setting up map32_3_bn_b
I0418 20:35:14.290611 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.290614 50350 net.cpp:137] Memory required for data: 358401600
I0418 20:35:14.290621 50350 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0418 20:35:14.290628 50350 net.cpp:84] Creating Layer map32_3_scale_b
I0418 20:35:14.290632 50350 net.cpp:406] map32_3_scale_b <- map32_3_conv_b
I0418 20:35:14.290635 50350 net.cpp:367] map32_3_scale_b -> map32_3_conv_b (in-place)
I0418 20:35:14.290674 50350 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0418 20:35:14.290781 50350 net.cpp:122] Setting up map32_3_scale_b
I0418 20:35:14.290786 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.290788 50350 net.cpp:137] Memory required for data: 361678400
I0418 20:35:14.290793 50350 layer_factory.hpp:77] Creating layer map32_3_eltsum
I0418 20:35:14.290801 50350 net.cpp:84] Creating Layer map32_3_eltsum
I0418 20:35:14.290819 50350 net.cpp:406] map32_3_eltsum <- map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0418 20:35:14.290823 50350 net.cpp:406] map32_3_eltsum <- map32_3_conv_b
I0418 20:35:14.290828 50350 net.cpp:380] map32_3_eltsum -> map32_3_eltsum
I0418 20:35:14.290845 50350 net.cpp:122] Setting up map32_3_eltsum
I0418 20:35:14.290853 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.290855 50350 net.cpp:137] Memory required for data: 364955200
I0418 20:35:14.290858 50350 layer_factory.hpp:77] Creating layer map32_3_relu_after_sum
I0418 20:35:14.290861 50350 net.cpp:84] Creating Layer map32_3_relu_after_sum
I0418 20:35:14.290864 50350 net.cpp:406] map32_3_relu_after_sum <- map32_3_eltsum
I0418 20:35:14.290868 50350 net.cpp:367] map32_3_relu_after_sum -> map32_3_eltsum (in-place)
I0418 20:35:14.291044 50350 net.cpp:122] Setting up map32_3_relu_after_sum
I0418 20:35:14.291052 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.291056 50350 net.cpp:137] Memory required for data: 368232000
I0418 20:35:14.291059 50350 layer_factory.hpp:77] Creating layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0418 20:35:14.291064 50350 net.cpp:84] Creating Layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0418 20:35:14.291069 50350 net.cpp:406] map32_3_eltsum_map32_3_relu_after_sum_0_split <- map32_3_eltsum
I0418 20:35:14.291074 50350 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0418 20:35:14.291079 50350 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0418 20:35:14.291121 50350 net.cpp:122] Setting up map32_3_eltsum_map32_3_relu_after_sum_0_split
I0418 20:35:14.291127 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.291131 50350 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0418 20:35:14.291133 50350 net.cpp:137] Memory required for data: 374785600
I0418 20:35:14.291136 50350 layer_factory.hpp:77] Creating layer map64_1_conv_proj
I0418 20:35:14.291146 50350 net.cpp:84] Creating Layer map64_1_conv_proj
I0418 20:35:14.291152 50350 net.cpp:406] map64_1_conv_proj <- map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0418 20:35:14.291157 50350 net.cpp:380] map64_1_conv_proj -> map64_1_conv_proj
I0418 20:35:14.292300 50350 net.cpp:122] Setting up map64_1_conv_proj
I0418 20:35:14.292313 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.292316 50350 net.cpp:137] Memory required for data: 376424000
I0418 20:35:14.292322 50350 layer_factory.hpp:77] Creating layer map64_1_bn_proj
I0418 20:35:14.292330 50350 net.cpp:84] Creating Layer map64_1_bn_proj
I0418 20:35:14.292333 50350 net.cpp:406] map64_1_bn_proj <- map64_1_conv_proj
I0418 20:35:14.292340 50350 net.cpp:367] map64_1_bn_proj -> map64_1_conv_proj (in-place)
I0418 20:35:14.292582 50350 net.cpp:122] Setting up map64_1_bn_proj
I0418 20:35:14.292589 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.292593 50350 net.cpp:137] Memory required for data: 378062400
I0418 20:35:14.292599 50350 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0418 20:35:14.292605 50350 net.cpp:84] Creating Layer map64_1_scale_proj
I0418 20:35:14.292608 50350 net.cpp:406] map64_1_scale_proj <- map64_1_conv_proj
I0418 20:35:14.292613 50350 net.cpp:367] map64_1_scale_proj -> map64_1_conv_proj (in-place)
I0418 20:35:14.292652 50350 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0418 20:35:14.292799 50350 net.cpp:122] Setting up map64_1_scale_proj
I0418 20:35:14.292805 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.292809 50350 net.cpp:137] Memory required for data: 379700800
I0418 20:35:14.292814 50350 layer_factory.hpp:77] Creating layer map64_1_conv_a
I0418 20:35:14.292821 50350 net.cpp:84] Creating Layer map64_1_conv_a
I0418 20:35:14.292825 50350 net.cpp:406] map64_1_conv_a <- map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0418 20:35:14.292834 50350 net.cpp:380] map64_1_conv_a -> map64_1_conv_a
I0418 20:35:14.293972 50350 net.cpp:122] Setting up map64_1_conv_a
I0418 20:35:14.293983 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.293988 50350 net.cpp:137] Memory required for data: 381339200
I0418 20:35:14.293994 50350 layer_factory.hpp:77] Creating layer map64_1_bn_a
I0418 20:35:14.294000 50350 net.cpp:84] Creating Layer map64_1_bn_a
I0418 20:35:14.294004 50350 net.cpp:406] map64_1_bn_a <- map64_1_conv_a
I0418 20:35:14.294011 50350 net.cpp:367] map64_1_bn_a -> map64_1_conv_a (in-place)
I0418 20:35:14.294208 50350 net.cpp:122] Setting up map64_1_bn_a
I0418 20:35:14.294214 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.294216 50350 net.cpp:137] Memory required for data: 382977600
I0418 20:35:14.294221 50350 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0418 20:35:14.294226 50350 net.cpp:84] Creating Layer map64_1_scale_a
I0418 20:35:14.294240 50350 net.cpp:406] map64_1_scale_a <- map64_1_conv_a
I0418 20:35:14.294245 50350 net.cpp:367] map64_1_scale_a -> map64_1_conv_a (in-place)
I0418 20:35:14.294286 50350 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0418 20:35:14.294394 50350 net.cpp:122] Setting up map64_1_scale_a
I0418 20:35:14.294400 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.294404 50350 net.cpp:137] Memory required for data: 384616000
I0418 20:35:14.294407 50350 layer_factory.hpp:77] Creating layer map64_1_relu_a
I0418 20:35:14.294412 50350 net.cpp:84] Creating Layer map64_1_relu_a
I0418 20:35:14.294415 50350 net.cpp:406] map64_1_relu_a <- map64_1_conv_a
I0418 20:35:14.294419 50350 net.cpp:367] map64_1_relu_a -> map64_1_conv_a (in-place)
I0418 20:35:14.294587 50350 net.cpp:122] Setting up map64_1_relu_a
I0418 20:35:14.294595 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.294597 50350 net.cpp:137] Memory required for data: 386254400
I0418 20:35:14.294600 50350 layer_factory.hpp:77] Creating layer map64_1_conv_b
I0418 20:35:14.294610 50350 net.cpp:84] Creating Layer map64_1_conv_b
I0418 20:35:14.294613 50350 net.cpp:406] map64_1_conv_b <- map64_1_conv_a
I0418 20:35:14.294620 50350 net.cpp:380] map64_1_conv_b -> map64_1_conv_b
I0418 20:35:14.295970 50350 net.cpp:122] Setting up map64_1_conv_b
I0418 20:35:14.295984 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.295986 50350 net.cpp:137] Memory required for data: 387892800
I0418 20:35:14.295992 50350 layer_factory.hpp:77] Creating layer map64_1_bn_b
I0418 20:35:14.296000 50350 net.cpp:84] Creating Layer map64_1_bn_b
I0418 20:35:14.296003 50350 net.cpp:406] map64_1_bn_b <- map64_1_conv_b
I0418 20:35:14.296010 50350 net.cpp:367] map64_1_bn_b -> map64_1_conv_b (in-place)
I0418 20:35:14.296206 50350 net.cpp:122] Setting up map64_1_bn_b
I0418 20:35:14.296213 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.296216 50350 net.cpp:137] Memory required for data: 389531200
I0418 20:35:14.296221 50350 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0418 20:35:14.296226 50350 net.cpp:84] Creating Layer map64_1_scale_b
I0418 20:35:14.296229 50350 net.cpp:406] map64_1_scale_b <- map64_1_conv_b
I0418 20:35:14.296234 50350 net.cpp:367] map64_1_scale_b -> map64_1_conv_b (in-place)
I0418 20:35:14.296270 50350 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0418 20:35:14.296377 50350 net.cpp:122] Setting up map64_1_scale_b
I0418 20:35:14.296383 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.296386 50350 net.cpp:137] Memory required for data: 391169600
I0418 20:35:14.296391 50350 layer_factory.hpp:77] Creating layer map64_1_eltsum
I0418 20:35:14.296396 50350 net.cpp:84] Creating Layer map64_1_eltsum
I0418 20:35:14.296401 50350 net.cpp:406] map64_1_eltsum <- map64_1_conv_proj
I0418 20:35:14.296406 50350 net.cpp:406] map64_1_eltsum <- map64_1_conv_b
I0418 20:35:14.296413 50350 net.cpp:380] map64_1_eltsum -> map64_1_eltsum
I0418 20:35:14.296437 50350 net.cpp:122] Setting up map64_1_eltsum
I0418 20:35:14.296450 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.296452 50350 net.cpp:137] Memory required for data: 392808000
I0418 20:35:14.296455 50350 layer_factory.hpp:77] Creating layer map64_1_relu_after_sum
I0418 20:35:14.296460 50350 net.cpp:84] Creating Layer map64_1_relu_after_sum
I0418 20:35:14.296464 50350 net.cpp:406] map64_1_relu_after_sum <- map64_1_eltsum
I0418 20:35:14.296486 50350 net.cpp:367] map64_1_relu_after_sum -> map64_1_eltsum (in-place)
I0418 20:35:14.296653 50350 net.cpp:122] Setting up map64_1_relu_after_sum
I0418 20:35:14.296669 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.296674 50350 net.cpp:137] Memory required for data: 394446400
I0418 20:35:14.296677 50350 layer_factory.hpp:77] Creating layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0418 20:35:14.296681 50350 net.cpp:84] Creating Layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0418 20:35:14.296686 50350 net.cpp:406] map64_1_eltsum_map64_1_relu_after_sum_0_split <- map64_1_eltsum
I0418 20:35:14.296703 50350 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0418 20:35:14.296710 50350 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0418 20:35:14.296769 50350 net.cpp:122] Setting up map64_1_eltsum_map64_1_relu_after_sum_0_split
I0418 20:35:14.296775 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.296782 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.296784 50350 net.cpp:137] Memory required for data: 397723200
I0418 20:35:14.296787 50350 layer_factory.hpp:77] Creating layer map64_2_conv_a
I0418 20:35:14.296795 50350 net.cpp:84] Creating Layer map64_2_conv_a
I0418 20:35:14.296800 50350 net.cpp:406] map64_2_conv_a <- map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0418 20:35:14.296808 50350 net.cpp:380] map64_2_conv_a -> map64_2_conv_a
I0418 20:35:14.298152 50350 net.cpp:122] Setting up map64_2_conv_a
I0418 20:35:14.298163 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.298167 50350 net.cpp:137] Memory required for data: 399361600
I0418 20:35:14.298172 50350 layer_factory.hpp:77] Creating layer map64_2_bn_a
I0418 20:35:14.298182 50350 net.cpp:84] Creating Layer map64_2_bn_a
I0418 20:35:14.298185 50350 net.cpp:406] map64_2_bn_a <- map64_2_conv_a
I0418 20:35:14.298192 50350 net.cpp:367] map64_2_bn_a -> map64_2_conv_a (in-place)
I0418 20:35:14.298383 50350 net.cpp:122] Setting up map64_2_bn_a
I0418 20:35:14.298389 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.298393 50350 net.cpp:137] Memory required for data: 401000000
I0418 20:35:14.298400 50350 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0418 20:35:14.298405 50350 net.cpp:84] Creating Layer map64_2_scale_a
I0418 20:35:14.298408 50350 net.cpp:406] map64_2_scale_a <- map64_2_conv_a
I0418 20:35:14.298413 50350 net.cpp:367] map64_2_scale_a -> map64_2_conv_a (in-place)
I0418 20:35:14.298456 50350 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0418 20:35:14.298565 50350 net.cpp:122] Setting up map64_2_scale_a
I0418 20:35:14.298571 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.298574 50350 net.cpp:137] Memory required for data: 402638400
I0418 20:35:14.298578 50350 layer_factory.hpp:77] Creating layer map64_2_relu_a
I0418 20:35:14.298583 50350 net.cpp:84] Creating Layer map64_2_relu_a
I0418 20:35:14.298586 50350 net.cpp:406] map64_2_relu_a <- map64_2_conv_a
I0418 20:35:14.298589 50350 net.cpp:367] map64_2_relu_a -> map64_2_conv_a (in-place)
I0418 20:35:14.298748 50350 net.cpp:122] Setting up map64_2_relu_a
I0418 20:35:14.298755 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.298758 50350 net.cpp:137] Memory required for data: 404276800
I0418 20:35:14.298760 50350 layer_factory.hpp:77] Creating layer map64_2_conv_b
I0418 20:35:14.298770 50350 net.cpp:84] Creating Layer map64_2_conv_b
I0418 20:35:14.298774 50350 net.cpp:406] map64_2_conv_b <- map64_2_conv_a
I0418 20:35:14.298780 50350 net.cpp:380] map64_2_conv_b -> map64_2_conv_b
I0418 20:35:14.300251 50350 net.cpp:122] Setting up map64_2_conv_b
I0418 20:35:14.300262 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.300266 50350 net.cpp:137] Memory required for data: 405915200
I0418 20:35:14.300271 50350 layer_factory.hpp:77] Creating layer map64_2_bn_b
I0418 20:35:14.300281 50350 net.cpp:84] Creating Layer map64_2_bn_b
I0418 20:35:14.300284 50350 net.cpp:406] map64_2_bn_b <- map64_2_conv_b
I0418 20:35:14.300289 50350 net.cpp:367] map64_2_bn_b -> map64_2_conv_b (in-place)
I0418 20:35:14.300485 50350 net.cpp:122] Setting up map64_2_bn_b
I0418 20:35:14.300493 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.300495 50350 net.cpp:137] Memory required for data: 407553600
I0418 20:35:14.300519 50350 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0418 20:35:14.300525 50350 net.cpp:84] Creating Layer map64_2_scale_b
I0418 20:35:14.300529 50350 net.cpp:406] map64_2_scale_b <- map64_2_conv_b
I0418 20:35:14.300532 50350 net.cpp:367] map64_2_scale_b -> map64_2_conv_b (in-place)
I0418 20:35:14.300586 50350 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0418 20:35:14.300693 50350 net.cpp:122] Setting up map64_2_scale_b
I0418 20:35:14.300698 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.300701 50350 net.cpp:137] Memory required for data: 409192000
I0418 20:35:14.300705 50350 layer_factory.hpp:77] Creating layer map64_2_eltsum
I0418 20:35:14.300715 50350 net.cpp:84] Creating Layer map64_2_eltsum
I0418 20:35:14.300719 50350 net.cpp:406] map64_2_eltsum <- map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0418 20:35:14.300722 50350 net.cpp:406] map64_2_eltsum <- map64_2_conv_b
I0418 20:35:14.300727 50350 net.cpp:380] map64_2_eltsum -> map64_2_eltsum
I0418 20:35:14.300750 50350 net.cpp:122] Setting up map64_2_eltsum
I0418 20:35:14.300755 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.300760 50350 net.cpp:137] Memory required for data: 410830400
I0418 20:35:14.300761 50350 layer_factory.hpp:77] Creating layer map64_2_relu_after_sum
I0418 20:35:14.300768 50350 net.cpp:84] Creating Layer map64_2_relu_after_sum
I0418 20:35:14.300772 50350 net.cpp:406] map64_2_relu_after_sum <- map64_2_eltsum
I0418 20:35:14.300776 50350 net.cpp:367] map64_2_relu_after_sum -> map64_2_eltsum (in-place)
I0418 20:35:14.300930 50350 net.cpp:122] Setting up map64_2_relu_after_sum
I0418 20:35:14.300936 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.300940 50350 net.cpp:137] Memory required for data: 412468800
I0418 20:35:14.300941 50350 layer_factory.hpp:77] Creating layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0418 20:35:14.300948 50350 net.cpp:84] Creating Layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0418 20:35:14.300951 50350 net.cpp:406] map64_2_eltsum_map64_2_relu_after_sum_0_split <- map64_2_eltsum
I0418 20:35:14.300956 50350 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0418 20:35:14.300961 50350 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0418 20:35:14.301000 50350 net.cpp:122] Setting up map64_2_eltsum_map64_2_relu_after_sum_0_split
I0418 20:35:14.301005 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.301008 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.301010 50350 net.cpp:137] Memory required for data: 415745600
I0418 20:35:14.301013 50350 layer_factory.hpp:77] Creating layer map64_3_conv_a
I0418 20:35:14.301023 50350 net.cpp:84] Creating Layer map64_3_conv_a
I0418 20:35:14.301025 50350 net.cpp:406] map64_3_conv_a <- map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0418 20:35:14.301033 50350 net.cpp:380] map64_3_conv_a -> map64_3_conv_a
I0418 20:35:14.302577 50350 net.cpp:122] Setting up map64_3_conv_a
I0418 20:35:14.302590 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.302593 50350 net.cpp:137] Memory required for data: 417384000
I0418 20:35:14.302599 50350 layer_factory.hpp:77] Creating layer map64_3_bn_a
I0418 20:35:14.302608 50350 net.cpp:84] Creating Layer map64_3_bn_a
I0418 20:35:14.302613 50350 net.cpp:406] map64_3_bn_a <- map64_3_conv_a
I0418 20:35:14.302618 50350 net.cpp:367] map64_3_bn_a -> map64_3_conv_a (in-place)
I0418 20:35:14.302819 50350 net.cpp:122] Setting up map64_3_bn_a
I0418 20:35:14.302825 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.302829 50350 net.cpp:137] Memory required for data: 419022400
I0418 20:35:14.302834 50350 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0418 20:35:14.302841 50350 net.cpp:84] Creating Layer map64_3_scale_a
I0418 20:35:14.302861 50350 net.cpp:406] map64_3_scale_a <- map64_3_conv_a
I0418 20:35:14.302866 50350 net.cpp:367] map64_3_scale_a -> map64_3_conv_a (in-place)
I0418 20:35:14.302904 50350 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0418 20:35:14.303014 50350 net.cpp:122] Setting up map64_3_scale_a
I0418 20:35:14.303020 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.303023 50350 net.cpp:137] Memory required for data: 420660800
I0418 20:35:14.303040 50350 layer_factory.hpp:77] Creating layer map64_3_relu_a
I0418 20:35:14.303048 50350 net.cpp:84] Creating Layer map64_3_relu_a
I0418 20:35:14.303052 50350 net.cpp:406] map64_3_relu_a <- map64_3_conv_a
I0418 20:35:14.303056 50350 net.cpp:367] map64_3_relu_a -> map64_3_conv_a (in-place)
I0418 20:35:14.303500 50350 net.cpp:122] Setting up map64_3_relu_a
I0418 20:35:14.303514 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.303516 50350 net.cpp:137] Memory required for data: 422299200
I0418 20:35:14.303519 50350 layer_factory.hpp:77] Creating layer map64_3_conv_b
I0418 20:35:14.303529 50350 net.cpp:84] Creating Layer map64_3_conv_b
I0418 20:35:14.303534 50350 net.cpp:406] map64_3_conv_b <- map64_3_conv_a
I0418 20:35:14.303540 50350 net.cpp:380] map64_3_conv_b -> map64_3_conv_b
I0418 20:35:14.304754 50350 net.cpp:122] Setting up map64_3_conv_b
I0418 20:35:14.304764 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.304769 50350 net.cpp:137] Memory required for data: 423937600
I0418 20:35:14.304774 50350 layer_factory.hpp:77] Creating layer map64_3_bn_b
I0418 20:35:14.304780 50350 net.cpp:84] Creating Layer map64_3_bn_b
I0418 20:35:14.304785 50350 net.cpp:406] map64_3_bn_b <- map64_3_conv_b
I0418 20:35:14.304791 50350 net.cpp:367] map64_3_bn_b -> map64_3_conv_b (in-place)
I0418 20:35:14.304976 50350 net.cpp:122] Setting up map64_3_bn_b
I0418 20:35:14.304982 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.304986 50350 net.cpp:137] Memory required for data: 425576000
I0418 20:35:14.304992 50350 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0418 20:35:14.304997 50350 net.cpp:84] Creating Layer map64_3_scale_b
I0418 20:35:14.305001 50350 net.cpp:406] map64_3_scale_b <- map64_3_conv_b
I0418 20:35:14.305006 50350 net.cpp:367] map64_3_scale_b -> map64_3_conv_b (in-place)
I0418 20:35:14.305042 50350 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0418 20:35:14.305156 50350 net.cpp:122] Setting up map64_3_scale_b
I0418 20:35:14.305161 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.305164 50350 net.cpp:137] Memory required for data: 427214400
I0418 20:35:14.305168 50350 layer_factory.hpp:77] Creating layer map64_3_eltsum
I0418 20:35:14.305173 50350 net.cpp:84] Creating Layer map64_3_eltsum
I0418 20:35:14.305177 50350 net.cpp:406] map64_3_eltsum <- map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0418 20:35:14.305181 50350 net.cpp:406] map64_3_eltsum <- map64_3_conv_b
I0418 20:35:14.305187 50350 net.cpp:380] map64_3_eltsum -> map64_3_eltsum
I0418 20:35:14.305208 50350 net.cpp:122] Setting up map64_3_eltsum
I0418 20:35:14.305213 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.305217 50350 net.cpp:137] Memory required for data: 428852800
I0418 20:35:14.305218 50350 layer_factory.hpp:77] Creating layer map64_3_relu_after_sum
I0418 20:35:14.305225 50350 net.cpp:84] Creating Layer map64_3_relu_after_sum
I0418 20:35:14.305228 50350 net.cpp:406] map64_3_relu_after_sum <- map64_3_eltsum
I0418 20:35:14.305233 50350 net.cpp:367] map64_3_relu_after_sum -> map64_3_eltsum (in-place)
I0418 20:35:14.305683 50350 net.cpp:122] Setting up map64_3_relu_after_sum
I0418 20:35:14.305696 50350 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0418 20:35:14.305699 50350 net.cpp:137] Memory required for data: 430491200
I0418 20:35:14.305702 50350 layer_factory.hpp:77] Creating layer pool_global
I0418 20:35:14.305708 50350 net.cpp:84] Creating Layer pool_global
I0418 20:35:14.305712 50350 net.cpp:406] pool_global <- map64_3_eltsum
I0418 20:35:14.305717 50350 net.cpp:380] pool_global -> pool_global
I0418 20:35:14.305899 50350 net.cpp:122] Setting up pool_global
I0418 20:35:14.305907 50350 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0418 20:35:14.305910 50350 net.cpp:137] Memory required for data: 430516800
I0418 20:35:14.305912 50350 layer_factory.hpp:77] Creating layer score
I0418 20:35:14.305920 50350 net.cpp:84] Creating Layer score
I0418 20:35:14.305923 50350 net.cpp:406] score <- pool_global
I0418 20:35:14.305927 50350 net.cpp:380] score -> score
I0418 20:35:14.306051 50350 net.cpp:122] Setting up score
I0418 20:35:14.306056 50350 net.cpp:129] Top shape: 100 10 (1000)
I0418 20:35:14.306059 50350 net.cpp:137] Memory required for data: 430520800
I0418 20:35:14.306064 50350 layer_factory.hpp:77] Creating layer score_score_0_split
I0418 20:35:14.306071 50350 net.cpp:84] Creating Layer score_score_0_split
I0418 20:35:14.306073 50350 net.cpp:406] score_score_0_split <- score
I0418 20:35:14.306077 50350 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0418 20:35:14.306085 50350 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0418 20:35:14.306092 50350 net.cpp:380] score_score_0_split -> score_score_0_split_2
I0418 20:35:14.306143 50350 net.cpp:122] Setting up score_score_0_split
I0418 20:35:14.306149 50350 net.cpp:129] Top shape: 100 10 (1000)
I0418 20:35:14.306152 50350 net.cpp:129] Top shape: 100 10 (1000)
I0418 20:35:14.306154 50350 net.cpp:129] Top shape: 100 10 (1000)
I0418 20:35:14.306157 50350 net.cpp:137] Memory required for data: 430532800
I0418 20:35:14.306159 50350 layer_factory.hpp:77] Creating layer loss
I0418 20:35:14.306165 50350 net.cpp:84] Creating Layer loss
I0418 20:35:14.306169 50350 net.cpp:406] loss <- score_score_0_split_0
I0418 20:35:14.306172 50350 net.cpp:406] loss <- label_data_1_split_0
I0418 20:35:14.306176 50350 net.cpp:380] loss -> loss
I0418 20:35:14.306182 50350 layer_factory.hpp:77] Creating layer loss
I0418 20:35:14.306421 50350 net.cpp:122] Setting up loss
I0418 20:35:14.306428 50350 net.cpp:129] Top shape: (1)
I0418 20:35:14.306432 50350 net.cpp:132]     with loss weight 1
I0418 20:35:14.306437 50350 net.cpp:137] Memory required for data: 430532804
I0418 20:35:14.306447 50350 layer_factory.hpp:77] Creating layer acc/top1
I0418 20:35:14.306452 50350 net.cpp:84] Creating Layer acc/top1
I0418 20:35:14.306457 50350 net.cpp:406] acc/top1 <- score_score_0_split_1
I0418 20:35:14.306460 50350 net.cpp:406] acc/top1 <- label_data_1_split_1
I0418 20:35:14.306468 50350 net.cpp:380] acc/top1 -> acctop1
I0418 20:35:14.306473 50350 net.cpp:122] Setting up acc/top1
I0418 20:35:14.306478 50350 net.cpp:129] Top shape: (1)
I0418 20:35:14.306481 50350 net.cpp:137] Memory required for data: 430532808
I0418 20:35:14.306483 50350 layer_factory.hpp:77] Creating layer acc/top5
I0418 20:35:14.306486 50350 net.cpp:84] Creating Layer acc/top5
I0418 20:35:14.306489 50350 net.cpp:406] acc/top5 <- score_score_0_split_2
I0418 20:35:14.306493 50350 net.cpp:406] acc/top5 <- label_data_1_split_2
I0418 20:35:14.306499 50350 net.cpp:380] acc/top5 -> acctop5
I0418 20:35:14.306504 50350 net.cpp:122] Setting up acc/top5
I0418 20:35:14.306509 50350 net.cpp:129] Top shape: (1)
I0418 20:35:14.306510 50350 net.cpp:137] Memory required for data: 430532812
I0418 20:35:14.306514 50350 net.cpp:200] acc/top5 does not need backward computation.
I0418 20:35:14.306516 50350 net.cpp:200] acc/top1 does not need backward computation.
I0418 20:35:14.306519 50350 net.cpp:198] loss needs backward computation.
I0418 20:35:14.306522 50350 net.cpp:198] score_score_0_split needs backward computation.
I0418 20:35:14.306525 50350 net.cpp:198] score needs backward computation.
I0418 20:35:14.306527 50350 net.cpp:198] pool_global needs backward computation.
I0418 20:35:14.306530 50350 net.cpp:198] map64_3_relu_after_sum needs backward computation.
I0418 20:35:14.306532 50350 net.cpp:198] map64_3_eltsum needs backward computation.
I0418 20:35:14.306535 50350 net.cpp:198] map64_3_scale_b needs backward computation.
I0418 20:35:14.306538 50350 net.cpp:198] map64_3_bn_b needs backward computation.
I0418 20:35:14.306540 50350 net.cpp:198] map64_3_conv_b needs backward computation.
I0418 20:35:14.306543 50350 net.cpp:198] map64_3_relu_a needs backward computation.
I0418 20:35:14.306546 50350 net.cpp:198] map64_3_scale_a needs backward computation.
I0418 20:35:14.306548 50350 net.cpp:198] map64_3_bn_a needs backward computation.
I0418 20:35:14.306550 50350 net.cpp:198] map64_3_conv_a needs backward computation.
I0418 20:35:14.306553 50350 net.cpp:198] map64_2_eltsum_map64_2_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.306567 50350 net.cpp:198] map64_2_relu_after_sum needs backward computation.
I0418 20:35:14.306571 50350 net.cpp:198] map64_2_eltsum needs backward computation.
I0418 20:35:14.306573 50350 net.cpp:198] map64_2_scale_b needs backward computation.
I0418 20:35:14.306576 50350 net.cpp:198] map64_2_bn_b needs backward computation.
I0418 20:35:14.306578 50350 net.cpp:198] map64_2_conv_b needs backward computation.
I0418 20:35:14.306581 50350 net.cpp:198] map64_2_relu_a needs backward computation.
I0418 20:35:14.306583 50350 net.cpp:198] map64_2_scale_a needs backward computation.
I0418 20:35:14.306586 50350 net.cpp:198] map64_2_bn_a needs backward computation.
I0418 20:35:14.306588 50350 net.cpp:198] map64_2_conv_a needs backward computation.
I0418 20:35:14.306591 50350 net.cpp:198] map64_1_eltsum_map64_1_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.306593 50350 net.cpp:198] map64_1_relu_after_sum needs backward computation.
I0418 20:35:14.306596 50350 net.cpp:198] map64_1_eltsum needs backward computation.
I0418 20:35:14.306599 50350 net.cpp:198] map64_1_scale_b needs backward computation.
I0418 20:35:14.306602 50350 net.cpp:198] map64_1_bn_b needs backward computation.
I0418 20:35:14.306604 50350 net.cpp:198] map64_1_conv_b needs backward computation.
I0418 20:35:14.306607 50350 net.cpp:198] map64_1_relu_a needs backward computation.
I0418 20:35:14.306610 50350 net.cpp:198] map64_1_scale_a needs backward computation.
I0418 20:35:14.306612 50350 net.cpp:198] map64_1_bn_a needs backward computation.
I0418 20:35:14.306614 50350 net.cpp:198] map64_1_conv_a needs backward computation.
I0418 20:35:14.306617 50350 net.cpp:198] map64_1_scale_proj needs backward computation.
I0418 20:35:14.306620 50350 net.cpp:198] map64_1_bn_proj needs backward computation.
I0418 20:35:14.306623 50350 net.cpp:198] map64_1_conv_proj needs backward computation.
I0418 20:35:14.306627 50350 net.cpp:198] map32_3_eltsum_map32_3_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.306632 50350 net.cpp:198] map32_3_relu_after_sum needs backward computation.
I0418 20:35:14.306633 50350 net.cpp:198] map32_3_eltsum needs backward computation.
I0418 20:35:14.306639 50350 net.cpp:198] map32_3_scale_b needs backward computation.
I0418 20:35:14.306643 50350 net.cpp:198] map32_3_bn_b needs backward computation.
I0418 20:35:14.306644 50350 net.cpp:198] map32_3_conv_b needs backward computation.
I0418 20:35:14.306646 50350 net.cpp:198] map32_3_relu_a needs backward computation.
I0418 20:35:14.306650 50350 net.cpp:198] map32_3_scale_a needs backward computation.
I0418 20:35:14.306653 50350 net.cpp:198] map32_3_bn_a needs backward computation.
I0418 20:35:14.306656 50350 net.cpp:198] map32_3_conv_a needs backward computation.
I0418 20:35:14.306659 50350 net.cpp:198] map32_2_eltsum_map32_2_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.306663 50350 net.cpp:198] map32_2_relu_after_sum needs backward computation.
I0418 20:35:14.306664 50350 net.cpp:198] map32_2_eltsum needs backward computation.
I0418 20:35:14.306668 50350 net.cpp:198] map32_2_scale_b needs backward computation.
I0418 20:35:14.306670 50350 net.cpp:198] map32_2_bn_b needs backward computation.
I0418 20:35:14.306673 50350 net.cpp:198] map32_2_conv_b needs backward computation.
I0418 20:35:14.306675 50350 net.cpp:198] map32_2_relu_a needs backward computation.
I0418 20:35:14.306677 50350 net.cpp:198] map32_2_scale_a needs backward computation.
I0418 20:35:14.306680 50350 net.cpp:198] map32_2_bn_a needs backward computation.
I0418 20:35:14.306682 50350 net.cpp:198] map32_2_conv_a needs backward computation.
I0418 20:35:14.306685 50350 net.cpp:198] map32_1_eltsum_map32_1_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.306689 50350 net.cpp:198] map32_1_relu_after_sum needs backward computation.
I0418 20:35:14.306690 50350 net.cpp:198] map32_1_eltsum needs backward computation.
I0418 20:35:14.306694 50350 net.cpp:198] map32_1_scale_b needs backward computation.
I0418 20:35:14.306696 50350 net.cpp:198] map32_1_bn_b needs backward computation.
I0418 20:35:14.306706 50350 net.cpp:198] map32_1_conv_b needs backward computation.
I0418 20:35:14.306710 50350 net.cpp:198] map32_1_relu_a needs backward computation.
I0418 20:35:14.306712 50350 net.cpp:198] map32_1_scale_a needs backward computation.
I0418 20:35:14.306715 50350 net.cpp:198] map32_1_bn_a needs backward computation.
I0418 20:35:14.306716 50350 net.cpp:198] map32_1_conv_a needs backward computation.
I0418 20:35:14.306720 50350 net.cpp:198] map32_1_scale_proj needs backward computation.
I0418 20:35:14.306722 50350 net.cpp:198] map32_1_bn_proj needs backward computation.
I0418 20:35:14.306725 50350 net.cpp:198] map32_1_conv_proj needs backward computation.
I0418 20:35:14.306727 50350 net.cpp:198] map16_3_eltsum_map16_3_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.306733 50350 net.cpp:198] map16_3_relu_after_sum needs backward computation.
I0418 20:35:14.306735 50350 net.cpp:198] map16_3_eltsum needs backward computation.
I0418 20:35:14.306738 50350 net.cpp:198] map16_3_scale_b needs backward computation.
I0418 20:35:14.306741 50350 net.cpp:198] map16_3_bn_b needs backward computation.
I0418 20:35:14.306744 50350 net.cpp:198] map16_3_conv_b needs backward computation.
I0418 20:35:14.306746 50350 net.cpp:198] map16_3_relu_a needs backward computation.
I0418 20:35:14.306748 50350 net.cpp:198] map16_3_scale_a needs backward computation.
I0418 20:35:14.306751 50350 net.cpp:198] map16_3_bn_a needs backward computation.
I0418 20:35:14.306753 50350 net.cpp:198] map16_3_conv_a needs backward computation.
I0418 20:35:14.306756 50350 net.cpp:198] map16_2_eltsum_map16_2_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.306759 50350 net.cpp:198] map16_2_relu_after_sum needs backward computation.
I0418 20:35:14.306761 50350 net.cpp:198] map16_2_eltsum needs backward computation.
I0418 20:35:14.306764 50350 net.cpp:198] map16_2_scale_b needs backward computation.
I0418 20:35:14.306766 50350 net.cpp:198] map16_2_bn_b needs backward computation.
I0418 20:35:14.306768 50350 net.cpp:198] map16_2_conv_b needs backward computation.
I0418 20:35:14.306771 50350 net.cpp:198] map16_2_relu_a needs backward computation.
I0418 20:35:14.306773 50350 net.cpp:198] map16_2_scale_a needs backward computation.
I0418 20:35:14.306776 50350 net.cpp:198] map16_2_bn_a needs backward computation.
I0418 20:35:14.306777 50350 net.cpp:198] map16_2_conv_a needs backward computation.
I0418 20:35:14.306780 50350 net.cpp:198] map16_1_eltsum_map16_1_relu_after_sum_0_split needs backward computation.
I0418 20:35:14.306783 50350 net.cpp:198] map16_1_relu_after_sum needs backward computation.
I0418 20:35:14.306785 50350 net.cpp:198] map16_1_eltsum needs backward computation.
I0418 20:35:14.306789 50350 net.cpp:198] map16_1_scale_b needs backward computation.
I0418 20:35:14.306792 50350 net.cpp:198] map16_1_bn_b needs backward computation.
I0418 20:35:14.306794 50350 net.cpp:198] map16_1_conv_b needs backward computation.
I0418 20:35:14.306797 50350 net.cpp:198] map16_1_relu_a needs backward computation.
I0418 20:35:14.306799 50350 net.cpp:198] map16_1_scale_a needs backward computation.
I0418 20:35:14.306802 50350 net.cpp:198] map16_1_bn_a needs backward computation.
I0418 20:35:14.306803 50350 net.cpp:198] map16_1_conv_a needs backward computation.
I0418 20:35:14.306807 50350 net.cpp:198] conv1_relu_conv1_0_split needs backward computation.
I0418 20:35:14.306809 50350 net.cpp:198] relu_conv1 needs backward computation.
I0418 20:35:14.306813 50350 net.cpp:198] scale_conv1 needs backward computation.
I0418 20:35:14.306814 50350 net.cpp:198] bn_conv1 needs backward computation.
I0418 20:35:14.306816 50350 net.cpp:198] conv1 needs backward computation.
I0418 20:35:14.306820 50350 net.cpp:200] label_data_1_split does not need backward computation.
I0418 20:35:14.306824 50350 net.cpp:200] data does not need backward computation.
I0418 20:35:14.306828 50350 net.cpp:242] This network produces output acctop1
I0418 20:35:14.306830 50350 net.cpp:242] This network produces output acctop5
I0418 20:35:14.306838 50350 net.cpp:242] This network produces output loss
I0418 20:35:14.306888 50350 net.cpp:255] Network initialization done.
I0418 20:35:14.307143 50350 solver.cpp:56] Solver scaffolding done.
I0418 20:35:14.312198 50350 caffe.cpp:242] Resuming from model/ResNet20_highway_padded_data_iter_50000.solverstate
I0418 20:35:14.357373 50350 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: model/ResNet20_highway_padded_data_iter_50000.caffemodel
I0418 20:35:14.357388 50350 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0418 20:35:14.357779 50350 sgd_solver.cpp:318] SGDSolver: restoring history
I0418 20:35:14.360716 50350 caffe.cpp:248] Starting Optimization
I0418 20:35:14.360728 50350 solver.cpp:273] Solving 
I0418 20:35:14.360730 50350 solver.cpp:274] Learning Rate Policy: multistep
I0418 20:35:14.363797 50350 solver.cpp:331] Iteration 50000, Testing net (#0)
I0418 20:35:16.441483 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:35:16.497496 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9004
I0418 20:35:16.497522 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.997
I0418 20:35:16.497546 50350 solver.cpp:398]     Test net output #2: loss = 0.325487 (* 1 = 0.325487 loss)
I0418 20:35:16.600653 50350 solver.cpp:219] Iteration 50000 (22322.3 iter/s, 2.23991s/100 iters), loss = 0.157279
I0418 20:35:16.600677 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:35:16.600683 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:35:16.600688 50350 solver.cpp:238]     Train net output #2: loss = 0.157279 (* 1 = 0.157279 loss)
I0418 20:35:16.600710 50350 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0418 20:35:26.741616 50350 solver.cpp:219] Iteration 50100 (9.86096 iter/s, 10.141s/100 iters), loss = 0.0670806
I0418 20:35:26.741643 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:35:26.741652 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:35:26.741660 50350 solver.cpp:238]     Train net output #2: loss = 0.0670806 (* 1 = 0.0670806 loss)
I0418 20:35:26.741667 50350 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0418 20:35:36.932593 50350 solver.cpp:219] Iteration 50200 (9.81259 iter/s, 10.191s/100 iters), loss = 0.150411
I0418 20:35:36.932636 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:35:36.932644 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:35:36.932652 50350 solver.cpp:238]     Train net output #2: loss = 0.150411 (* 1 = 0.150411 loss)
I0418 20:35:36.932657 50350 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0418 20:35:47.066846 50350 solver.cpp:219] Iteration 50300 (9.86751 iter/s, 10.1343s/100 iters), loss = 0.102275
I0418 20:35:47.066959 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:35:47.066968 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:35:47.066978 50350 solver.cpp:238]     Train net output #2: loss = 0.102275 (* 1 = 0.102275 loss)
I0418 20:35:47.066984 50350 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0418 20:35:55.887923 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:35:57.335691 50350 solver.cpp:219] Iteration 50400 (9.73825 iter/s, 10.2688s/100 iters), loss = 0.187715
I0418 20:35:57.335736 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 20:35:57.335743 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:35:57.335752 50350 solver.cpp:238]     Train net output #2: loss = 0.187715 (* 1 = 0.187715 loss)
I0418 20:35:57.335759 50350 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0418 20:36:07.725167 50350 solver.cpp:219] Iteration 50500 (9.62512 iter/s, 10.3895s/100 iters), loss = 0.109589
I0418 20:36:07.725217 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:36:07.725224 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:36:07.725234 50350 solver.cpp:238]     Train net output #2: loss = 0.109589 (* 1 = 0.109589 loss)
I0418 20:36:07.725241 50350 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0418 20:36:18.115571 50350 solver.cpp:219] Iteration 50600 (9.62426 iter/s, 10.3904s/100 iters), loss = 0.15623
I0418 20:36:18.115839 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:36:18.115850 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:36:18.115860 50350 solver.cpp:238]     Train net output #2: loss = 0.15623 (* 1 = 0.15623 loss)
I0418 20:36:18.115865 50350 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0418 20:36:28.498687 50350 solver.cpp:219] Iteration 50700 (9.63123 iter/s, 10.3829s/100 iters), loss = 0.0782422
I0418 20:36:28.498730 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:36:28.498736 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:36:28.498744 50350 solver.cpp:238]     Train net output #2: loss = 0.0782422 (* 1 = 0.0782422 loss)
I0418 20:36:28.498747 50350 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0418 20:36:36.503739 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:36:38.889205 50350 solver.cpp:219] Iteration 50800 (9.62415 iter/s, 10.3905s/100 iters), loss = 0.0448501
I0418 20:36:38.889269 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 20:36:38.889276 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:36:38.889283 50350 solver.cpp:238]     Train net output #2: loss = 0.0448501 (* 1 = 0.0448501 loss)
I0418 20:36:38.889288 50350 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0418 20:36:49.283126 50350 solver.cpp:219] Iteration 50900 (9.62101 iter/s, 10.3939s/100 iters), loss = 0.111906
I0418 20:36:49.283329 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:36:49.283336 50350 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 20:36:49.283344 50350 solver.cpp:238]     Train net output #2: loss = 0.111906 (* 1 = 0.111906 loss)
I0418 20:36:49.283349 50350 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0418 20:36:59.572160 50350 solver.cpp:331] Iteration 51000, Testing net (#0)
I0418 20:37:01.552445 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:37:01.632946 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9057
I0418 20:37:01.632966 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.997
I0418 20:37:01.632973 50350 solver.cpp:398]     Test net output #2: loss = 0.318045 (* 1 = 0.318045 loss)
I0418 20:37:01.731647 50350 solver.cpp:219] Iteration 51000 (8.03317 iter/s, 12.4484s/100 iters), loss = 0.104348
I0418 20:37:01.731667 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 20:37:01.731689 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:37:01.731696 50350 solver.cpp:238]     Train net output #2: loss = 0.104348 (* 1 = 0.104348 loss)
I0418 20:37:01.731700 50350 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0418 20:37:12.096761 50350 solver.cpp:219] Iteration 51100 (9.64773 iter/s, 10.3651s/100 iters), loss = 0.13633
I0418 20:37:12.096807 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 20:37:12.096812 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:37:12.096819 50350 solver.cpp:238]     Train net output #2: loss = 0.13633 (* 1 = 0.13633 loss)
I0418 20:37:12.096823 50350 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0418 20:37:19.061561 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:37:22.483253 50350 solver.cpp:219] Iteration 51200 (9.62789 iter/s, 10.3865s/100 iters), loss = 0.0766533
I0418 20:37:22.483435 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:37:22.483448 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:37:22.483456 50350 solver.cpp:238]     Train net output #2: loss = 0.0766532 (* 1 = 0.0766532 loss)
I0418 20:37:22.483461 50350 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0418 20:37:32.875753 50350 solver.cpp:219] Iteration 51300 (9.62245 iter/s, 10.3924s/100 iters), loss = 0.181861
I0418 20:37:32.875797 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 20:37:32.875802 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:37:32.875808 50350 solver.cpp:238]     Train net output #2: loss = 0.181861 (* 1 = 0.181861 loss)
I0418 20:37:32.875813 50350 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0418 20:37:43.235873 50350 solver.cpp:219] Iteration 51400 (9.6524 iter/s, 10.3601s/100 iters), loss = 0.123674
I0418 20:37:43.235937 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 20:37:43.235945 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:37:43.235952 50350 solver.cpp:238]     Train net output #2: loss = 0.123674 (* 1 = 0.123674 loss)
I0418 20:37:43.235956 50350 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0418 20:37:53.632004 50350 solver.cpp:219] Iteration 51500 (9.61898 iter/s, 10.3961s/100 iters), loss = 0.0474152
I0418 20:37:53.632216 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:37:53.632225 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:37:53.632232 50350 solver.cpp:238]     Train net output #2: loss = 0.0474151 (* 1 = 0.0474151 loss)
I0418 20:37:53.632237 50350 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0418 20:37:59.667531 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:38:04.030048 50350 solver.cpp:219] Iteration 51600 (9.61735 iter/s, 10.3979s/100 iters), loss = 0.079249
I0418 20:38:04.030108 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:38:04.030114 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:38:04.030122 50350 solver.cpp:238]     Train net output #2: loss = 0.0792489 (* 1 = 0.0792489 loss)
I0418 20:38:04.030125 50350 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0418 20:38:14.429352 50350 solver.cpp:219] Iteration 51700 (9.61603 iter/s, 10.3993s/100 iters), loss = 0.0972113
I0418 20:38:14.429399 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:38:14.429404 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:38:14.429411 50350 solver.cpp:238]     Train net output #2: loss = 0.0972112 (* 1 = 0.0972112 loss)
I0418 20:38:14.429419 50350 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0418 20:38:24.701683 50350 solver.cpp:219] Iteration 51800 (9.73489 iter/s, 10.2723s/100 iters), loss = 0.115616
I0418 20:38:24.701890 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:38:24.701897 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:38:24.701905 50350 solver.cpp:238]     Train net output #2: loss = 0.115616 (* 1 = 0.115616 loss)
I0418 20:38:24.701910 50350 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0418 20:38:34.842974 50350 solver.cpp:219] Iteration 51900 (9.86083 iter/s, 10.1411s/100 iters), loss = 0.0664766
I0418 20:38:34.842995 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:38:34.842999 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:38:34.843004 50350 solver.cpp:238]     Train net output #2: loss = 0.0664765 (* 1 = 0.0664765 loss)
I0418 20:38:34.843008 50350 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0418 20:38:39.826159 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:38:44.897851 50350 solver.cpp:331] Iteration 52000, Testing net (#0)
I0418 20:38:46.875493 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:38:46.956073 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9026
I0418 20:38:46.956090 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9969
I0418 20:38:46.956096 50350 solver.cpp:398]     Test net output #2: loss = 0.334372 (* 1 = 0.334372 loss)
I0418 20:38:47.054870 50350 solver.cpp:219] Iteration 52000 (8.18871 iter/s, 12.2119s/100 iters), loss = 0.100148
I0418 20:38:47.054889 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:38:47.054894 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:38:47.054899 50350 solver.cpp:238]     Train net output #2: loss = 0.100147 (* 1 = 0.100147 loss)
I0418 20:38:47.054903 50350 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0418 20:38:57.169805 50350 solver.cpp:219] Iteration 52100 (9.88634 iter/s, 10.115s/100 iters), loss = 0.0565732
I0418 20:38:57.169935 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:38:57.169942 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:38:57.169948 50350 solver.cpp:238]     Train net output #2: loss = 0.056573 (* 1 = 0.056573 loss)
I0418 20:38:57.169953 50350 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0418 20:39:07.307282 50350 solver.cpp:219] Iteration 52200 (9.86447 iter/s, 10.1374s/100 iters), loss = 0.0600463
I0418 20:39:07.307314 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:39:07.307320 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:39:07.307325 50350 solver.cpp:238]     Train net output #2: loss = 0.0600462 (* 1 = 0.0600462 loss)
I0418 20:39:07.307329 50350 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0418 20:39:17.466483 50350 solver.cpp:219] Iteration 52300 (9.84328 iter/s, 10.1592s/100 iters), loss = 0.119635
I0418 20:39:17.466503 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:39:17.466508 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:39:17.466513 50350 solver.cpp:238]     Train net output #2: loss = 0.119635 (* 1 = 0.119635 loss)
I0418 20:39:17.466516 50350 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0418 20:39:21.423393 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:39:27.588551 50350 solver.cpp:219] Iteration 52400 (9.87938 iter/s, 10.1221s/100 iters), loss = 0.0687378
I0418 20:39:27.588682 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:39:27.588690 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:39:27.588696 50350 solver.cpp:238]     Train net output #2: loss = 0.0687377 (* 1 = 0.0687377 loss)
I0418 20:39:27.588699 50350 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0418 20:39:37.728127 50350 solver.cpp:219] Iteration 52500 (9.86243 iter/s, 10.1395s/100 iters), loss = 0.152421
I0418 20:39:37.728152 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:39:37.728155 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:39:37.728160 50350 solver.cpp:238]     Train net output #2: loss = 0.152421 (* 1 = 0.152421 loss)
I0418 20:39:37.728164 50350 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0418 20:39:47.881861 50350 solver.cpp:219] Iteration 52600 (9.84857 iter/s, 10.1538s/100 iters), loss = 0.122275
I0418 20:39:47.881888 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:39:47.881892 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:39:47.881898 50350 solver.cpp:238]     Train net output #2: loss = 0.122275 (* 1 = 0.122275 loss)
I0418 20:39:47.881902 50350 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0418 20:39:58.045946 50350 solver.cpp:219] Iteration 52700 (9.83854 iter/s, 10.1641s/100 iters), loss = 0.0817584
I0418 20:39:58.046064 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:39:58.046070 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:39:58.046077 50350 solver.cpp:238]     Train net output #2: loss = 0.0817583 (* 1 = 0.0817583 loss)
I0418 20:39:58.046080 50350 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0418 20:40:01.091167 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:40:08.209847 50350 solver.cpp:219] Iteration 52800 (9.83881 iter/s, 10.1638s/100 iters), loss = 0.0458777
I0418 20:40:08.209874 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:40:08.209879 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:40:08.209884 50350 solver.cpp:238]     Train net output #2: loss = 0.0458776 (* 1 = 0.0458776 loss)
I0418 20:40:08.209888 50350 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0418 20:40:18.386603 50350 solver.cpp:219] Iteration 52900 (9.82629 iter/s, 10.1768s/100 iters), loss = 0.11934
I0418 20:40:18.386623 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 20:40:18.386628 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:40:18.386633 50350 solver.cpp:238]     Train net output #2: loss = 0.11934 (* 1 = 0.11934 loss)
I0418 20:40:18.386637 50350 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0418 20:40:28.414940 50350 solver.cpp:331] Iteration 53000, Testing net (#0)
I0418 20:40:30.393465 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:40:30.474131 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9067
I0418 20:40:30.474149 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9973
I0418 20:40:30.474155 50350 solver.cpp:398]     Test net output #2: loss = 0.329211 (* 1 = 0.329211 loss)
I0418 20:40:30.572856 50350 solver.cpp:219] Iteration 53000 (8.20594 iter/s, 12.1863s/100 iters), loss = 0.103732
I0418 20:40:30.572875 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:40:30.572880 50350 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 20:40:30.572885 50350 solver.cpp:238]     Train net output #2: loss = 0.103732 (* 1 = 0.103732 loss)
I0418 20:40:30.572888 50350 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0418 20:40:40.689538 50350 solver.cpp:219] Iteration 53100 (9.88465 iter/s, 10.1167s/100 iters), loss = 0.0918017
I0418 20:40:40.689581 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:40:40.689586 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:40:40.689594 50350 solver.cpp:238]     Train net output #2: loss = 0.0918016 (* 1 = 0.0918016 loss)
I0418 20:40:40.689599 50350 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0418 20:40:42.729099 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:40:50.867532 50350 solver.cpp:219] Iteration 53200 (9.82513 iter/s, 10.178s/100 iters), loss = 0.0921196
I0418 20:40:50.867588 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:40:50.867594 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:40:50.867600 50350 solver.cpp:238]     Train net output #2: loss = 0.0921195 (* 1 = 0.0921195 loss)
I0418 20:40:50.867604 50350 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0418 20:41:01.217913 50350 solver.cpp:219] Iteration 53300 (9.66148 iter/s, 10.3504s/100 iters), loss = 0.132522
I0418 20:41:01.218128 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:41:01.218135 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:41:01.218143 50350 solver.cpp:238]     Train net output #2: loss = 0.132522 (* 1 = 0.132522 loss)
I0418 20:41:01.218148 50350 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0418 20:41:11.567703 50350 solver.cpp:219] Iteration 53400 (9.6622 iter/s, 10.3496s/100 iters), loss = 0.0998851
I0418 20:41:11.567745 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:41:11.567750 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:41:11.567757 50350 solver.cpp:238]     Train net output #2: loss = 0.099885 (* 1 = 0.099885 loss)
I0418 20:41:11.567761 50350 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0418 20:41:21.916541 50350 solver.cpp:219] Iteration 53500 (9.66292 iter/s, 10.3488s/100 iters), loss = 0.0394687
I0418 20:41:21.916601 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 20:41:21.916607 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:41:21.916615 50350 solver.cpp:238]     Train net output #2: loss = 0.0394686 (* 1 = 0.0394686 loss)
I0418 20:41:21.916618 50350 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0418 20:41:23.063299 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:41:32.302532 50350 solver.cpp:219] Iteration 53600 (9.62836 iter/s, 10.386s/100 iters), loss = 0.034405
I0418 20:41:32.302717 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 20:41:32.302726 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:41:32.302733 50350 solver.cpp:238]     Train net output #2: loss = 0.0344049 (* 1 = 0.0344049 loss)
I0418 20:41:32.302760 50350 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0418 20:41:42.693161 50350 solver.cpp:219] Iteration 53700 (9.6242 iter/s, 10.3905s/100 iters), loss = 0.0628413
I0418 20:41:42.693224 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:41:42.693231 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:41:42.693239 50350 solver.cpp:238]     Train net output #2: loss = 0.0628412 (* 1 = 0.0628412 loss)
I0418 20:41:42.693243 50350 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0418 20:41:53.080420 50350 solver.cpp:219] Iteration 53800 (9.6272 iter/s, 10.3872s/100 iters), loss = 0.0967003
I0418 20:41:53.080464 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:41:53.080469 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:41:53.080476 50350 solver.cpp:238]     Train net output #2: loss = 0.0967002 (* 1 = 0.0967002 loss)
I0418 20:41:53.080480 50350 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0418 20:42:03.465961 50350 solver.cpp:219] Iteration 53900 (9.62878 iter/s, 10.3855s/100 iters), loss = 0.0377134
I0418 20:42:03.466161 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 20:42:03.466168 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:42:03.466176 50350 solver.cpp:238]     Train net output #2: loss = 0.0377133 (* 1 = 0.0377133 loss)
I0418 20:42:03.466181 50350 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0418 20:42:03.675928 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:42:13.754189 50350 solver.cpp:331] Iteration 54000, Testing net (#0)
I0418 20:42:15.734802 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:42:15.815750 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9025
I0418 20:42:15.815775 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9968
I0418 20:42:15.815783 50350 solver.cpp:398]     Test net output #2: loss = 0.336875 (* 1 = 0.336875 loss)
I0418 20:42:15.914400 50350 solver.cpp:219] Iteration 54000 (8.03323 iter/s, 12.4483s/100 iters), loss = 0.0935955
I0418 20:42:15.914419 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:42:15.914424 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:42:15.914429 50350 solver.cpp:238]     Train net output #2: loss = 0.0935954 (* 1 = 0.0935954 loss)
I0418 20:42:15.914434 50350 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0418 20:42:26.303611 50350 solver.cpp:219] Iteration 54100 (9.62535 iter/s, 10.3892s/100 iters), loss = 0.0885943
I0418 20:42:26.303653 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:42:26.303658 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:42:26.303665 50350 solver.cpp:238]     Train net output #2: loss = 0.0885941 (* 1 = 0.0885941 loss)
I0418 20:42:26.303669 50350 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0418 20:42:36.693460 50350 solver.cpp:219] Iteration 54200 (9.62478 iter/s, 10.3898s/100 iters), loss = 0.0737062
I0418 20:42:36.693644 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:42:36.693651 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:42:36.693658 50350 solver.cpp:238]     Train net output #2: loss = 0.073706 (* 1 = 0.073706 loss)
I0418 20:42:36.693665 50350 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0418 20:42:46.257596 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:42:47.083009 50350 solver.cpp:219] Iteration 54300 (9.62519 iter/s, 10.3894s/100 iters), loss = 0.058174
I0418 20:42:47.083047 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:42:47.083052 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:42:47.083060 50350 solver.cpp:238]     Train net output #2: loss = 0.0581739 (* 1 = 0.0581739 loss)
I0418 20:42:47.083063 50350 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0418 20:42:57.470856 50350 solver.cpp:219] Iteration 54400 (9.62663 iter/s, 10.3878s/100 iters), loss = 0.0976309
I0418 20:42:57.470917 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:42:57.470924 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:42:57.470932 50350 solver.cpp:238]     Train net output #2: loss = 0.0976308 (* 1 = 0.0976308 loss)
I0418 20:42:57.470935 50350 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0418 20:43:07.802209 50350 solver.cpp:219] Iteration 54500 (9.6793 iter/s, 10.3313s/100 iters), loss = 0.0694587
I0418 20:43:07.802449 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:43:07.802458 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:43:07.802465 50350 solver.cpp:238]     Train net output #2: loss = 0.0694586 (* 1 = 0.0694586 loss)
I0418 20:43:07.802470 50350 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0418 20:43:18.188387 50350 solver.cpp:219] Iteration 54600 (9.62837 iter/s, 10.386s/100 iters), loss = 0.108389
I0418 20:43:18.188429 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:43:18.188434 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:43:18.188443 50350 solver.cpp:238]     Train net output #2: loss = 0.108389 (* 1 = 0.108389 loss)
I0418 20:43:18.188448 50350 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0418 20:43:26.813417 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:43:28.573810 50350 solver.cpp:219] Iteration 54700 (9.62888 iter/s, 10.3854s/100 iters), loss = 0.0371753
I0418 20:43:28.573853 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 20:43:28.573858 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:43:28.573864 50350 solver.cpp:238]     Train net output #2: loss = 0.0371752 (* 1 = 0.0371752 loss)
I0418 20:43:28.573868 50350 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0418 20:43:38.964318 50350 solver.cpp:219] Iteration 54800 (9.62418 iter/s, 10.3905s/100 iters), loss = 0.0885202
I0418 20:43:38.964845 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:43:38.964869 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:43:38.964876 50350 solver.cpp:238]     Train net output #2: loss = 0.0885201 (* 1 = 0.0885201 loss)
I0418 20:43:38.964881 50350 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0418 20:43:49.359858 50350 solver.cpp:219] Iteration 54900 (9.61996 iter/s, 10.3951s/100 iters), loss = 0.102101
I0418 20:43:49.359901 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:43:49.359906 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:43:49.359913 50350 solver.cpp:238]     Train net output #2: loss = 0.102101 (* 1 = 0.102101 loss)
I0418 20:43:49.359917 50350 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0418 20:43:59.650516 50350 solver.cpp:331] Iteration 55000, Testing net (#0)
I0418 20:44:01.630712 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:44:01.711443 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.8921
I0418 20:44:01.711464 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9972
I0418 20:44:01.711472 50350 solver.cpp:398]     Test net output #2: loss = 0.406719 (* 1 = 0.406719 loss)
I0418 20:44:01.810586 50350 solver.cpp:219] Iteration 55000 (8.03165 iter/s, 12.4507s/100 iters), loss = 0.0555487
I0418 20:44:01.810606 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:44:01.810611 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:44:01.810616 50350 solver.cpp:238]     Train net output #2: loss = 0.0555486 (* 1 = 0.0555486 loss)
I0418 20:44:01.810621 50350 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0418 20:44:09.475641 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:44:12.175312 50350 solver.cpp:219] Iteration 55100 (9.64809 iter/s, 10.3647s/100 iters), loss = 0.0467195
I0418 20:44:12.175374 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:44:12.175379 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:44:12.175386 50350 solver.cpp:238]     Train net output #2: loss = 0.0467194 (* 1 = 0.0467194 loss)
I0418 20:44:12.175391 50350 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0418 20:44:22.529487 50350 solver.cpp:219] Iteration 55200 (9.65796 iter/s, 10.3542s/100 iters), loss = 0.116118
I0418 20:44:22.529531 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:44:22.529536 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:44:22.529542 50350 solver.cpp:238]     Train net output #2: loss = 0.116118 (* 1 = 0.116118 loss)
I0418 20:44:22.529546 50350 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0418 20:44:32.923424 50350 solver.cpp:219] Iteration 55300 (9.621 iter/s, 10.3939s/100 iters), loss = 0.0903476
I0418 20:44:32.923466 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:44:32.923472 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:44:32.923480 50350 solver.cpp:238]     Train net output #2: loss = 0.0903475 (* 1 = 0.0903475 loss)
I0418 20:44:32.923483 50350 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0418 20:44:43.193694 50350 solver.cpp:219] Iteration 55400 (9.73685 iter/s, 10.2703s/100 iters), loss = 0.0667998
I0418 20:44:43.193930 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:44:43.193938 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:44:43.193945 50350 solver.cpp:238]     Train net output #2: loss = 0.0667997 (* 1 = 0.0667997 loss)
I0418 20:44:43.193951 50350 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0418 20:44:49.847121 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:44:53.581826 50350 solver.cpp:219] Iteration 55500 (9.62655 iter/s, 10.3879s/100 iters), loss = 0.0549679
I0418 20:44:53.581884 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:44:53.581892 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:44:53.581898 50350 solver.cpp:238]     Train net output #2: loss = 0.0549678 (* 1 = 0.0549678 loss)
I0418 20:44:53.581903 50350 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0418 20:45:03.973837 50350 solver.cpp:219] Iteration 55600 (9.62279 iter/s, 10.392s/100 iters), loss = 0.183331
I0418 20:45:03.973881 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 20:45:03.973886 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:45:03.973891 50350 solver.cpp:238]     Train net output #2: loss = 0.183331 (* 1 = 0.183331 loss)
I0418 20:45:03.973896 50350 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0418 20:45:14.369431 50350 solver.cpp:219] Iteration 55700 (9.61947 iter/s, 10.3956s/100 iters), loss = 0.0763608
I0418 20:45:14.369634 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:45:14.369642 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:45:14.369649 50350 solver.cpp:238]     Train net output #2: loss = 0.0763607 (* 1 = 0.0763607 loss)
I0418 20:45:14.369654 50350 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0418 20:45:24.764129 50350 solver.cpp:219] Iteration 55800 (9.62044 iter/s, 10.3945s/100 iters), loss = 0.0664283
I0418 20:45:24.764190 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:45:24.764196 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:45:24.764204 50350 solver.cpp:238]     Train net output #2: loss = 0.0664281 (* 1 = 0.0664281 loss)
I0418 20:45:24.764207 50350 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0418 20:45:30.484804 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:45:35.156515 50350 solver.cpp:219] Iteration 55900 (9.62245 iter/s, 10.3924s/100 iters), loss = 0.108328
I0418 20:45:35.156558 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 20:45:35.156563 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:45:35.156569 50350 solver.cpp:238]     Train net output #2: loss = 0.108328 (* 1 = 0.108328 loss)
I0418 20:45:35.156574 50350 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0418 20:45:45.449847 50350 solver.cpp:331] Iteration 56000, Testing net (#0)
I0418 20:45:47.426398 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:45:47.507086 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9066
I0418 20:45:47.507109 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9971
I0418 20:45:47.507133 50350 solver.cpp:398]     Test net output #2: loss = 0.351555 (* 1 = 0.351555 loss)
I0418 20:45:47.605872 50350 solver.cpp:219] Iteration 56000 (8.03253 iter/s, 12.4494s/100 iters), loss = 0.0795763
I0418 20:45:47.605892 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:45:47.605896 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:45:47.605901 50350 solver.cpp:238]     Train net output #2: loss = 0.0795762 (* 1 = 0.0795762 loss)
I0418 20:45:47.605906 50350 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0418 20:45:57.968142 50350 solver.cpp:219] Iteration 56100 (9.65038 iter/s, 10.3623s/100 iters), loss = 0.157662
I0418 20:45:57.968200 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:45:57.968205 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:45:57.968212 50350 solver.cpp:238]     Train net output #2: loss = 0.157662 (* 1 = 0.157662 loss)
I0418 20:45:57.968216 50350 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0418 20:46:08.358876 50350 solver.cpp:219] Iteration 56200 (9.62398 iter/s, 10.3907s/100 iters), loss = 0.0599693
I0418 20:46:08.358938 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:46:08.358944 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:46:08.358952 50350 solver.cpp:238]     Train net output #2: loss = 0.0599691 (* 1 = 0.0599691 loss)
I0418 20:46:08.358956 50350 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0418 20:46:12.998878 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:46:18.710042 50350 solver.cpp:219] Iteration 56300 (9.66076 iter/s, 10.3512s/100 iters), loss = 0.0304229
I0418 20:46:18.710213 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 20:46:18.710220 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:46:18.710228 50350 solver.cpp:238]     Train net output #2: loss = 0.0304228 (* 1 = 0.0304228 loss)
I0418 20:46:18.710234 50350 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0418 20:46:29.102263 50350 solver.cpp:219] Iteration 56400 (9.6227 iter/s, 10.3921s/100 iters), loss = 0.110393
I0418 20:46:29.102322 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:46:29.102329 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:46:29.102335 50350 solver.cpp:238]     Train net output #2: loss = 0.110393 (* 1 = 0.110393 loss)
I0418 20:46:29.102339 50350 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0418 20:46:39.493811 50350 solver.cpp:219] Iteration 56500 (9.62323 iter/s, 10.3915s/100 iters), loss = 0.0638206
I0418 20:46:39.493857 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 20:46:39.493863 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:46:39.493870 50350 solver.cpp:238]     Train net output #2: loss = 0.0638205 (* 1 = 0.0638205 loss)
I0418 20:46:39.493875 50350 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0418 20:46:49.889670 50350 solver.cpp:219] Iteration 56600 (9.61922 iter/s, 10.3959s/100 iters), loss = 0.0993236
I0418 20:46:49.889835 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 20:46:49.889843 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:46:49.889850 50350 solver.cpp:238]     Train net output #2: loss = 0.0993235 (* 1 = 0.0993235 loss)
I0418 20:46:49.889855 50350 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0418 20:46:53.634876 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:47:00.278901 50350 solver.cpp:219] Iteration 56700 (9.62547 iter/s, 10.3891s/100 iters), loss = 0.0806513
I0418 20:47:00.278937 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:47:00.278944 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:47:00.278949 50350 solver.cpp:238]     Train net output #2: loss = 0.0806512 (* 1 = 0.0806512 loss)
I0418 20:47:00.278954 50350 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0418 20:47:10.628962 50350 solver.cpp:219] Iteration 56800 (9.66178 iter/s, 10.3501s/100 iters), loss = 0.0770831
I0418 20:47:10.629004 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:47:10.629009 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:47:10.629015 50350 solver.cpp:238]     Train net output #2: loss = 0.077083 (* 1 = 0.077083 loss)
I0418 20:47:10.629020 50350 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0418 20:47:20.951093 50350 solver.cpp:219] Iteration 56900 (9.68793 iter/s, 10.3221s/100 iters), loss = 0.171508
I0418 20:47:20.951344 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0418 20:47:20.951351 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:47:20.951359 50350 solver.cpp:238]     Train net output #2: loss = 0.171508 (* 1 = 0.171508 loss)
I0418 20:47:20.951364 50350 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0418 20:47:31.240384 50350 solver.cpp:331] Iteration 57000, Testing net (#0)
I0418 20:47:33.216908 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:47:33.297404 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9062
I0418 20:47:33.297423 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9964
I0418 20:47:33.297430 50350 solver.cpp:398]     Test net output #2: loss = 0.36055 (* 1 = 0.36055 loss)
I0418 20:47:33.397004 50350 solver.cpp:219] Iteration 57000 (8.03489 iter/s, 12.4457s/100 iters), loss = 0.0831297
I0418 20:47:33.397024 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:47:33.397029 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:47:33.397034 50350 solver.cpp:238]     Train net output #2: loss = 0.0831296 (* 1 = 0.0831296 loss)
I0418 20:47:33.397038 50350 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0418 20:47:36.203737 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:47:43.792737 50350 solver.cpp:219] Iteration 57100 (9.61932 iter/s, 10.3957s/100 iters), loss = 0.107469
I0418 20:47:43.792803 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:47:43.792809 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:47:43.792815 50350 solver.cpp:238]     Train net output #2: loss = 0.107469 (* 1 = 0.107469 loss)
I0418 20:47:43.792820 50350 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0418 20:47:54.187008 50350 solver.cpp:219] Iteration 57200 (9.62071 iter/s, 10.3942s/100 iters), loss = 0.11753
I0418 20:47:54.187180 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:47:54.187186 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:47:54.187194 50350 solver.cpp:238]     Train net output #2: loss = 0.11753 (* 1 = 0.11753 loss)
I0418 20:47:54.187199 50350 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0418 20:48:04.578289 50350 solver.cpp:219] Iteration 57300 (9.62358 iter/s, 10.3911s/100 iters), loss = 0.0987656
I0418 20:48:04.578349 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:48:04.578356 50350 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 20:48:04.578363 50350 solver.cpp:238]     Train net output #2: loss = 0.0987655 (* 1 = 0.0987655 loss)
I0418 20:48:04.578367 50350 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0418 20:48:14.974054 50350 solver.cpp:219] Iteration 57400 (9.61933 iter/s, 10.3957s/100 iters), loss = 0.0456891
I0418 20:48:14.974118 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:48:14.974124 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:48:14.974131 50350 solver.cpp:238]     Train net output #2: loss = 0.045689 (* 1 = 0.045689 loss)
I0418 20:48:14.974136 50350 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0418 20:48:16.747167 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:48:25.369503 50350 solver.cpp:219] Iteration 57500 (9.6196 iter/s, 10.3954s/100 iters), loss = 0.109881
I0418 20:48:25.369751 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 20:48:25.369760 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:48:25.369766 50350 solver.cpp:238]     Train net output #2: loss = 0.109881 (* 1 = 0.109881 loss)
I0418 20:48:25.369772 50350 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0418 20:48:35.762962 50350 solver.cpp:219] Iteration 57600 (9.62163 iter/s, 10.3933s/100 iters), loss = 0.109486
I0418 20:48:35.763005 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:48:35.763010 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:48:35.763017 50350 solver.cpp:238]     Train net output #2: loss = 0.109486 (* 1 = 0.109486 loss)
I0418 20:48:35.763021 50350 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0418 20:48:46.159008 50350 solver.cpp:219] Iteration 57700 (9.61905 iter/s, 10.396s/100 iters), loss = 0.0712582
I0418 20:48:46.159071 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:48:46.159077 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:48:46.159085 50350 solver.cpp:238]     Train net output #2: loss = 0.0712581 (* 1 = 0.0712581 loss)
I0418 20:48:46.159088 50350 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0418 20:48:56.552459 50350 solver.cpp:219] Iteration 57800 (9.62145 iter/s, 10.3934s/100 iters), loss = 0.102628
I0418 20:48:56.552639 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:48:56.552646 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:48:56.552654 50350 solver.cpp:238]     Train net output #2: loss = 0.102628 (* 1 = 0.102628 loss)
I0418 20:48:56.552659 50350 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0418 20:48:57.388625 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:49:06.946733 50350 solver.cpp:219] Iteration 57900 (9.62079 iter/s, 10.3942s/100 iters), loss = 0.0530124
I0418 20:49:06.946776 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:49:06.946781 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:49:06.946789 50350 solver.cpp:238]     Train net output #2: loss = 0.0530123 (* 1 = 0.0530123 loss)
I0418 20:49:06.946792 50350 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0418 20:49:17.238281 50350 solver.cpp:331] Iteration 58000, Testing net (#0)
I0418 20:49:19.216125 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:49:19.297242 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9036
I0418 20:49:19.297266 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9974
I0418 20:49:19.297274 50350 solver.cpp:398]     Test net output #2: loss = 0.380636 (* 1 = 0.380636 loss)
I0418 20:49:19.395977 50350 solver.cpp:219] Iteration 58000 (8.03261 iter/s, 12.4493s/100 iters), loss = 0.0625332
I0418 20:49:19.395997 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:49:19.396018 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:49:19.396024 50350 solver.cpp:238]     Train net output #2: loss = 0.0625331 (* 1 = 0.0625331 loss)
I0418 20:49:19.396028 50350 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0418 20:49:29.780992 50350 solver.cpp:219] Iteration 58100 (9.62924 iter/s, 10.385s/100 iters), loss = 0.108514
I0418 20:49:29.781170 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:49:29.781177 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:49:29.781185 50350 solver.cpp:238]     Train net output #2: loss = 0.108514 (* 1 = 0.108514 loss)
I0418 20:49:29.781189 50350 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0418 20:49:40.077172 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:49:40.178382 50350 solver.cpp:219] Iteration 58200 (9.61792 iter/s, 10.3973s/100 iters), loss = 0.0937178
I0418 20:49:40.178431 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:49:40.178437 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:49:40.178447 50350 solver.cpp:238]     Train net output #2: loss = 0.0937177 (* 1 = 0.0937177 loss)
I0418 20:49:40.178452 50350 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0418 20:49:50.577221 50350 solver.cpp:219] Iteration 58300 (9.61645 iter/s, 10.3988s/100 iters), loss = 0.051566
I0418 20:49:50.577263 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:49:50.577270 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:49:50.577276 50350 solver.cpp:238]     Train net output #2: loss = 0.0515659 (* 1 = 0.0515659 loss)
I0418 20:49:50.577280 50350 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0418 20:50:00.968464 50350 solver.cpp:219] Iteration 58400 (9.62349 iter/s, 10.3912s/100 iters), loss = 0.0998129
I0418 20:50:00.968670 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:50:00.968678 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:50:00.968686 50350 solver.cpp:238]     Train net output #2: loss = 0.0998128 (* 1 = 0.0998128 loss)
I0418 20:50:00.968691 50350 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0418 20:50:11.361202 50350 solver.cpp:219] Iteration 58500 (9.62226 iter/s, 10.3926s/100 iters), loss = 0.0891949
I0418 20:50:11.361263 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:50:11.361271 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:50:11.361279 50350 solver.cpp:238]     Train net output #2: loss = 0.0891948 (* 1 = 0.0891948 loss)
I0418 20:50:11.361284 50350 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0418 20:50:20.611301 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:50:21.748667 50350 solver.cpp:219] Iteration 58600 (9.62701 iter/s, 10.3874s/100 iters), loss = 0.110405
I0418 20:50:21.748706 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:50:21.748713 50350 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 20:50:21.748719 50350 solver.cpp:238]     Train net output #2: loss = 0.110405 (* 1 = 0.110405 loss)
I0418 20:50:21.748723 50350 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0418 20:50:32.146483 50350 solver.cpp:219] Iteration 58700 (9.6174 iter/s, 10.3978s/100 iters), loss = 0.0620526
I0418 20:50:32.146698 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:50:32.146705 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:50:32.146713 50350 solver.cpp:238]     Train net output #2: loss = 0.0620525 (* 1 = 0.0620525 loss)
I0418 20:50:32.146718 50350 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0418 20:50:42.543313 50350 solver.cpp:219] Iteration 58800 (9.61849 iter/s, 10.3966s/100 iters), loss = 0.123019
I0418 20:50:42.543376 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 20:50:42.543383 50350 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 20:50:42.543391 50350 solver.cpp:238]     Train net output #2: loss = 0.123019 (* 1 = 0.123019 loss)
I0418 20:50:42.543395 50350 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0418 20:50:52.938040 50350 solver.cpp:219] Iteration 58900 (9.62029 iter/s, 10.3947s/100 iters), loss = 0.054738
I0418 20:50:52.938099 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:50:52.938105 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:50:52.938112 50350 solver.cpp:238]     Train net output #2: loss = 0.0547379 (* 1 = 0.0547379 loss)
I0418 20:50:52.938117 50350 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0418 20:51:01.257843 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:51:03.229940 50350 solver.cpp:331] Iteration 59000, Testing net (#0)
I0418 20:51:05.210235 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:51:05.290750 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9075
I0418 20:51:05.290771 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9973
I0418 20:51:05.290777 50350 solver.cpp:398]     Test net output #2: loss = 0.365662 (* 1 = 0.365662 loss)
I0418 20:51:05.389708 50350 solver.cpp:219] Iteration 59000 (8.03104 iter/s, 12.4517s/100 iters), loss = 0.047452
I0418 20:51:05.389727 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 20:51:05.389750 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:51:05.389755 50350 solver.cpp:238]     Train net output #2: loss = 0.0474519 (* 1 = 0.0474519 loss)
I0418 20:51:05.389760 50350 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0418 20:51:15.779222 50350 solver.cpp:219] Iteration 59100 (9.62508 iter/s, 10.3895s/100 iters), loss = 0.0916096
I0418 20:51:15.779285 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:51:15.779291 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:51:15.779299 50350 solver.cpp:238]     Train net output #2: loss = 0.0916094 (* 1 = 0.0916094 loss)
I0418 20:51:15.779304 50350 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0418 20:51:26.171849 50350 solver.cpp:219] Iteration 59200 (9.62222 iter/s, 10.3926s/100 iters), loss = 0.0581674
I0418 20:51:26.171910 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:51:26.171916 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:51:26.171923 50350 solver.cpp:238]     Train net output #2: loss = 0.0581672 (* 1 = 0.0581672 loss)
I0418 20:51:26.171928 50350 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0418 20:51:36.564199 50350 solver.cpp:219] Iteration 59300 (9.62248 iter/s, 10.3923s/100 iters), loss = 0.085972
I0418 20:51:36.564419 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:51:36.564427 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:51:36.564435 50350 solver.cpp:238]     Train net output #2: loss = 0.0859719 (* 1 = 0.0859719 loss)
I0418 20:51:36.564445 50350 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0418 20:51:43.844663 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:51:46.955274 50350 solver.cpp:219] Iteration 59400 (9.62381 iter/s, 10.3909s/100 iters), loss = 0.0443261
I0418 20:51:46.955319 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 20:51:46.955325 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:51:46.955332 50350 solver.cpp:238]     Train net output #2: loss = 0.044326 (* 1 = 0.044326 loss)
I0418 20:51:46.955337 50350 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0418 20:51:57.347491 50350 solver.cpp:219] Iteration 59500 (9.62259 iter/s, 10.3922s/100 iters), loss = 0.136806
I0418 20:51:57.347532 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0418 20:51:57.347554 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:51:57.347563 50350 solver.cpp:238]     Train net output #2: loss = 0.136806 (* 1 = 0.136806 loss)
I0418 20:51:57.347566 50350 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0418 20:52:07.728634 50350 solver.cpp:219] Iteration 59600 (9.63285 iter/s, 10.3811s/100 iters), loss = 0.0181596
I0418 20:52:07.729246 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 20:52:07.729271 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:52:07.729279 50350 solver.cpp:238]     Train net output #2: loss = 0.0181595 (* 1 = 0.0181595 loss)
I0418 20:52:07.729282 50350 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0418 20:52:25.681522 50350 solver.cpp:219] Iteration 59700 (5.5703 iter/s, 17.9524s/100 iters), loss = 0.0850633
I0418 20:52:25.681584 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:52:25.681591 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:52:25.681597 50350 solver.cpp:238]     Train net output #2: loss = 0.0850631 (* 1 = 0.0850631 loss)
I0418 20:52:25.681602 50350 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0418 20:52:39.647691 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:52:48.506821 50350 solver.cpp:219] Iteration 59800 (4.3815 iter/s, 22.8232s/100 iters), loss = 0.0593454
I0418 20:52:48.506882 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:52:48.506887 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:52:48.506894 50350 solver.cpp:238]     Train net output #2: loss = 0.0593452 (* 1 = 0.0593452 loss)
I0418 20:52:48.506899 50350 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0418 20:53:11.237373 50350 solver.cpp:219] Iteration 59900 (4.39977 iter/s, 22.7285s/100 iters), loss = 0.131478
I0418 20:53:11.237594 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 20:53:11.237602 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:53:11.237608 50350 solver.cpp:238]     Train net output #2: loss = 0.131478 (* 1 = 0.131478 loss)
I0418 20:53:11.237613 50350 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0418 20:53:33.875490 50350 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_highway_padded_data_iter_60000.caffemodel
I0418 20:53:33.928630 50350 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_highway_padded_data_iter_60000.solverstate
I0418 20:53:33.943884 50350 solver.cpp:331] Iteration 60000, Testing net (#0)
I0418 20:53:38.474407 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:53:38.658529 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9059
I0418 20:53:38.658555 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9966
I0418 20:53:38.658581 50350 solver.cpp:398]     Test net output #2: loss = 0.376333 (* 1 = 0.376333 loss)
I0418 20:53:38.857884 50350 solver.cpp:219] Iteration 60000 (3.62052 iter/s, 27.6204s/100 iters), loss = 0.083926
I0418 20:53:38.857905 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 20:53:38.857926 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:53:38.857933 50350 solver.cpp:238]     Train net output #2: loss = 0.0839259 (* 1 = 0.0839259 loss)
I0418 20:53:38.857939 50350 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0418 20:54:01.154140 50350 solver.cpp:219] Iteration 60100 (4.48548 iter/s, 22.2942s/100 iters), loss = 0.0341639
I0418 20:54:01.154870 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 20:54:01.154877 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:54:01.154882 50350 solver.cpp:238]     Train net output #2: loss = 0.0341638 (* 1 = 0.0341638 loss)
I0418 20:54:01.154887 50350 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0418 20:54:12.834761 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:54:23.540289 50350 solver.cpp:219] Iteration 60200 (4.46719 iter/s, 22.3854s/100 iters), loss = 0.0674194
I0418 20:54:23.540346 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:54:23.540352 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:54:23.540359 50350 solver.cpp:238]     Train net output #2: loss = 0.0674193 (* 1 = 0.0674193 loss)
I0418 20:54:23.540364 50350 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0418 20:54:45.798099 50350 solver.cpp:219] Iteration 60300 (4.49323 iter/s, 22.2557s/100 iters), loss = 0.111378
I0418 20:54:45.798488 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:54:45.798496 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:54:45.798502 50350 solver.cpp:238]     Train net output #2: loss = 0.111378 (* 1 = 0.111378 loss)
I0418 20:54:45.798506 50350 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0418 20:55:08.110494 50350 solver.cpp:219] Iteration 60400 (4.48227 iter/s, 22.3101s/100 iters), loss = 0.0720892
I0418 20:55:08.110532 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 20:55:08.110538 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:55:08.110543 50350 solver.cpp:238]     Train net output #2: loss = 0.0720891 (* 1 = 0.0720891 loss)
I0418 20:55:08.110548 50350 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0418 20:55:30.398216 50350 solver.cpp:219] Iteration 60500 (4.48678 iter/s, 22.2877s/100 iters), loss = 0.107179
I0418 20:55:30.398362 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0418 20:55:30.398370 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:55:30.398377 50350 solver.cpp:238]     Train net output #2: loss = 0.107179 (* 1 = 0.107179 loss)
I0418 20:55:30.398381 50350 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0418 20:55:39.825402 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:55:52.704689 50350 solver.cpp:219] Iteration 60600 (4.48342 iter/s, 22.3044s/100 iters), loss = 0.136214
I0418 20:55:52.704730 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 20:55:52.704735 50350 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 20:55:52.704742 50350 solver.cpp:238]     Train net output #2: loss = 0.136214 (* 1 = 0.136214 loss)
I0418 20:55:52.704746 50350 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0418 20:56:15.043598 50350 solver.cpp:219] Iteration 60700 (4.4765 iter/s, 22.3389s/100 iters), loss = 0.0503903
I0418 20:56:15.043763 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:56:15.043771 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:56:15.043779 50350 solver.cpp:238]     Train net output #2: loss = 0.0503903 (* 1 = 0.0503903 loss)
I0418 20:56:15.043783 50350 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0418 20:56:37.349869 50350 solver.cpp:219] Iteration 60800 (4.48347 iter/s, 22.3042s/100 iters), loss = 0.0486666
I0418 20:56:37.349907 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:56:37.349912 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:56:37.349920 50350 solver.cpp:238]     Train net output #2: loss = 0.0486666 (* 1 = 0.0486666 loss)
I0418 20:56:37.349923 50350 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0418 20:56:59.680600 50350 solver.cpp:219] Iteration 60900 (4.47855 iter/s, 22.3286s/100 iters), loss = 0.0674252
I0418 20:56:59.681468 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:56:59.681493 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:56:59.681501 50350 solver.cpp:238]     Train net output #2: loss = 0.0674251 (* 1 = 0.0674251 loss)
I0418 20:56:59.681506 50350 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0418 20:57:07.059695 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:57:21.771046 50350 solver.cpp:331] Iteration 61000, Testing net (#0)
I0418 20:57:26.310681 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:57:26.470053 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.8986
I0418 20:57:26.470080 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9968
I0418 20:57:26.470104 50350 solver.cpp:398]     Test net output #2: loss = 0.425451 (* 1 = 0.425451 loss)
I0418 20:57:26.682972 50350 solver.cpp:219] Iteration 61000 (3.70349 iter/s, 27.0016s/100 iters), loss = 0.0395934
I0418 20:57:26.683010 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 20:57:26.683015 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:57:26.683022 50350 solver.cpp:238]     Train net output #2: loss = 0.0395933 (* 1 = 0.0395933 loss)
I0418 20:57:26.683027 50350 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0418 20:57:48.940244 50350 solver.cpp:219] Iteration 61100 (4.49336 iter/s, 22.2551s/100 iters), loss = 0.0292582
I0418 20:57:48.940486 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 20:57:48.940505 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:57:48.940520 50350 solver.cpp:238]     Train net output #2: loss = 0.0292581 (* 1 = 0.0292581 loss)
I0418 20:57:48.940529 50350 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0418 20:58:11.243031 50350 solver.cpp:219] Iteration 61200 (4.48416 iter/s, 22.3007s/100 iters), loss = 0.0783252
I0418 20:58:11.243067 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 20:58:11.243073 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:58:11.243080 50350 solver.cpp:238]     Train net output #2: loss = 0.0783251 (* 1 = 0.0783251 loss)
I0418 20:58:11.243084 50350 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0418 20:58:33.750454 50350 solver.cpp:219] Iteration 61300 (4.44341 iter/s, 22.5053s/100 iters), loss = 0.14199
I0418 20:58:33.750620 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 20:58:33.750645 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:58:33.750653 50350 solver.cpp:238]     Train net output #2: loss = 0.14199 (* 1 = 0.14199 loss)
I0418 20:58:33.750658 50350 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0418 20:58:39.125491 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 20:58:56.074517 50350 solver.cpp:219] Iteration 61400 (4.47989 iter/s, 22.322s/100 iters), loss = 0.045939
I0418 20:58:56.074558 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:58:56.074563 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:58:56.074570 50350 solver.cpp:238]     Train net output #2: loss = 0.0459389 (* 1 = 0.0459389 loss)
I0418 20:58:56.074574 50350 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0418 20:59:18.455179 50350 solver.cpp:219] Iteration 61500 (4.46814 iter/s, 22.3807s/100 iters), loss = 0.0361576
I0418 20:59:18.455339 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 20:59:18.455346 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:59:18.455353 50350 solver.cpp:238]     Train net output #2: loss = 0.0361574 (* 1 = 0.0361574 loss)
I0418 20:59:18.455360 50350 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0418 20:59:40.736755 50350 solver.cpp:219] Iteration 61600 (4.48845 iter/s, 22.2794s/100 iters), loss = 0.0408033
I0418 20:59:40.736790 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 20:59:40.736795 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 20:59:40.736802 50350 solver.cpp:238]     Train net output #2: loss = 0.0408032 (* 1 = 0.0408032 loss)
I0418 20:59:40.736806 50350 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0418 21:00:03.066869 50350 solver.cpp:219] Iteration 61700 (4.47868 iter/s, 22.328s/100 iters), loss = 0.0942677
I0418 21:00:03.067013 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 21:00:03.067020 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:00:03.067028 50350 solver.cpp:238]     Train net output #2: loss = 0.0942676 (* 1 = 0.0942676 loss)
I0418 21:00:03.067032 50350 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0418 21:00:06.252765 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:00:25.374950 50350 solver.cpp:219] Iteration 61800 (4.4827 iter/s, 22.308s/100 iters), loss = 0.116349
I0418 21:00:25.374995 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 21:00:25.375001 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:00:25.375007 50350 solver.cpp:238]     Train net output #2: loss = 0.116349 (* 1 = 0.116349 loss)
I0418 21:00:25.375011 50350 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0418 21:00:47.669389 50350 solver.cpp:219] Iteration 61900 (4.48586 iter/s, 22.2923s/100 iters), loss = 0.0391376
I0418 21:00:47.670490 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:00:47.670497 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:00:47.670505 50350 solver.cpp:238]     Train net output #2: loss = 0.0391375 (* 1 = 0.0391375 loss)
I0418 21:00:47.670508 50350 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0418 21:01:09.769381 50350 solver.cpp:331] Iteration 62000, Testing net (#0)
I0418 21:01:14.333293 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:01:14.518558 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9008
I0418 21:01:14.518586 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9971
I0418 21:01:14.518594 50350 solver.cpp:398]     Test net output #2: loss = 0.40833 (* 1 = 0.40833 loss)
I0418 21:01:14.711696 50350 solver.cpp:219] Iteration 62000 (3.69819 iter/s, 27.0403s/100 iters), loss = 0.069259
I0418 21:01:14.711719 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:01:14.711724 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:01:14.711729 50350 solver.cpp:238]     Train net output #2: loss = 0.0692589 (* 1 = 0.0692589 loss)
I0418 21:01:14.711735 50350 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0418 21:01:37.005198 50350 solver.cpp:219] Iteration 62100 (4.48603 iter/s, 22.2914s/100 iters), loss = 0.046843
I0418 21:01:37.005388 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:01:37.005396 50350 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 21:01:37.005404 50350 solver.cpp:238]     Train net output #2: loss = 0.0468428 (* 1 = 0.0468428 loss)
I0418 21:01:37.005409 50350 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0418 21:01:38.169286 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:01:59.336453 50350 solver.cpp:219] Iteration 62200 (4.47845 iter/s, 22.3292s/100 iters), loss = 0.0865711
I0418 21:01:59.336498 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 21:01:59.336503 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:01:59.336509 50350 solver.cpp:238]     Train net output #2: loss = 0.086571 (* 1 = 0.086571 loss)
I0418 21:01:59.336513 50350 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0418 21:02:21.597424 50350 solver.cpp:219] Iteration 62300 (4.49259 iter/s, 22.2589s/100 iters), loss = 0.118517
I0418 21:02:21.597648 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:02:21.597656 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:02:21.597662 50350 solver.cpp:238]     Train net output #2: loss = 0.118517 (* 1 = 0.118517 loss)
I0418 21:02:21.597668 50350 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0418 21:02:43.931977 50350 solver.cpp:219] Iteration 62400 (4.4778 iter/s, 22.3324s/100 iters), loss = 0.0664499
I0418 21:02:43.932016 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:02:43.932023 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:02:43.932029 50350 solver.cpp:238]     Train net output #2: loss = 0.0664497 (* 1 = 0.0664497 loss)
I0418 21:02:43.932032 50350 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0418 21:03:05.113695 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:03:06.183686 50350 solver.cpp:219] Iteration 62500 (4.49447 iter/s, 22.2495s/100 iters), loss = 0.11753
I0418 21:03:06.183715 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 21:03:06.183722 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:03:06.183727 50350 solver.cpp:238]     Train net output #2: loss = 0.11753 (* 1 = 0.11753 loss)
I0418 21:03:06.183732 50350 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0418 21:03:28.528385 50350 solver.cpp:219] Iteration 62600 (4.47575 iter/s, 22.3426s/100 iters), loss = 0.0270806
I0418 21:03:28.528427 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:03:28.528434 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:03:28.528439 50350 solver.cpp:238]     Train net output #2: loss = 0.0270805 (* 1 = 0.0270805 loss)
I0418 21:03:28.528445 50350 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0418 21:03:50.796986 50350 solver.cpp:219] Iteration 62700 (4.49074 iter/s, 22.2681s/100 iters), loss = 0.0503959
I0418 21:03:50.797178 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:03:50.797185 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:03:50.797193 50350 solver.cpp:238]     Train net output #2: loss = 0.0503957 (* 1 = 0.0503957 loss)
I0418 21:03:50.797196 50350 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0418 21:04:13.124099 50350 solver.cpp:219] Iteration 62800 (4.47928 iter/s, 22.325s/100 iters), loss = 0.0510154
I0418 21:04:13.124137 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:04:13.124142 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:04:13.124150 50350 solver.cpp:238]     Train net output #2: loss = 0.0510152 (* 1 = 0.0510152 loss)
I0418 21:04:13.124153 50350 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0418 21:04:32.373986 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:04:35.565899 50350 solver.cpp:219] Iteration 62900 (4.4564 iter/s, 22.4396s/100 iters), loss = 0.0874346
I0418 21:04:35.565958 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:04:35.565963 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:04:35.565969 50350 solver.cpp:238]     Train net output #2: loss = 0.0874344 (* 1 = 0.0874344 loss)
I0418 21:04:35.565973 50350 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0418 21:04:57.797034 50350 solver.cpp:331] Iteration 63000, Testing net (#0)
I0418 21:05:02.362262 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:05:02.514765 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9064
I0418 21:05:02.514946 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.996
I0418 21:05:02.514957 50350 solver.cpp:398]     Test net output #2: loss = 0.383673 (* 1 = 0.383673 loss)
I0418 21:05:02.740996 50350 solver.cpp:219] Iteration 63000 (3.67984 iter/s, 27.1751s/100 iters), loss = 0.065424
I0418 21:05:02.741016 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:05:02.741039 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:05:02.741044 50350 solver.cpp:238]     Train net output #2: loss = 0.0654238 (* 1 = 0.0654238 loss)
I0418 21:05:02.741051 50350 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0418 21:05:25.044549 50350 solver.cpp:219] Iteration 63100 (4.48401 iter/s, 22.3015s/100 iters), loss = 0.155923
I0418 21:05:25.044592 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0418 21:05:25.044598 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:05:25.044605 50350 solver.cpp:238]     Train net output #2: loss = 0.155923 (* 1 = 0.155923 loss)
I0418 21:05:25.044610 50350 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0418 21:05:47.337955 50350 solver.cpp:219] Iteration 63200 (4.48605 iter/s, 22.2913s/100 iters), loss = 0.0520032
I0418 21:05:47.338141 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:05:47.338150 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:05:47.338156 50350 solver.cpp:238]     Train net output #2: loss = 0.052003 (* 1 = 0.052003 loss)
I0418 21:05:47.338160 50350 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0418 21:06:04.578148 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:06:09.669206 50350 solver.cpp:219] Iteration 63300 (4.47845 iter/s, 22.3292s/100 iters), loss = 0.0529367
I0418 21:06:09.669241 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:06:09.669246 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:06:09.669252 50350 solver.cpp:238]     Train net output #2: loss = 0.0529366 (* 1 = 0.0529366 loss)
I0418 21:06:09.669256 50350 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0418 21:06:31.958184 50350 solver.cpp:219] Iteration 63400 (4.48695 iter/s, 22.2869s/100 iters), loss = 0.0562441
I0418 21:06:31.958254 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:06:31.958261 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:06:31.958266 50350 solver.cpp:238]     Train net output #2: loss = 0.056244 (* 1 = 0.056244 loss)
I0418 21:06:31.958271 50350 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0418 21:06:54.291051 50350 solver.cpp:219] Iteration 63500 (4.47771 iter/s, 22.3328s/100 iters), loss = 0.0700562
I0418 21:06:54.291095 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:06:54.291100 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:06:54.291105 50350 solver.cpp:238]     Train net output #2: loss = 0.070056 (* 1 = 0.070056 loss)
I0418 21:06:54.291110 50350 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0418 21:07:16.599241 50350 solver.cpp:219] Iteration 63600 (4.48266 iter/s, 22.3082s/100 iters), loss = 0.0657534
I0418 21:07:16.599445 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:07:16.599453 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:07:16.599463 50350 solver.cpp:238]     Train net output #2: loss = 0.0657532 (* 1 = 0.0657532 loss)
I0418 21:07:16.599467 50350 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0418 21:07:31.557466 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:07:38.888582 50350 solver.cpp:219] Iteration 63700 (4.48687 iter/s, 22.2873s/100 iters), loss = 0.0731345
I0418 21:07:38.888623 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:07:38.888629 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:07:38.888635 50350 solver.cpp:238]     Train net output #2: loss = 0.0731343 (* 1 = 0.0731343 loss)
I0418 21:07:38.888639 50350 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0418 21:08:01.227768 50350 solver.cpp:219] Iteration 63800 (4.47687 iter/s, 22.337s/100 iters), loss = 0.0625031
I0418 21:08:01.227926 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:08:01.227933 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:08:01.227941 50350 solver.cpp:238]     Train net output #2: loss = 0.0625029 (* 1 = 0.0625029 loss)
I0418 21:08:01.227944 50350 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0418 21:08:23.563954 50350 solver.cpp:219] Iteration 63900 (4.47706 iter/s, 22.3361s/100 iters), loss = 0.0423836
I0418 21:08:23.563992 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:08:23.563998 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:08:23.564004 50350 solver.cpp:238]     Train net output #2: loss = 0.0423834 (* 1 = 0.0423834 loss)
I0418 21:08:23.564008 50350 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0418 21:08:45.685803 50350 solver.cpp:331] Iteration 64000, Testing net (#0)
I0418 21:08:50.252904 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:08:50.424320 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.8981
I0418 21:08:50.424348 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9967
I0418 21:08:50.424356 50350 solver.cpp:398]     Test net output #2: loss = 0.440219 (* 1 = 0.440219 loss)
I0418 21:08:50.631449 50350 solver.cpp:219] Iteration 64000 (3.69476 iter/s, 27.0654s/100 iters), loss = 0.0601965
I0418 21:08:50.631471 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:08:50.631476 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:08:50.631481 50350 solver.cpp:238]     Train net output #2: loss = 0.0601963 (* 1 = 0.0601963 loss)
I0418 21:08:50.631486 50350 sgd_solver.cpp:46] MultiStep Status: Iteration 64000, step = 2
I0418 21:08:50.631490 50350 sgd_solver.cpp:105] Iteration 64000, lr = 0.001
I0418 21:09:03.627285 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:09:12.947252 50350 solver.cpp:219] Iteration 64100 (4.48113 iter/s, 22.3158s/100 iters), loss = 0.0523794
I0418 21:09:12.947293 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:09:12.947298 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:09:12.947304 50350 solver.cpp:238]     Train net output #2: loss = 0.0523792 (* 1 = 0.0523792 loss)
I0418 21:09:12.947309 50350 sgd_solver.cpp:105] Iteration 64100, lr = 0.001
I0418 21:09:35.268602 50350 solver.cpp:219] Iteration 64200 (4.48044 iter/s, 22.3193s/100 iters), loss = 0.0304415
I0418 21:09:35.268674 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:09:35.268681 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:09:35.268687 50350 solver.cpp:238]     Train net output #2: loss = 0.0304414 (* 1 = 0.0304414 loss)
I0418 21:09:35.268692 50350 sgd_solver.cpp:105] Iteration 64200, lr = 0.001
I0418 21:09:57.609505 50350 solver.cpp:219] Iteration 64300 (4.4761 iter/s, 22.3409s/100 iters), loss = 0.0383793
I0418 21:09:57.609546 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:09:57.609552 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:09:57.609558 50350 solver.cpp:238]     Train net output #2: loss = 0.0383791 (* 1 = 0.0383791 loss)
I0418 21:09:57.609562 50350 sgd_solver.cpp:105] Iteration 64300, lr = 0.001
I0418 21:10:19.934669 50350 solver.cpp:219] Iteration 64400 (4.47925 iter/s, 22.3252s/100 iters), loss = 0.10067
I0418 21:10:19.934891 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 21:10:19.934900 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:10:19.934907 50350 solver.cpp:238]     Train net output #2: loss = 0.10067 (* 1 = 0.10067 loss)
I0418 21:10:19.934912 50350 sgd_solver.cpp:105] Iteration 64400, lr = 0.001
I0418 21:10:30.888911 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:10:42.282999 50350 solver.cpp:219] Iteration 64500 (4.47503 iter/s, 22.3462s/100 iters), loss = 0.0479442
I0418 21:10:42.283059 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:10:42.283066 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:10:42.283072 50350 solver.cpp:238]     Train net output #2: loss = 0.047944 (* 1 = 0.047944 loss)
I0418 21:10:42.283077 50350 sgd_solver.cpp:105] Iteration 64500, lr = 0.001
I0418 21:11:04.832087 50350 solver.cpp:219] Iteration 64600 (4.43477 iter/s, 22.5491s/100 iters), loss = 0.0715155
I0418 21:11:04.832258 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:11:04.832265 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:11:04.832273 50350 solver.cpp:238]     Train net output #2: loss = 0.0715153 (* 1 = 0.0715153 loss)
I0418 21:11:04.832278 50350 sgd_solver.cpp:105] Iteration 64600, lr = 0.001
I0418 21:11:27.103605 50350 solver.cpp:219] Iteration 64700 (4.49016 iter/s, 22.2709s/100 iters), loss = 0.0907502
I0418 21:11:27.103647 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:11:27.103653 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:11:27.103659 50350 solver.cpp:238]     Train net output #2: loss = 0.0907501 (* 1 = 0.0907501 loss)
I0418 21:11:27.103663 50350 sgd_solver.cpp:105] Iteration 64700, lr = 0.001
I0418 21:11:49.436378 50350 solver.cpp:219] Iteration 64800 (4.47814 iter/s, 22.3307s/100 iters), loss = 0.042646
I0418 21:11:49.436555 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:11:49.436564 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:11:49.436571 50350 solver.cpp:238]     Train net output #2: loss = 0.0426458 (* 1 = 0.0426458 loss)
I0418 21:11:49.436575 50350 sgd_solver.cpp:105] Iteration 64800, lr = 0.001
I0418 21:11:58.189822 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:12:11.796213 50350 solver.cpp:219] Iteration 64900 (4.47272 iter/s, 22.3577s/100 iters), loss = 0.0728958
I0418 21:12:11.796253 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:12:11.796259 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:12:11.796265 50350 solver.cpp:238]     Train net output #2: loss = 0.0728956 (* 1 = 0.0728956 loss)
I0418 21:12:11.796269 50350 sgd_solver.cpp:105] Iteration 64900, lr = 0.001
I0418 21:12:33.923113 50350 solver.cpp:331] Iteration 65000, Testing net (#0)
I0418 21:12:38.464380 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:12:38.677546 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9101
I0418 21:12:38.677574 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.997
I0418 21:12:38.677599 50350 solver.cpp:398]     Test net output #2: loss = 0.365207 (* 1 = 0.365207 loss)
I0418 21:12:38.840740 50350 solver.cpp:219] Iteration 65000 (3.69789 iter/s, 27.0425s/100 iters), loss = 0.102092
I0418 21:12:38.840762 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:12:38.840785 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:12:38.840790 50350 solver.cpp:238]     Train net output #2: loss = 0.102092 (* 1 = 0.102092 loss)
I0418 21:12:38.840796 50350 sgd_solver.cpp:105] Iteration 65000, lr = 0.001
I0418 21:13:01.209844 50350 solver.cpp:219] Iteration 65100 (4.47046 iter/s, 22.3691s/100 iters), loss = 0.085977
I0418 21:13:01.209903 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 21:13:01.209908 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:13:01.209915 50350 solver.cpp:238]     Train net output #2: loss = 0.0859768 (* 1 = 0.0859768 loss)
I0418 21:13:01.209919 50350 sgd_solver.cpp:105] Iteration 65100, lr = 0.001
I0418 21:13:23.448468 50350 solver.cpp:219] Iteration 65200 (4.4971 iter/s, 22.2365s/100 iters), loss = 0.0538482
I0418 21:13:23.448664 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:13:23.448673 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:13:23.448681 50350 solver.cpp:238]     Train net output #2: loss = 0.0538481 (* 1 = 0.0538481 loss)
I0418 21:13:23.448686 50350 sgd_solver.cpp:105] Iteration 65200, lr = 0.001
I0418 21:13:30.201022 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:13:45.777925 50350 solver.cpp:219] Iteration 65300 (4.47883 iter/s, 22.3273s/100 iters), loss = 0.0435814
I0418 21:13:45.777968 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:13:45.777973 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:13:45.777981 50350 solver.cpp:238]     Train net output #2: loss = 0.0435812 (* 1 = 0.0435812 loss)
I0418 21:13:45.777984 50350 sgd_solver.cpp:105] Iteration 65300, lr = 0.001
I0418 21:14:08.076813 50350 solver.cpp:219] Iteration 65400 (4.48495 iter/s, 22.2968s/100 iters), loss = 0.0862245
I0418 21:14:08.076968 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 21:14:08.076977 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:14:08.076983 50350 solver.cpp:238]     Train net output #2: loss = 0.0862243 (* 1 = 0.0862243 loss)
I0418 21:14:08.076987 50350 sgd_solver.cpp:105] Iteration 65400, lr = 0.001
I0418 21:14:30.385864 50350 solver.cpp:219] Iteration 65500 (4.48291 iter/s, 22.307s/100 iters), loss = 0.0496136
I0418 21:14:30.385907 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:14:30.385912 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:14:30.385920 50350 solver.cpp:238]     Train net output #2: loss = 0.0496134 (* 1 = 0.0496134 loss)
I0418 21:14:30.385923 50350 sgd_solver.cpp:105] Iteration 65500, lr = 0.001
I0418 21:14:52.747920 50350 solver.cpp:219] Iteration 65600 (4.47228 iter/s, 22.36s/100 iters), loss = 0.0271554
I0418 21:14:52.748041 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:14:52.748047 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:14:52.748054 50350 solver.cpp:238]     Train net output #2: loss = 0.0271552 (* 1 = 0.0271552 loss)
I0418 21:14:52.748059 50350 sgd_solver.cpp:105] Iteration 65600, lr = 0.001
I0418 21:14:57.215886 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:15:15.002497 50350 solver.cpp:219] Iteration 65700 (4.4939 iter/s, 22.2524s/100 iters), loss = 0.0536569
I0418 21:15:15.002538 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:15:15.002543 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:15:15.002550 50350 solver.cpp:238]     Train net output #2: loss = 0.0536567 (* 1 = 0.0536567 loss)
I0418 21:15:15.002554 50350 sgd_solver.cpp:105] Iteration 65700, lr = 0.001
I0418 21:15:37.330875 50350 solver.cpp:219] Iteration 65800 (4.47861 iter/s, 22.3284s/100 iters), loss = 0.0732805
I0418 21:15:37.331043 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:15:37.331049 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:15:37.331056 50350 solver.cpp:238]     Train net output #2: loss = 0.0732803 (* 1 = 0.0732803 loss)
I0418 21:15:37.331061 50350 sgd_solver.cpp:105] Iteration 65800, lr = 0.001
I0418 21:15:59.681893 50350 solver.cpp:219] Iteration 65900 (4.47409 iter/s, 22.3509s/100 iters), loss = 0.0190283
I0418 21:15:59.681931 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:15:59.681936 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:15:59.681942 50350 solver.cpp:238]     Train net output #2: loss = 0.0190281 (* 1 = 0.0190281 loss)
I0418 21:15:59.681946 50350 sgd_solver.cpp:105] Iteration 65900, lr = 0.001
I0418 21:16:21.790532 50350 solver.cpp:331] Iteration 66000, Testing net (#0)
I0418 21:16:26.357640 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:16:26.515584 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9135
I0418 21:16:26.515612 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9975
I0418 21:16:26.515620 50350 solver.cpp:398]     Test net output #2: loss = 0.355937 (* 1 = 0.355937 loss)
I0418 21:16:26.739486 50350 solver.cpp:219] Iteration 66000 (3.6961 iter/s, 27.0555s/100 iters), loss = 0.025004
I0418 21:16:26.739507 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:16:26.739511 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:16:26.739517 50350 solver.cpp:238]     Train net output #2: loss = 0.0250039 (* 1 = 0.0250039 loss)
I0418 21:16:26.739523 50350 sgd_solver.cpp:105] Iteration 66000, lr = 0.001
I0418 21:16:29.226943 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:16:49.000166 50350 solver.cpp:219] Iteration 66100 (4.49267 iter/s, 22.2585s/100 iters), loss = 0.0392765
I0418 21:16:49.000210 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:16:49.000216 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:16:49.000221 50350 solver.cpp:238]     Train net output #2: loss = 0.0392764 (* 1 = 0.0392764 loss)
I0418 21:16:49.000226 50350 sgd_solver.cpp:105] Iteration 66100, lr = 0.001
I0418 21:17:11.559170 50350 solver.cpp:219] Iteration 66200 (4.43323 iter/s, 22.5569s/100 iters), loss = 0.0924658
I0418 21:17:11.559391 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:17:11.559398 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:17:11.559406 50350 solver.cpp:238]     Train net output #2: loss = 0.0924657 (* 1 = 0.0924657 loss)
I0418 21:17:11.559411 50350 sgd_solver.cpp:105] Iteration 66200, lr = 0.001
I0418 21:17:33.856797 50350 solver.cpp:219] Iteration 66300 (4.4852 iter/s, 22.2955s/100 iters), loss = 0.0392099
I0418 21:17:33.856839 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:17:33.856844 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:17:33.856851 50350 solver.cpp:238]     Train net output #2: loss = 0.0392097 (* 1 = 0.0392097 loss)
I0418 21:17:33.856855 50350 sgd_solver.cpp:105] Iteration 66300, lr = 0.001
I0418 21:17:56.156945 50350 solver.cpp:219] Iteration 66400 (4.48469 iter/s, 22.2981s/100 iters), loss = 0.0395514
I0418 21:17:56.157095 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:17:56.157104 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:17:56.157110 50350 solver.cpp:238]     Train net output #2: loss = 0.0395512 (* 1 = 0.0395512 loss)
I0418 21:17:56.157115 50350 sgd_solver.cpp:105] Iteration 66400, lr = 0.001
I0418 21:17:56.635495 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:18:18.451105 50350 solver.cpp:219] Iteration 66500 (4.4855 iter/s, 22.2941s/100 iters), loss = 0.0699703
I0418 21:18:18.451148 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:18:18.451153 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:18:18.451159 50350 solver.cpp:238]     Train net output #2: loss = 0.0699701 (* 1 = 0.0699701 loss)
I0418 21:18:18.451164 50350 sgd_solver.cpp:105] Iteration 66500, lr = 0.001
I0418 21:18:40.793138 50350 solver.cpp:219] Iteration 66600 (4.47629 iter/s, 22.3399s/100 iters), loss = 0.0468736
I0418 21:18:40.793344 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:18:40.793351 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:18:40.793359 50350 solver.cpp:238]     Train net output #2: loss = 0.0468735 (* 1 = 0.0468735 loss)
I0418 21:18:40.793364 50350 sgd_solver.cpp:105] Iteration 66600, lr = 0.001
I0418 21:19:03.130530 50350 solver.cpp:219] Iteration 66700 (4.47722 iter/s, 22.3353s/100 iters), loss = 0.0286442
I0418 21:19:03.130570 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:19:03.130575 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:19:03.130581 50350 solver.cpp:238]     Train net output #2: loss = 0.0286441 (* 1 = 0.0286441 loss)
I0418 21:19:03.130585 50350 sgd_solver.cpp:105] Iteration 66700, lr = 0.001
I0418 21:19:23.692272 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:19:25.421622 50350 solver.cpp:219] Iteration 66800 (4.48652 iter/s, 22.289s/100 iters), loss = 0.0774677
I0418 21:19:25.421656 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:19:25.421663 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:19:25.421669 50350 solver.cpp:238]     Train net output #2: loss = 0.0774676 (* 1 = 0.0774676 loss)
I0418 21:19:25.421672 50350 sgd_solver.cpp:105] Iteration 66800, lr = 0.001
I0418 21:19:47.719367 50350 solver.cpp:219] Iteration 66900 (4.48518 iter/s, 22.2957s/100 iters), loss = 0.0468141
I0418 21:19:47.719410 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:19:47.719416 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:19:47.719422 50350 solver.cpp:238]     Train net output #2: loss = 0.046814 (* 1 = 0.046814 loss)
I0418 21:19:47.719427 50350 sgd_solver.cpp:105] Iteration 66900, lr = 0.001
I0418 21:20:09.902006 50350 solver.cpp:331] Iteration 67000, Testing net (#0)
I0418 21:20:14.453843 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:20:14.625347 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9124
I0418 21:20:14.625376 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9973
I0418 21:20:14.625401 50350 solver.cpp:398]     Test net output #2: loss = 0.361 (* 1 = 0.361 loss)
I0418 21:20:14.841218 50350 solver.cpp:219] Iteration 67000 (3.68735 iter/s, 27.1197s/100 iters), loss = 0.0359234
I0418 21:20:14.841239 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:20:14.841261 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:20:14.841267 50350 solver.cpp:238]     Train net output #2: loss = 0.0359233 (* 1 = 0.0359233 loss)
I0418 21:20:14.841274 50350 sgd_solver.cpp:105] Iteration 67000, lr = 0.001
I0418 21:20:37.144496 50350 solver.cpp:219] Iteration 67100 (4.48407 iter/s, 22.3012s/100 iters), loss = 0.0247313
I0418 21:20:37.144538 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:20:37.144543 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:20:37.144549 50350 solver.cpp:238]     Train net output #2: loss = 0.0247312 (* 1 = 0.0247312 loss)
I0418 21:20:37.144553 50350 sgd_solver.cpp:105] Iteration 67100, lr = 0.001
I0418 21:20:55.750416 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:20:59.518223 50350 solver.cpp:219] Iteration 67200 (4.46996 iter/s, 22.3716s/100 iters), loss = 0.0364502
I0418 21:20:59.518278 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:20:59.518283 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:20:59.518290 50350 solver.cpp:238]     Train net output #2: loss = 0.0364501 (* 1 = 0.0364501 loss)
I0418 21:20:59.518295 50350 sgd_solver.cpp:105] Iteration 67200, lr = 0.001
I0418 21:21:21.827488 50350 solver.cpp:219] Iteration 67300 (4.48244 iter/s, 22.3093s/100 iters), loss = 0.0208863
I0418 21:21:21.827533 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:21:21.827539 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:21:21.827545 50350 solver.cpp:238]     Train net output #2: loss = 0.0208862 (* 1 = 0.0208862 loss)
I0418 21:21:21.827549 50350 sgd_solver.cpp:105] Iteration 67300, lr = 0.001
I0418 21:21:44.127993 50350 solver.cpp:219] Iteration 67400 (4.48462 iter/s, 22.2984s/100 iters), loss = 0.0356456
I0418 21:21:44.128244 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:21:44.128253 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:21:44.128260 50350 solver.cpp:238]     Train net output #2: loss = 0.0356455 (* 1 = 0.0356455 loss)
I0418 21:21:44.128265 50350 sgd_solver.cpp:105] Iteration 67400, lr = 0.001
I0418 21:22:06.499395 50350 solver.cpp:219] Iteration 67500 (4.47043 iter/s, 22.3692s/100 iters), loss = 0.0341722
I0418 21:22:06.499434 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:22:06.499444 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:22:06.499450 50350 solver.cpp:238]     Train net output #2: loss = 0.0341721 (* 1 = 0.0341721 loss)
I0418 21:22:06.499454 50350 sgd_solver.cpp:105] Iteration 67500, lr = 0.001
I0418 21:22:23.076014 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:22:28.828794 50350 solver.cpp:219] Iteration 67600 (4.47882 iter/s, 22.3273s/100 iters), loss = 0.0512487
I0418 21:22:28.828833 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:22:28.828838 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:22:28.828845 50350 solver.cpp:238]     Train net output #2: loss = 0.0512486 (* 1 = 0.0512486 loss)
I0418 21:22:28.828848 50350 sgd_solver.cpp:105] Iteration 67600, lr = 0.001
I0418 21:22:51.134477 50350 solver.cpp:219] Iteration 67700 (4.4836 iter/s, 22.3035s/100 iters), loss = 0.10521
I0418 21:22:51.134521 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 21:22:51.134526 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:22:51.134532 50350 solver.cpp:238]     Train net output #2: loss = 0.10521 (* 1 = 0.10521 loss)
I0418 21:22:51.134537 50350 sgd_solver.cpp:105] Iteration 67700, lr = 0.001
I0418 21:23:13.668997 50350 solver.cpp:219] Iteration 67800 (4.43806 iter/s, 22.5324s/100 iters), loss = 0.0555009
I0418 21:23:13.669214 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:23:13.669220 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:23:13.669227 50350 solver.cpp:238]     Train net output #2: loss = 0.0555008 (* 1 = 0.0555008 loss)
I0418 21:23:13.669232 50350 sgd_solver.cpp:105] Iteration 67800, lr = 0.001
I0418 21:23:35.951928 50350 solver.cpp:219] Iteration 67900 (4.48816 iter/s, 22.2809s/100 iters), loss = 0.0421594
I0418 21:23:35.951967 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:23:35.951972 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:23:35.951978 50350 solver.cpp:238]     Train net output #2: loss = 0.0421593 (* 1 = 0.0421593 loss)
I0418 21:23:35.951982 50350 sgd_solver.cpp:105] Iteration 67900, lr = 0.001
I0418 21:23:50.301764 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:23:58.077808 50350 solver.cpp:331] Iteration 68000, Testing net (#0)
I0418 21:24:02.625742 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:24:02.833263 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9124
I0418 21:24:02.833292 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9973
I0418 21:24:02.833315 50350 solver.cpp:398]     Test net output #2: loss = 0.360243 (* 1 = 0.360243 loss)
I0418 21:24:02.989801 50350 solver.cpp:219] Iteration 68000 (3.69881 iter/s, 27.0357s/100 iters), loss = 0.0688537
I0418 21:24:02.989837 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 21:24:02.989859 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:24:02.989866 50350 solver.cpp:238]     Train net output #2: loss = 0.0688536 (* 1 = 0.0688536 loss)
I0418 21:24:02.989871 50350 sgd_solver.cpp:105] Iteration 68000, lr = 0.001
I0418 21:24:25.331020 50350 solver.cpp:219] Iteration 68100 (4.47645 iter/s, 22.3391s/100 iters), loss = 0.111753
I0418 21:24:25.331226 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:24:25.331234 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:24:25.331243 50350 solver.cpp:238]     Train net output #2: loss = 0.111753 (* 1 = 0.111753 loss)
I0418 21:24:25.331248 50350 sgd_solver.cpp:105] Iteration 68100, lr = 0.001
I0418 21:24:47.627959 50350 solver.cpp:219] Iteration 68200 (4.48535 iter/s, 22.2948s/100 iters), loss = 0.0639604
I0418 21:24:47.628001 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:24:47.628007 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:24:47.628013 50350 solver.cpp:238]     Train net output #2: loss = 0.0639604 (* 1 = 0.0639604 loss)
I0418 21:24:47.628017 50350 sgd_solver.cpp:105] Iteration 68200, lr = 0.001
I0418 21:25:09.920372 50350 solver.cpp:219] Iteration 68300 (4.48626 iter/s, 22.2903s/100 iters), loss = 0.038278
I0418 21:25:09.920557 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:25:09.920563 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:25:09.920570 50350 solver.cpp:238]     Train net output #2: loss = 0.038278 (* 1 = 0.038278 loss)
I0418 21:25:09.920575 50350 sgd_solver.cpp:105] Iteration 68300, lr = 0.001
I0418 21:25:22.224635 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:25:32.231196 50350 solver.cpp:219] Iteration 68400 (4.48216 iter/s, 22.3107s/100 iters), loss = 0.0294176
I0418 21:25:32.231237 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:25:32.231242 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:25:32.231250 50350 solver.cpp:238]     Train net output #2: loss = 0.0294176 (* 1 = 0.0294176 loss)
I0418 21:25:32.231253 50350 sgd_solver.cpp:105] Iteration 68400, lr = 0.001
I0418 21:25:54.566577 50350 solver.cpp:219] Iteration 68500 (4.47762 iter/s, 22.3333s/100 iters), loss = 0.052892
I0418 21:25:54.566769 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:25:54.566777 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:25:54.566784 50350 solver.cpp:238]     Train net output #2: loss = 0.0528919 (* 1 = 0.0528919 loss)
I0418 21:25:54.566788 50350 sgd_solver.cpp:105] Iteration 68500, lr = 0.001
I0418 21:26:16.882890 50350 solver.cpp:219] Iteration 68600 (4.48145 iter/s, 22.3142s/100 iters), loss = 0.050286
I0418 21:26:16.882936 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:26:16.882941 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:26:16.882946 50350 solver.cpp:238]     Train net output #2: loss = 0.0502859 (* 1 = 0.0502859 loss)
I0418 21:26:16.882951 50350 sgd_solver.cpp:105] Iteration 68600, lr = 0.001
I0418 21:26:39.257089 50350 solver.cpp:219] Iteration 68700 (4.46985 iter/s, 22.3721s/100 iters), loss = 0.0143085
I0418 21:26:39.257251 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:26:39.257258 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:26:39.257266 50350 solver.cpp:238]     Train net output #2: loss = 0.0143084 (* 1 = 0.0143084 loss)
I0418 21:26:39.257271 50350 sgd_solver.cpp:105] Iteration 68700, lr = 0.001
I0418 21:26:49.351613 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:27:01.581014 50350 solver.cpp:219] Iteration 68800 (4.47952 iter/s, 22.3238s/100 iters), loss = 0.0549764
I0418 21:27:01.581050 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:27:01.581056 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:27:01.581063 50350 solver.cpp:238]     Train net output #2: loss = 0.0549763 (* 1 = 0.0549763 loss)
I0418 21:27:01.581068 50350 sgd_solver.cpp:105] Iteration 68800, lr = 0.001
I0418 21:27:23.861585 50350 solver.cpp:219] Iteration 68900 (4.48866 iter/s, 22.2784s/100 iters), loss = 0.0554107
I0418 21:27:23.861690 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:27:23.861696 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:27:23.861702 50350 solver.cpp:238]     Train net output #2: loss = 0.0554106 (* 1 = 0.0554106 loss)
I0418 21:27:23.861708 50350 sgd_solver.cpp:105] Iteration 68900, lr = 0.001
I0418 21:27:45.962713 50350 solver.cpp:331] Iteration 69000, Testing net (#0)
I0418 21:27:50.525732 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:27:50.739421 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9118
I0418 21:27:50.739454 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9974
I0418 21:27:50.739461 50350 solver.cpp:398]     Test net output #2: loss = 0.365381 (* 1 = 0.365381 loss)
I0418 21:27:50.897255 50350 solver.cpp:219] Iteration 69000 (3.6991 iter/s, 27.0336s/100 iters), loss = 0.0649201
I0418 21:27:50.897275 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:27:50.897280 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:27:50.897285 50350 solver.cpp:238]     Train net output #2: loss = 0.06492 (* 1 = 0.06492 loss)
I0418 21:27:50.897292 50350 sgd_solver.cpp:105] Iteration 69000, lr = 0.001
I0418 21:28:13.235227 50350 solver.cpp:219] Iteration 69100 (4.4771 iter/s, 22.3359s/100 iters), loss = 0.0758086
I0418 21:28:13.235424 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:28:13.235431 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:28:13.235438 50350 solver.cpp:238]     Train net output #2: loss = 0.0758086 (* 1 = 0.0758086 loss)
I0418 21:28:13.235452 50350 sgd_solver.cpp:105] Iteration 69100, lr = 0.001
I0418 21:28:21.330312 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:28:35.599017 50350 solver.cpp:219] Iteration 69200 (4.47154 iter/s, 22.3636s/100 iters), loss = 0.0329308
I0418 21:28:35.599069 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:28:35.599076 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:28:35.599082 50350 solver.cpp:238]     Train net output #2: loss = 0.0329308 (* 1 = 0.0329308 loss)
I0418 21:28:35.599086 50350 sgd_solver.cpp:105] Iteration 69200, lr = 0.001
I0418 21:28:57.884971 50350 solver.cpp:219] Iteration 69300 (4.48757 iter/s, 22.2838s/100 iters), loss = 0.105767
I0418 21:28:57.885123 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:28:57.885129 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:28:57.885136 50350 solver.cpp:238]     Train net output #2: loss = 0.105767 (* 1 = 0.105767 loss)
I0418 21:28:57.885140 50350 sgd_solver.cpp:105] Iteration 69300, lr = 0.001
I0418 21:29:20.448777 50350 solver.cpp:219] Iteration 69400 (4.43229 iter/s, 22.5617s/100 iters), loss = 0.0682392
I0418 21:29:20.448822 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:29:20.448827 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:29:20.448833 50350 solver.cpp:238]     Train net output #2: loss = 0.0682391 (* 1 = 0.0682391 loss)
I0418 21:29:20.448837 50350 sgd_solver.cpp:105] Iteration 69400, lr = 0.001
I0418 21:29:42.730810 50350 solver.cpp:219] Iteration 69500 (4.48792 iter/s, 22.282s/100 iters), loss = 0.0209369
I0418 21:29:42.730967 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:29:42.730973 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:29:42.730980 50350 solver.cpp:238]     Train net output #2: loss = 0.0209368 (* 1 = 0.0209368 loss)
I0418 21:29:42.730985 50350 sgd_solver.cpp:105] Iteration 69500, lr = 0.001
I0418 21:29:48.793346 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:30:05.068034 50350 solver.cpp:219] Iteration 69600 (4.47725 iter/s, 22.3351s/100 iters), loss = 0.0228042
I0418 21:30:05.068073 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:30:05.068078 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:30:05.068084 50350 solver.cpp:238]     Train net output #2: loss = 0.0228042 (* 1 = 0.0228042 loss)
I0418 21:30:05.068087 50350 sgd_solver.cpp:105] Iteration 69600, lr = 0.001
I0418 21:30:27.412216 50350 solver.cpp:219] Iteration 69700 (4.47588 iter/s, 22.342s/100 iters), loss = 0.0513557
I0418 21:30:27.412322 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:30:27.412329 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:30:27.412336 50350 solver.cpp:238]     Train net output #2: loss = 0.0513556 (* 1 = 0.0513556 loss)
I0418 21:30:27.412340 50350 sgd_solver.cpp:105] Iteration 69700, lr = 0.001
I0418 21:30:49.727365 50350 solver.cpp:219] Iteration 69800 (4.48127 iter/s, 22.3151s/100 iters), loss = 0.114177
I0418 21:30:49.727409 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:30:49.727414 50350 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0418 21:30:49.727421 50350 solver.cpp:238]     Train net output #2: loss = 0.114177 (* 1 = 0.114177 loss)
I0418 21:30:49.727424 50350 sgd_solver.cpp:105] Iteration 69800, lr = 0.001
I0418 21:31:12.044598 50350 solver.cpp:219] Iteration 69900 (4.48126 iter/s, 22.3151s/100 iters), loss = 0.0164172
I0418 21:31:12.044775 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:31:12.044783 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:31:12.044790 50350 solver.cpp:238]     Train net output #2: loss = 0.0164171 (* 1 = 0.0164171 loss)
I0418 21:31:12.044795 50350 sgd_solver.cpp:105] Iteration 69900, lr = 0.001
I0418 21:31:15.901185 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:31:34.157238 50350 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_highway_padded_data_iter_70000.caffemodel
I0418 21:31:34.189481 50350 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_highway_padded_data_iter_70000.solverstate
I0418 21:31:34.207029 50350 solver.cpp:331] Iteration 70000, Testing net (#0)
I0418 21:31:38.755642 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:31:38.919591 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9141
I0418 21:31:38.919620 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9973
I0418 21:31:38.919644 50350 solver.cpp:398]     Test net output #2: loss = 0.363109 (* 1 = 0.363109 loss)
I0418 21:31:39.140539 50350 solver.cpp:219] Iteration 70000 (3.69087 iter/s, 27.0939s/100 iters), loss = 0.0277634
I0418 21:31:39.140560 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:31:39.140583 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:31:39.140588 50350 solver.cpp:238]     Train net output #2: loss = 0.0277634 (* 1 = 0.0277634 loss)
I0418 21:31:39.140594 50350 sgd_solver.cpp:105] Iteration 70000, lr = 0.001
I0418 21:32:01.437636 50350 solver.cpp:219] Iteration 70100 (4.48531 iter/s, 22.295s/100 iters), loss = 0.0559115
I0418 21:32:01.437799 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:32:01.437808 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:32:01.437814 50350 solver.cpp:238]     Train net output #2: loss = 0.0559114 (* 1 = 0.0559114 loss)
I0418 21:32:01.437819 50350 sgd_solver.cpp:105] Iteration 70100, lr = 0.001
I0418 21:32:23.788971 50350 solver.cpp:219] Iteration 70200 (4.47444 iter/s, 22.3492s/100 iters), loss = 0.03431
I0418 21:32:23.789012 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:32:23.789018 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:32:23.789024 50350 solver.cpp:238]     Train net output #2: loss = 0.03431 (* 1 = 0.03431 loss)
I0418 21:32:23.789029 50350 sgd_solver.cpp:105] Iteration 70200, lr = 0.001
I0418 21:32:46.086673 50350 solver.cpp:219] Iteration 70300 (4.48477 iter/s, 22.2977s/100 iters), loss = 0.0203532
I0418 21:32:46.086838 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:32:46.086845 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:32:46.086853 50350 solver.cpp:238]     Train net output #2: loss = 0.0203532 (* 1 = 0.0203532 loss)
I0418 21:32:46.086858 50350 sgd_solver.cpp:105] Iteration 70300, lr = 0.001
I0418 21:32:47.920359 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:33:08.370863 50350 solver.cpp:219] Iteration 70400 (4.48791 iter/s, 22.2821s/100 iters), loss = 0.0460347
I0418 21:33:08.370903 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:33:08.370908 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:33:08.370915 50350 solver.cpp:238]     Train net output #2: loss = 0.0460347 (* 1 = 0.0460347 loss)
I0418 21:33:08.370919 50350 sgd_solver.cpp:105] Iteration 70400, lr = 0.001
I0418 21:33:30.726667 50350 solver.cpp:219] Iteration 70500 (4.47321 iter/s, 22.3553s/100 iters), loss = 0.0204763
I0418 21:33:30.726779 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:33:30.726786 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:33:30.726793 50350 solver.cpp:238]     Train net output #2: loss = 0.0204763 (* 1 = 0.0204763 loss)
I0418 21:33:30.726797 50350 sgd_solver.cpp:105] Iteration 70500, lr = 0.001
I0418 21:33:53.017192 50350 solver.cpp:219] Iteration 70600 (4.48663 iter/s, 22.2884s/100 iters), loss = 0.0200313
I0418 21:33:53.017236 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:33:53.017241 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:33:53.017247 50350 solver.cpp:238]     Train net output #2: loss = 0.0200313 (* 1 = 0.0200313 loss)
I0418 21:33:53.017252 50350 sgd_solver.cpp:105] Iteration 70600, lr = 0.001
I0418 21:34:15.187649 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:34:15.343291 50350 solver.cpp:219] Iteration 70700 (4.47948 iter/s, 22.324s/100 iters), loss = 0.0491854
I0418 21:34:15.343322 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:34:15.343327 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:34:15.343333 50350 solver.cpp:238]     Train net output #2: loss = 0.0491853 (* 1 = 0.0491853 loss)
I0418 21:34:15.343336 50350 sgd_solver.cpp:105] Iteration 70700, lr = 0.001
I0418 21:34:37.695219 50350 solver.cpp:219] Iteration 70800 (4.47389 iter/s, 22.3519s/100 iters), loss = 0.0640693
I0418 21:34:37.695255 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:34:37.695261 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:34:37.695266 50350 solver.cpp:238]     Train net output #2: loss = 0.0640692 (* 1 = 0.0640692 loss)
I0418 21:34:37.695271 50350 sgd_solver.cpp:105] Iteration 70800, lr = 0.001
I0418 21:34:59.998667 50350 solver.cpp:219] Iteration 70900 (4.48403 iter/s, 22.3014s/100 iters), loss = 0.0419695
I0418 21:34:59.998740 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:34:59.998746 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:34:59.998752 50350 solver.cpp:238]     Train net output #2: loss = 0.0419694 (* 1 = 0.0419694 loss)
I0418 21:34:59.998759 50350 sgd_solver.cpp:105] Iteration 70900, lr = 0.001
I0418 21:35:22.324542 50350 solver.cpp:331] Iteration 71000, Testing net (#0)
I0418 21:35:26.918211 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:35:27.115856 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9133
I0418 21:35:27.115885 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9973
I0418 21:35:27.115908 50350 solver.cpp:398]     Test net output #2: loss = 0.363134 (* 1 = 0.363134 loss)
I0418 21:35:27.288175 50350 solver.cpp:219] Iteration 71000 (3.66469 iter/s, 27.2875s/100 iters), loss = 0.0681293
I0418 21:35:27.288195 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:35:27.288218 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:35:27.288223 50350 solver.cpp:238]     Train net output #2: loss = 0.0681292 (* 1 = 0.0681292 loss)
I0418 21:35:27.288229 50350 sgd_solver.cpp:105] Iteration 71000, lr = 0.001
I0418 21:35:47.188344 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:35:49.609427 50350 solver.cpp:219] Iteration 71100 (4.48046 iter/s, 22.3192s/100 iters), loss = 0.0639012
I0418 21:35:49.609470 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:35:49.609475 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:35:49.609482 50350 solver.cpp:238]     Train net output #2: loss = 0.0639012 (* 1 = 0.0639012 loss)
I0418 21:35:49.609486 50350 sgd_solver.cpp:105] Iteration 71100, lr = 0.001
I0418 21:36:11.929661 50350 solver.cpp:219] Iteration 71200 (4.48024 iter/s, 22.3202s/100 iters), loss = 0.104878
I0418 21:36:11.929698 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:36:11.929704 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:36:11.929710 50350 solver.cpp:238]     Train net output #2: loss = 0.104878 (* 1 = 0.104878 loss)
I0418 21:36:11.929714 50350 sgd_solver.cpp:105] Iteration 71200, lr = 0.001
I0418 21:36:34.229115 50350 solver.cpp:219] Iteration 71300 (4.48484 iter/s, 22.2974s/100 iters), loss = 0.0333053
I0418 21:36:34.229315 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:36:34.229323 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:36:34.229331 50350 solver.cpp:238]     Train net output #2: loss = 0.0333052 (* 1 = 0.0333052 loss)
I0418 21:36:34.229334 50350 sgd_solver.cpp:105] Iteration 71300, lr = 0.001
I0418 21:36:56.570793 50350 solver.cpp:219] Iteration 71400 (4.47638 iter/s, 22.3395s/100 iters), loss = 0.0486481
I0418 21:36:56.570837 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:36:56.570842 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:36:56.570848 50350 solver.cpp:238]     Train net output #2: loss = 0.0486481 (* 1 = 0.0486481 loss)
I0418 21:36:56.570852 50350 sgd_solver.cpp:105] Iteration 71400, lr = 0.001
I0418 21:37:14.417037 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:37:18.848477 50350 solver.cpp:219] Iteration 71500 (4.48922 iter/s, 22.2756s/100 iters), loss = 0.0378745
I0418 21:37:18.848520 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:37:18.848525 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:37:18.848531 50350 solver.cpp:238]     Train net output #2: loss = 0.0378745 (* 1 = 0.0378745 loss)
I0418 21:37:18.848536 50350 sgd_solver.cpp:105] Iteration 71500, lr = 0.001
I0418 21:37:41.178124 50350 solver.cpp:219] Iteration 71600 (4.47877 iter/s, 22.3276s/100 iters), loss = 0.0239315
I0418 21:37:41.178160 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:37:41.178165 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:37:41.178172 50350 solver.cpp:238]     Train net output #2: loss = 0.0239314 (* 1 = 0.0239314 loss)
I0418 21:37:41.178176 50350 sgd_solver.cpp:105] Iteration 71600, lr = 0.001
I0418 21:38:03.486834 50350 solver.cpp:219] Iteration 71700 (4.48256 iter/s, 22.3087s/100 iters), loss = 0.0595013
I0418 21:38:03.486989 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:38:03.486996 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:38:03.487004 50350 solver.cpp:238]     Train net output #2: loss = 0.0595012 (* 1 = 0.0595012 loss)
I0418 21:38:03.487007 50350 sgd_solver.cpp:105] Iteration 71700, lr = 0.001
I0418 21:38:25.782826 50350 solver.cpp:219] Iteration 71800 (4.48553 iter/s, 22.2939s/100 iters), loss = 0.0631645
I0418 21:38:25.782868 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:38:25.782873 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:38:25.782881 50350 solver.cpp:238]     Train net output #2: loss = 0.0631644 (* 1 = 0.0631644 loss)
I0418 21:38:25.782884 50350 sgd_solver.cpp:105] Iteration 71800, lr = 0.001
I0418 21:38:41.444453 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:38:48.104276 50350 solver.cpp:219] Iteration 71900 (4.48041 iter/s, 22.3194s/100 iters), loss = 0.0381732
I0418 21:38:48.104315 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:38:48.104321 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:38:48.104326 50350 solver.cpp:238]     Train net output #2: loss = 0.0381732 (* 1 = 0.0381732 loss)
I0418 21:38:48.104331 50350 sgd_solver.cpp:105] Iteration 71900, lr = 0.001
I0418 21:39:10.234864 50350 solver.cpp:331] Iteration 72000, Testing net (#0)
I0418 21:39:14.774652 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:39:14.993645 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9133
I0418 21:39:14.993674 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9973
I0418 21:39:14.993697 50350 solver.cpp:398]     Test net output #2: loss = 0.367405 (* 1 = 0.367405 loss)
I0418 21:39:15.147967 50350 solver.cpp:219] Iteration 72000 (3.698 iter/s, 27.0416s/100 iters), loss = 0.0586924
I0418 21:39:15.147987 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:39:15.148010 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:39:15.148015 50350 solver.cpp:238]     Train net output #2: loss = 0.0586924 (* 1 = 0.0586924 loss)
I0418 21:39:15.148021 50350 sgd_solver.cpp:105] Iteration 72000, lr = 0.001
I0418 21:39:37.517598 50350 solver.cpp:219] Iteration 72100 (4.47077 iter/s, 22.3675s/100 iters), loss = 0.0250827
I0418 21:39:37.517642 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:39:37.517647 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:39:37.517653 50350 solver.cpp:238]     Train net output #2: loss = 0.0250827 (* 1 = 0.0250827 loss)
I0418 21:39:37.517657 50350 sgd_solver.cpp:105] Iteration 72100, lr = 0.001
I0418 21:39:59.832734 50350 solver.cpp:219] Iteration 72200 (4.48127 iter/s, 22.3151s/100 iters), loss = 0.0716465
I0418 21:39:59.832937 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:39:59.832945 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:39:59.832952 50350 solver.cpp:238]     Train net output #2: loss = 0.0716465 (* 1 = 0.0716465 loss)
I0418 21:39:59.832957 50350 sgd_solver.cpp:105] Iteration 72200, lr = 0.001
I0418 21:40:13.486172 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:40:22.159523 50350 solver.cpp:219] Iteration 72300 (4.47934 iter/s, 22.3247s/100 iters), loss = 0.0497676
I0418 21:40:22.159564 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:40:22.159569 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:40:22.159575 50350 solver.cpp:238]     Train net output #2: loss = 0.0497676 (* 1 = 0.0497676 loss)
I0418 21:40:22.159579 50350 sgd_solver.cpp:105] Iteration 72300, lr = 0.001
I0418 21:40:44.524796 50350 solver.cpp:219] Iteration 72400 (4.47165 iter/s, 22.3631s/100 iters), loss = 0.0646
I0418 21:40:44.524978 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:40:44.524986 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:40:44.524992 50350 solver.cpp:238]     Train net output #2: loss = 0.0645999 (* 1 = 0.0645999 loss)
I0418 21:40:44.524996 50350 sgd_solver.cpp:105] Iteration 72400, lr = 0.001
I0418 21:41:06.866832 50350 solver.cpp:219] Iteration 72500 (4.47589 iter/s, 22.3419s/100 iters), loss = 0.0813393
I0418 21:41:06.866873 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:41:06.866879 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:41:06.866885 50350 solver.cpp:238]     Train net output #2: loss = 0.0813393 (* 1 = 0.0813393 loss)
I0418 21:41:06.866889 50350 sgd_solver.cpp:105] Iteration 72500, lr = 0.001
I0418 21:41:29.306748 50350 solver.cpp:219] Iteration 72600 (4.45676 iter/s, 22.4378s/100 iters), loss = 0.0367807
I0418 21:41:29.306838 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:41:29.306844 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:41:29.306852 50350 solver.cpp:238]     Train net output #2: loss = 0.0367806 (* 1 = 0.0367806 loss)
I0418 21:41:29.306856 50350 sgd_solver.cpp:105] Iteration 72600, lr = 0.001
I0418 21:41:41.043081 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:41:51.752957 50350 solver.cpp:219] Iteration 72700 (4.45539 iter/s, 22.4447s/100 iters), loss = 0.0386577
I0418 21:41:51.752998 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:41:51.753005 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:41:51.753010 50350 solver.cpp:238]     Train net output #2: loss = 0.0386576 (* 1 = 0.0386576 loss)
I0418 21:41:51.753015 50350 sgd_solver.cpp:105] Iteration 72700, lr = 0.001
I0418 21:42:14.038681 50350 solver.cpp:219] Iteration 72800 (4.48718 iter/s, 22.2857s/100 iters), loss = 0.046737
I0418 21:42:14.038862 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:42:14.038872 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:42:14.038878 50350 solver.cpp:238]     Train net output #2: loss = 0.0467369 (* 1 = 0.0467369 loss)
I0418 21:42:14.038883 50350 sgd_solver.cpp:105] Iteration 72800, lr = 0.001
I0418 21:42:36.319294 50350 solver.cpp:219] Iteration 72900 (4.48863 iter/s, 22.2785s/100 iters), loss = 0.0443576
I0418 21:42:36.319334 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:42:36.319339 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:42:36.319345 50350 solver.cpp:238]     Train net output #2: loss = 0.0443576 (* 1 = 0.0443576 loss)
I0418 21:42:36.319350 50350 sgd_solver.cpp:105] Iteration 72900, lr = 0.001
I0418 21:42:58.405169 50350 solver.cpp:331] Iteration 73000, Testing net (#0)
I0418 21:43:02.961614 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:43:03.168859 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9114
I0418 21:43:03.168886 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9976
I0418 21:43:03.168910 50350 solver.cpp:398]     Test net output #2: loss = 0.367701 (* 1 = 0.367701 loss)
I0418 21:43:03.338404 50350 solver.cpp:219] Iteration 73000 (3.70108 iter/s, 27.0191s/100 iters), loss = 0.075605
I0418 21:43:03.338426 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:43:03.338431 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:43:03.338438 50350 solver.cpp:238]     Train net output #2: loss = 0.0756049 (* 1 = 0.0756049 loss)
I0418 21:43:03.338446 50350 sgd_solver.cpp:105] Iteration 73000, lr = 0.001
I0418 21:43:12.741780 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:43:25.647703 50350 solver.cpp:219] Iteration 73100 (4.48244 iter/s, 22.3093s/100 iters), loss = 0.10269
I0418 21:43:25.647744 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:43:25.647749 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:43:25.647756 50350 solver.cpp:238]     Train net output #2: loss = 0.10269 (* 1 = 0.10269 loss)
I0418 21:43:25.647760 50350 sgd_solver.cpp:105] Iteration 73100, lr = 0.001
I0418 21:43:47.939508 50350 solver.cpp:219] Iteration 73200 (4.48637 iter/s, 22.2897s/100 iters), loss = 0.0789808
I0418 21:43:47.939671 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:43:47.939678 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:43:47.939685 50350 solver.cpp:238]     Train net output #2: loss = 0.0789807 (* 1 = 0.0789807 loss)
I0418 21:43:47.939690 50350 sgd_solver.cpp:105] Iteration 73200, lr = 0.001
I0418 21:44:10.276027 50350 solver.cpp:219] Iteration 73300 (4.47739 iter/s, 22.3344s/100 iters), loss = 0.0323777
I0418 21:44:10.276070 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:44:10.276077 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:44:10.276082 50350 solver.cpp:238]     Train net output #2: loss = 0.0323776 (* 1 = 0.0323776 loss)
I0418 21:44:10.276087 50350 sgd_solver.cpp:105] Iteration 73300, lr = 0.001
I0418 21:44:32.567997 50350 solver.cpp:219] Iteration 73400 (4.48592 iter/s, 22.292s/100 iters), loss = 0.0613326
I0418 21:44:32.568215 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:44:32.568223 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:44:32.568230 50350 solver.cpp:238]     Train net output #2: loss = 0.0613325 (* 1 = 0.0613325 loss)
I0418 21:44:32.568234 50350 sgd_solver.cpp:105] Iteration 73400, lr = 0.001
I0418 21:44:39.969903 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:44:54.879142 50350 solver.cpp:219] Iteration 73500 (4.48248 iter/s, 22.3091s/100 iters), loss = 0.0661073
I0418 21:44:54.879185 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:44:54.879191 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:44:54.879197 50350 solver.cpp:238]     Train net output #2: loss = 0.0661073 (* 1 = 0.0661073 loss)
I0418 21:44:54.879201 50350 sgd_solver.cpp:105] Iteration 73500, lr = 0.001
I0418 21:45:17.233074 50350 solver.cpp:219] Iteration 73600 (4.4739 iter/s, 22.3519s/100 iters), loss = 0.0404555
I0418 21:45:17.233264 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:45:17.233273 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:45:17.233280 50350 solver.cpp:238]     Train net output #2: loss = 0.0404555 (* 1 = 0.0404555 loss)
I0418 21:45:17.233285 50350 sgd_solver.cpp:105] Iteration 73600, lr = 0.001
I0418 21:45:39.510052 50350 solver.cpp:219] Iteration 73700 (4.48921 iter/s, 22.2756s/100 iters), loss = 0.0775037
I0418 21:45:39.510094 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:45:39.510100 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:45:39.510107 50350 solver.cpp:238]     Train net output #2: loss = 0.0775037 (* 1 = 0.0775037 loss)
I0418 21:45:39.510110 50350 sgd_solver.cpp:105] Iteration 73700, lr = 0.001
I0418 21:46:01.825407 50350 solver.cpp:219] Iteration 73800 (4.48164 iter/s, 22.3133s/100 iters), loss = 0.0855483
I0418 21:46:01.825574 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:46:01.825582 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:46:01.825589 50350 solver.cpp:238]     Train net output #2: loss = 0.0855482 (* 1 = 0.0855482 loss)
I0418 21:46:01.825593 50350 sgd_solver.cpp:105] Iteration 73800, lr = 0.001
I0418 21:46:07.220168 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:46:24.183812 50350 solver.cpp:219] Iteration 73900 (4.47269 iter/s, 22.3579s/100 iters), loss = 0.0650985
I0418 21:46:24.183851 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:46:24.183856 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:46:24.183862 50350 solver.cpp:238]     Train net output #2: loss = 0.0650984 (* 1 = 0.0650984 loss)
I0418 21:46:24.183866 50350 sgd_solver.cpp:105] Iteration 73900, lr = 0.001
I0418 21:46:46.306221 50350 solver.cpp:331] Iteration 74000, Testing net (#0)
I0418 21:46:50.859526 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:46:51.053062 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9123
I0418 21:46:51.053091 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9974
I0418 21:46:51.053114 50350 solver.cpp:398]     Test net output #2: loss = 0.36618 (* 1 = 0.36618 loss)
I0418 21:46:51.239629 50350 solver.cpp:219] Iteration 74000 (3.69636 iter/s, 27.0537s/100 iters), loss = 0.0810774
I0418 21:46:51.239648 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:46:51.239670 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:46:51.239675 50350 solver.cpp:238]     Train net output #2: loss = 0.0810774 (* 1 = 0.0810774 loss)
I0418 21:46:51.239681 50350 sgd_solver.cpp:105] Iteration 74000, lr = 0.001
I0418 21:47:13.521647 50350 solver.cpp:219] Iteration 74100 (4.48793 iter/s, 22.282s/100 iters), loss = 0.0237573
I0418 21:47:13.521708 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:47:13.521714 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:47:13.521720 50350 solver.cpp:238]     Train net output #2: loss = 0.0237573 (* 1 = 0.0237573 loss)
I0418 21:47:13.521724 50350 sgd_solver.cpp:105] Iteration 74100, lr = 0.001
I0418 21:47:35.902343 50350 solver.cpp:219] Iteration 74200 (4.46855 iter/s, 22.3786s/100 iters), loss = 0.05794
I0418 21:47:35.902530 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:47:35.902555 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:47:35.902564 50350 solver.cpp:238]     Train net output #2: loss = 0.0579399 (* 1 = 0.0579399 loss)
I0418 21:47:35.902568 50350 sgd_solver.cpp:105] Iteration 74200, lr = 0.001
I0418 21:47:39.149734 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:47:58.393965 50350 solver.cpp:219] Iteration 74300 (4.44651 iter/s, 22.4895s/100 iters), loss = 0.0520984
I0418 21:47:58.394007 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:47:58.394012 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:47:58.394019 50350 solver.cpp:238]     Train net output #2: loss = 0.0520984 (* 1 = 0.0520984 loss)
I0418 21:47:58.394023 50350 sgd_solver.cpp:105] Iteration 74300, lr = 0.001
I0418 21:48:20.698964 50350 solver.cpp:219] Iteration 74400 (4.48372 iter/s, 22.3029s/100 iters), loss = 0.0190811
I0418 21:48:20.699035 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:48:20.699043 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:48:20.699048 50350 solver.cpp:238]     Train net output #2: loss = 0.0190811 (* 1 = 0.0190811 loss)
I0418 21:48:20.699054 50350 sgd_solver.cpp:105] Iteration 74400, lr = 0.001
I0418 21:48:43.019024 50350 solver.cpp:219] Iteration 74500 (4.48069 iter/s, 22.318s/100 iters), loss = 0.0480599
I0418 21:48:43.019068 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:48:43.019073 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:48:43.019080 50350 solver.cpp:238]     Train net output #2: loss = 0.0480599 (* 1 = 0.0480599 loss)
I0418 21:48:43.019084 50350 sgd_solver.cpp:105] Iteration 74500, lr = 0.001
I0418 21:49:05.369400 50350 solver.cpp:219] Iteration 74600 (4.4742 iter/s, 22.3504s/100 iters), loss = 0.0537621
I0418 21:49:05.369603 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:49:05.369611 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:49:05.369618 50350 solver.cpp:238]     Train net output #2: loss = 0.0537621 (* 1 = 0.0537621 loss)
I0418 21:49:05.369623 50350 sgd_solver.cpp:105] Iteration 74600, lr = 0.001
I0418 21:49:06.507128 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:49:27.650465 50350 solver.cpp:219] Iteration 74700 (4.48854 iter/s, 22.279s/100 iters), loss = 0.116311
I0418 21:49:27.650507 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0418 21:49:27.650513 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:49:27.650519 50350 solver.cpp:238]     Train net output #2: loss = 0.116311 (* 1 = 0.116311 loss)
I0418 21:49:27.650523 50350 sgd_solver.cpp:105] Iteration 74700, lr = 0.001
I0418 21:49:50.004724 50350 solver.cpp:219] Iteration 74800 (4.47384 iter/s, 22.3522s/100 iters), loss = 0.124391
I0418 21:49:50.004890 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:49:50.004897 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:49:50.004904 50350 solver.cpp:238]     Train net output #2: loss = 0.124391 (* 1 = 0.124391 loss)
I0418 21:49:50.004909 50350 sgd_solver.cpp:105] Iteration 74800, lr = 0.001
I0418 21:50:12.288731 50350 solver.cpp:219] Iteration 74900 (4.48755 iter/s, 22.2839s/100 iters), loss = 0.0193476
I0418 21:50:12.288772 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:50:12.288779 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:50:12.288784 50350 solver.cpp:238]     Train net output #2: loss = 0.0193476 (* 1 = 0.0193476 loss)
I0418 21:50:12.288789 50350 sgd_solver.cpp:105] Iteration 74900, lr = 0.001
I0418 21:50:33.518661 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:50:34.433867 50350 solver.cpp:331] Iteration 75000, Testing net (#0)
I0418 21:50:38.999804 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:50:39.158044 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.912
I0418 21:50:39.158071 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9972
I0418 21:50:39.158095 50350 solver.cpp:398]     Test net output #2: loss = 0.373156 (* 1 = 0.373156 loss)
I0418 21:50:39.376338 50350 solver.cpp:219] Iteration 75000 (3.692 iter/s, 27.0856s/100 iters), loss = 0.0696866
I0418 21:50:39.376358 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:50:39.376379 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:50:39.376385 50350 solver.cpp:238]     Train net output #2: loss = 0.0696866 (* 1 = 0.0696866 loss)
I0418 21:50:39.376391 50350 sgd_solver.cpp:105] Iteration 75000, lr = 0.001
I0418 21:51:01.658118 50350 solver.cpp:219] Iteration 75100 (4.48841 iter/s, 22.2796s/100 iters), loss = 0.0508856
I0418 21:51:01.658159 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:51:01.658164 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:51:01.658170 50350 solver.cpp:238]     Train net output #2: loss = 0.0508856 (* 1 = 0.0508856 loss)
I0418 21:51:01.658174 50350 sgd_solver.cpp:105] Iteration 75100, lr = 0.001
I0418 21:51:23.996361 50350 solver.cpp:219] Iteration 75200 (4.47705 iter/s, 22.3362s/100 iters), loss = 0.0166269
I0418 21:51:23.996505 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:51:23.996512 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:51:23.996518 50350 solver.cpp:238]     Train net output #2: loss = 0.0166269 (* 1 = 0.0166269 loss)
I0418 21:51:23.996541 50350 sgd_solver.cpp:105] Iteration 75200, lr = 0.001
I0418 21:51:46.274797 50350 solver.cpp:219] Iteration 75300 (4.48866 iter/s, 22.2783s/100 iters), loss = 0.0609799
I0418 21:51:46.274840 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:51:46.274847 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:51:46.274852 50350 solver.cpp:238]     Train net output #2: loss = 0.0609799 (* 1 = 0.0609799 loss)
I0418 21:51:46.274857 50350 sgd_solver.cpp:105] Iteration 75300, lr = 0.001
I0418 21:52:05.505280 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:52:08.577867 50350 solver.cpp:219] Iteration 75400 (4.48411 iter/s, 22.301s/100 iters), loss = 0.0582535
I0418 21:52:08.577906 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:52:08.577913 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:52:08.577919 50350 solver.cpp:238]     Train net output #2: loss = 0.0582535 (* 1 = 0.0582535 loss)
I0418 21:52:08.577922 50350 sgd_solver.cpp:105] Iteration 75400, lr = 0.001
I0418 21:52:30.891558 50350 solver.cpp:219] Iteration 75500 (4.48156 iter/s, 22.3137s/100 iters), loss = 0.053779
I0418 21:52:30.891600 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:52:30.891605 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:52:30.891613 50350 solver.cpp:238]     Train net output #2: loss = 0.053779 (* 1 = 0.053779 loss)
I0418 21:52:30.891616 50350 sgd_solver.cpp:105] Iteration 75500, lr = 0.001
I0418 21:52:53.177983 50350 solver.cpp:219] Iteration 75600 (4.48747 iter/s, 22.2843s/100 iters), loss = 0.0637552
I0418 21:52:53.178128 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:52:53.178135 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:52:53.178143 50350 solver.cpp:238]     Train net output #2: loss = 0.0637552 (* 1 = 0.0637552 loss)
I0418 21:52:53.178146 50350 sgd_solver.cpp:105] Iteration 75600, lr = 0.001
I0418 21:53:15.533941 50350 solver.cpp:219] Iteration 75700 (4.4735 iter/s, 22.3539s/100 iters), loss = 0.0348527
I0418 21:53:15.533979 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:53:15.533985 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:53:15.533991 50350 solver.cpp:238]     Train net output #2: loss = 0.0348527 (* 1 = 0.0348527 loss)
I0418 21:53:15.533995 50350 sgd_solver.cpp:105] Iteration 75700, lr = 0.001
I0418 21:53:32.754344 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:53:37.850874 50350 solver.cpp:219] Iteration 75800 (4.4809 iter/s, 22.3169s/100 iters), loss = 0.034779
I0418 21:53:37.850914 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:53:37.850920 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:53:37.850926 50350 solver.cpp:238]     Train net output #2: loss = 0.034779 (* 1 = 0.034779 loss)
I0418 21:53:37.850930 50350 sgd_solver.cpp:105] Iteration 75800, lr = 0.001
I0418 21:54:00.095584 50350 solver.cpp:219] Iteration 75900 (4.49587 iter/s, 22.2426s/100 iters), loss = 0.0395816
I0418 21:54:00.095623 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:54:00.095629 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:54:00.095635 50350 solver.cpp:238]     Train net output #2: loss = 0.0395817 (* 1 = 0.0395817 loss)
I0418 21:54:00.095639 50350 sgd_solver.cpp:105] Iteration 75900, lr = 0.001
I0418 21:54:22.236616 50350 solver.cpp:331] Iteration 76000, Testing net (#0)
I0418 21:54:26.802841 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:54:26.969310 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9124
I0418 21:54:26.969337 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9971
I0418 21:54:26.969362 50350 solver.cpp:398]     Test net output #2: loss = 0.370007 (* 1 = 0.370007 loss)
I0418 21:54:27.183451 50350 solver.cpp:219] Iteration 76000 (3.69197 iter/s, 27.0858s/100 iters), loss = 0.0301627
I0418 21:54:27.183471 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:54:27.183492 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:54:27.183498 50350 solver.cpp:238]     Train net output #2: loss = 0.0301627 (* 1 = 0.0301627 loss)
I0418 21:54:27.183506 50350 sgd_solver.cpp:105] Iteration 76000, lr = 0.001
I0418 21:54:49.463088 50350 solver.cpp:219] Iteration 76100 (4.48841 iter/s, 22.2796s/100 iters), loss = 0.00987208
I0418 21:54:49.463130 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:54:49.463136 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:54:49.463142 50350 solver.cpp:238]     Train net output #2: loss = 0.00987211 (* 1 = 0.00987211 loss)
I0418 21:54:49.463146 50350 sgd_solver.cpp:105] Iteration 76100, lr = 0.001
I0418 21:55:04.466154 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:55:11.794962 50350 solver.cpp:219] Iteration 76200 (4.47834 iter/s, 22.3297s/100 iters), loss = 0.0150404
I0418 21:55:11.795001 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:55:11.795006 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:55:11.795012 50350 solver.cpp:238]     Train net output #2: loss = 0.0150405 (* 1 = 0.0150405 loss)
I0418 21:55:11.795017 50350 sgd_solver.cpp:105] Iteration 76200, lr = 0.001
I0418 21:55:34.137529 50350 solver.cpp:219] Iteration 76300 (4.47619 iter/s, 22.3404s/100 iters), loss = 0.0905593
I0418 21:55:34.137570 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 21:55:34.137576 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:55:34.137583 50350 solver.cpp:238]     Train net output #2: loss = 0.0905593 (* 1 = 0.0905593 loss)
I0418 21:55:34.137586 50350 sgd_solver.cpp:105] Iteration 76300, lr = 0.001
I0418 21:55:56.432389 50350 solver.cpp:219] Iteration 76400 (4.48534 iter/s, 22.2949s/100 iters), loss = 0.0388871
I0418 21:55:56.432559 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:55:56.432566 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:55:56.432574 50350 solver.cpp:238]     Train net output #2: loss = 0.0388872 (* 1 = 0.0388872 loss)
I0418 21:55:56.432579 50350 sgd_solver.cpp:105] Iteration 76400, lr = 0.001
I0418 21:56:18.730968 50350 solver.cpp:219] Iteration 76500 (4.48501 iter/s, 22.2965s/100 iters), loss = 0.0437914
I0418 21:56:18.731029 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:56:18.731037 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:56:18.731043 50350 solver.cpp:238]     Train net output #2: loss = 0.0437914 (* 1 = 0.0437914 loss)
I0418 21:56:18.731048 50350 sgd_solver.cpp:105] Iteration 76500, lr = 0.001
I0418 21:56:31.799561 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:56:41.106016 50350 solver.cpp:219] Iteration 76600 (4.46969 iter/s, 22.3729s/100 iters), loss = 0.0258583
I0418 21:56:41.106060 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 21:56:41.106065 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:56:41.106072 50350 solver.cpp:238]     Train net output #2: loss = 0.0258583 (* 1 = 0.0258583 loss)
I0418 21:56:41.106076 50350 sgd_solver.cpp:105] Iteration 76600, lr = 0.001
I0418 21:57:03.376256 50350 solver.cpp:219] Iteration 76700 (4.49073 iter/s, 22.2681s/100 iters), loss = 0.0314119
I0418 21:57:03.376461 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:57:03.376468 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:57:03.376477 50350 solver.cpp:238]     Train net output #2: loss = 0.031412 (* 1 = 0.031412 loss)
I0418 21:57:03.376480 50350 sgd_solver.cpp:105] Iteration 76700, lr = 0.001
I0418 21:57:25.653138 50350 solver.cpp:219] Iteration 76800 (4.48899 iter/s, 22.2767s/100 iters), loss = 0.0624584
I0418 21:57:25.653177 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:57:25.653182 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:57:25.653188 50350 solver.cpp:238]     Train net output #2: loss = 0.0624585 (* 1 = 0.0624585 loss)
I0418 21:57:25.653192 50350 sgd_solver.cpp:105] Iteration 76800, lr = 0.001
I0418 21:57:47.967641 50350 solver.cpp:219] Iteration 76900 (4.48183 iter/s, 22.3123s/100 iters), loss = 0.0477807
I0418 21:57:47.967844 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:57:47.967851 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:57:47.967859 50350 solver.cpp:238]     Train net output #2: loss = 0.0477807 (* 1 = 0.0477807 loss)
I0418 21:57:47.967864 50350 sgd_solver.cpp:105] Iteration 76900, lr = 0.001
I0418 21:57:58.889672 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:58:10.031726 50350 solver.cpp:331] Iteration 77000, Testing net (#0)
I0418 21:58:14.601869 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:58:14.760187 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9128
I0418 21:58:14.760215 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9973
I0418 21:58:14.760237 50350 solver.cpp:398]     Test net output #2: loss = 0.371109 (* 1 = 0.371109 loss)
I0418 21:58:14.977363 50350 solver.cpp:219] Iteration 77000 (3.70265 iter/s, 27.0077s/100 iters), loss = 0.0695126
I0418 21:58:14.977401 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 21:58:14.977406 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:58:14.977412 50350 solver.cpp:238]     Train net output #2: loss = 0.0695126 (* 1 = 0.0695126 loss)
I0418 21:58:14.977418 50350 sgd_solver.cpp:105] Iteration 77000, lr = 0.001
I0418 21:58:37.233237 50350 solver.cpp:219] Iteration 77100 (4.49362 iter/s, 22.2538s/100 iters), loss = 0.0227875
I0418 21:58:37.233393 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:58:37.233402 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:58:37.233408 50350 solver.cpp:238]     Train net output #2: loss = 0.0227876 (* 1 = 0.0227876 loss)
I0418 21:58:37.233414 50350 sgd_solver.cpp:105] Iteration 77100, lr = 0.001
I0418 21:58:59.523149 50350 solver.cpp:219] Iteration 77200 (4.48677 iter/s, 22.2877s/100 iters), loss = 0.0353038
I0418 21:58:59.523188 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 21:58:59.523193 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:58:59.523200 50350 solver.cpp:238]     Train net output #2: loss = 0.0353038 (* 1 = 0.0353038 loss)
I0418 21:58:59.523203 50350 sgd_solver.cpp:105] Iteration 77200, lr = 0.001
I0418 21:59:21.803259 50350 solver.cpp:219] Iteration 77300 (4.48873 iter/s, 22.278s/100 iters), loss = 0.0463118
I0418 21:59:21.803390 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:59:21.803396 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:59:21.803403 50350 solver.cpp:238]     Train net output #2: loss = 0.0463118 (* 1 = 0.0463118 loss)
I0418 21:59:21.803408 50350 sgd_solver.cpp:105] Iteration 77300, lr = 0.001
I0418 21:59:30.548800 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 21:59:44.142954 50350 solver.cpp:219] Iteration 77400 (4.47675 iter/s, 22.3376s/100 iters), loss = 0.0686264
I0418 21:59:44.142999 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 21:59:44.143005 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 21:59:44.143012 50350 solver.cpp:238]     Train net output #2: loss = 0.0686265 (* 1 = 0.0686265 loss)
I0418 21:59:44.143015 50350 sgd_solver.cpp:105] Iteration 77400, lr = 0.001
I0418 22:00:06.648820 50350 solver.cpp:219] Iteration 77500 (4.44371 iter/s, 22.5037s/100 iters), loss = 0.0392372
I0418 22:00:06.648990 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 22:00:06.648998 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:00:06.649005 50350 solver.cpp:238]     Train net output #2: loss = 0.0392372 (* 1 = 0.0392372 loss)
I0418 22:00:06.649009 50350 sgd_solver.cpp:105] Iteration 77500, lr = 0.001
I0418 22:00:28.914041 50350 solver.cpp:219] Iteration 77600 (4.49133 iter/s, 22.2651s/100 iters), loss = 0.0588055
I0418 22:00:28.914079 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 22:00:28.914085 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:00:28.914091 50350 solver.cpp:238]     Train net output #2: loss = 0.0588055 (* 1 = 0.0588055 loss)
I0418 22:00:28.914096 50350 sgd_solver.cpp:105] Iteration 77600, lr = 0.001
I0418 22:00:51.212477 50350 solver.cpp:219] Iteration 77700 (4.48504 iter/s, 22.2963s/100 iters), loss = 0.0360151
I0418 22:00:51.212582 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 22:00:51.212589 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:00:51.212595 50350 solver.cpp:238]     Train net output #2: loss = 0.0360151 (* 1 = 0.0360151 loss)
I0418 22:00:51.212600 50350 sgd_solver.cpp:105] Iteration 77700, lr = 0.001
I0418 22:00:57.899494 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 22:01:13.487118 50350 solver.cpp:219] Iteration 77800 (4.48983 iter/s, 22.2726s/100 iters), loss = 0.0150914
I0418 22:01:13.487161 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 22:01:13.487166 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:01:13.487172 50350 solver.cpp:238]     Train net output #2: loss = 0.0150915 (* 1 = 0.0150915 loss)
I0418 22:01:13.487177 50350 sgd_solver.cpp:105] Iteration 77800, lr = 0.001
I0418 22:01:35.775753 50350 solver.cpp:219] Iteration 77900 (4.48659 iter/s, 22.2886s/100 iters), loss = 0.0644849
I0418 22:01:35.775912 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 22:01:35.775918 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:01:35.775925 50350 solver.cpp:238]     Train net output #2: loss = 0.0644849 (* 1 = 0.0644849 loss)
I0418 22:01:35.775930 50350 sgd_solver.cpp:105] Iteration 77900, lr = 0.001
I0418 22:01:57.866842 50350 solver.cpp:331] Iteration 78000, Testing net (#0)
I0418 22:02:02.412613 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 22:02:02.568781 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9135
I0418 22:02:02.568807 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9975
I0418 22:02:02.568831 50350 solver.cpp:398]     Test net output #2: loss = 0.372148 (* 1 = 0.372148 loss)
I0418 22:02:02.780078 50350 solver.cpp:219] Iteration 78000 (3.70339 iter/s, 27.0023s/100 iters), loss = 0.0131812
I0418 22:02:02.780102 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 22:02:02.780107 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:02:02.780112 50350 solver.cpp:238]     Train net output #2: loss = 0.0131812 (* 1 = 0.0131812 loss)
I0418 22:02:02.780118 50350 sgd_solver.cpp:105] Iteration 78000, lr = 0.001
I0418 22:02:25.024776 50350 solver.cpp:219] Iteration 78100 (4.49589 iter/s, 22.2425s/100 iters), loss = 0.047708
I0418 22:02:25.024989 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 22:02:25.024998 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:02:25.025005 50350 solver.cpp:238]     Train net output #2: loss = 0.047708 (* 1 = 0.047708 loss)
I0418 22:02:25.025010 50350 sgd_solver.cpp:105] Iteration 78100, lr = 0.001
I0418 22:02:29.547168 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 22:02:47.302424 50350 solver.cpp:219] Iteration 78200 (4.48884 iter/s, 22.2775s/100 iters), loss = 0.056163
I0418 22:02:47.302474 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 22:02:47.302479 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:02:47.302486 50350 solver.cpp:238]     Train net output #2: loss = 0.0561631 (* 1 = 0.0561631 loss)
I0418 22:02:47.302491 50350 sgd_solver.cpp:105] Iteration 78200, lr = 0.001
I0418 22:03:09.608166 50350 solver.cpp:219] Iteration 78300 (4.48359 iter/s, 22.3036s/100 iters), loss = 0.0700212
I0418 22:03:09.608242 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 22:03:09.608248 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:03:09.608255 50350 solver.cpp:238]     Train net output #2: loss = 0.0700212 (* 1 = 0.0700212 loss)
I0418 22:03:09.608261 50350 sgd_solver.cpp:105] Iteration 78300, lr = 0.001
I0418 22:03:31.930301 50350 solver.cpp:219] Iteration 78400 (4.47986 iter/s, 22.3221s/100 iters), loss = 0.0832441
I0418 22:03:31.930341 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 22:03:31.930346 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:03:31.930352 50350 solver.cpp:238]     Train net output #2: loss = 0.0832441 (* 1 = 0.0832441 loss)
I0418 22:03:31.930356 50350 sgd_solver.cpp:105] Iteration 78400, lr = 0.001
I0418 22:03:54.198797 50350 solver.cpp:219] Iteration 78500 (4.49107 iter/s, 22.2664s/100 iters), loss = 0.0529023
I0418 22:03:54.198981 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 22:03:54.198987 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:03:54.198994 50350 solver.cpp:238]     Train net output #2: loss = 0.0529023 (* 1 = 0.0529023 loss)
I0418 22:03:54.198999 50350 sgd_solver.cpp:105] Iteration 78500, lr = 0.001
I0418 22:03:56.683470 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 22:04:16.473526 50350 solver.cpp:219] Iteration 78600 (4.48982 iter/s, 22.2726s/100 iters), loss = 0.0389292
I0418 22:04:16.473567 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 22:04:16.473573 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:04:16.473579 50350 solver.cpp:238]     Train net output #2: loss = 0.0389292 (* 1 = 0.0389292 loss)
I0418 22:04:16.473583 50350 sgd_solver.cpp:105] Iteration 78600, lr = 0.001
I0418 22:04:38.769178 50350 solver.cpp:219] Iteration 78700 (4.48561 iter/s, 22.2935s/100 iters), loss = 0.0152914
I0418 22:04:38.769387 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 22:04:38.769393 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:04:38.769400 50350 solver.cpp:238]     Train net output #2: loss = 0.0152914 (* 1 = 0.0152914 loss)
I0418 22:04:38.769404 50350 sgd_solver.cpp:105] Iteration 78700, lr = 0.001
I0418 22:05:01.049492 50350 solver.cpp:219] Iteration 78800 (4.4883 iter/s, 22.2802s/100 iters), loss = 0.0229233
I0418 22:05:01.049533 50350 solver.cpp:238]     Train net output #0: acctop1 = 1
I0418 22:05:01.049540 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:05:01.049546 50350 solver.cpp:238]     Train net output #2: loss = 0.0229233 (* 1 = 0.0229233 loss)
I0418 22:05:01.049551 50350 sgd_solver.cpp:105] Iteration 78800, lr = 0.001
I0418 22:05:23.345839 50350 solver.cpp:219] Iteration 78900 (4.48546 iter/s, 22.2943s/100 iters), loss = 0.030005
I0418 22:05:23.346053 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 22:05:23.346062 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:05:23.346070 50350 solver.cpp:238]     Train net output #2: loss = 0.030005 (* 1 = 0.030005 loss)
I0418 22:05:23.346074 50350 sgd_solver.cpp:105] Iteration 78900, lr = 0.001
I0418 22:05:23.808795 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 22:05:45.442024 50350 solver.cpp:331] Iteration 79000, Testing net (#0)
I0418 22:05:49.997964 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 22:05:50.200214 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9106
I0418 22:05:50.200242 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9975
I0418 22:05:50.200266 50350 solver.cpp:398]     Test net output #2: loss = 0.377403 (* 1 = 0.377403 loss)
I0418 22:05:50.378382 50350 solver.cpp:219] Iteration 79000 (3.69926 iter/s, 27.0324s/100 iters), loss = 0.0442238
I0418 22:05:50.378402 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 22:05:50.378423 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:05:50.378429 50350 solver.cpp:238]     Train net output #2: loss = 0.0442239 (* 1 = 0.0442239 loss)
I0418 22:05:50.378435 50350 sgd_solver.cpp:105] Iteration 79000, lr = 0.001
I0418 22:06:12.956828 50350 solver.cpp:219] Iteration 79100 (4.42901 iter/s, 22.5784s/100 iters), loss = 0.0504411
I0418 22:06:12.957005 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 22:06:12.957013 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:06:12.957020 50350 solver.cpp:238]     Train net output #2: loss = 0.0504411 (* 1 = 0.0504411 loss)
I0418 22:06:12.957026 50350 sgd_solver.cpp:105] Iteration 79100, lr = 0.001
I0418 22:06:35.209445 50350 solver.cpp:219] Iteration 79200 (4.49428 iter/s, 22.2505s/100 iters), loss = 0.0306959
I0418 22:06:35.209486 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 22:06:35.209491 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:06:35.209497 50350 solver.cpp:238]     Train net output #2: loss = 0.0306959 (* 1 = 0.0306959 loss)
I0418 22:06:35.209501 50350 sgd_solver.cpp:105] Iteration 79200, lr = 0.001
I0418 22:06:55.771874 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 22:06:57.490540 50350 solver.cpp:219] Iteration 79300 (4.48811 iter/s, 22.2811s/100 iters), loss = 0.0755788
I0418 22:06:57.490583 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0418 22:06:57.490589 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:06:57.490595 50350 solver.cpp:238]     Train net output #2: loss = 0.0755788 (* 1 = 0.0755788 loss)
I0418 22:06:57.490599 50350 sgd_solver.cpp:105] Iteration 79300, lr = 0.001
I0418 22:07:19.790817 50350 solver.cpp:219] Iteration 79400 (4.48467 iter/s, 22.2982s/100 iters), loss = 0.0426425
I0418 22:07:19.790861 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 22:07:19.790868 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:07:19.790874 50350 solver.cpp:238]     Train net output #2: loss = 0.0426425 (* 1 = 0.0426425 loss)
I0418 22:07:19.790879 50350 sgd_solver.cpp:105] Iteration 79400, lr = 0.001
I0418 22:07:42.037703 50350 solver.cpp:219] Iteration 79500 (4.49545 iter/s, 22.2447s/100 iters), loss = 0.0487526
I0418 22:07:42.037854 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 22:07:42.037863 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:07:42.037869 50350 solver.cpp:238]     Train net output #2: loss = 0.0487526 (* 1 = 0.0487526 loss)
I0418 22:07:42.037875 50350 sgd_solver.cpp:105] Iteration 79500, lr = 0.001
I0418 22:08:04.313555 50350 solver.cpp:219] Iteration 79600 (4.4896 iter/s, 22.2737s/100 iters), loss = 0.0532867
I0418 22:08:04.313592 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0418 22:08:04.313597 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:08:04.313604 50350 solver.cpp:238]     Train net output #2: loss = 0.0532867 (* 1 = 0.0532867 loss)
I0418 22:08:04.313608 50350 sgd_solver.cpp:105] Iteration 79600, lr = 0.001
I0418 22:08:22.817807 50361 data_layer.cpp:73] Restarting data prefetching from start.
I0418 22:08:26.562985 50350 solver.cpp:219] Iteration 79700 (4.49492 iter/s, 22.2473s/100 iters), loss = 0.05679
I0418 22:08:26.563027 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 22:08:26.563032 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:08:26.563040 50350 solver.cpp:238]     Train net output #2: loss = 0.05679 (* 1 = 0.05679 loss)
I0418 22:08:26.563043 50350 sgd_solver.cpp:105] Iteration 79700, lr = 0.001
I0418 22:08:48.816395 50350 solver.cpp:219] Iteration 79800 (4.4937 iter/s, 22.2534s/100 iters), loss = 0.0519463
I0418 22:08:48.816438 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0418 22:08:48.816448 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:08:48.816454 50350 solver.cpp:238]     Train net output #2: loss = 0.0519463 (* 1 = 0.0519463 loss)
I0418 22:08:48.816459 50350 sgd_solver.cpp:105] Iteration 79800, lr = 0.001
I0418 22:09:11.164695 50350 solver.cpp:219] Iteration 79900 (4.47503 iter/s, 22.3462s/100 iters), loss = 0.0329993
I0418 22:09:11.164877 50350 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0418 22:09:11.164885 50350 solver.cpp:238]     Train net output #1: acctop5 = 1
I0418 22:09:11.164892 50350 solver.cpp:238]     Train net output #2: loss = 0.0329993 (* 1 = 0.0329993 loss)
I0418 22:09:11.164897 50350 sgd_solver.cpp:105] Iteration 79900, lr = 0.001
I0418 22:09:33.250205 50350 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_highway_padded_data_iter_80000.caffemodel
I0418 22:09:33.359926 50350 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_highway_padded_data_iter_80000.solverstate
I0418 22:09:33.451716 50350 solver.cpp:311] Iteration 80000, loss = 0.0443819
I0418 22:09:33.451740 50350 solver.cpp:331] Iteration 80000, Testing net (#0)
I0418 22:09:37.999686 50495 data_layer.cpp:73] Restarting data prefetching from start.
I0418 22:09:38.204906 50350 solver.cpp:398]     Test net output #0: acctop1 = 0.9118
I0418 22:09:38.204928 50350 solver.cpp:398]     Test net output #1: acctop5 = 0.9974
I0418 22:09:38.204953 50350 solver.cpp:398]     Test net output #2: loss = 0.370212 (* 1 = 0.370212 loss)
I0418 22:09:38.204958 50350 solver.cpp:316] Optimization Done.
I0418 22:09:38.204960 50350 caffe.cpp:259] Optimization Done.
