I0420 10:58:49.052722 28419 caffe.cpp:218] Using GPUs 0
I0420 10:58:49.059118 28419 caffe.cpp:223] GPU 0: Tesla P100-PCIE-16GB
I0420 10:58:49.548238 28419 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "model/ResNet20_finetune_quant_0.09"
solver_mode: GPU
device_id: 0
net: "resnet20_relu_msra_cifar10_fix_pattern.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 48000
stepvalue: 64000
I0420 10:58:49.550411 28419 solver.cpp:87] Creating training net from net file: resnet20_relu_msra_cifar10_fix_pattern.prototxt
I0420 10:58:49.552706 28419 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet20_relu_msra_cifar10_fix_pattern.prototxt
I0420 10:58:49.552718 28419 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0420 10:58:49.552944 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0420 10:58:49.552953 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv1
I0420 10:58:49.552963 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_1_bn_a
I0420 10:58:49.552968 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_1_bn_b
I0420 10:58:49.552973 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_2_bn_a
I0420 10:58:49.552978 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_2_bn_b
I0420 10:58:49.552983 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_3_bn_a
I0420 10:58:49.552989 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_3_bn_b
I0420 10:58:49.552994 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_proj
I0420 10:58:49.552997 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_a
I0420 10:58:49.553002 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_b
I0420 10:58:49.553007 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_2_bn_a
I0420 10:58:49.553012 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_2_bn_b
I0420 10:58:49.553017 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_3_bn_a
I0420 10:58:49.553022 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_3_bn_b
I0420 10:58:49.553027 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_proj
I0420 10:58:49.553032 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_a
I0420 10:58:49.553037 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_b
I0420 10:58:49.553045 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_2_bn_a
I0420 10:58:49.553050 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_2_bn_b
I0420 10:58:49.553056 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_3_bn_a
I0420 10:58:49.553061 28419 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_3_bn_b
I0420 10:58:49.553526 28419 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
    mean_file: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/paddedmean.binaryproto"
  }
  data_param {
    source: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_full_train_leveldb_padded/"
    batch_size: 128
    backend: LEVELDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "map16_1_conv_a"
  type: "Convolution"
  bottom: "conv1"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_a"
  type: "BatchNorm"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_1_scale_a"
  type: "Scale"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_relu_a"
  type: "ReLU"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
}
layer {
  name: "map16_1_conv_b"
  type: "Convolution"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_b"
  type: "BatchNorm"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_1_scale_b"
  type: "Scale"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_eltsum"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "map16_1_conv_b"
  top: "map16_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_1_relu_after_sum"
  type: "ReLU"
  bottom: "map16_1_eltsum"
  top: "map16_1_eltsum"
}
layer {
  name: "map16_2_conv_a"
  type: "Convolution"
  bottom: "map16_1_eltsum"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_a"
  type: "BatchNorm"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_2_scale_a"
  type: "Scale"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_relu_a"
  type: "ReLU"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
}
layer {
  name: "map16_2_conv_b"
  type: "Convolution"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_b"
  type: "BatchNorm"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_2_scale_b"
  type: "Scale"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_eltsum"
  type: "Eltwise"
  bottom: "map16_1_eltsum"
  bottom: "map16_2_conv_b"
  top: "map16_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_2_relu_after_sum"
  type: "ReLU"
  bottom: "map16_2_eltsum"
  top: "map16_2_eltsum"
}
layer {
  name: "map16_3_conv_a"
  type: "Convolution"
  bottom: "map16_2_eltsum"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_a"
  type: "BatchNorm"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_3_scale_a"
  type: "Scale"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_relu_a"
  type: "ReLU"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
}
layer {
  name: "map16_3_conv_b"
  type: "Convolution"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_b"
  type: "BatchNorm"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_3_scale_b"
  type: "Scale"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_eltsum"
  type: "Eltwise"
  bottom: "map16_2_eltsum"
  bottom: "map16_3_conv_b"
  top: "map16_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_3_relu_after_sum"
  type: "ReLU"
  bottom: "map16_3_eltsum"
  top: "map16_3_eltsum"
}
layer {
  name: "map32_1_conv_proj"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_proj"
  type: "BatchNorm"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_proj"
  type: "Scale"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_conv_a"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_a"
  type: "BatchNorm"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_a"
  type: "Scale"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_relu_a"
  type: "ReLU"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
}
layer {
  name: "map32_1_conv_b"
  type: "Convolution"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_b"
  type: "BatchNorm"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_b"
  type: "Scale"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_eltsum"
  type: "Eltwise"
  bottom: "map32_1_conv_proj"
  bottom: "map32_1_conv_b"
  top: "map32_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_1_relu_after_sum"
  type: "ReLU"
  bottom: "map32_1_eltsum"
  top: "map32_1_eltsum"
}
layer {
  name: "map32_2_conv_a"
  type: "Convolution"
  bottom: "map32_1_eltsum"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_a"
  type: "BatchNorm"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_2_scale_a"
  type: "Scale"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_relu_a"
  type: "ReLU"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
}
layer {
  name: "map32_2_conv_b"
  type: "Convolution"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_b"
  type: "BatchNorm"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_2_scale_b"
  type: "Scale"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_eltsum"
  type: "Eltwise"
  bottom: "map32_1_eltsum"
  bottom: "map32_2_conv_b"
  top: "map32_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_2_relu_after_sum"
  type: "ReLU"
  bottom: "map32_2_eltsum"
  top: "map32_2_eltsum"
}
layer {
  name: "map32_3_conv_a"
  type: "Convolution"
  bottom: "map32_2_eltsum"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_a"
  type: "BatchNorm"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_3_scale_a"
  type: "Scale"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_relu_a"
  type: "ReLU"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
}
layer {
  name: "map32_3_conv_b"
  type: "Convolution"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_b"
  type: "BatchNorm"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_3_scale_b"
  type: "Scale"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_eltsum"
  type: "Eltwise"
  bottom: "map32_2_eltsum"
  bottom: "map32_3_conv_b"
  top: "map32_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_3_relu_after_sum"
  type: "ReLU"
  bottom: "map32_3_eltsum"
  top: "map32_3_eltsum"
}
layer {
  name: "map64_1_conv_proj"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_proj"
  type: "BatchNorm"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_proj"
  type: "Scale"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_conv_a"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_a"
  type: "BatchNorm"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_a"
  type: "Scale"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_relu_a"
  type: "ReLU"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
}
layer {
  name: "map64_1_conv_b"
  type: "Convolution"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_b"
  type: "BatchNorm"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_b"
  type: "Scale"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_eltsum"
  type: "Eltwise"
  bottom: "map64_1_conv_proj"
  bottom: "map64_1_conv_b"
  top: "map64_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_1_relu_after_sum"
  type: "ReLU"
  bottom: "map64_1_eltsum"
  top: "map64_1_eltsum"
}
layer {
  name: "map64_2_conv_a"
  type: "Convolution"
  bottom: "map64_1_eltsum"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_a"
  type: "BatchNorm"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_2_scale_a"
  type: "Scale"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_relu_a"
  type: "ReLU"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
}
layer {
  name: "map64_2_conv_b"
  type: "Convolution"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_b"
  type: "BatchNorm"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_2_scale_b"
  type: "Scale"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_eltsum"
  type: "Eltwise"
  bottom: "map64_1_eltsum"
  bottom: "map64_2_conv_b"
  top: "map64_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_2_relu_after_sum"
  type: "ReLU"
  bottom: "map64_2_eltsum"
  top: "map64_2_eltsum"
}
layer {
  name: "map64_3_conv_a"
  type: "Convolution"
  bottom: "map64_2_eltsum"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_a"
  type: "BatchNorm"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_3_scale_a"
  type: "Scale"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_relu_a"
  type: "ReLU"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
}
layer {
  name: "map64_3_conv_b"
  type: "Convolution"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_b"
  type: "BatchNorm"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_3_scale_b"
  type: "Scale"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_eltsum"
  type: "Eltwise"
  bottom: "map64_2_eltsum"
  bottom: "map64_3_conv_b"
  top: "map64_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_3_relu_after_sum"
  type: "ReLU"
  bottom: "map64_3_eltsum"
  top: "map64_3_eltsum"
}
layer {
  name: "pool_global"
  type: "Pooling"
  bottom: "map64_3_eltsum"
  top: "pool_global"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_global"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc/top1"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc/top5"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop5"
  accuracy_param {
    top_k: 5
  }
}
I0420 10:58:49.553956 28419 layer_factory.hpp:77] Creating layer data
I0420 10:58:49.613818 28419 db_leveldb.cpp:18] Opened leveldb /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_full_train_leveldb_padded/
I0420 10:58:49.615208 28419 net.cpp:84] Creating Layer data
I0420 10:58:49.615242 28419 net.cpp:380] data -> data
I0420 10:58:49.615274 28419 net.cpp:380] data -> label
I0420 10:58:49.615293 28419 data_transformer.cpp:25] Loading mean file from: /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/paddedmean.binaryproto
I0420 10:58:49.618084 28419 data_layer.cpp:45] output data size: 128,3,32,32
I0420 10:58:49.624629 28419 net.cpp:122] Setting up data
I0420 10:58:49.624644 28419 net.cpp:129] Top shape: 128 3 32 32 (393216)
I0420 10:58:49.624665 28419 net.cpp:129] Top shape: 128 (128)
I0420 10:58:49.624666 28419 net.cpp:137] Memory required for data: 1573376
I0420 10:58:49.624673 28419 layer_factory.hpp:77] Creating layer label_data_1_split
I0420 10:58:49.624704 28419 net.cpp:84] Creating Layer label_data_1_split
I0420 10:58:49.624711 28419 net.cpp:406] label_data_1_split <- label
I0420 10:58:49.624722 28419 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0420 10:58:49.624729 28419 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0420 10:58:49.624735 28419 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0420 10:58:49.624897 28419 net.cpp:122] Setting up label_data_1_split
I0420 10:58:49.624903 28419 net.cpp:129] Top shape: 128 (128)
I0420 10:58:49.624907 28419 net.cpp:129] Top shape: 128 (128)
I0420 10:58:49.624930 28419 net.cpp:129] Top shape: 128 (128)
I0420 10:58:49.624933 28419 net.cpp:137] Memory required for data: 1574912
I0420 10:58:49.624935 28419 layer_factory.hpp:77] Creating layer conv1
I0420 10:58:49.624953 28419 net.cpp:84] Creating Layer conv1
I0420 10:58:49.624955 28419 net.cpp:406] conv1 <- data
I0420 10:58:49.624960 28419 net.cpp:380] conv1 -> conv1
I0420 10:58:50.143437 28419 net.cpp:122] Setting up conv1
I0420 10:58:50.143484 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.143488 28419 net.cpp:137] Memory required for data: 9963520
I0420 10:58:50.143513 28419 layer_factory.hpp:77] Creating layer bn_conv1
I0420 10:58:50.143529 28419 net.cpp:84] Creating Layer bn_conv1
I0420 10:58:50.143534 28419 net.cpp:406] bn_conv1 <- conv1
I0420 10:58:50.143542 28419 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0420 10:58:50.143721 28419 net.cpp:122] Setting up bn_conv1
I0420 10:58:50.143728 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.143731 28419 net.cpp:137] Memory required for data: 18352128
I0420 10:58:50.143740 28419 layer_factory.hpp:77] Creating layer scale_conv1
I0420 10:58:50.143751 28419 net.cpp:84] Creating Layer scale_conv1
I0420 10:58:50.143755 28419 net.cpp:406] scale_conv1 <- conv1
I0420 10:58:50.143759 28419 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0420 10:58:50.143795 28419 layer_factory.hpp:77] Creating layer scale_conv1
I0420 10:58:50.143887 28419 net.cpp:122] Setting up scale_conv1
I0420 10:58:50.143893 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.143896 28419 net.cpp:137] Memory required for data: 26740736
I0420 10:58:50.143901 28419 layer_factory.hpp:77] Creating layer relu_conv1
I0420 10:58:50.143908 28419 net.cpp:84] Creating Layer relu_conv1
I0420 10:58:50.143911 28419 net.cpp:406] relu_conv1 <- conv1
I0420 10:58:50.143915 28419 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0420 10:58:50.144078 28419 net.cpp:122] Setting up relu_conv1
I0420 10:58:50.144085 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.144088 28419 net.cpp:137] Memory required for data: 35129344
I0420 10:58:50.144090 28419 layer_factory.hpp:77] Creating layer conv1_relu_conv1_0_split
I0420 10:58:50.144096 28419 net.cpp:84] Creating Layer conv1_relu_conv1_0_split
I0420 10:58:50.144100 28419 net.cpp:406] conv1_relu_conv1_0_split <- conv1
I0420 10:58:50.144104 28419 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_0
I0420 10:58:50.144110 28419 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_1
I0420 10:58:50.144141 28419 net.cpp:122] Setting up conv1_relu_conv1_0_split
I0420 10:58:50.144146 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.144150 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.144151 28419 net.cpp:137] Memory required for data: 51906560
I0420 10:58:50.144155 28419 layer_factory.hpp:77] Creating layer map16_1_conv_a
I0420 10:58:50.144163 28419 net.cpp:84] Creating Layer map16_1_conv_a
I0420 10:58:50.144166 28419 net.cpp:406] map16_1_conv_a <- conv1_relu_conv1_0_split_0
I0420 10:58:50.144170 28419 net.cpp:380] map16_1_conv_a -> map16_1_conv_a
I0420 10:58:50.146230 28419 net.cpp:122] Setting up map16_1_conv_a
I0420 10:58:50.146242 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.146246 28419 net.cpp:137] Memory required for data: 60295168
I0420 10:58:50.146255 28419 layer_factory.hpp:77] Creating layer map16_1_bn_a
I0420 10:58:50.146262 28419 net.cpp:84] Creating Layer map16_1_bn_a
I0420 10:58:50.146266 28419 net.cpp:406] map16_1_bn_a <- map16_1_conv_a
I0420 10:58:50.146270 28419 net.cpp:367] map16_1_bn_a -> map16_1_conv_a (in-place)
I0420 10:58:50.146412 28419 net.cpp:122] Setting up map16_1_bn_a
I0420 10:58:50.146417 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.146420 28419 net.cpp:137] Memory required for data: 68683776
I0420 10:58:50.146426 28419 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0420 10:58:50.146432 28419 net.cpp:84] Creating Layer map16_1_scale_a
I0420 10:58:50.146435 28419 net.cpp:406] map16_1_scale_a <- map16_1_conv_a
I0420 10:58:50.146468 28419 net.cpp:367] map16_1_scale_a -> map16_1_conv_a (in-place)
I0420 10:58:50.146497 28419 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0420 10:58:50.146575 28419 net.cpp:122] Setting up map16_1_scale_a
I0420 10:58:50.146581 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.146584 28419 net.cpp:137] Memory required for data: 77072384
I0420 10:58:50.146589 28419 layer_factory.hpp:77] Creating layer map16_1_relu_a
I0420 10:58:50.146594 28419 net.cpp:84] Creating Layer map16_1_relu_a
I0420 10:58:50.146596 28419 net.cpp:406] map16_1_relu_a <- map16_1_conv_a
I0420 10:58:50.146600 28419 net.cpp:367] map16_1_relu_a -> map16_1_conv_a (in-place)
I0420 10:58:50.146997 28419 net.cpp:122] Setting up map16_1_relu_a
I0420 10:58:50.147008 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.147011 28419 net.cpp:137] Memory required for data: 85460992
I0420 10:58:50.147014 28419 layer_factory.hpp:77] Creating layer map16_1_conv_b
I0420 10:58:50.147024 28419 net.cpp:84] Creating Layer map16_1_conv_b
I0420 10:58:50.147027 28419 net.cpp:406] map16_1_conv_b <- map16_1_conv_a
I0420 10:58:50.147032 28419 net.cpp:380] map16_1_conv_b -> map16_1_conv_b
I0420 10:58:50.147718 28419 net.cpp:122] Setting up map16_1_conv_b
I0420 10:58:50.147727 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.147730 28419 net.cpp:137] Memory required for data: 93849600
I0420 10:58:50.147735 28419 layer_factory.hpp:77] Creating layer map16_1_bn_b
I0420 10:58:50.147742 28419 net.cpp:84] Creating Layer map16_1_bn_b
I0420 10:58:50.147747 28419 net.cpp:406] map16_1_bn_b <- map16_1_conv_b
I0420 10:58:50.147750 28419 net.cpp:367] map16_1_bn_b -> map16_1_conv_b (in-place)
I0420 10:58:50.147887 28419 net.cpp:122] Setting up map16_1_bn_b
I0420 10:58:50.147893 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.147897 28419 net.cpp:137] Memory required for data: 102238208
I0420 10:58:50.147904 28419 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0420 10:58:50.147910 28419 net.cpp:84] Creating Layer map16_1_scale_b
I0420 10:58:50.147913 28419 net.cpp:406] map16_1_scale_b <- map16_1_conv_b
I0420 10:58:50.147917 28419 net.cpp:367] map16_1_scale_b -> map16_1_conv_b (in-place)
I0420 10:58:50.147943 28419 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0420 10:58:50.148020 28419 net.cpp:122] Setting up map16_1_scale_b
I0420 10:58:50.148025 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.148028 28419 net.cpp:137] Memory required for data: 110626816
I0420 10:58:50.148033 28419 layer_factory.hpp:77] Creating layer map16_1_eltsum
I0420 10:58:50.148042 28419 net.cpp:84] Creating Layer map16_1_eltsum
I0420 10:58:50.148046 28419 net.cpp:406] map16_1_eltsum <- conv1_relu_conv1_0_split_1
I0420 10:58:50.148049 28419 net.cpp:406] map16_1_eltsum <- map16_1_conv_b
I0420 10:58:50.148053 28419 net.cpp:380] map16_1_eltsum -> map16_1_eltsum
I0420 10:58:50.148077 28419 net.cpp:122] Setting up map16_1_eltsum
I0420 10:58:50.148082 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.148084 28419 net.cpp:137] Memory required for data: 119015424
I0420 10:58:50.148087 28419 layer_factory.hpp:77] Creating layer map16_1_relu_after_sum
I0420 10:58:50.148092 28419 net.cpp:84] Creating Layer map16_1_relu_after_sum
I0420 10:58:50.148095 28419 net.cpp:406] map16_1_relu_after_sum <- map16_1_eltsum
I0420 10:58:50.148098 28419 net.cpp:367] map16_1_relu_after_sum -> map16_1_eltsum (in-place)
I0420 10:58:50.148489 28419 net.cpp:122] Setting up map16_1_relu_after_sum
I0420 10:58:50.148499 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.148502 28419 net.cpp:137] Memory required for data: 127404032
I0420 10:58:50.148505 28419 layer_factory.hpp:77] Creating layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 10:58:50.148514 28419 net.cpp:84] Creating Layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 10:58:50.148516 28419 net.cpp:406] map16_1_eltsum_map16_1_relu_after_sum_0_split <- map16_1_eltsum
I0420 10:58:50.148532 28419 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0420 10:58:50.148538 28419 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0420 10:58:50.148571 28419 net.cpp:122] Setting up map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 10:58:50.148577 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.148581 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.148582 28419 net.cpp:137] Memory required for data: 144181248
I0420 10:58:50.148586 28419 layer_factory.hpp:77] Creating layer map16_2_conv_a
I0420 10:58:50.148593 28419 net.cpp:84] Creating Layer map16_2_conv_a
I0420 10:58:50.148597 28419 net.cpp:406] map16_2_conv_a <- map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0420 10:58:50.148600 28419 net.cpp:380] map16_2_conv_a -> map16_2_conv_a
I0420 10:58:50.149497 28419 net.cpp:122] Setting up map16_2_conv_a
I0420 10:58:50.149508 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.149511 28419 net.cpp:137] Memory required for data: 152569856
I0420 10:58:50.149516 28419 layer_factory.hpp:77] Creating layer map16_2_bn_a
I0420 10:58:50.149524 28419 net.cpp:84] Creating Layer map16_2_bn_a
I0420 10:58:50.149528 28419 net.cpp:406] map16_2_bn_a <- map16_2_conv_a
I0420 10:58:50.149533 28419 net.cpp:367] map16_2_bn_a -> map16_2_conv_a (in-place)
I0420 10:58:50.149670 28419 net.cpp:122] Setting up map16_2_bn_a
I0420 10:58:50.149677 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.149679 28419 net.cpp:137] Memory required for data: 160958464
I0420 10:58:50.149689 28419 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0420 10:58:50.149713 28419 net.cpp:84] Creating Layer map16_2_scale_a
I0420 10:58:50.149715 28419 net.cpp:406] map16_2_scale_a <- map16_2_conv_a
I0420 10:58:50.149719 28419 net.cpp:367] map16_2_scale_a -> map16_2_conv_a (in-place)
I0420 10:58:50.149747 28419 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0420 10:58:50.149828 28419 net.cpp:122] Setting up map16_2_scale_a
I0420 10:58:50.149833 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.149837 28419 net.cpp:137] Memory required for data: 169347072
I0420 10:58:50.149842 28419 layer_factory.hpp:77] Creating layer map16_2_relu_a
I0420 10:58:50.149847 28419 net.cpp:84] Creating Layer map16_2_relu_a
I0420 10:58:50.149849 28419 net.cpp:406] map16_2_relu_a <- map16_2_conv_a
I0420 10:58:50.149852 28419 net.cpp:367] map16_2_relu_a -> map16_2_conv_a (in-place)
I0420 10:58:50.150007 28419 net.cpp:122] Setting up map16_2_relu_a
I0420 10:58:50.150013 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.150017 28419 net.cpp:137] Memory required for data: 177735680
I0420 10:58:50.150018 28419 layer_factory.hpp:77] Creating layer map16_2_conv_b
I0420 10:58:50.150027 28419 net.cpp:84] Creating Layer map16_2_conv_b
I0420 10:58:50.150030 28419 net.cpp:406] map16_2_conv_b <- map16_2_conv_a
I0420 10:58:50.150034 28419 net.cpp:380] map16_2_conv_b -> map16_2_conv_b
I0420 10:58:50.150848 28419 net.cpp:122] Setting up map16_2_conv_b
I0420 10:58:50.150859 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.150863 28419 net.cpp:137] Memory required for data: 186124288
I0420 10:58:50.150868 28419 layer_factory.hpp:77] Creating layer map16_2_bn_b
I0420 10:58:50.150876 28419 net.cpp:84] Creating Layer map16_2_bn_b
I0420 10:58:50.150879 28419 net.cpp:406] map16_2_bn_b <- map16_2_conv_b
I0420 10:58:50.150884 28419 net.cpp:367] map16_2_bn_b -> map16_2_conv_b (in-place)
I0420 10:58:50.151027 28419 net.cpp:122] Setting up map16_2_bn_b
I0420 10:58:50.151033 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.151036 28419 net.cpp:137] Memory required for data: 194512896
I0420 10:58:50.151046 28419 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0420 10:58:50.151051 28419 net.cpp:84] Creating Layer map16_2_scale_b
I0420 10:58:50.151054 28419 net.cpp:406] map16_2_scale_b <- map16_2_conv_b
I0420 10:58:50.151058 28419 net.cpp:367] map16_2_scale_b -> map16_2_conv_b (in-place)
I0420 10:58:50.151098 28419 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0420 10:58:50.151178 28419 net.cpp:122] Setting up map16_2_scale_b
I0420 10:58:50.151185 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.151187 28419 net.cpp:137] Memory required for data: 202901504
I0420 10:58:50.151192 28419 layer_factory.hpp:77] Creating layer map16_2_eltsum
I0420 10:58:50.151197 28419 net.cpp:84] Creating Layer map16_2_eltsum
I0420 10:58:50.151201 28419 net.cpp:406] map16_2_eltsum <- map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0420 10:58:50.151204 28419 net.cpp:406] map16_2_eltsum <- map16_2_conv_b
I0420 10:58:50.151208 28419 net.cpp:380] map16_2_eltsum -> map16_2_eltsum
I0420 10:58:50.151226 28419 net.cpp:122] Setting up map16_2_eltsum
I0420 10:58:50.151232 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.151233 28419 net.cpp:137] Memory required for data: 211290112
I0420 10:58:50.151237 28419 layer_factory.hpp:77] Creating layer map16_2_relu_after_sum
I0420 10:58:50.151240 28419 net.cpp:84] Creating Layer map16_2_relu_after_sum
I0420 10:58:50.151243 28419 net.cpp:406] map16_2_relu_after_sum <- map16_2_eltsum
I0420 10:58:50.151247 28419 net.cpp:367] map16_2_relu_after_sum -> map16_2_eltsum (in-place)
I0420 10:58:50.151381 28419 net.cpp:122] Setting up map16_2_relu_after_sum
I0420 10:58:50.151387 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.151389 28419 net.cpp:137] Memory required for data: 219678720
I0420 10:58:50.151392 28419 layer_factory.hpp:77] Creating layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 10:58:50.151397 28419 net.cpp:84] Creating Layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 10:58:50.151401 28419 net.cpp:406] map16_2_eltsum_map16_2_relu_after_sum_0_split <- map16_2_eltsum
I0420 10:58:50.151404 28419 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0420 10:58:50.151412 28419 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0420 10:58:50.151440 28419 net.cpp:122] Setting up map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 10:58:50.151445 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.151449 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.151451 28419 net.cpp:137] Memory required for data: 236455936
I0420 10:58:50.151454 28419 layer_factory.hpp:77] Creating layer map16_3_conv_a
I0420 10:58:50.151463 28419 net.cpp:84] Creating Layer map16_3_conv_a
I0420 10:58:50.151465 28419 net.cpp:406] map16_3_conv_a <- map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0420 10:58:50.151469 28419 net.cpp:380] map16_3_conv_a -> map16_3_conv_a
I0420 10:58:50.152348 28419 net.cpp:122] Setting up map16_3_conv_a
I0420 10:58:50.152359 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.152361 28419 net.cpp:137] Memory required for data: 244844544
I0420 10:58:50.152367 28419 layer_factory.hpp:77] Creating layer map16_3_bn_a
I0420 10:58:50.152374 28419 net.cpp:84] Creating Layer map16_3_bn_a
I0420 10:58:50.152379 28419 net.cpp:406] map16_3_bn_a <- map16_3_conv_a
I0420 10:58:50.152382 28419 net.cpp:367] map16_3_bn_a -> map16_3_conv_a (in-place)
I0420 10:58:50.152524 28419 net.cpp:122] Setting up map16_3_bn_a
I0420 10:58:50.152529 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.152532 28419 net.cpp:137] Memory required for data: 253233152
I0420 10:58:50.152537 28419 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0420 10:58:50.152544 28419 net.cpp:84] Creating Layer map16_3_scale_a
I0420 10:58:50.152546 28419 net.cpp:406] map16_3_scale_a <- map16_3_conv_a
I0420 10:58:50.152550 28419 net.cpp:367] map16_3_scale_a -> map16_3_conv_a (in-place)
I0420 10:58:50.152576 28419 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0420 10:58:50.152657 28419 net.cpp:122] Setting up map16_3_scale_a
I0420 10:58:50.152662 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.152664 28419 net.cpp:137] Memory required for data: 261621760
I0420 10:58:50.152680 28419 layer_factory.hpp:77] Creating layer map16_3_relu_a
I0420 10:58:50.152706 28419 net.cpp:84] Creating Layer map16_3_relu_a
I0420 10:58:50.152710 28419 net.cpp:406] map16_3_relu_a <- map16_3_conv_a
I0420 10:58:50.152714 28419 net.cpp:367] map16_3_relu_a -> map16_3_conv_a (in-place)
I0420 10:58:50.152855 28419 net.cpp:122] Setting up map16_3_relu_a
I0420 10:58:50.152863 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.152865 28419 net.cpp:137] Memory required for data: 270010368
I0420 10:58:50.152868 28419 layer_factory.hpp:77] Creating layer map16_3_conv_b
I0420 10:58:50.152876 28419 net.cpp:84] Creating Layer map16_3_conv_b
I0420 10:58:50.152880 28419 net.cpp:406] map16_3_conv_b <- map16_3_conv_a
I0420 10:58:50.152884 28419 net.cpp:380] map16_3_conv_b -> map16_3_conv_b
I0420 10:58:50.153731 28419 net.cpp:122] Setting up map16_3_conv_b
I0420 10:58:50.153743 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.153745 28419 net.cpp:137] Memory required for data: 278398976
I0420 10:58:50.153750 28419 layer_factory.hpp:77] Creating layer map16_3_bn_b
I0420 10:58:50.153760 28419 net.cpp:84] Creating Layer map16_3_bn_b
I0420 10:58:50.153764 28419 net.cpp:406] map16_3_bn_b <- map16_3_conv_b
I0420 10:58:50.153767 28419 net.cpp:367] map16_3_bn_b -> map16_3_conv_b (in-place)
I0420 10:58:50.153913 28419 net.cpp:122] Setting up map16_3_bn_b
I0420 10:58:50.153919 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.153923 28419 net.cpp:137] Memory required for data: 286787584
I0420 10:58:50.153928 28419 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0420 10:58:50.153933 28419 net.cpp:84] Creating Layer map16_3_scale_b
I0420 10:58:50.153936 28419 net.cpp:406] map16_3_scale_b <- map16_3_conv_b
I0420 10:58:50.153939 28419 net.cpp:367] map16_3_scale_b -> map16_3_conv_b (in-place)
I0420 10:58:50.153965 28419 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0420 10:58:50.154047 28419 net.cpp:122] Setting up map16_3_scale_b
I0420 10:58:50.154052 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.154054 28419 net.cpp:137] Memory required for data: 295176192
I0420 10:58:50.154058 28419 layer_factory.hpp:77] Creating layer map16_3_eltsum
I0420 10:58:50.154064 28419 net.cpp:84] Creating Layer map16_3_eltsum
I0420 10:58:50.154067 28419 net.cpp:406] map16_3_eltsum <- map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0420 10:58:50.154070 28419 net.cpp:406] map16_3_eltsum <- map16_3_conv_b
I0420 10:58:50.154075 28419 net.cpp:380] map16_3_eltsum -> map16_3_eltsum
I0420 10:58:50.154093 28419 net.cpp:122] Setting up map16_3_eltsum
I0420 10:58:50.154098 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.154100 28419 net.cpp:137] Memory required for data: 303564800
I0420 10:58:50.154103 28419 layer_factory.hpp:77] Creating layer map16_3_relu_after_sum
I0420 10:58:50.154106 28419 net.cpp:84] Creating Layer map16_3_relu_after_sum
I0420 10:58:50.154109 28419 net.cpp:406] map16_3_relu_after_sum <- map16_3_eltsum
I0420 10:58:50.154114 28419 net.cpp:367] map16_3_relu_after_sum -> map16_3_eltsum (in-place)
I0420 10:58:50.154248 28419 net.cpp:122] Setting up map16_3_relu_after_sum
I0420 10:58:50.154254 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.154258 28419 net.cpp:137] Memory required for data: 311953408
I0420 10:58:50.154260 28419 layer_factory.hpp:77] Creating layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 10:58:50.154265 28419 net.cpp:84] Creating Layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 10:58:50.154268 28419 net.cpp:406] map16_3_eltsum_map16_3_relu_after_sum_0_split <- map16_3_eltsum
I0420 10:58:50.154273 28419 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0420 10:58:50.154278 28419 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0420 10:58:50.154309 28419 net.cpp:122] Setting up map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 10:58:50.154323 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.154327 28419 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 10:58:50.154330 28419 net.cpp:137] Memory required for data: 328730624
I0420 10:58:50.154331 28419 layer_factory.hpp:77] Creating layer map32_1_conv_proj
I0420 10:58:50.154340 28419 net.cpp:84] Creating Layer map32_1_conv_proj
I0420 10:58:50.154343 28419 net.cpp:406] map32_1_conv_proj <- map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0420 10:58:50.154347 28419 net.cpp:380] map32_1_conv_proj -> map32_1_conv_proj
I0420 10:58:50.155565 28419 net.cpp:122] Setting up map32_1_conv_proj
I0420 10:58:50.155576 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.155580 28419 net.cpp:137] Memory required for data: 332924928
I0420 10:58:50.155585 28419 layer_factory.hpp:77] Creating layer map32_1_bn_proj
I0420 10:58:50.155592 28419 net.cpp:84] Creating Layer map32_1_bn_proj
I0420 10:58:50.155596 28419 net.cpp:406] map32_1_bn_proj <- map32_1_conv_proj
I0420 10:58:50.155601 28419 net.cpp:367] map32_1_bn_proj -> map32_1_conv_proj (in-place)
I0420 10:58:50.155769 28419 net.cpp:122] Setting up map32_1_bn_proj
I0420 10:58:50.155776 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.155779 28419 net.cpp:137] Memory required for data: 337119232
I0420 10:58:50.155786 28419 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0420 10:58:50.155791 28419 net.cpp:84] Creating Layer map32_1_scale_proj
I0420 10:58:50.155794 28419 net.cpp:406] map32_1_scale_proj <- map32_1_conv_proj
I0420 10:58:50.155798 28419 net.cpp:367] map32_1_scale_proj -> map32_1_conv_proj (in-place)
I0420 10:58:50.155825 28419 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0420 10:58:50.155906 28419 net.cpp:122] Setting up map32_1_scale_proj
I0420 10:58:50.155911 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.155915 28419 net.cpp:137] Memory required for data: 341313536
I0420 10:58:50.155920 28419 layer_factory.hpp:77] Creating layer map32_1_conv_a
I0420 10:58:50.155927 28419 net.cpp:84] Creating Layer map32_1_conv_a
I0420 10:58:50.155930 28419 net.cpp:406] map32_1_conv_a <- map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0420 10:58:50.155936 28419 net.cpp:380] map32_1_conv_a -> map32_1_conv_a
I0420 10:58:50.156839 28419 net.cpp:122] Setting up map32_1_conv_a
I0420 10:58:50.156850 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.156853 28419 net.cpp:137] Memory required for data: 345507840
I0420 10:58:50.156858 28419 layer_factory.hpp:77] Creating layer map32_1_bn_a
I0420 10:58:50.156865 28419 net.cpp:84] Creating Layer map32_1_bn_a
I0420 10:58:50.156869 28419 net.cpp:406] map32_1_bn_a <- map32_1_conv_a
I0420 10:58:50.156873 28419 net.cpp:367] map32_1_bn_a -> map32_1_conv_a (in-place)
I0420 10:58:50.157016 28419 net.cpp:122] Setting up map32_1_bn_a
I0420 10:58:50.157021 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.157024 28419 net.cpp:137] Memory required for data: 349702144
I0420 10:58:50.157029 28419 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0420 10:58:50.157035 28419 net.cpp:84] Creating Layer map32_1_scale_a
I0420 10:58:50.157038 28419 net.cpp:406] map32_1_scale_a <- map32_1_conv_a
I0420 10:58:50.157042 28419 net.cpp:367] map32_1_scale_a -> map32_1_conv_a (in-place)
I0420 10:58:50.157068 28419 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0420 10:58:50.157148 28419 net.cpp:122] Setting up map32_1_scale_a
I0420 10:58:50.157153 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.157156 28419 net.cpp:137] Memory required for data: 353896448
I0420 10:58:50.157161 28419 layer_factory.hpp:77] Creating layer map32_1_relu_a
I0420 10:58:50.157166 28419 net.cpp:84] Creating Layer map32_1_relu_a
I0420 10:58:50.157168 28419 net.cpp:406] map32_1_relu_a <- map32_1_conv_a
I0420 10:58:50.157172 28419 net.cpp:367] map32_1_relu_a -> map32_1_conv_a (in-place)
I0420 10:58:50.157310 28419 net.cpp:122] Setting up map32_1_relu_a
I0420 10:58:50.157315 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.157328 28419 net.cpp:137] Memory required for data: 358090752
I0420 10:58:50.157331 28419 layer_factory.hpp:77] Creating layer map32_1_conv_b
I0420 10:58:50.157341 28419 net.cpp:84] Creating Layer map32_1_conv_b
I0420 10:58:50.157343 28419 net.cpp:406] map32_1_conv_b <- map32_1_conv_a
I0420 10:58:50.157348 28419 net.cpp:380] map32_1_conv_b -> map32_1_conv_b
I0420 10:58:50.158244 28419 net.cpp:122] Setting up map32_1_conv_b
I0420 10:58:50.158255 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.158258 28419 net.cpp:137] Memory required for data: 362285056
I0420 10:58:50.158269 28419 layer_factory.hpp:77] Creating layer map32_1_bn_b
I0420 10:58:50.158277 28419 net.cpp:84] Creating Layer map32_1_bn_b
I0420 10:58:50.158280 28419 net.cpp:406] map32_1_bn_b <- map32_1_conv_b
I0420 10:58:50.158285 28419 net.cpp:367] map32_1_bn_b -> map32_1_conv_b (in-place)
I0420 10:58:50.158426 28419 net.cpp:122] Setting up map32_1_bn_b
I0420 10:58:50.158432 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.158433 28419 net.cpp:137] Memory required for data: 366479360
I0420 10:58:50.158439 28419 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0420 10:58:50.158444 28419 net.cpp:84] Creating Layer map32_1_scale_b
I0420 10:58:50.158448 28419 net.cpp:406] map32_1_scale_b <- map32_1_conv_b
I0420 10:58:50.158452 28419 net.cpp:367] map32_1_scale_b -> map32_1_conv_b (in-place)
I0420 10:58:50.158478 28419 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0420 10:58:50.158557 28419 net.cpp:122] Setting up map32_1_scale_b
I0420 10:58:50.158562 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.158565 28419 net.cpp:137] Memory required for data: 370673664
I0420 10:58:50.158570 28419 layer_factory.hpp:77] Creating layer map32_1_eltsum
I0420 10:58:50.158574 28419 net.cpp:84] Creating Layer map32_1_eltsum
I0420 10:58:50.158578 28419 net.cpp:406] map32_1_eltsum <- map32_1_conv_proj
I0420 10:58:50.158581 28419 net.cpp:406] map32_1_eltsum <- map32_1_conv_b
I0420 10:58:50.158586 28419 net.cpp:380] map32_1_eltsum -> map32_1_eltsum
I0420 10:58:50.158601 28419 net.cpp:122] Setting up map32_1_eltsum
I0420 10:58:50.158604 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.158607 28419 net.cpp:137] Memory required for data: 374867968
I0420 10:58:50.158609 28419 layer_factory.hpp:77] Creating layer map32_1_relu_after_sum
I0420 10:58:50.158613 28419 net.cpp:84] Creating Layer map32_1_relu_after_sum
I0420 10:58:50.158617 28419 net.cpp:406] map32_1_relu_after_sum <- map32_1_eltsum
I0420 10:58:50.158619 28419 net.cpp:367] map32_1_relu_after_sum -> map32_1_eltsum (in-place)
I0420 10:58:50.159011 28419 net.cpp:122] Setting up map32_1_relu_after_sum
I0420 10:58:50.159021 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.159024 28419 net.cpp:137] Memory required for data: 379062272
I0420 10:58:50.159027 28419 layer_factory.hpp:77] Creating layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 10:58:50.159034 28419 net.cpp:84] Creating Layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 10:58:50.159036 28419 net.cpp:406] map32_1_eltsum_map32_1_relu_after_sum_0_split <- map32_1_eltsum
I0420 10:58:50.159041 28419 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0420 10:58:50.159047 28419 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0420 10:58:50.159080 28419 net.cpp:122] Setting up map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 10:58:50.159085 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.159090 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.159091 28419 net.cpp:137] Memory required for data: 387450880
I0420 10:58:50.159093 28419 layer_factory.hpp:77] Creating layer map32_2_conv_a
I0420 10:58:50.159101 28419 net.cpp:84] Creating Layer map32_2_conv_a
I0420 10:58:50.159104 28419 net.cpp:406] map32_2_conv_a <- map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0420 10:58:50.159121 28419 net.cpp:380] map32_2_conv_a -> map32_2_conv_a
I0420 10:58:50.159801 28419 net.cpp:122] Setting up map32_2_conv_a
I0420 10:58:50.159811 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.159813 28419 net.cpp:137] Memory required for data: 391645184
I0420 10:58:50.159818 28419 layer_factory.hpp:77] Creating layer map32_2_bn_a
I0420 10:58:50.159827 28419 net.cpp:84] Creating Layer map32_2_bn_a
I0420 10:58:50.159831 28419 net.cpp:406] map32_2_bn_a <- map32_2_conv_a
I0420 10:58:50.159838 28419 net.cpp:367] map32_2_bn_a -> map32_2_conv_a (in-place)
I0420 10:58:50.159988 28419 net.cpp:122] Setting up map32_2_bn_a
I0420 10:58:50.159993 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.159996 28419 net.cpp:137] Memory required for data: 395839488
I0420 10:58:50.160001 28419 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0420 10:58:50.160007 28419 net.cpp:84] Creating Layer map32_2_scale_a
I0420 10:58:50.160010 28419 net.cpp:406] map32_2_scale_a <- map32_2_conv_a
I0420 10:58:50.160015 28419 net.cpp:367] map32_2_scale_a -> map32_2_conv_a (in-place)
I0420 10:58:50.160042 28419 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0420 10:58:50.160128 28419 net.cpp:122] Setting up map32_2_scale_a
I0420 10:58:50.160135 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.160137 28419 net.cpp:137] Memory required for data: 400033792
I0420 10:58:50.160141 28419 layer_factory.hpp:77] Creating layer map32_2_relu_a
I0420 10:58:50.160146 28419 net.cpp:84] Creating Layer map32_2_relu_a
I0420 10:58:50.160151 28419 net.cpp:406] map32_2_relu_a <- map32_2_conv_a
I0420 10:58:50.160153 28419 net.cpp:367] map32_2_relu_a -> map32_2_conv_a (in-place)
I0420 10:58:50.160516 28419 net.cpp:122] Setting up map32_2_relu_a
I0420 10:58:50.160527 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.160531 28419 net.cpp:137] Memory required for data: 404228096
I0420 10:58:50.160533 28419 layer_factory.hpp:77] Creating layer map32_2_conv_b
I0420 10:58:50.160544 28419 net.cpp:84] Creating Layer map32_2_conv_b
I0420 10:58:50.160547 28419 net.cpp:406] map32_2_conv_b <- map32_2_conv_a
I0420 10:58:50.160552 28419 net.cpp:380] map32_2_conv_b -> map32_2_conv_b
I0420 10:58:50.161526 28419 net.cpp:122] Setting up map32_2_conv_b
I0420 10:58:50.161537 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.161540 28419 net.cpp:137] Memory required for data: 408422400
I0420 10:58:50.161545 28419 layer_factory.hpp:77] Creating layer map32_2_bn_b
I0420 10:58:50.161554 28419 net.cpp:84] Creating Layer map32_2_bn_b
I0420 10:58:50.161558 28419 net.cpp:406] map32_2_bn_b <- map32_2_conv_b
I0420 10:58:50.161564 28419 net.cpp:367] map32_2_bn_b -> map32_2_conv_b (in-place)
I0420 10:58:50.161743 28419 net.cpp:122] Setting up map32_2_bn_b
I0420 10:58:50.161751 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.161753 28419 net.cpp:137] Memory required for data: 412616704
I0420 10:58:50.161758 28419 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0420 10:58:50.161764 28419 net.cpp:84] Creating Layer map32_2_scale_b
I0420 10:58:50.161767 28419 net.cpp:406] map32_2_scale_b <- map32_2_conv_b
I0420 10:58:50.161773 28419 net.cpp:367] map32_2_scale_b -> map32_2_conv_b (in-place)
I0420 10:58:50.161801 28419 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0420 10:58:50.161891 28419 net.cpp:122] Setting up map32_2_scale_b
I0420 10:58:50.161898 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.161901 28419 net.cpp:137] Memory required for data: 416811008
I0420 10:58:50.161906 28419 layer_factory.hpp:77] Creating layer map32_2_eltsum
I0420 10:58:50.161911 28419 net.cpp:84] Creating Layer map32_2_eltsum
I0420 10:58:50.161914 28419 net.cpp:406] map32_2_eltsum <- map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0420 10:58:50.161918 28419 net.cpp:406] map32_2_eltsum <- map32_2_conv_b
I0420 10:58:50.161922 28419 net.cpp:380] map32_2_eltsum -> map32_2_eltsum
I0420 10:58:50.161937 28419 net.cpp:122] Setting up map32_2_eltsum
I0420 10:58:50.161942 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.161957 28419 net.cpp:137] Memory required for data: 421005312
I0420 10:58:50.161959 28419 layer_factory.hpp:77] Creating layer map32_2_relu_after_sum
I0420 10:58:50.161967 28419 net.cpp:84] Creating Layer map32_2_relu_after_sum
I0420 10:58:50.161969 28419 net.cpp:406] map32_2_relu_after_sum <- map32_2_eltsum
I0420 10:58:50.161973 28419 net.cpp:367] map32_2_relu_after_sum -> map32_2_eltsum (in-place)
I0420 10:58:50.162139 28419 net.cpp:122] Setting up map32_2_relu_after_sum
I0420 10:58:50.162145 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.162148 28419 net.cpp:137] Memory required for data: 425199616
I0420 10:58:50.162151 28419 layer_factory.hpp:77] Creating layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 10:58:50.162156 28419 net.cpp:84] Creating Layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 10:58:50.162160 28419 net.cpp:406] map32_2_eltsum_map32_2_relu_after_sum_0_split <- map32_2_eltsum
I0420 10:58:50.162165 28419 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0420 10:58:50.162173 28419 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0420 10:58:50.162207 28419 net.cpp:122] Setting up map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 10:58:50.162214 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.162216 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.162219 28419 net.cpp:137] Memory required for data: 433588224
I0420 10:58:50.162221 28419 layer_factory.hpp:77] Creating layer map32_3_conv_a
I0420 10:58:50.162230 28419 net.cpp:84] Creating Layer map32_3_conv_a
I0420 10:58:50.162233 28419 net.cpp:406] map32_3_conv_a <- map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0420 10:58:50.162240 28419 net.cpp:380] map32_3_conv_a -> map32_3_conv_a
I0420 10:58:50.163233 28419 net.cpp:122] Setting up map32_3_conv_a
I0420 10:58:50.163244 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.163246 28419 net.cpp:137] Memory required for data: 437782528
I0420 10:58:50.163252 28419 layer_factory.hpp:77] Creating layer map32_3_bn_a
I0420 10:58:50.163260 28419 net.cpp:84] Creating Layer map32_3_bn_a
I0420 10:58:50.163264 28419 net.cpp:406] map32_3_bn_a <- map32_3_conv_a
I0420 10:58:50.163270 28419 net.cpp:367] map32_3_bn_a -> map32_3_conv_a (in-place)
I0420 10:58:50.163432 28419 net.cpp:122] Setting up map32_3_bn_a
I0420 10:58:50.163439 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.163441 28419 net.cpp:137] Memory required for data: 441976832
I0420 10:58:50.163446 28419 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0420 10:58:50.163452 28419 net.cpp:84] Creating Layer map32_3_scale_a
I0420 10:58:50.163455 28419 net.cpp:406] map32_3_scale_a <- map32_3_conv_a
I0420 10:58:50.163460 28419 net.cpp:367] map32_3_scale_a -> map32_3_conv_a (in-place)
I0420 10:58:50.163488 28419 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0420 10:58:50.163578 28419 net.cpp:122] Setting up map32_3_scale_a
I0420 10:58:50.163583 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.163586 28419 net.cpp:137] Memory required for data: 446171136
I0420 10:58:50.163590 28419 layer_factory.hpp:77] Creating layer map32_3_relu_a
I0420 10:58:50.163596 28419 net.cpp:84] Creating Layer map32_3_relu_a
I0420 10:58:50.163600 28419 net.cpp:406] map32_3_relu_a <- map32_3_conv_a
I0420 10:58:50.163604 28419 net.cpp:367] map32_3_relu_a -> map32_3_conv_a (in-place)
I0420 10:58:50.163755 28419 net.cpp:122] Setting up map32_3_relu_a
I0420 10:58:50.163763 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.163765 28419 net.cpp:137] Memory required for data: 450365440
I0420 10:58:50.163767 28419 layer_factory.hpp:77] Creating layer map32_3_conv_b
I0420 10:58:50.163784 28419 net.cpp:84] Creating Layer map32_3_conv_b
I0420 10:58:50.163787 28419 net.cpp:406] map32_3_conv_b <- map32_3_conv_a
I0420 10:58:50.163791 28419 net.cpp:380] map32_3_conv_b -> map32_3_conv_b
I0420 10:58:50.164903 28419 net.cpp:122] Setting up map32_3_conv_b
I0420 10:58:50.164916 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.164921 28419 net.cpp:137] Memory required for data: 454559744
I0420 10:58:50.164927 28419 layer_factory.hpp:77] Creating layer map32_3_bn_b
I0420 10:58:50.164933 28419 net.cpp:84] Creating Layer map32_3_bn_b
I0420 10:58:50.164937 28419 net.cpp:406] map32_3_bn_b <- map32_3_conv_b
I0420 10:58:50.164943 28419 net.cpp:367] map32_3_bn_b -> map32_3_conv_b (in-place)
I0420 10:58:50.165117 28419 net.cpp:122] Setting up map32_3_bn_b
I0420 10:58:50.165122 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.165124 28419 net.cpp:137] Memory required for data: 458754048
I0420 10:58:50.165130 28419 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0420 10:58:50.165135 28419 net.cpp:84] Creating Layer map32_3_scale_b
I0420 10:58:50.165139 28419 net.cpp:406] map32_3_scale_b <- map32_3_conv_b
I0420 10:58:50.165143 28419 net.cpp:367] map32_3_scale_b -> map32_3_conv_b (in-place)
I0420 10:58:50.165170 28419 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0420 10:58:50.165262 28419 net.cpp:122] Setting up map32_3_scale_b
I0420 10:58:50.165267 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.165271 28419 net.cpp:137] Memory required for data: 462948352
I0420 10:58:50.165274 28419 layer_factory.hpp:77] Creating layer map32_3_eltsum
I0420 10:58:50.165279 28419 net.cpp:84] Creating Layer map32_3_eltsum
I0420 10:58:50.165283 28419 net.cpp:406] map32_3_eltsum <- map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0420 10:58:50.165287 28419 net.cpp:406] map32_3_eltsum <- map32_3_conv_b
I0420 10:58:50.165293 28419 net.cpp:380] map32_3_eltsum -> map32_3_eltsum
I0420 10:58:50.165308 28419 net.cpp:122] Setting up map32_3_eltsum
I0420 10:58:50.165313 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.165315 28419 net.cpp:137] Memory required for data: 467142656
I0420 10:58:50.165318 28419 layer_factory.hpp:77] Creating layer map32_3_relu_after_sum
I0420 10:58:50.165323 28419 net.cpp:84] Creating Layer map32_3_relu_after_sum
I0420 10:58:50.165325 28419 net.cpp:406] map32_3_relu_after_sum <- map32_3_eltsum
I0420 10:58:50.165329 28419 net.cpp:367] map32_3_relu_after_sum -> map32_3_eltsum (in-place)
I0420 10:58:50.165478 28419 net.cpp:122] Setting up map32_3_relu_after_sum
I0420 10:58:50.165484 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.165488 28419 net.cpp:137] Memory required for data: 471336960
I0420 10:58:50.165490 28419 layer_factory.hpp:77] Creating layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 10:58:50.165494 28419 net.cpp:84] Creating Layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 10:58:50.165498 28419 net.cpp:406] map32_3_eltsum_map32_3_relu_after_sum_0_split <- map32_3_eltsum
I0420 10:58:50.165503 28419 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0420 10:58:50.165509 28419 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0420 10:58:50.165544 28419 net.cpp:122] Setting up map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 10:58:50.165549 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.165554 28419 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 10:58:50.165556 28419 net.cpp:137] Memory required for data: 479725568
I0420 10:58:50.165558 28419 layer_factory.hpp:77] Creating layer map64_1_conv_proj
I0420 10:58:50.165566 28419 net.cpp:84] Creating Layer map64_1_conv_proj
I0420 10:58:50.165570 28419 net.cpp:406] map64_1_conv_proj <- map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0420 10:58:50.165575 28419 net.cpp:380] map64_1_conv_proj -> map64_1_conv_proj
I0420 10:58:50.167631 28419 net.cpp:122] Setting up map64_1_conv_proj
I0420 10:58:50.167644 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.167646 28419 net.cpp:137] Memory required for data: 481822720
I0420 10:58:50.167652 28419 layer_factory.hpp:77] Creating layer map64_1_bn_proj
I0420 10:58:50.167671 28419 net.cpp:84] Creating Layer map64_1_bn_proj
I0420 10:58:50.167675 28419 net.cpp:406] map64_1_bn_proj <- map64_1_conv_proj
I0420 10:58:50.167685 28419 net.cpp:367] map64_1_bn_proj -> map64_1_conv_proj (in-place)
I0420 10:58:50.167867 28419 net.cpp:122] Setting up map64_1_bn_proj
I0420 10:58:50.167873 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.167876 28419 net.cpp:137] Memory required for data: 483919872
I0420 10:58:50.167883 28419 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0420 10:58:50.167889 28419 net.cpp:84] Creating Layer map64_1_scale_proj
I0420 10:58:50.167892 28419 net.cpp:406] map64_1_scale_proj <- map64_1_conv_proj
I0420 10:58:50.167896 28419 net.cpp:367] map64_1_scale_proj -> map64_1_conv_proj (in-place)
I0420 10:58:50.167927 28419 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0420 10:58:50.168036 28419 net.cpp:122] Setting up map64_1_scale_proj
I0420 10:58:50.168041 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.168045 28419 net.cpp:137] Memory required for data: 486017024
I0420 10:58:50.168050 28419 layer_factory.hpp:77] Creating layer map64_1_conv_a
I0420 10:58:50.168059 28419 net.cpp:84] Creating Layer map64_1_conv_a
I0420 10:58:50.168063 28419 net.cpp:406] map64_1_conv_a <- map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0420 10:58:50.168068 28419 net.cpp:380] map64_1_conv_a -> map64_1_conv_a
I0420 10:58:50.169118 28419 net.cpp:122] Setting up map64_1_conv_a
I0420 10:58:50.169131 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.169133 28419 net.cpp:137] Memory required for data: 488114176
I0420 10:58:50.169139 28419 layer_factory.hpp:77] Creating layer map64_1_bn_a
I0420 10:58:50.169147 28419 net.cpp:84] Creating Layer map64_1_bn_a
I0420 10:58:50.169150 28419 net.cpp:406] map64_1_bn_a <- map64_1_conv_a
I0420 10:58:50.169159 28419 net.cpp:367] map64_1_bn_a -> map64_1_conv_a (in-place)
I0420 10:58:50.169322 28419 net.cpp:122] Setting up map64_1_bn_a
I0420 10:58:50.169328 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.169332 28419 net.cpp:137] Memory required for data: 490211328
I0420 10:58:50.169337 28419 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0420 10:58:50.169342 28419 net.cpp:84] Creating Layer map64_1_scale_a
I0420 10:58:50.169345 28419 net.cpp:406] map64_1_scale_a <- map64_1_conv_a
I0420 10:58:50.169349 28419 net.cpp:367] map64_1_scale_a -> map64_1_conv_a (in-place)
I0420 10:58:50.169379 28419 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0420 10:58:50.169473 28419 net.cpp:122] Setting up map64_1_scale_a
I0420 10:58:50.169479 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.169481 28419 net.cpp:137] Memory required for data: 492308480
I0420 10:58:50.169486 28419 layer_factory.hpp:77] Creating layer map64_1_relu_a
I0420 10:58:50.169492 28419 net.cpp:84] Creating Layer map64_1_relu_a
I0420 10:58:50.169497 28419 net.cpp:406] map64_1_relu_a <- map64_1_conv_a
I0420 10:58:50.169499 28419 net.cpp:367] map64_1_relu_a -> map64_1_conv_a (in-place)
I0420 10:58:50.169643 28419 net.cpp:122] Setting up map64_1_relu_a
I0420 10:58:50.169649 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.169652 28419 net.cpp:137] Memory required for data: 494405632
I0420 10:58:50.169656 28419 layer_factory.hpp:77] Creating layer map64_1_conv_b
I0420 10:58:50.169667 28419 net.cpp:84] Creating Layer map64_1_conv_b
I0420 10:58:50.169669 28419 net.cpp:406] map64_1_conv_b <- map64_1_conv_a
I0420 10:58:50.169674 28419 net.cpp:380] map64_1_conv_b -> map64_1_conv_b
I0420 10:58:50.171453 28419 net.cpp:122] Setting up map64_1_conv_b
I0420 10:58:50.171466 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.171469 28419 net.cpp:137] Memory required for data: 496502784
I0420 10:58:50.171475 28419 layer_factory.hpp:77] Creating layer map64_1_bn_b
I0420 10:58:50.171484 28419 net.cpp:84] Creating Layer map64_1_bn_b
I0420 10:58:50.171489 28419 net.cpp:406] map64_1_bn_b <- map64_1_conv_b
I0420 10:58:50.171494 28419 net.cpp:367] map64_1_bn_b -> map64_1_conv_b (in-place)
I0420 10:58:50.171672 28419 net.cpp:122] Setting up map64_1_bn_b
I0420 10:58:50.171679 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.171687 28419 net.cpp:137] Memory required for data: 498599936
I0420 10:58:50.171695 28419 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0420 10:58:50.171701 28419 net.cpp:84] Creating Layer map64_1_scale_b
I0420 10:58:50.171705 28419 net.cpp:406] map64_1_scale_b <- map64_1_conv_b
I0420 10:58:50.171708 28419 net.cpp:367] map64_1_scale_b -> map64_1_conv_b (in-place)
I0420 10:58:50.171741 28419 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0420 10:58:50.171836 28419 net.cpp:122] Setting up map64_1_scale_b
I0420 10:58:50.171841 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.171844 28419 net.cpp:137] Memory required for data: 500697088
I0420 10:58:50.171849 28419 layer_factory.hpp:77] Creating layer map64_1_eltsum
I0420 10:58:50.171855 28419 net.cpp:84] Creating Layer map64_1_eltsum
I0420 10:58:50.171859 28419 net.cpp:406] map64_1_eltsum <- map64_1_conv_proj
I0420 10:58:50.171862 28419 net.cpp:406] map64_1_eltsum <- map64_1_conv_b
I0420 10:58:50.171866 28419 net.cpp:380] map64_1_eltsum -> map64_1_eltsum
I0420 10:58:50.171885 28419 net.cpp:122] Setting up map64_1_eltsum
I0420 10:58:50.171888 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.171891 28419 net.cpp:137] Memory required for data: 502794240
I0420 10:58:50.171893 28419 layer_factory.hpp:77] Creating layer map64_1_relu_after_sum
I0420 10:58:50.171897 28419 net.cpp:84] Creating Layer map64_1_relu_after_sum
I0420 10:58:50.171900 28419 net.cpp:406] map64_1_relu_after_sum <- map64_1_eltsum
I0420 10:58:50.171905 28419 net.cpp:367] map64_1_relu_after_sum -> map64_1_eltsum (in-place)
I0420 10:58:50.172065 28419 net.cpp:122] Setting up map64_1_relu_after_sum
I0420 10:58:50.172072 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.172075 28419 net.cpp:137] Memory required for data: 504891392
I0420 10:58:50.172078 28419 layer_factory.hpp:77] Creating layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 10:58:50.172083 28419 net.cpp:84] Creating Layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 10:58:50.172087 28419 net.cpp:406] map64_1_eltsum_map64_1_relu_after_sum_0_split <- map64_1_eltsum
I0420 10:58:50.172092 28419 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0420 10:58:50.172098 28419 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0420 10:58:50.172132 28419 net.cpp:122] Setting up map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 10:58:50.172137 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.172142 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.172144 28419 net.cpp:137] Memory required for data: 509085696
I0420 10:58:50.172147 28419 layer_factory.hpp:77] Creating layer map64_2_conv_a
I0420 10:58:50.172158 28419 net.cpp:84] Creating Layer map64_2_conv_a
I0420 10:58:50.172160 28419 net.cpp:406] map64_2_conv_a <- map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0420 10:58:50.172165 28419 net.cpp:380] map64_2_conv_a -> map64_2_conv_a
I0420 10:58:50.173504 28419 net.cpp:122] Setting up map64_2_conv_a
I0420 10:58:50.173517 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.173521 28419 net.cpp:137] Memory required for data: 511182848
I0420 10:58:50.173527 28419 layer_factory.hpp:77] Creating layer map64_2_bn_a
I0420 10:58:50.173533 28419 net.cpp:84] Creating Layer map64_2_bn_a
I0420 10:58:50.173537 28419 net.cpp:406] map64_2_bn_a <- map64_2_conv_a
I0420 10:58:50.173543 28419 net.cpp:367] map64_2_bn_a -> map64_2_conv_a (in-place)
I0420 10:58:50.173734 28419 net.cpp:122] Setting up map64_2_bn_a
I0420 10:58:50.173740 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.173743 28419 net.cpp:137] Memory required for data: 513280000
I0420 10:58:50.173749 28419 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0420 10:58:50.173755 28419 net.cpp:84] Creating Layer map64_2_scale_a
I0420 10:58:50.173769 28419 net.cpp:406] map64_2_scale_a <- map64_2_conv_a
I0420 10:58:50.173774 28419 net.cpp:367] map64_2_scale_a -> map64_2_conv_a (in-place)
I0420 10:58:50.173809 28419 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0420 10:58:50.173907 28419 net.cpp:122] Setting up map64_2_scale_a
I0420 10:58:50.173913 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.173915 28419 net.cpp:137] Memory required for data: 515377152
I0420 10:58:50.173920 28419 layer_factory.hpp:77] Creating layer map64_2_relu_a
I0420 10:58:50.173928 28419 net.cpp:84] Creating Layer map64_2_relu_a
I0420 10:58:50.173930 28419 net.cpp:406] map64_2_relu_a <- map64_2_conv_a
I0420 10:58:50.173934 28419 net.cpp:367] map64_2_relu_a -> map64_2_conv_a (in-place)
I0420 10:58:50.174338 28419 net.cpp:122] Setting up map64_2_relu_a
I0420 10:58:50.174348 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.174351 28419 net.cpp:137] Memory required for data: 517474304
I0420 10:58:50.174355 28419 layer_factory.hpp:77] Creating layer map64_2_conv_b
I0420 10:58:50.174365 28419 net.cpp:84] Creating Layer map64_2_conv_b
I0420 10:58:50.174368 28419 net.cpp:406] map64_2_conv_b <- map64_2_conv_a
I0420 10:58:50.174374 28419 net.cpp:380] map64_2_conv_b -> map64_2_conv_b
I0420 10:58:50.175803 28419 net.cpp:122] Setting up map64_2_conv_b
I0420 10:58:50.175817 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.175819 28419 net.cpp:137] Memory required for data: 519571456
I0420 10:58:50.175825 28419 layer_factory.hpp:77] Creating layer map64_2_bn_b
I0420 10:58:50.175834 28419 net.cpp:84] Creating Layer map64_2_bn_b
I0420 10:58:50.175838 28419 net.cpp:406] map64_2_bn_b <- map64_2_conv_b
I0420 10:58:50.175844 28419 net.cpp:367] map64_2_bn_b -> map64_2_conv_b (in-place)
I0420 10:58:50.176020 28419 net.cpp:122] Setting up map64_2_bn_b
I0420 10:58:50.176026 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.176029 28419 net.cpp:137] Memory required for data: 521668608
I0420 10:58:50.176048 28419 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0420 10:58:50.176054 28419 net.cpp:84] Creating Layer map64_2_scale_b
I0420 10:58:50.176057 28419 net.cpp:406] map64_2_scale_b <- map64_2_conv_b
I0420 10:58:50.176061 28419 net.cpp:367] map64_2_scale_b -> map64_2_conv_b (in-place)
I0420 10:58:50.176095 28419 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0420 10:58:50.176190 28419 net.cpp:122] Setting up map64_2_scale_b
I0420 10:58:50.176195 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.176198 28419 net.cpp:137] Memory required for data: 523765760
I0420 10:58:50.176203 28419 layer_factory.hpp:77] Creating layer map64_2_eltsum
I0420 10:58:50.176209 28419 net.cpp:84] Creating Layer map64_2_eltsum
I0420 10:58:50.176213 28419 net.cpp:406] map64_2_eltsum <- map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0420 10:58:50.176216 28419 net.cpp:406] map64_2_eltsum <- map64_2_conv_b
I0420 10:58:50.176220 28419 net.cpp:380] map64_2_eltsum -> map64_2_eltsum
I0420 10:58:50.176236 28419 net.cpp:122] Setting up map64_2_eltsum
I0420 10:58:50.176240 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.176244 28419 net.cpp:137] Memory required for data: 525862912
I0420 10:58:50.176245 28419 layer_factory.hpp:77] Creating layer map64_2_relu_after_sum
I0420 10:58:50.176249 28419 net.cpp:84] Creating Layer map64_2_relu_after_sum
I0420 10:58:50.176252 28419 net.cpp:406] map64_2_relu_after_sum <- map64_2_eltsum
I0420 10:58:50.176255 28419 net.cpp:367] map64_2_relu_after_sum -> map64_2_eltsum (in-place)
I0420 10:58:50.176415 28419 net.cpp:122] Setting up map64_2_relu_after_sum
I0420 10:58:50.176422 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.176424 28419 net.cpp:137] Memory required for data: 527960064
I0420 10:58:50.176427 28419 layer_factory.hpp:77] Creating layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 10:58:50.176431 28419 net.cpp:84] Creating Layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 10:58:50.176435 28419 net.cpp:406] map64_2_eltsum_map64_2_relu_after_sum_0_split <- map64_2_eltsum
I0420 10:58:50.176450 28419 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0420 10:58:50.176458 28419 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0420 10:58:50.176496 28419 net.cpp:122] Setting up map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 10:58:50.176501 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.176506 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.176508 28419 net.cpp:137] Memory required for data: 532154368
I0420 10:58:50.176511 28419 layer_factory.hpp:77] Creating layer map64_3_conv_a
I0420 10:58:50.176520 28419 net.cpp:84] Creating Layer map64_3_conv_a
I0420 10:58:50.176524 28419 net.cpp:406] map64_3_conv_a <- map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0420 10:58:50.176528 28419 net.cpp:380] map64_3_conv_a -> map64_3_conv_a
I0420 10:58:50.177799 28419 net.cpp:122] Setting up map64_3_conv_a
I0420 10:58:50.177811 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.177814 28419 net.cpp:137] Memory required for data: 534251520
I0420 10:58:50.177819 28419 layer_factory.hpp:77] Creating layer map64_3_bn_a
I0420 10:58:50.177829 28419 net.cpp:84] Creating Layer map64_3_bn_a
I0420 10:58:50.177832 28419 net.cpp:406] map64_3_bn_a <- map64_3_conv_a
I0420 10:58:50.177839 28419 net.cpp:367] map64_3_bn_a -> map64_3_conv_a (in-place)
I0420 10:58:50.178011 28419 net.cpp:122] Setting up map64_3_bn_a
I0420 10:58:50.178017 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.178020 28419 net.cpp:137] Memory required for data: 536348672
I0420 10:58:50.178025 28419 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0420 10:58:50.178033 28419 net.cpp:84] Creating Layer map64_3_scale_a
I0420 10:58:50.178036 28419 net.cpp:406] map64_3_scale_a <- map64_3_conv_a
I0420 10:58:50.178040 28419 net.cpp:367] map64_3_scale_a -> map64_3_conv_a (in-place)
I0420 10:58:50.178071 28419 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0420 10:58:50.178169 28419 net.cpp:122] Setting up map64_3_scale_a
I0420 10:58:50.178174 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.178175 28419 net.cpp:137] Memory required for data: 538445824
I0420 10:58:50.178180 28419 layer_factory.hpp:77] Creating layer map64_3_relu_a
I0420 10:58:50.178186 28419 net.cpp:84] Creating Layer map64_3_relu_a
I0420 10:58:50.178189 28419 net.cpp:406] map64_3_relu_a <- map64_3_conv_a
I0420 10:58:50.178194 28419 net.cpp:367] map64_3_relu_a -> map64_3_conv_a (in-place)
I0420 10:58:50.178341 28419 net.cpp:122] Setting up map64_3_relu_a
I0420 10:58:50.178349 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.178351 28419 net.cpp:137] Memory required for data: 540542976
I0420 10:58:50.178354 28419 layer_factory.hpp:77] Creating layer map64_3_conv_b
I0420 10:58:50.178364 28419 net.cpp:84] Creating Layer map64_3_conv_b
I0420 10:58:50.178367 28419 net.cpp:406] map64_3_conv_b <- map64_3_conv_a
I0420 10:58:50.178372 28419 net.cpp:380] map64_3_conv_b -> map64_3_conv_b
I0420 10:58:50.179832 28419 net.cpp:122] Setting up map64_3_conv_b
I0420 10:58:50.179846 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.179849 28419 net.cpp:137] Memory required for data: 542640128
I0420 10:58:50.179855 28419 layer_factory.hpp:77] Creating layer map64_3_bn_b
I0420 10:58:50.179863 28419 net.cpp:84] Creating Layer map64_3_bn_b
I0420 10:58:50.179867 28419 net.cpp:406] map64_3_bn_b <- map64_3_conv_b
I0420 10:58:50.179875 28419 net.cpp:367] map64_3_bn_b -> map64_3_conv_b (in-place)
I0420 10:58:50.180088 28419 net.cpp:122] Setting up map64_3_bn_b
I0420 10:58:50.180094 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.180096 28419 net.cpp:137] Memory required for data: 544737280
I0420 10:58:50.180101 28419 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0420 10:58:50.180107 28419 net.cpp:84] Creating Layer map64_3_scale_b
I0420 10:58:50.180110 28419 net.cpp:406] map64_3_scale_b <- map64_3_conv_b
I0420 10:58:50.180125 28419 net.cpp:367] map64_3_scale_b -> map64_3_conv_b (in-place)
I0420 10:58:50.180158 28419 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0420 10:58:50.180258 28419 net.cpp:122] Setting up map64_3_scale_b
I0420 10:58:50.180265 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.180269 28419 net.cpp:137] Memory required for data: 546834432
I0420 10:58:50.180272 28419 layer_factory.hpp:77] Creating layer map64_3_eltsum
I0420 10:58:50.180279 28419 net.cpp:84] Creating Layer map64_3_eltsum
I0420 10:58:50.180281 28419 net.cpp:406] map64_3_eltsum <- map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0420 10:58:50.180285 28419 net.cpp:406] map64_3_eltsum <- map64_3_conv_b
I0420 10:58:50.180289 28419 net.cpp:380] map64_3_eltsum -> map64_3_eltsum
I0420 10:58:50.180307 28419 net.cpp:122] Setting up map64_3_eltsum
I0420 10:58:50.180312 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.180315 28419 net.cpp:137] Memory required for data: 548931584
I0420 10:58:50.180317 28419 layer_factory.hpp:77] Creating layer map64_3_relu_after_sum
I0420 10:58:50.180321 28419 net.cpp:84] Creating Layer map64_3_relu_after_sum
I0420 10:58:50.180325 28419 net.cpp:406] map64_3_relu_after_sum <- map64_3_eltsum
I0420 10:58:50.180330 28419 net.cpp:367] map64_3_relu_after_sum -> map64_3_eltsum (in-place)
I0420 10:58:50.180486 28419 net.cpp:122] Setting up map64_3_relu_after_sum
I0420 10:58:50.180493 28419 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 10:58:50.180496 28419 net.cpp:137] Memory required for data: 551028736
I0420 10:58:50.180498 28419 layer_factory.hpp:77] Creating layer pool_global
I0420 10:58:50.180506 28419 net.cpp:84] Creating Layer pool_global
I0420 10:58:50.180510 28419 net.cpp:406] pool_global <- map64_3_eltsum
I0420 10:58:50.180516 28419 net.cpp:380] pool_global -> pool_global
I0420 10:58:50.180712 28419 net.cpp:122] Setting up pool_global
I0420 10:58:50.180721 28419 net.cpp:129] Top shape: 128 64 1 1 (8192)
I0420 10:58:50.180723 28419 net.cpp:137] Memory required for data: 551061504
I0420 10:58:50.180726 28419 layer_factory.hpp:77] Creating layer score
I0420 10:58:50.180735 28419 net.cpp:84] Creating Layer score
I0420 10:58:50.180739 28419 net.cpp:406] score <- pool_global
I0420 10:58:50.180743 28419 net.cpp:380] score -> score
I0420 10:58:50.180852 28419 net.cpp:122] Setting up score
I0420 10:58:50.180857 28419 net.cpp:129] Top shape: 128 10 (1280)
I0420 10:58:50.180860 28419 net.cpp:137] Memory required for data: 551066624
I0420 10:58:50.180866 28419 layer_factory.hpp:77] Creating layer score_score_0_split
I0420 10:58:50.180871 28419 net.cpp:84] Creating Layer score_score_0_split
I0420 10:58:50.180873 28419 net.cpp:406] score_score_0_split <- score
I0420 10:58:50.180879 28419 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0420 10:58:50.180884 28419 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0420 10:58:50.180889 28419 net.cpp:380] score_score_0_split -> score_score_0_split_2
I0420 10:58:50.180929 28419 net.cpp:122] Setting up score_score_0_split
I0420 10:58:50.180934 28419 net.cpp:129] Top shape: 128 10 (1280)
I0420 10:58:50.180938 28419 net.cpp:129] Top shape: 128 10 (1280)
I0420 10:58:50.180940 28419 net.cpp:129] Top shape: 128 10 (1280)
I0420 10:58:50.180943 28419 net.cpp:137] Memory required for data: 551081984
I0420 10:58:50.180945 28419 layer_factory.hpp:77] Creating layer loss
I0420 10:58:50.180953 28419 net.cpp:84] Creating Layer loss
I0420 10:58:50.180955 28419 net.cpp:406] loss <- score_score_0_split_0
I0420 10:58:50.180959 28419 net.cpp:406] loss <- label_data_1_split_0
I0420 10:58:50.180963 28419 net.cpp:380] loss -> loss
I0420 10:58:50.180974 28419 layer_factory.hpp:77] Creating layer loss
I0420 10:58:50.181433 28419 net.cpp:122] Setting up loss
I0420 10:58:50.181444 28419 net.cpp:129] Top shape: (1)
I0420 10:58:50.181447 28419 net.cpp:132]     with loss weight 1
I0420 10:58:50.181473 28419 net.cpp:137] Memory required for data: 551081988
I0420 10:58:50.181475 28419 layer_factory.hpp:77] Creating layer acc/top1
I0420 10:58:50.181494 28419 net.cpp:84] Creating Layer acc/top1
I0420 10:58:50.181499 28419 net.cpp:406] acc/top1 <- score_score_0_split_1
I0420 10:58:50.181504 28419 net.cpp:406] acc/top1 <- label_data_1_split_1
I0420 10:58:50.181511 28419 net.cpp:380] acc/top1 -> acctop1
I0420 10:58:50.181524 28419 net.cpp:122] Setting up acc/top1
I0420 10:58:50.181529 28419 net.cpp:129] Top shape: (1)
I0420 10:58:50.181530 28419 net.cpp:137] Memory required for data: 551081992
I0420 10:58:50.181532 28419 layer_factory.hpp:77] Creating layer acc/top5
I0420 10:58:50.181536 28419 net.cpp:84] Creating Layer acc/top5
I0420 10:58:50.181540 28419 net.cpp:406] acc/top5 <- score_score_0_split_2
I0420 10:58:50.181543 28419 net.cpp:406] acc/top5 <- label_data_1_split_2
I0420 10:58:50.181548 28419 net.cpp:380] acc/top5 -> acctop5
I0420 10:58:50.181555 28419 net.cpp:122] Setting up acc/top5
I0420 10:58:50.181557 28419 net.cpp:129] Top shape: (1)
I0420 10:58:50.181560 28419 net.cpp:137] Memory required for data: 551081996
I0420 10:58:50.181563 28419 net.cpp:200] acc/top5 does not need backward computation.
I0420 10:58:50.181566 28419 net.cpp:200] acc/top1 does not need backward computation.
I0420 10:58:50.181569 28419 net.cpp:198] loss needs backward computation.
I0420 10:58:50.181572 28419 net.cpp:198] score_score_0_split needs backward computation.
I0420 10:58:50.181574 28419 net.cpp:198] score needs backward computation.
I0420 10:58:50.181577 28419 net.cpp:198] pool_global needs backward computation.
I0420 10:58:50.181581 28419 net.cpp:198] map64_3_relu_after_sum needs backward computation.
I0420 10:58:50.181582 28419 net.cpp:198] map64_3_eltsum needs backward computation.
I0420 10:58:50.181586 28419 net.cpp:198] map64_3_scale_b needs backward computation.
I0420 10:58:50.181587 28419 net.cpp:198] map64_3_bn_b needs backward computation.
I0420 10:58:50.181591 28419 net.cpp:198] map64_3_conv_b needs backward computation.
I0420 10:58:50.181592 28419 net.cpp:198] map64_3_relu_a needs backward computation.
I0420 10:58:50.181596 28419 net.cpp:198] map64_3_scale_a needs backward computation.
I0420 10:58:50.181597 28419 net.cpp:198] map64_3_bn_a needs backward computation.
I0420 10:58:50.181599 28419 net.cpp:198] map64_3_conv_a needs backward computation.
I0420 10:58:50.181602 28419 net.cpp:198] map64_2_eltsum_map64_2_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.181605 28419 net.cpp:198] map64_2_relu_after_sum needs backward computation.
I0420 10:58:50.181607 28419 net.cpp:198] map64_2_eltsum needs backward computation.
I0420 10:58:50.181610 28419 net.cpp:198] map64_2_scale_b needs backward computation.
I0420 10:58:50.181612 28419 net.cpp:198] map64_2_bn_b needs backward computation.
I0420 10:58:50.181614 28419 net.cpp:198] map64_2_conv_b needs backward computation.
I0420 10:58:50.181617 28419 net.cpp:198] map64_2_relu_a needs backward computation.
I0420 10:58:50.181619 28419 net.cpp:198] map64_2_scale_a needs backward computation.
I0420 10:58:50.181622 28419 net.cpp:198] map64_2_bn_a needs backward computation.
I0420 10:58:50.181623 28419 net.cpp:198] map64_2_conv_a needs backward computation.
I0420 10:58:50.181627 28419 net.cpp:198] map64_1_eltsum_map64_1_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.181629 28419 net.cpp:198] map64_1_relu_after_sum needs backward computation.
I0420 10:58:50.181632 28419 net.cpp:198] map64_1_eltsum needs backward computation.
I0420 10:58:50.181634 28419 net.cpp:198] map64_1_scale_b needs backward computation.
I0420 10:58:50.181637 28419 net.cpp:198] map64_1_bn_b needs backward computation.
I0420 10:58:50.181638 28419 net.cpp:198] map64_1_conv_b needs backward computation.
I0420 10:58:50.181641 28419 net.cpp:198] map64_1_relu_a needs backward computation.
I0420 10:58:50.181643 28419 net.cpp:198] map64_1_scale_a needs backward computation.
I0420 10:58:50.181645 28419 net.cpp:198] map64_1_bn_a needs backward computation.
I0420 10:58:50.181648 28419 net.cpp:198] map64_1_conv_a needs backward computation.
I0420 10:58:50.181650 28419 net.cpp:198] map64_1_scale_proj needs backward computation.
I0420 10:58:50.181659 28419 net.cpp:198] map64_1_bn_proj needs backward computation.
I0420 10:58:50.181663 28419 net.cpp:198] map64_1_conv_proj needs backward computation.
I0420 10:58:50.181664 28419 net.cpp:198] map32_3_eltsum_map32_3_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.181666 28419 net.cpp:198] map32_3_relu_after_sum needs backward computation.
I0420 10:58:50.181668 28419 net.cpp:198] map32_3_eltsum needs backward computation.
I0420 10:58:50.181673 28419 net.cpp:198] map32_3_scale_b needs backward computation.
I0420 10:58:50.181674 28419 net.cpp:198] map32_3_bn_b needs backward computation.
I0420 10:58:50.181676 28419 net.cpp:198] map32_3_conv_b needs backward computation.
I0420 10:58:50.181679 28419 net.cpp:198] map32_3_relu_a needs backward computation.
I0420 10:58:50.181685 28419 net.cpp:198] map32_3_scale_a needs backward computation.
I0420 10:58:50.181689 28419 net.cpp:198] map32_3_bn_a needs backward computation.
I0420 10:58:50.181691 28419 net.cpp:198] map32_3_conv_a needs backward computation.
I0420 10:58:50.181694 28419 net.cpp:198] map32_2_eltsum_map32_2_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.181695 28419 net.cpp:198] map32_2_relu_after_sum needs backward computation.
I0420 10:58:50.181699 28419 net.cpp:198] map32_2_eltsum needs backward computation.
I0420 10:58:50.181700 28419 net.cpp:198] map32_2_scale_b needs backward computation.
I0420 10:58:50.181704 28419 net.cpp:198] map32_2_bn_b needs backward computation.
I0420 10:58:50.181705 28419 net.cpp:198] map32_2_conv_b needs backward computation.
I0420 10:58:50.181709 28419 net.cpp:198] map32_2_relu_a needs backward computation.
I0420 10:58:50.181710 28419 net.cpp:198] map32_2_scale_a needs backward computation.
I0420 10:58:50.181713 28419 net.cpp:198] map32_2_bn_a needs backward computation.
I0420 10:58:50.181715 28419 net.cpp:198] map32_2_conv_a needs backward computation.
I0420 10:58:50.181717 28419 net.cpp:198] map32_1_eltsum_map32_1_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.181720 28419 net.cpp:198] map32_1_relu_after_sum needs backward computation.
I0420 10:58:50.181722 28419 net.cpp:198] map32_1_eltsum needs backward computation.
I0420 10:58:50.181725 28419 net.cpp:198] map32_1_scale_b needs backward computation.
I0420 10:58:50.181727 28419 net.cpp:198] map32_1_bn_b needs backward computation.
I0420 10:58:50.181730 28419 net.cpp:198] map32_1_conv_b needs backward computation.
I0420 10:58:50.181732 28419 net.cpp:198] map32_1_relu_a needs backward computation.
I0420 10:58:50.181735 28419 net.cpp:198] map32_1_scale_a needs backward computation.
I0420 10:58:50.181736 28419 net.cpp:198] map32_1_bn_a needs backward computation.
I0420 10:58:50.181740 28419 net.cpp:198] map32_1_conv_a needs backward computation.
I0420 10:58:50.181741 28419 net.cpp:198] map32_1_scale_proj needs backward computation.
I0420 10:58:50.181744 28419 net.cpp:198] map32_1_bn_proj needs backward computation.
I0420 10:58:50.181746 28419 net.cpp:198] map32_1_conv_proj needs backward computation.
I0420 10:58:50.181749 28419 net.cpp:198] map16_3_eltsum_map16_3_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.181752 28419 net.cpp:198] map16_3_relu_after_sum needs backward computation.
I0420 10:58:50.181754 28419 net.cpp:198] map16_3_eltsum needs backward computation.
I0420 10:58:50.181758 28419 net.cpp:198] map16_3_scale_b needs backward computation.
I0420 10:58:50.181761 28419 net.cpp:198] map16_3_bn_b needs backward computation.
I0420 10:58:50.181763 28419 net.cpp:198] map16_3_conv_b needs backward computation.
I0420 10:58:50.181766 28419 net.cpp:198] map16_3_relu_a needs backward computation.
I0420 10:58:50.181768 28419 net.cpp:198] map16_3_scale_a needs backward computation.
I0420 10:58:50.181771 28419 net.cpp:198] map16_3_bn_a needs backward computation.
I0420 10:58:50.181772 28419 net.cpp:198] map16_3_conv_a needs backward computation.
I0420 10:58:50.181792 28419 net.cpp:198] map16_2_eltsum_map16_2_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.181795 28419 net.cpp:198] map16_2_relu_after_sum needs backward computation.
I0420 10:58:50.181803 28419 net.cpp:198] map16_2_eltsum needs backward computation.
I0420 10:58:50.181805 28419 net.cpp:198] map16_2_scale_b needs backward computation.
I0420 10:58:50.181808 28419 net.cpp:198] map16_2_bn_b needs backward computation.
I0420 10:58:50.181810 28419 net.cpp:198] map16_2_conv_b needs backward computation.
I0420 10:58:50.181813 28419 net.cpp:198] map16_2_relu_a needs backward computation.
I0420 10:58:50.181814 28419 net.cpp:198] map16_2_scale_a needs backward computation.
I0420 10:58:50.181818 28419 net.cpp:198] map16_2_bn_a needs backward computation.
I0420 10:58:50.181820 28419 net.cpp:198] map16_2_conv_a needs backward computation.
I0420 10:58:50.181823 28419 net.cpp:198] map16_1_eltsum_map16_1_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.181824 28419 net.cpp:198] map16_1_relu_after_sum needs backward computation.
I0420 10:58:50.181828 28419 net.cpp:198] map16_1_eltsum needs backward computation.
I0420 10:58:50.181830 28419 net.cpp:198] map16_1_scale_b needs backward computation.
I0420 10:58:50.181833 28419 net.cpp:198] map16_1_bn_b needs backward computation.
I0420 10:58:50.181835 28419 net.cpp:198] map16_1_conv_b needs backward computation.
I0420 10:58:50.181838 28419 net.cpp:198] map16_1_relu_a needs backward computation.
I0420 10:58:50.181839 28419 net.cpp:198] map16_1_scale_a needs backward computation.
I0420 10:58:50.181843 28419 net.cpp:198] map16_1_bn_a needs backward computation.
I0420 10:58:50.181844 28419 net.cpp:198] map16_1_conv_a needs backward computation.
I0420 10:58:50.181848 28419 net.cpp:198] conv1_relu_conv1_0_split needs backward computation.
I0420 10:58:50.181850 28419 net.cpp:198] relu_conv1 needs backward computation.
I0420 10:58:50.181852 28419 net.cpp:198] scale_conv1 needs backward computation.
I0420 10:58:50.181854 28419 net.cpp:198] bn_conv1 needs backward computation.
I0420 10:58:50.181857 28419 net.cpp:198] conv1 needs backward computation.
I0420 10:58:50.181861 28419 net.cpp:200] label_data_1_split does not need backward computation.
I0420 10:58:50.181865 28419 net.cpp:200] data does not need backward computation.
I0420 10:58:50.181869 28419 net.cpp:242] This network produces output acctop1
I0420 10:58:50.181870 28419 net.cpp:242] This network produces output acctop5
I0420 10:58:50.181874 28419 net.cpp:242] This network produces output loss
I0420 10:58:50.181926 28419 net.cpp:255] Network initialization done.
I0420 10:58:50.184628 28419 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet20_relu_msra_cifar10_fix_pattern.prototxt
I0420 10:58:50.184643 28419 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0420 10:58:50.184650 28419 solver.cpp:173] Creating test net (#0) specified by net file: resnet20_relu_msra_cifar10_fix_pattern.prototxt
I0420 10:58:50.184770 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0420 10:58:50.184778 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv1
I0420 10:58:50.184784 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_1_bn_a
I0420 10:58:50.184789 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_1_bn_b
I0420 10:58:50.184795 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_2_bn_a
I0420 10:58:50.184800 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_2_bn_b
I0420 10:58:50.184805 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_3_bn_a
I0420 10:58:50.184810 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_3_bn_b
I0420 10:58:50.184816 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_proj
I0420 10:58:50.184833 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_a
I0420 10:58:50.184836 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_b
I0420 10:58:50.184842 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_2_bn_a
I0420 10:58:50.184847 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_2_bn_b
I0420 10:58:50.184852 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_3_bn_a
I0420 10:58:50.184857 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_3_bn_b
I0420 10:58:50.184862 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_proj
I0420 10:58:50.184867 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_a
I0420 10:58:50.184872 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_b
I0420 10:58:50.184877 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_2_bn_a
I0420 10:58:50.184882 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_2_bn_b
I0420 10:58:50.184887 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_3_bn_a
I0420 10:58:50.184892 28419 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_3_bn_b
I0420 10:58:50.185339 28419 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 32
    mean_file: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/mean.binaryproto"
  }
  data_param {
    source: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_test_leveldb_copy/"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "map16_1_conv_a"
  type: "Convolution"
  bottom: "conv1"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_a"
  type: "BatchNorm"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_1_scale_a"
  type: "Scale"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_relu_a"
  type: "ReLU"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
}
layer {
  name: "map16_1_conv_b"
  type: "Convolution"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_b"
  type: "BatchNorm"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_1_scale_b"
  type: "Scale"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_eltsum"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "map16_1_conv_b"
  top: "map16_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_1_relu_after_sum"
  type: "ReLU"
  bottom: "map16_1_eltsum"
  top: "map16_1_eltsum"
}
layer {
  name: "map16_2_conv_a"
  type: "Convolution"
  bottom: "map16_1_eltsum"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_a"
  type: "BatchNorm"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_2_scale_a"
  type: "Scale"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_relu_a"
  type: "ReLU"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
}
layer {
  name: "map16_2_conv_b"
  type: "Convolution"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_b"
  type: "BatchNorm"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_2_scale_b"
  type: "Scale"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_eltsum"
  type: "Eltwise"
  bottom: "map16_1_eltsum"
  bottom: "map16_2_conv_b"
  top: "map16_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_2_relu_after_sum"
  type: "ReLU"
  bottom: "map16_2_eltsum"
  top: "map16_2_eltsum"
}
layer {
  name: "map16_3_conv_a"
  type: "Convolution"
  bottom: "map16_2_eltsum"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_a"
  type: "BatchNorm"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_3_scale_a"
  type: "Scale"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_relu_a"
  type: "ReLU"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
}
layer {
  name: "map16_3_conv_b"
  type: "Convolution"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_b"
  type: "BatchNorm"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_3_scale_b"
  type: "Scale"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_eltsum"
  type: "Eltwise"
  bottom: "map16_2_eltsum"
  bottom: "map16_3_conv_b"
  top: "map16_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_3_relu_after_sum"
  type: "ReLU"
  bottom: "map16_3_eltsum"
  top: "map16_3_eltsum"
}
layer {
  name: "map32_1_conv_proj"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_proj"
  type: "BatchNorm"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_proj"
  type: "Scale"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_conv_a"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_a"
  type: "BatchNorm"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_a"
  type: "Scale"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_relu_a"
  type: "ReLU"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
}
layer {
  name: "map32_1_conv_b"
  type: "Convolution"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_b"
  type: "BatchNorm"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_b"
  type: "Scale"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_eltsum"
  type: "Eltwise"
  bottom: "map32_1_conv_proj"
  bottom: "map32_1_conv_b"
  top: "map32_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_1_relu_after_sum"
  type: "ReLU"
  bottom: "map32_1_eltsum"
  top: "map32_1_eltsum"
}
layer {
  name: "map32_2_conv_a"
  type: "Convolution"
  bottom: "map32_1_eltsum"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_a"
  type: "BatchNorm"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_2_scale_a"
  type: "Scale"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_relu_a"
  type: "ReLU"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
}
layer {
  name: "map32_2_conv_b"
  type: "Convolution"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_b"
  type: "BatchNorm"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_2_scale_b"
  type: "Scale"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_eltsum"
  type: "Eltwise"
  bottom: "map32_1_eltsum"
  bottom: "map32_2_conv_b"
  top: "map32_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_2_relu_after_sum"
  type: "ReLU"
  bottom: "map32_2_eltsum"
  top: "map32_2_eltsum"
}
layer {
  name: "map32_3_conv_a"
  type: "Convolution"
  bottom: "map32_2_eltsum"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_a"
  type: "BatchNorm"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_3_scale_a"
  type: "Scale"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_relu_a"
  type: "ReLU"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
}
layer {
  name: "map32_3_conv_b"
  type: "Convolution"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_b"
  type: "BatchNorm"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_3_scale_b"
  type: "Scale"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_eltsum"
  type: "Eltwise"
  bottom: "map32_2_eltsum"
  bottom: "map32_3_conv_b"
  top: "map32_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_3_relu_after_sum"
  type: "ReLU"
  bottom: "map32_3_eltsum"
  top: "map32_3_eltsum"
}
layer {
  name: "map64_1_conv_proj"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_proj"
  type: "BatchNorm"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_proj"
  type: "Scale"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_conv_a"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_a"
  type: "BatchNorm"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_a"
  type: "Scale"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_relu_a"
  type: "ReLU"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
}
layer {
  name: "map64_1_conv_b"
  type: "Convolution"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_b"
  type: "BatchNorm"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_b"
  type: "Scale"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_eltsum"
  type: "Eltwise"
  bottom: "map64_1_conv_proj"
  bottom: "map64_1_conv_b"
  top: "map64_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_1_relu_after_sum"
  type: "ReLU"
  bottom: "map64_1_eltsum"
  top: "map64_1_eltsum"
}
layer {
  name: "map64_2_conv_a"
  type: "Convolution"
  bottom: "map64_1_eltsum"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_a"
  type: "BatchNorm"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_2_scale_a"
  type: "Scale"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_relu_a"
  type: "ReLU"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
}
layer {
  name: "map64_2_conv_b"
  type: "Convolution"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_b"
  type: "BatchNorm"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_2_scale_b"
  type: "Scale"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_eltsum"
  type: "Eltwise"
  bottom: "map64_1_eltsum"
  bottom: "map64_2_conv_b"
  top: "map64_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_2_relu_after_sum"
  type: "ReLU"
  bottom: "map64_2_eltsum"
  top: "map64_2_eltsum"
}
layer {
  name: "map64_3_conv_a"
  type: "Convolution"
  bottom: "map64_2_eltsum"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_a"
  type: "BatchNorm"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_3_scale_a"
  type: "Scale"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_relu_a"
  type: "ReLU"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
}
layer {
  name: "map64_3_conv_b"
  type: "Convolution"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_b"
  type: "BatchNorm"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_3_scale_b"
  type: "Scale"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_eltsum"
  type: "Eltwise"
  bottom: "map64_2_eltsum"
  bottom: "map64_3_conv_b"
  top: "map64_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_3_relu_after_sum"
  type: "ReLU"
  bottom: "map64_3_eltsum"
  top: "map64_3_eltsum"
}
layer {
  name: "pool_global"
  type: "Pooling"
  bottom: "map64_3_eltsum"
  top: "pool_global"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_global"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc/top1"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc/top5"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop5"
  accuracy_param {
    top_k: 5
  }
}
I0420 10:58:50.185677 28419 layer_factory.hpp:77] Creating layer data
I0420 10:58:50.196605 28419 db_leveldb.cpp:18] Opened leveldb /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_test_leveldb_copy/
I0420 10:58:50.197863 28419 net.cpp:84] Creating Layer data
I0420 10:58:50.197875 28419 net.cpp:380] data -> data
I0420 10:58:50.197899 28419 net.cpp:380] data -> label
I0420 10:58:50.197906 28419 data_transformer.cpp:25] Loading mean file from: /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/mean.binaryproto
I0420 10:58:50.198431 28419 data_layer.cpp:45] output data size: 100,3,32,32
I0420 10:58:50.204839 28419 net.cpp:122] Setting up data
I0420 10:58:50.204851 28419 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0420 10:58:50.204871 28419 net.cpp:129] Top shape: 100 (100)
I0420 10:58:50.204874 28419 net.cpp:137] Memory required for data: 1229200
I0420 10:58:50.204876 28419 layer_factory.hpp:77] Creating layer label_data_1_split
I0420 10:58:50.204883 28419 net.cpp:84] Creating Layer label_data_1_split
I0420 10:58:50.204886 28419 net.cpp:406] label_data_1_split <- label
I0420 10:58:50.204905 28419 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0420 10:58:50.204912 28419 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0420 10:58:50.204917 28419 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0420 10:58:50.204982 28419 net.cpp:122] Setting up label_data_1_split
I0420 10:58:50.205003 28419 net.cpp:129] Top shape: 100 (100)
I0420 10:58:50.205006 28419 net.cpp:129] Top shape: 100 (100)
I0420 10:58:50.205009 28419 net.cpp:129] Top shape: 100 (100)
I0420 10:58:50.205013 28419 net.cpp:137] Memory required for data: 1230400
I0420 10:58:50.205014 28419 layer_factory.hpp:77] Creating layer conv1
I0420 10:58:50.205025 28419 net.cpp:84] Creating Layer conv1
I0420 10:58:50.205029 28419 net.cpp:406] conv1 <- data
I0420 10:58:50.205035 28419 net.cpp:380] conv1 -> conv1
I0420 10:58:50.206431 28419 net.cpp:122] Setting up conv1
I0420 10:58:50.206444 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.206449 28419 net.cpp:137] Memory required for data: 7784000
I0420 10:58:50.206457 28419 layer_factory.hpp:77] Creating layer bn_conv1
I0420 10:58:50.206467 28419 net.cpp:84] Creating Layer bn_conv1
I0420 10:58:50.206471 28419 net.cpp:406] bn_conv1 <- conv1
I0420 10:58:50.206476 28419 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0420 10:58:50.206667 28419 net.cpp:122] Setting up bn_conv1
I0420 10:58:50.206674 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.206677 28419 net.cpp:137] Memory required for data: 14337600
I0420 10:58:50.206691 28419 layer_factory.hpp:77] Creating layer scale_conv1
I0420 10:58:50.206698 28419 net.cpp:84] Creating Layer scale_conv1
I0420 10:58:50.206702 28419 net.cpp:406] scale_conv1 <- conv1
I0420 10:58:50.206712 28419 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0420 10:58:50.206750 28419 layer_factory.hpp:77] Creating layer scale_conv1
I0420 10:58:50.206858 28419 net.cpp:122] Setting up scale_conv1
I0420 10:58:50.206866 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.206869 28419 net.cpp:137] Memory required for data: 20891200
I0420 10:58:50.206873 28419 layer_factory.hpp:77] Creating layer relu_conv1
I0420 10:58:50.206879 28419 net.cpp:84] Creating Layer relu_conv1
I0420 10:58:50.206883 28419 net.cpp:406] relu_conv1 <- conv1
I0420 10:58:50.206887 28419 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0420 10:58:50.207072 28419 net.cpp:122] Setting up relu_conv1
I0420 10:58:50.207082 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.207084 28419 net.cpp:137] Memory required for data: 27444800
I0420 10:58:50.207088 28419 layer_factory.hpp:77] Creating layer conv1_relu_conv1_0_split
I0420 10:58:50.207093 28419 net.cpp:84] Creating Layer conv1_relu_conv1_0_split
I0420 10:58:50.207108 28419 net.cpp:406] conv1_relu_conv1_0_split <- conv1
I0420 10:58:50.207114 28419 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_0
I0420 10:58:50.207121 28419 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_1
I0420 10:58:50.207165 28419 net.cpp:122] Setting up conv1_relu_conv1_0_split
I0420 10:58:50.207170 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.207175 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.207178 28419 net.cpp:137] Memory required for data: 40552000
I0420 10:58:50.207180 28419 layer_factory.hpp:77] Creating layer map16_1_conv_a
I0420 10:58:50.207191 28419 net.cpp:84] Creating Layer map16_1_conv_a
I0420 10:58:50.207195 28419 net.cpp:406] map16_1_conv_a <- conv1_relu_conv1_0_split_0
I0420 10:58:50.207201 28419 net.cpp:380] map16_1_conv_a -> map16_1_conv_a
I0420 10:58:50.208340 28419 net.cpp:122] Setting up map16_1_conv_a
I0420 10:58:50.208353 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.208355 28419 net.cpp:137] Memory required for data: 47105600
I0420 10:58:50.208364 28419 layer_factory.hpp:77] Creating layer map16_1_bn_a
I0420 10:58:50.208374 28419 net.cpp:84] Creating Layer map16_1_bn_a
I0420 10:58:50.208377 28419 net.cpp:406] map16_1_bn_a <- map16_1_conv_a
I0420 10:58:50.208384 28419 net.cpp:367] map16_1_bn_a -> map16_1_conv_a (in-place)
I0420 10:58:50.208650 28419 net.cpp:122] Setting up map16_1_bn_a
I0420 10:58:50.208657 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.208659 28419 net.cpp:137] Memory required for data: 53659200
I0420 10:58:50.208665 28419 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0420 10:58:50.208673 28419 net.cpp:84] Creating Layer map16_1_scale_a
I0420 10:58:50.208676 28419 net.cpp:406] map16_1_scale_a <- map16_1_conv_a
I0420 10:58:50.208685 28419 net.cpp:367] map16_1_scale_a -> map16_1_conv_a (in-place)
I0420 10:58:50.208726 28419 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0420 10:58:50.208835 28419 net.cpp:122] Setting up map16_1_scale_a
I0420 10:58:50.208842 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.208845 28419 net.cpp:137] Memory required for data: 60212800
I0420 10:58:50.208849 28419 layer_factory.hpp:77] Creating layer map16_1_relu_a
I0420 10:58:50.208855 28419 net.cpp:84] Creating Layer map16_1_relu_a
I0420 10:58:50.208859 28419 net.cpp:406] map16_1_relu_a <- map16_1_conv_a
I0420 10:58:50.208864 28419 net.cpp:367] map16_1_relu_a -> map16_1_conv_a (in-place)
I0420 10:58:50.209030 28419 net.cpp:122] Setting up map16_1_relu_a
I0420 10:58:50.209039 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.209043 28419 net.cpp:137] Memory required for data: 66766400
I0420 10:58:50.209046 28419 layer_factory.hpp:77] Creating layer map16_1_conv_b
I0420 10:58:50.209056 28419 net.cpp:84] Creating Layer map16_1_conv_b
I0420 10:58:50.209060 28419 net.cpp:406] map16_1_conv_b <- map16_1_conv_a
I0420 10:58:50.209066 28419 net.cpp:380] map16_1_conv_b -> map16_1_conv_b
I0420 10:58:50.210248 28419 net.cpp:122] Setting up map16_1_conv_b
I0420 10:58:50.210260 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.210263 28419 net.cpp:137] Memory required for data: 73320000
I0420 10:58:50.210269 28419 layer_factory.hpp:77] Creating layer map16_1_bn_b
I0420 10:58:50.210278 28419 net.cpp:84] Creating Layer map16_1_bn_b
I0420 10:58:50.210281 28419 net.cpp:406] map16_1_bn_b <- map16_1_conv_b
I0420 10:58:50.210286 28419 net.cpp:367] map16_1_bn_b -> map16_1_conv_b (in-place)
I0420 10:58:50.210494 28419 net.cpp:122] Setting up map16_1_bn_b
I0420 10:58:50.210500 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.210503 28419 net.cpp:137] Memory required for data: 79873600
I0420 10:58:50.210512 28419 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0420 10:58:50.210521 28419 net.cpp:84] Creating Layer map16_1_scale_b
I0420 10:58:50.210525 28419 net.cpp:406] map16_1_scale_b <- map16_1_conv_b
I0420 10:58:50.210530 28419 net.cpp:367] map16_1_scale_b -> map16_1_conv_b (in-place)
I0420 10:58:50.210649 28419 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0420 10:58:50.210785 28419 net.cpp:122] Setting up map16_1_scale_b
I0420 10:58:50.210793 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.210796 28419 net.cpp:137] Memory required for data: 86427200
I0420 10:58:50.210803 28419 layer_factory.hpp:77] Creating layer map16_1_eltsum
I0420 10:58:50.210808 28419 net.cpp:84] Creating Layer map16_1_eltsum
I0420 10:58:50.210811 28419 net.cpp:406] map16_1_eltsum <- conv1_relu_conv1_0_split_1
I0420 10:58:50.210815 28419 net.cpp:406] map16_1_eltsum <- map16_1_conv_b
I0420 10:58:50.210822 28419 net.cpp:380] map16_1_eltsum -> map16_1_eltsum
I0420 10:58:50.210844 28419 net.cpp:122] Setting up map16_1_eltsum
I0420 10:58:50.210852 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.210855 28419 net.cpp:137] Memory required for data: 92980800
I0420 10:58:50.210857 28419 layer_factory.hpp:77] Creating layer map16_1_relu_after_sum
I0420 10:58:50.210861 28419 net.cpp:84] Creating Layer map16_1_relu_after_sum
I0420 10:58:50.210865 28419 net.cpp:406] map16_1_relu_after_sum <- map16_1_eltsum
I0420 10:58:50.210870 28419 net.cpp:367] map16_1_relu_after_sum -> map16_1_eltsum (in-place)
I0420 10:58:50.211055 28419 net.cpp:122] Setting up map16_1_relu_after_sum
I0420 10:58:50.211063 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.211067 28419 net.cpp:137] Memory required for data: 99534400
I0420 10:58:50.211071 28419 layer_factory.hpp:77] Creating layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 10:58:50.211076 28419 net.cpp:84] Creating Layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 10:58:50.211081 28419 net.cpp:406] map16_1_eltsum_map16_1_relu_after_sum_0_split <- map16_1_eltsum
I0420 10:58:50.211086 28419 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0420 10:58:50.211093 28419 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0420 10:58:50.211133 28419 net.cpp:122] Setting up map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 10:58:50.211138 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.211141 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.211144 28419 net.cpp:137] Memory required for data: 112641600
I0420 10:58:50.211148 28419 layer_factory.hpp:77] Creating layer map16_2_conv_a
I0420 10:58:50.211158 28419 net.cpp:84] Creating Layer map16_2_conv_a
I0420 10:58:50.211160 28419 net.cpp:406] map16_2_conv_a <- map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0420 10:58:50.211166 28419 net.cpp:380] map16_2_conv_a -> map16_2_conv_a
I0420 10:58:50.212266 28419 net.cpp:122] Setting up map16_2_conv_a
I0420 10:58:50.212280 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.212282 28419 net.cpp:137] Memory required for data: 119195200
I0420 10:58:50.212288 28419 layer_factory.hpp:77] Creating layer map16_2_bn_a
I0420 10:58:50.212296 28419 net.cpp:84] Creating Layer map16_2_bn_a
I0420 10:58:50.212301 28419 net.cpp:406] map16_2_bn_a <- map16_2_conv_a
I0420 10:58:50.212308 28419 net.cpp:367] map16_2_bn_a -> map16_2_conv_a (in-place)
I0420 10:58:50.212507 28419 net.cpp:122] Setting up map16_2_bn_a
I0420 10:58:50.212513 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.212517 28419 net.cpp:137] Memory required for data: 125748800
I0420 10:58:50.212523 28419 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0420 10:58:50.212530 28419 net.cpp:84] Creating Layer map16_2_scale_a
I0420 10:58:50.212533 28419 net.cpp:406] map16_2_scale_a <- map16_2_conv_a
I0420 10:58:50.212539 28419 net.cpp:367] map16_2_scale_a -> map16_2_conv_a (in-place)
I0420 10:58:50.212575 28419 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0420 10:58:50.212710 28419 net.cpp:122] Setting up map16_2_scale_a
I0420 10:58:50.212718 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.212720 28419 net.cpp:137] Memory required for data: 132302400
I0420 10:58:50.212736 28419 layer_factory.hpp:77] Creating layer map16_2_relu_a
I0420 10:58:50.212746 28419 net.cpp:84] Creating Layer map16_2_relu_a
I0420 10:58:50.212749 28419 net.cpp:406] map16_2_relu_a <- map16_2_conv_a
I0420 10:58:50.212754 28419 net.cpp:367] map16_2_relu_a -> map16_2_conv_a (in-place)
I0420 10:58:50.213222 28419 net.cpp:122] Setting up map16_2_relu_a
I0420 10:58:50.213230 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.213235 28419 net.cpp:137] Memory required for data: 138856000
I0420 10:58:50.213238 28419 layer_factory.hpp:77] Creating layer map16_2_conv_b
I0420 10:58:50.213246 28419 net.cpp:84] Creating Layer map16_2_conv_b
I0420 10:58:50.213251 28419 net.cpp:406] map16_2_conv_b <- map16_2_conv_a
I0420 10:58:50.213258 28419 net.cpp:380] map16_2_conv_b -> map16_2_conv_b
I0420 10:58:50.214582 28419 net.cpp:122] Setting up map16_2_conv_b
I0420 10:58:50.214594 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.214598 28419 net.cpp:137] Memory required for data: 145409600
I0420 10:58:50.214604 28419 layer_factory.hpp:77] Creating layer map16_2_bn_b
I0420 10:58:50.214614 28419 net.cpp:84] Creating Layer map16_2_bn_b
I0420 10:58:50.214618 28419 net.cpp:406] map16_2_bn_b <- map16_2_conv_b
I0420 10:58:50.214625 28419 net.cpp:367] map16_2_bn_b -> map16_2_conv_b (in-place)
I0420 10:58:50.214828 28419 net.cpp:122] Setting up map16_2_bn_b
I0420 10:58:50.214834 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.214838 28419 net.cpp:137] Memory required for data: 151963200
I0420 10:58:50.214848 28419 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0420 10:58:50.214854 28419 net.cpp:84] Creating Layer map16_2_scale_b
I0420 10:58:50.214857 28419 net.cpp:406] map16_2_scale_b <- map16_2_conv_b
I0420 10:58:50.214861 28419 net.cpp:367] map16_2_scale_b -> map16_2_conv_b (in-place)
I0420 10:58:50.214901 28419 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0420 10:58:50.215001 28419 net.cpp:122] Setting up map16_2_scale_b
I0420 10:58:50.215006 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.215009 28419 net.cpp:137] Memory required for data: 158516800
I0420 10:58:50.215014 28419 layer_factory.hpp:77] Creating layer map16_2_eltsum
I0420 10:58:50.215019 28419 net.cpp:84] Creating Layer map16_2_eltsum
I0420 10:58:50.215023 28419 net.cpp:406] map16_2_eltsum <- map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0420 10:58:50.215025 28419 net.cpp:406] map16_2_eltsum <- map16_2_conv_b
I0420 10:58:50.215031 28419 net.cpp:380] map16_2_eltsum -> map16_2_eltsum
I0420 10:58:50.215051 28419 net.cpp:122] Setting up map16_2_eltsum
I0420 10:58:50.215056 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.215059 28419 net.cpp:137] Memory required for data: 165070400
I0420 10:58:50.215061 28419 layer_factory.hpp:77] Creating layer map16_2_relu_after_sum
I0420 10:58:50.215068 28419 net.cpp:84] Creating Layer map16_2_relu_after_sum
I0420 10:58:50.215071 28419 net.cpp:406] map16_2_relu_after_sum <- map16_2_eltsum
I0420 10:58:50.215075 28419 net.cpp:367] map16_2_relu_after_sum -> map16_2_eltsum (in-place)
I0420 10:58:50.215469 28419 net.cpp:122] Setting up map16_2_relu_after_sum
I0420 10:58:50.215481 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.215484 28419 net.cpp:137] Memory required for data: 171624000
I0420 10:58:50.215487 28419 layer_factory.hpp:77] Creating layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 10:58:50.215493 28419 net.cpp:84] Creating Layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 10:58:50.215497 28419 net.cpp:406] map16_2_eltsum_map16_2_relu_after_sum_0_split <- map16_2_eltsum
I0420 10:58:50.215500 28419 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0420 10:58:50.215508 28419 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0420 10:58:50.215548 28419 net.cpp:122] Setting up map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 10:58:50.215564 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.215567 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.215569 28419 net.cpp:137] Memory required for data: 184731200
I0420 10:58:50.215571 28419 layer_factory.hpp:77] Creating layer map16_3_conv_a
I0420 10:58:50.215580 28419 net.cpp:84] Creating Layer map16_3_conv_a
I0420 10:58:50.215585 28419 net.cpp:406] map16_3_conv_a <- map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0420 10:58:50.215590 28419 net.cpp:380] map16_3_conv_a -> map16_3_conv_a
I0420 10:58:50.216311 28419 net.cpp:122] Setting up map16_3_conv_a
I0420 10:58:50.216320 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.216323 28419 net.cpp:137] Memory required for data: 191284800
I0420 10:58:50.216330 28419 layer_factory.hpp:77] Creating layer map16_3_bn_a
I0420 10:58:50.216337 28419 net.cpp:84] Creating Layer map16_3_bn_a
I0420 10:58:50.216341 28419 net.cpp:406] map16_3_bn_a <- map16_3_conv_a
I0420 10:58:50.216344 28419 net.cpp:367] map16_3_bn_a -> map16_3_conv_a (in-place)
I0420 10:58:50.216521 28419 net.cpp:122] Setting up map16_3_bn_a
I0420 10:58:50.216527 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.216529 28419 net.cpp:137] Memory required for data: 197838400
I0420 10:58:50.216536 28419 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0420 10:58:50.216542 28419 net.cpp:84] Creating Layer map16_3_scale_a
I0420 10:58:50.216545 28419 net.cpp:406] map16_3_scale_a <- map16_3_conv_a
I0420 10:58:50.216548 28419 net.cpp:367] map16_3_scale_a -> map16_3_conv_a (in-place)
I0420 10:58:50.216583 28419 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0420 10:58:50.216687 28419 net.cpp:122] Setting up map16_3_scale_a
I0420 10:58:50.216711 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.216713 28419 net.cpp:137] Memory required for data: 204392000
I0420 10:58:50.216717 28419 layer_factory.hpp:77] Creating layer map16_3_relu_a
I0420 10:58:50.216723 28419 net.cpp:84] Creating Layer map16_3_relu_a
I0420 10:58:50.216727 28419 net.cpp:406] map16_3_relu_a <- map16_3_conv_a
I0420 10:58:50.216730 28419 net.cpp:367] map16_3_relu_a -> map16_3_conv_a (in-place)
I0420 10:58:50.217136 28419 net.cpp:122] Setting up map16_3_relu_a
I0420 10:58:50.217149 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.217151 28419 net.cpp:137] Memory required for data: 210945600
I0420 10:58:50.217154 28419 layer_factory.hpp:77] Creating layer map16_3_conv_b
I0420 10:58:50.217164 28419 net.cpp:84] Creating Layer map16_3_conv_b
I0420 10:58:50.217167 28419 net.cpp:406] map16_3_conv_b <- map16_3_conv_a
I0420 10:58:50.217171 28419 net.cpp:380] map16_3_conv_b -> map16_3_conv_b
I0420 10:58:50.218169 28419 net.cpp:122] Setting up map16_3_conv_b
I0420 10:58:50.218180 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.218183 28419 net.cpp:137] Memory required for data: 217499200
I0420 10:58:50.218189 28419 layer_factory.hpp:77] Creating layer map16_3_bn_b
I0420 10:58:50.218201 28419 net.cpp:84] Creating Layer map16_3_bn_b
I0420 10:58:50.218204 28419 net.cpp:406] map16_3_bn_b <- map16_3_conv_b
I0420 10:58:50.218209 28419 net.cpp:367] map16_3_bn_b -> map16_3_conv_b (in-place)
I0420 10:58:50.218389 28419 net.cpp:122] Setting up map16_3_bn_b
I0420 10:58:50.218394 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.218397 28419 net.cpp:137] Memory required for data: 224052800
I0420 10:58:50.218403 28419 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0420 10:58:50.218408 28419 net.cpp:84] Creating Layer map16_3_scale_b
I0420 10:58:50.218411 28419 net.cpp:406] map16_3_scale_b <- map16_3_conv_b
I0420 10:58:50.218415 28419 net.cpp:367] map16_3_scale_b -> map16_3_conv_b (in-place)
I0420 10:58:50.218453 28419 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0420 10:58:50.218554 28419 net.cpp:122] Setting up map16_3_scale_b
I0420 10:58:50.218559 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.218561 28419 net.cpp:137] Memory required for data: 230606400
I0420 10:58:50.218577 28419 layer_factory.hpp:77] Creating layer map16_3_eltsum
I0420 10:58:50.218583 28419 net.cpp:84] Creating Layer map16_3_eltsum
I0420 10:58:50.218587 28419 net.cpp:406] map16_3_eltsum <- map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0420 10:58:50.218591 28419 net.cpp:406] map16_3_eltsum <- map16_3_conv_b
I0420 10:58:50.218595 28419 net.cpp:380] map16_3_eltsum -> map16_3_eltsum
I0420 10:58:50.218621 28419 net.cpp:122] Setting up map16_3_eltsum
I0420 10:58:50.218626 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.218628 28419 net.cpp:137] Memory required for data: 237160000
I0420 10:58:50.218631 28419 layer_factory.hpp:77] Creating layer map16_3_relu_after_sum
I0420 10:58:50.218634 28419 net.cpp:84] Creating Layer map16_3_relu_after_sum
I0420 10:58:50.218637 28419 net.cpp:406] map16_3_relu_after_sum <- map16_3_eltsum
I0420 10:58:50.218641 28419 net.cpp:367] map16_3_relu_after_sum -> map16_3_eltsum (in-place)
I0420 10:58:50.218804 28419 net.cpp:122] Setting up map16_3_relu_after_sum
I0420 10:58:50.218812 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.218816 28419 net.cpp:137] Memory required for data: 243713600
I0420 10:58:50.218817 28419 layer_factory.hpp:77] Creating layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 10:58:50.218823 28419 net.cpp:84] Creating Layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 10:58:50.218827 28419 net.cpp:406] map16_3_eltsum_map16_3_relu_after_sum_0_split <- map16_3_eltsum
I0420 10:58:50.218832 28419 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0420 10:58:50.218837 28419 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0420 10:58:50.218874 28419 net.cpp:122] Setting up map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 10:58:50.218880 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.218884 28419 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 10:58:50.218886 28419 net.cpp:137] Memory required for data: 256820800
I0420 10:58:50.218889 28419 layer_factory.hpp:77] Creating layer map32_1_conv_proj
I0420 10:58:50.218896 28419 net.cpp:84] Creating Layer map32_1_conv_proj
I0420 10:58:50.218900 28419 net.cpp:406] map32_1_conv_proj <- map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0420 10:58:50.218904 28419 net.cpp:380] map32_1_conv_proj -> map32_1_conv_proj
I0420 10:58:50.219907 28419 net.cpp:122] Setting up map32_1_conv_proj
I0420 10:58:50.219918 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.219921 28419 net.cpp:137] Memory required for data: 260097600
I0420 10:58:50.219926 28419 layer_factory.hpp:77] Creating layer map32_1_bn_proj
I0420 10:58:50.219934 28419 net.cpp:84] Creating Layer map32_1_bn_proj
I0420 10:58:50.219938 28419 net.cpp:406] map32_1_bn_proj <- map32_1_conv_proj
I0420 10:58:50.219943 28419 net.cpp:367] map32_1_bn_proj -> map32_1_conv_proj (in-place)
I0420 10:58:50.220118 28419 net.cpp:122] Setting up map32_1_bn_proj
I0420 10:58:50.220124 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.220126 28419 net.cpp:137] Memory required for data: 263374400
I0420 10:58:50.220131 28419 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0420 10:58:50.220136 28419 net.cpp:84] Creating Layer map32_1_scale_proj
I0420 10:58:50.220139 28419 net.cpp:406] map32_1_scale_proj <- map32_1_conv_proj
I0420 10:58:50.220144 28419 net.cpp:367] map32_1_scale_proj -> map32_1_conv_proj (in-place)
I0420 10:58:50.220178 28419 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0420 10:58:50.220278 28419 net.cpp:122] Setting up map32_1_scale_proj
I0420 10:58:50.220283 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.220285 28419 net.cpp:137] Memory required for data: 266651200
I0420 10:58:50.220289 28419 layer_factory.hpp:77] Creating layer map32_1_conv_a
I0420 10:58:50.220299 28419 net.cpp:84] Creating Layer map32_1_conv_a
I0420 10:58:50.220302 28419 net.cpp:406] map32_1_conv_a <- map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0420 10:58:50.220320 28419 net.cpp:380] map32_1_conv_a -> map32_1_conv_a
I0420 10:58:50.221412 28419 net.cpp:122] Setting up map32_1_conv_a
I0420 10:58:50.221424 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.221427 28419 net.cpp:137] Memory required for data: 269928000
I0420 10:58:50.221433 28419 layer_factory.hpp:77] Creating layer map32_1_bn_a
I0420 10:58:50.221441 28419 net.cpp:84] Creating Layer map32_1_bn_a
I0420 10:58:50.221446 28419 net.cpp:406] map32_1_bn_a <- map32_1_conv_a
I0420 10:58:50.221449 28419 net.cpp:367] map32_1_bn_a -> map32_1_conv_a (in-place)
I0420 10:58:50.221623 28419 net.cpp:122] Setting up map32_1_bn_a
I0420 10:58:50.221629 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.221632 28419 net.cpp:137] Memory required for data: 273204800
I0420 10:58:50.221638 28419 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0420 10:58:50.221644 28419 net.cpp:84] Creating Layer map32_1_scale_a
I0420 10:58:50.221647 28419 net.cpp:406] map32_1_scale_a <- map32_1_conv_a
I0420 10:58:50.221650 28419 net.cpp:367] map32_1_scale_a -> map32_1_conv_a (in-place)
I0420 10:58:50.221694 28419 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0420 10:58:50.221817 28419 net.cpp:122] Setting up map32_1_scale_a
I0420 10:58:50.221823 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.221825 28419 net.cpp:137] Memory required for data: 276481600
I0420 10:58:50.221830 28419 layer_factory.hpp:77] Creating layer map32_1_relu_a
I0420 10:58:50.221837 28419 net.cpp:84] Creating Layer map32_1_relu_a
I0420 10:58:50.221839 28419 net.cpp:406] map32_1_relu_a <- map32_1_conv_a
I0420 10:58:50.221843 28419 net.cpp:367] map32_1_relu_a -> map32_1_conv_a (in-place)
I0420 10:58:50.222025 28419 net.cpp:122] Setting up map32_1_relu_a
I0420 10:58:50.222034 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.222038 28419 net.cpp:137] Memory required for data: 279758400
I0420 10:58:50.222039 28419 layer_factory.hpp:77] Creating layer map32_1_conv_b
I0420 10:58:50.222048 28419 net.cpp:84] Creating Layer map32_1_conv_b
I0420 10:58:50.222051 28419 net.cpp:406] map32_1_conv_b <- map32_1_conv_a
I0420 10:58:50.222056 28419 net.cpp:380] map32_1_conv_b -> map32_1_conv_b
I0420 10:58:50.223163 28419 net.cpp:122] Setting up map32_1_conv_b
I0420 10:58:50.223176 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.223178 28419 net.cpp:137] Memory required for data: 283035200
I0420 10:58:50.223192 28419 layer_factory.hpp:77] Creating layer map32_1_bn_b
I0420 10:58:50.223199 28419 net.cpp:84] Creating Layer map32_1_bn_b
I0420 10:58:50.223203 28419 net.cpp:406] map32_1_bn_b <- map32_1_conv_b
I0420 10:58:50.223209 28419 net.cpp:367] map32_1_bn_b -> map32_1_conv_b (in-place)
I0420 10:58:50.223382 28419 net.cpp:122] Setting up map32_1_bn_b
I0420 10:58:50.223388 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.223392 28419 net.cpp:137] Memory required for data: 286312000
I0420 10:58:50.223397 28419 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0420 10:58:50.223404 28419 net.cpp:84] Creating Layer map32_1_scale_b
I0420 10:58:50.223407 28419 net.cpp:406] map32_1_scale_b <- map32_1_conv_b
I0420 10:58:50.223412 28419 net.cpp:367] map32_1_scale_b -> map32_1_conv_b (in-place)
I0420 10:58:50.223446 28419 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0420 10:58:50.223548 28419 net.cpp:122] Setting up map32_1_scale_b
I0420 10:58:50.223553 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.223556 28419 net.cpp:137] Memory required for data: 289588800
I0420 10:58:50.223562 28419 layer_factory.hpp:77] Creating layer map32_1_eltsum
I0420 10:58:50.223567 28419 net.cpp:84] Creating Layer map32_1_eltsum
I0420 10:58:50.223569 28419 net.cpp:406] map32_1_eltsum <- map32_1_conv_proj
I0420 10:58:50.223572 28419 net.cpp:406] map32_1_eltsum <- map32_1_conv_b
I0420 10:58:50.223578 28419 net.cpp:380] map32_1_eltsum -> map32_1_eltsum
I0420 10:58:50.223597 28419 net.cpp:122] Setting up map32_1_eltsum
I0420 10:58:50.223600 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.223613 28419 net.cpp:137] Memory required for data: 292865600
I0420 10:58:50.223616 28419 layer_factory.hpp:77] Creating layer map32_1_relu_after_sum
I0420 10:58:50.223623 28419 net.cpp:84] Creating Layer map32_1_relu_after_sum
I0420 10:58:50.223626 28419 net.cpp:406] map32_1_relu_after_sum <- map32_1_eltsum
I0420 10:58:50.223629 28419 net.cpp:367] map32_1_relu_after_sum -> map32_1_eltsum (in-place)
I0420 10:58:50.223791 28419 net.cpp:122] Setting up map32_1_relu_after_sum
I0420 10:58:50.223798 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.223801 28419 net.cpp:137] Memory required for data: 296142400
I0420 10:58:50.223803 28419 layer_factory.hpp:77] Creating layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 10:58:50.223810 28419 net.cpp:84] Creating Layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 10:58:50.223814 28419 net.cpp:406] map32_1_eltsum_map32_1_relu_after_sum_0_split <- map32_1_eltsum
I0420 10:58:50.223817 28419 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0420 10:58:50.223824 28419 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0420 10:58:50.223861 28419 net.cpp:122] Setting up map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 10:58:50.223866 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.223870 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.223871 28419 net.cpp:137] Memory required for data: 302696000
I0420 10:58:50.223875 28419 layer_factory.hpp:77] Creating layer map32_2_conv_a
I0420 10:58:50.223882 28419 net.cpp:84] Creating Layer map32_2_conv_a
I0420 10:58:50.223886 28419 net.cpp:406] map32_2_conv_a <- map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0420 10:58:50.223891 28419 net.cpp:380] map32_2_conv_a -> map32_2_conv_a
I0420 10:58:50.225178 28419 net.cpp:122] Setting up map32_2_conv_a
I0420 10:58:50.225190 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.225193 28419 net.cpp:137] Memory required for data: 305972800
I0420 10:58:50.225199 28419 layer_factory.hpp:77] Creating layer map32_2_bn_a
I0420 10:58:50.225208 28419 net.cpp:84] Creating Layer map32_2_bn_a
I0420 10:58:50.225211 28419 net.cpp:406] map32_2_bn_a <- map32_2_conv_a
I0420 10:58:50.225215 28419 net.cpp:367] map32_2_bn_a -> map32_2_conv_a (in-place)
I0420 10:58:50.225392 28419 net.cpp:122] Setting up map32_2_bn_a
I0420 10:58:50.225399 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.225400 28419 net.cpp:137] Memory required for data: 309249600
I0420 10:58:50.225409 28419 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0420 10:58:50.225414 28419 net.cpp:84] Creating Layer map32_2_scale_a
I0420 10:58:50.225417 28419 net.cpp:406] map32_2_scale_a <- map32_2_conv_a
I0420 10:58:50.225421 28419 net.cpp:367] map32_2_scale_a -> map32_2_conv_a (in-place)
I0420 10:58:50.225459 28419 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0420 10:58:50.225560 28419 net.cpp:122] Setting up map32_2_scale_a
I0420 10:58:50.225566 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.225569 28419 net.cpp:137] Memory required for data: 312526400
I0420 10:58:50.225574 28419 layer_factory.hpp:77] Creating layer map32_2_relu_a
I0420 10:58:50.225579 28419 net.cpp:84] Creating Layer map32_2_relu_a
I0420 10:58:50.225582 28419 net.cpp:406] map32_2_relu_a <- map32_2_conv_a
I0420 10:58:50.225585 28419 net.cpp:367] map32_2_relu_a -> map32_2_conv_a (in-place)
I0420 10:58:50.225749 28419 net.cpp:122] Setting up map32_2_relu_a
I0420 10:58:50.225756 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.225759 28419 net.cpp:137] Memory required for data: 315803200
I0420 10:58:50.225762 28419 layer_factory.hpp:77] Creating layer map32_2_conv_b
I0420 10:58:50.225772 28419 net.cpp:84] Creating Layer map32_2_conv_b
I0420 10:58:50.225776 28419 net.cpp:406] map32_2_conv_b <- map32_2_conv_a
I0420 10:58:50.225781 28419 net.cpp:380] map32_2_conv_b -> map32_2_conv_b
I0420 10:58:50.226933 28419 net.cpp:122] Setting up map32_2_conv_b
I0420 10:58:50.226963 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.226965 28419 net.cpp:137] Memory required for data: 319080000
I0420 10:58:50.226971 28419 layer_factory.hpp:77] Creating layer map32_2_bn_b
I0420 10:58:50.226982 28419 net.cpp:84] Creating Layer map32_2_bn_b
I0420 10:58:50.226986 28419 net.cpp:406] map32_2_bn_b <- map32_2_conv_b
I0420 10:58:50.226992 28419 net.cpp:367] map32_2_bn_b -> map32_2_conv_b (in-place)
I0420 10:58:50.227169 28419 net.cpp:122] Setting up map32_2_bn_b
I0420 10:58:50.227174 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.227177 28419 net.cpp:137] Memory required for data: 322356800
I0420 10:58:50.227182 28419 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0420 10:58:50.227187 28419 net.cpp:84] Creating Layer map32_2_scale_b
I0420 10:58:50.227191 28419 net.cpp:406] map32_2_scale_b <- map32_2_conv_b
I0420 10:58:50.227196 28419 net.cpp:367] map32_2_scale_b -> map32_2_conv_b (in-place)
I0420 10:58:50.227232 28419 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0420 10:58:50.227334 28419 net.cpp:122] Setting up map32_2_scale_b
I0420 10:58:50.227340 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.227342 28419 net.cpp:137] Memory required for data: 325633600
I0420 10:58:50.227347 28419 layer_factory.hpp:77] Creating layer map32_2_eltsum
I0420 10:58:50.227352 28419 net.cpp:84] Creating Layer map32_2_eltsum
I0420 10:58:50.227355 28419 net.cpp:406] map32_2_eltsum <- map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0420 10:58:50.227360 28419 net.cpp:406] map32_2_eltsum <- map32_2_conv_b
I0420 10:58:50.227363 28419 net.cpp:380] map32_2_eltsum -> map32_2_eltsum
I0420 10:58:50.227382 28419 net.cpp:122] Setting up map32_2_eltsum
I0420 10:58:50.227386 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.227390 28419 net.cpp:137] Memory required for data: 328910400
I0420 10:58:50.227391 28419 layer_factory.hpp:77] Creating layer map32_2_relu_after_sum
I0420 10:58:50.227396 28419 net.cpp:84] Creating Layer map32_2_relu_after_sum
I0420 10:58:50.227398 28419 net.cpp:406] map32_2_relu_after_sum <- map32_2_eltsum
I0420 10:58:50.227402 28419 net.cpp:367] map32_2_relu_after_sum -> map32_2_eltsum (in-place)
I0420 10:58:50.227560 28419 net.cpp:122] Setting up map32_2_relu_after_sum
I0420 10:58:50.227566 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.227569 28419 net.cpp:137] Memory required for data: 332187200
I0420 10:58:50.227571 28419 layer_factory.hpp:77] Creating layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 10:58:50.227576 28419 net.cpp:84] Creating Layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 10:58:50.227579 28419 net.cpp:406] map32_2_eltsum_map32_2_relu_after_sum_0_split <- map32_2_eltsum
I0420 10:58:50.227584 28419 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0420 10:58:50.227592 28419 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0420 10:58:50.227632 28419 net.cpp:122] Setting up map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 10:58:50.227636 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.227639 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.227641 28419 net.cpp:137] Memory required for data: 338740800
I0420 10:58:50.227644 28419 layer_factory.hpp:77] Creating layer map32_3_conv_a
I0420 10:58:50.227653 28419 net.cpp:84] Creating Layer map32_3_conv_a
I0420 10:58:50.227658 28419 net.cpp:406] map32_3_conv_a <- map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0420 10:58:50.227663 28419 net.cpp:380] map32_3_conv_a -> map32_3_conv_a
I0420 10:58:50.228814 28419 net.cpp:122] Setting up map32_3_conv_a
I0420 10:58:50.228826 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.228828 28419 net.cpp:137] Memory required for data: 342017600
I0420 10:58:50.228833 28419 layer_factory.hpp:77] Creating layer map32_3_bn_a
I0420 10:58:50.228842 28419 net.cpp:84] Creating Layer map32_3_bn_a
I0420 10:58:50.228857 28419 net.cpp:406] map32_3_bn_a <- map32_3_conv_a
I0420 10:58:50.228865 28419 net.cpp:367] map32_3_bn_a -> map32_3_conv_a (in-place)
I0420 10:58:50.229043 28419 net.cpp:122] Setting up map32_3_bn_a
I0420 10:58:50.229048 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.229051 28419 net.cpp:137] Memory required for data: 345294400
I0420 10:58:50.229058 28419 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0420 10:58:50.229063 28419 net.cpp:84] Creating Layer map32_3_scale_a
I0420 10:58:50.229065 28419 net.cpp:406] map32_3_scale_a <- map32_3_conv_a
I0420 10:58:50.229070 28419 net.cpp:367] map32_3_scale_a -> map32_3_conv_a (in-place)
I0420 10:58:50.229106 28419 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0420 10:58:50.229209 28419 net.cpp:122] Setting up map32_3_scale_a
I0420 10:58:50.229214 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.229218 28419 net.cpp:137] Memory required for data: 348571200
I0420 10:58:50.229221 28419 layer_factory.hpp:77] Creating layer map32_3_relu_a
I0420 10:58:50.229226 28419 net.cpp:84] Creating Layer map32_3_relu_a
I0420 10:58:50.229229 28419 net.cpp:406] map32_3_relu_a <- map32_3_conv_a
I0420 10:58:50.229233 28419 net.cpp:367] map32_3_relu_a -> map32_3_conv_a (in-place)
I0420 10:58:50.229666 28419 net.cpp:122] Setting up map32_3_relu_a
I0420 10:58:50.229677 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.229686 28419 net.cpp:137] Memory required for data: 351848000
I0420 10:58:50.229691 28419 layer_factory.hpp:77] Creating layer map32_3_conv_b
I0420 10:58:50.229706 28419 net.cpp:84] Creating Layer map32_3_conv_b
I0420 10:58:50.229709 28419 net.cpp:406] map32_3_conv_b <- map32_3_conv_a
I0420 10:58:50.229715 28419 net.cpp:380] map32_3_conv_b -> map32_3_conv_b
I0420 10:58:50.230768 28419 net.cpp:122] Setting up map32_3_conv_b
I0420 10:58:50.230779 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.230782 28419 net.cpp:137] Memory required for data: 355124800
I0420 10:58:50.230788 28419 layer_factory.hpp:77] Creating layer map32_3_bn_b
I0420 10:58:50.230798 28419 net.cpp:84] Creating Layer map32_3_bn_b
I0420 10:58:50.230801 28419 net.cpp:406] map32_3_bn_b <- map32_3_conv_b
I0420 10:58:50.230805 28419 net.cpp:367] map32_3_bn_b -> map32_3_conv_b (in-place)
I0420 10:58:50.231007 28419 net.cpp:122] Setting up map32_3_bn_b
I0420 10:58:50.231014 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.231016 28419 net.cpp:137] Memory required for data: 358401600
I0420 10:58:50.231024 28419 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0420 10:58:50.231029 28419 net.cpp:84] Creating Layer map32_3_scale_b
I0420 10:58:50.231031 28419 net.cpp:406] map32_3_scale_b <- map32_3_conv_b
I0420 10:58:50.231035 28419 net.cpp:367] map32_3_scale_b -> map32_3_conv_b (in-place)
I0420 10:58:50.231072 28419 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0420 10:58:50.231173 28419 net.cpp:122] Setting up map32_3_scale_b
I0420 10:58:50.231178 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.231181 28419 net.cpp:137] Memory required for data: 361678400
I0420 10:58:50.231185 28419 layer_factory.hpp:77] Creating layer map32_3_eltsum
I0420 10:58:50.231192 28419 net.cpp:84] Creating Layer map32_3_eltsum
I0420 10:58:50.231195 28419 net.cpp:406] map32_3_eltsum <- map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0420 10:58:50.231199 28419 net.cpp:406] map32_3_eltsum <- map32_3_conv_b
I0420 10:58:50.231204 28419 net.cpp:380] map32_3_eltsum -> map32_3_eltsum
I0420 10:58:50.231222 28419 net.cpp:122] Setting up map32_3_eltsum
I0420 10:58:50.231227 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.231230 28419 net.cpp:137] Memory required for data: 364955200
I0420 10:58:50.231232 28419 layer_factory.hpp:77] Creating layer map32_3_relu_after_sum
I0420 10:58:50.231236 28419 net.cpp:84] Creating Layer map32_3_relu_after_sum
I0420 10:58:50.231240 28419 net.cpp:406] map32_3_relu_after_sum <- map32_3_eltsum
I0420 10:58:50.231243 28419 net.cpp:367] map32_3_relu_after_sum -> map32_3_eltsum (in-place)
I0420 10:58:50.231407 28419 net.cpp:122] Setting up map32_3_relu_after_sum
I0420 10:58:50.231415 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.231418 28419 net.cpp:137] Memory required for data: 368232000
I0420 10:58:50.231420 28419 layer_factory.hpp:77] Creating layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 10:58:50.231426 28419 net.cpp:84] Creating Layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 10:58:50.231428 28419 net.cpp:406] map32_3_eltsum_map32_3_relu_after_sum_0_split <- map32_3_eltsum
I0420 10:58:50.231433 28419 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0420 10:58:50.231439 28419 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0420 10:58:50.231477 28419 net.cpp:122] Setting up map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 10:58:50.231483 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.231487 28419 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 10:58:50.231489 28419 net.cpp:137] Memory required for data: 374785600
I0420 10:58:50.231492 28419 layer_factory.hpp:77] Creating layer map64_1_conv_proj
I0420 10:58:50.231499 28419 net.cpp:84] Creating Layer map64_1_conv_proj
I0420 10:58:50.231503 28419 net.cpp:406] map64_1_conv_proj <- map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0420 10:58:50.231508 28419 net.cpp:380] map64_1_conv_proj -> map64_1_conv_proj
I0420 10:58:50.232653 28419 net.cpp:122] Setting up map64_1_conv_proj
I0420 10:58:50.232664 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.232668 28419 net.cpp:137] Memory required for data: 376424000
I0420 10:58:50.232673 28419 layer_factory.hpp:77] Creating layer map64_1_bn_proj
I0420 10:58:50.232687 28419 net.cpp:84] Creating Layer map64_1_bn_proj
I0420 10:58:50.232692 28419 net.cpp:406] map64_1_bn_proj <- map64_1_conv_proj
I0420 10:58:50.232697 28419 net.cpp:367] map64_1_bn_proj -> map64_1_conv_proj (in-place)
I0420 10:58:50.232883 28419 net.cpp:122] Setting up map64_1_bn_proj
I0420 10:58:50.232889 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.232892 28419 net.cpp:137] Memory required for data: 378062400
I0420 10:58:50.232897 28419 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0420 10:58:50.232903 28419 net.cpp:84] Creating Layer map64_1_scale_proj
I0420 10:58:50.232906 28419 net.cpp:406] map64_1_scale_proj <- map64_1_conv_proj
I0420 10:58:50.232910 28419 net.cpp:367] map64_1_scale_proj -> map64_1_conv_proj (in-place)
I0420 10:58:50.232950 28419 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0420 10:58:50.233055 28419 net.cpp:122] Setting up map64_1_scale_proj
I0420 10:58:50.233060 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.233063 28419 net.cpp:137] Memory required for data: 379700800
I0420 10:58:50.233067 28419 layer_factory.hpp:77] Creating layer map64_1_conv_a
I0420 10:58:50.233077 28419 net.cpp:84] Creating Layer map64_1_conv_a
I0420 10:58:50.233079 28419 net.cpp:406] map64_1_conv_a <- map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0420 10:58:50.233088 28419 net.cpp:380] map64_1_conv_a -> map64_1_conv_a
I0420 10:58:50.234241 28419 net.cpp:122] Setting up map64_1_conv_a
I0420 10:58:50.234254 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.234258 28419 net.cpp:137] Memory required for data: 381339200
I0420 10:58:50.234263 28419 layer_factory.hpp:77] Creating layer map64_1_bn_a
I0420 10:58:50.234271 28419 net.cpp:84] Creating Layer map64_1_bn_a
I0420 10:58:50.234273 28419 net.cpp:406] map64_1_bn_a <- map64_1_conv_a
I0420 10:58:50.234279 28419 net.cpp:367] map64_1_bn_a -> map64_1_conv_a (in-place)
I0420 10:58:50.234465 28419 net.cpp:122] Setting up map64_1_bn_a
I0420 10:58:50.234472 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.234473 28419 net.cpp:137] Memory required for data: 382977600
I0420 10:58:50.234478 28419 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0420 10:58:50.234494 28419 net.cpp:84] Creating Layer map64_1_scale_a
I0420 10:58:50.234498 28419 net.cpp:406] map64_1_scale_a <- map64_1_conv_a
I0420 10:58:50.234503 28419 net.cpp:367] map64_1_scale_a -> map64_1_conv_a (in-place)
I0420 10:58:50.234544 28419 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0420 10:58:50.234649 28419 net.cpp:122] Setting up map64_1_scale_a
I0420 10:58:50.234655 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.234658 28419 net.cpp:137] Memory required for data: 384616000
I0420 10:58:50.234663 28419 layer_factory.hpp:77] Creating layer map64_1_relu_a
I0420 10:58:50.234668 28419 net.cpp:84] Creating Layer map64_1_relu_a
I0420 10:58:50.234670 28419 net.cpp:406] map64_1_relu_a <- map64_1_conv_a
I0420 10:58:50.234675 28419 net.cpp:367] map64_1_relu_a -> map64_1_conv_a (in-place)
I0420 10:58:50.234838 28419 net.cpp:122] Setting up map64_1_relu_a
I0420 10:58:50.234846 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.234849 28419 net.cpp:137] Memory required for data: 386254400
I0420 10:58:50.234851 28419 layer_factory.hpp:77] Creating layer map64_1_conv_b
I0420 10:58:50.234859 28419 net.cpp:84] Creating Layer map64_1_conv_b
I0420 10:58:50.234863 28419 net.cpp:406] map64_1_conv_b <- map64_1_conv_a
I0420 10:58:50.234869 28419 net.cpp:380] map64_1_conv_b -> map64_1_conv_b
I0420 10:58:50.236187 28419 net.cpp:122] Setting up map64_1_conv_b
I0420 10:58:50.236198 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.236202 28419 net.cpp:137] Memory required for data: 387892800
I0420 10:58:50.236207 28419 layer_factory.hpp:77] Creating layer map64_1_bn_b
I0420 10:58:50.236217 28419 net.cpp:84] Creating Layer map64_1_bn_b
I0420 10:58:50.236220 28419 net.cpp:406] map64_1_bn_b <- map64_1_conv_b
I0420 10:58:50.236224 28419 net.cpp:367] map64_1_bn_b -> map64_1_conv_b (in-place)
I0420 10:58:50.236412 28419 net.cpp:122] Setting up map64_1_bn_b
I0420 10:58:50.236418 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.236420 28419 net.cpp:137] Memory required for data: 389531200
I0420 10:58:50.236425 28419 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0420 10:58:50.236433 28419 net.cpp:84] Creating Layer map64_1_scale_b
I0420 10:58:50.236436 28419 net.cpp:406] map64_1_scale_b <- map64_1_conv_b
I0420 10:58:50.236439 28419 net.cpp:367] map64_1_scale_b -> map64_1_conv_b (in-place)
I0420 10:58:50.236479 28419 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0420 10:58:50.236584 28419 net.cpp:122] Setting up map64_1_scale_b
I0420 10:58:50.236589 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.236593 28419 net.cpp:137] Memory required for data: 391169600
I0420 10:58:50.236598 28419 layer_factory.hpp:77] Creating layer map64_1_eltsum
I0420 10:58:50.236603 28419 net.cpp:84] Creating Layer map64_1_eltsum
I0420 10:58:50.236608 28419 net.cpp:406] map64_1_eltsum <- map64_1_conv_proj
I0420 10:58:50.236610 28419 net.cpp:406] map64_1_eltsum <- map64_1_conv_b
I0420 10:58:50.236614 28419 net.cpp:380] map64_1_eltsum -> map64_1_eltsum
I0420 10:58:50.236637 28419 net.cpp:122] Setting up map64_1_eltsum
I0420 10:58:50.236642 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.236645 28419 net.cpp:137] Memory required for data: 392808000
I0420 10:58:50.236647 28419 layer_factory.hpp:77] Creating layer map64_1_relu_after_sum
I0420 10:58:50.236651 28419 net.cpp:84] Creating Layer map64_1_relu_after_sum
I0420 10:58:50.236654 28419 net.cpp:406] map64_1_relu_after_sum <- map64_1_eltsum
I0420 10:58:50.236660 28419 net.cpp:367] map64_1_relu_after_sum -> map64_1_eltsum (in-place)
I0420 10:58:50.236838 28419 net.cpp:122] Setting up map64_1_relu_after_sum
I0420 10:58:50.236845 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.236850 28419 net.cpp:137] Memory required for data: 394446400
I0420 10:58:50.236851 28419 layer_factory.hpp:77] Creating layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 10:58:50.236856 28419 net.cpp:84] Creating Layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 10:58:50.236860 28419 net.cpp:406] map64_1_eltsum_map64_1_relu_after_sum_0_split <- map64_1_eltsum
I0420 10:58:50.236876 28419 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0420 10:58:50.236882 28419 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0420 10:58:50.236922 28419 net.cpp:122] Setting up map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 10:58:50.236930 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.236934 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.236937 28419 net.cpp:137] Memory required for data: 397723200
I0420 10:58:50.236939 28419 layer_factory.hpp:77] Creating layer map64_2_conv_a
I0420 10:58:50.236948 28419 net.cpp:84] Creating Layer map64_2_conv_a
I0420 10:58:50.236951 28419 net.cpp:406] map64_2_conv_a <- map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0420 10:58:50.236956 28419 net.cpp:380] map64_2_conv_a -> map64_2_conv_a
I0420 10:58:50.238245 28419 net.cpp:122] Setting up map64_2_conv_a
I0420 10:58:50.238258 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.238261 28419 net.cpp:137] Memory required for data: 399361600
I0420 10:58:50.238267 28419 layer_factory.hpp:77] Creating layer map64_2_bn_a
I0420 10:58:50.238276 28419 net.cpp:84] Creating Layer map64_2_bn_a
I0420 10:58:50.238279 28419 net.cpp:406] map64_2_bn_a <- map64_2_conv_a
I0420 10:58:50.238283 28419 net.cpp:367] map64_2_bn_a -> map64_2_conv_a (in-place)
I0420 10:58:50.238472 28419 net.cpp:122] Setting up map64_2_bn_a
I0420 10:58:50.238478 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.238481 28419 net.cpp:137] Memory required for data: 401000000
I0420 10:58:50.238487 28419 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0420 10:58:50.238492 28419 net.cpp:84] Creating Layer map64_2_scale_a
I0420 10:58:50.238495 28419 net.cpp:406] map64_2_scale_a <- map64_2_conv_a
I0420 10:58:50.238498 28419 net.cpp:367] map64_2_scale_a -> map64_2_conv_a (in-place)
I0420 10:58:50.238538 28419 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0420 10:58:50.238644 28419 net.cpp:122] Setting up map64_2_scale_a
I0420 10:58:50.238649 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.238652 28419 net.cpp:137] Memory required for data: 402638400
I0420 10:58:50.238656 28419 layer_factory.hpp:77] Creating layer map64_2_relu_a
I0420 10:58:50.238662 28419 net.cpp:84] Creating Layer map64_2_relu_a
I0420 10:58:50.238664 28419 net.cpp:406] map64_2_relu_a <- map64_2_conv_a
I0420 10:58:50.238669 28419 net.cpp:367] map64_2_relu_a -> map64_2_conv_a (in-place)
I0420 10:58:50.238828 28419 net.cpp:122] Setting up map64_2_relu_a
I0420 10:58:50.238836 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.238838 28419 net.cpp:137] Memory required for data: 404276800
I0420 10:58:50.238842 28419 layer_factory.hpp:77] Creating layer map64_2_conv_b
I0420 10:58:50.238850 28419 net.cpp:84] Creating Layer map64_2_conv_b
I0420 10:58:50.238853 28419 net.cpp:406] map64_2_conv_b <- map64_2_conv_a
I0420 10:58:50.238860 28419 net.cpp:380] map64_2_conv_b -> map64_2_conv_b
I0420 10:58:50.240170 28419 net.cpp:122] Setting up map64_2_conv_b
I0420 10:58:50.240180 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.240185 28419 net.cpp:137] Memory required for data: 405915200
I0420 10:58:50.240190 28419 layer_factory.hpp:77] Creating layer map64_2_bn_b
I0420 10:58:50.240198 28419 net.cpp:84] Creating Layer map64_2_bn_b
I0420 10:58:50.240201 28419 net.cpp:406] map64_2_bn_b <- map64_2_conv_b
I0420 10:58:50.240207 28419 net.cpp:367] map64_2_bn_b -> map64_2_conv_b (in-place)
I0420 10:58:50.240394 28419 net.cpp:122] Setting up map64_2_bn_b
I0420 10:58:50.240399 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.240402 28419 net.cpp:137] Memory required for data: 407553600
I0420 10:58:50.240419 28419 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0420 10:58:50.240427 28419 net.cpp:84] Creating Layer map64_2_scale_b
I0420 10:58:50.240430 28419 net.cpp:406] map64_2_scale_b <- map64_2_conv_b
I0420 10:58:50.240445 28419 net.cpp:367] map64_2_scale_b -> map64_2_conv_b (in-place)
I0420 10:58:50.240489 28419 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0420 10:58:50.240595 28419 net.cpp:122] Setting up map64_2_scale_b
I0420 10:58:50.240602 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.240603 28419 net.cpp:137] Memory required for data: 409192000
I0420 10:58:50.240608 28419 layer_factory.hpp:77] Creating layer map64_2_eltsum
I0420 10:58:50.240613 28419 net.cpp:84] Creating Layer map64_2_eltsum
I0420 10:58:50.240617 28419 net.cpp:406] map64_2_eltsum <- map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0420 10:58:50.240620 28419 net.cpp:406] map64_2_eltsum <- map64_2_conv_b
I0420 10:58:50.240624 28419 net.cpp:380] map64_2_eltsum -> map64_2_eltsum
I0420 10:58:50.240650 28419 net.cpp:122] Setting up map64_2_eltsum
I0420 10:58:50.240655 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.240658 28419 net.cpp:137] Memory required for data: 410830400
I0420 10:58:50.240660 28419 layer_factory.hpp:77] Creating layer map64_2_relu_after_sum
I0420 10:58:50.240664 28419 net.cpp:84] Creating Layer map64_2_relu_after_sum
I0420 10:58:50.240667 28419 net.cpp:406] map64_2_relu_after_sum <- map64_2_eltsum
I0420 10:58:50.240672 28419 net.cpp:367] map64_2_relu_after_sum -> map64_2_eltsum (in-place)
I0420 10:58:50.240859 28419 net.cpp:122] Setting up map64_2_relu_after_sum
I0420 10:58:50.240866 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.240869 28419 net.cpp:137] Memory required for data: 412468800
I0420 10:58:50.240872 28419 layer_factory.hpp:77] Creating layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 10:58:50.240877 28419 net.cpp:84] Creating Layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 10:58:50.240881 28419 net.cpp:406] map64_2_eltsum_map64_2_relu_after_sum_0_split <- map64_2_eltsum
I0420 10:58:50.240886 28419 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0420 10:58:50.240892 28419 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0420 10:58:50.240931 28419 net.cpp:122] Setting up map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 10:58:50.240938 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.240942 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.240944 28419 net.cpp:137] Memory required for data: 415745600
I0420 10:58:50.240947 28419 layer_factory.hpp:77] Creating layer map64_3_conv_a
I0420 10:58:50.240955 28419 net.cpp:84] Creating Layer map64_3_conv_a
I0420 10:58:50.240958 28419 net.cpp:406] map64_3_conv_a <- map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0420 10:58:50.240963 28419 net.cpp:380] map64_3_conv_a -> map64_3_conv_a
I0420 10:58:50.242636 28419 net.cpp:122] Setting up map64_3_conv_a
I0420 10:58:50.242647 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.242651 28419 net.cpp:137] Memory required for data: 417384000
I0420 10:58:50.242657 28419 layer_factory.hpp:77] Creating layer map64_3_bn_a
I0420 10:58:50.242666 28419 net.cpp:84] Creating Layer map64_3_bn_a
I0420 10:58:50.242669 28419 net.cpp:406] map64_3_bn_a <- map64_3_conv_a
I0420 10:58:50.242676 28419 net.cpp:367] map64_3_bn_a -> map64_3_conv_a (in-place)
I0420 10:58:50.242869 28419 net.cpp:122] Setting up map64_3_bn_a
I0420 10:58:50.242877 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.242879 28419 net.cpp:137] Memory required for data: 419022400
I0420 10:58:50.242887 28419 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0420 10:58:50.242892 28419 net.cpp:84] Creating Layer map64_3_scale_a
I0420 10:58:50.242895 28419 net.cpp:406] map64_3_scale_a <- map64_3_conv_a
I0420 10:58:50.242898 28419 net.cpp:367] map64_3_scale_a -> map64_3_conv_a (in-place)
I0420 10:58:50.242938 28419 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0420 10:58:50.243046 28419 net.cpp:122] Setting up map64_3_scale_a
I0420 10:58:50.243052 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.243065 28419 net.cpp:137] Memory required for data: 420660800
I0420 10:58:50.243070 28419 layer_factory.hpp:77] Creating layer map64_3_relu_a
I0420 10:58:50.243074 28419 net.cpp:84] Creating Layer map64_3_relu_a
I0420 10:58:50.243078 28419 net.cpp:406] map64_3_relu_a <- map64_3_conv_a
I0420 10:58:50.243083 28419 net.cpp:367] map64_3_relu_a -> map64_3_conv_a (in-place)
I0420 10:58:50.243475 28419 net.cpp:122] Setting up map64_3_relu_a
I0420 10:58:50.243486 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.243489 28419 net.cpp:137] Memory required for data: 422299200
I0420 10:58:50.243492 28419 layer_factory.hpp:77] Creating layer map64_3_conv_b
I0420 10:58:50.243502 28419 net.cpp:84] Creating Layer map64_3_conv_b
I0420 10:58:50.243506 28419 net.cpp:406] map64_3_conv_b <- map64_3_conv_a
I0420 10:58:50.243512 28419 net.cpp:380] map64_3_conv_b -> map64_3_conv_b
I0420 10:58:50.244705 28419 net.cpp:122] Setting up map64_3_conv_b
I0420 10:58:50.244715 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.244719 28419 net.cpp:137] Memory required for data: 423937600
I0420 10:58:50.244724 28419 layer_factory.hpp:77] Creating layer map64_3_bn_b
I0420 10:58:50.244731 28419 net.cpp:84] Creating Layer map64_3_bn_b
I0420 10:58:50.244735 28419 net.cpp:406] map64_3_bn_b <- map64_3_conv_b
I0420 10:58:50.244740 28419 net.cpp:367] map64_3_bn_b -> map64_3_conv_b (in-place)
I0420 10:58:50.244928 28419 net.cpp:122] Setting up map64_3_bn_b
I0420 10:58:50.244935 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.244936 28419 net.cpp:137] Memory required for data: 425576000
I0420 10:58:50.244942 28419 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0420 10:58:50.244947 28419 net.cpp:84] Creating Layer map64_3_scale_b
I0420 10:58:50.244951 28419 net.cpp:406] map64_3_scale_b <- map64_3_conv_b
I0420 10:58:50.244954 28419 net.cpp:367] map64_3_scale_b -> map64_3_conv_b (in-place)
I0420 10:58:50.244994 28419 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0420 10:58:50.245100 28419 net.cpp:122] Setting up map64_3_scale_b
I0420 10:58:50.245106 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.245110 28419 net.cpp:137] Memory required for data: 427214400
I0420 10:58:50.245115 28419 layer_factory.hpp:77] Creating layer map64_3_eltsum
I0420 10:58:50.245118 28419 net.cpp:84] Creating Layer map64_3_eltsum
I0420 10:58:50.245122 28419 net.cpp:406] map64_3_eltsum <- map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0420 10:58:50.245126 28419 net.cpp:406] map64_3_eltsum <- map64_3_conv_b
I0420 10:58:50.245131 28419 net.cpp:380] map64_3_eltsum -> map64_3_eltsum
I0420 10:58:50.245154 28419 net.cpp:122] Setting up map64_3_eltsum
I0420 10:58:50.245158 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.245162 28419 net.cpp:137] Memory required for data: 428852800
I0420 10:58:50.245164 28419 layer_factory.hpp:77] Creating layer map64_3_relu_after_sum
I0420 10:58:50.245167 28419 net.cpp:84] Creating Layer map64_3_relu_after_sum
I0420 10:58:50.245170 28419 net.cpp:406] map64_3_relu_after_sum <- map64_3_eltsum
I0420 10:58:50.245177 28419 net.cpp:367] map64_3_relu_after_sum -> map64_3_eltsum (in-place)
I0420 10:58:50.245568 28419 net.cpp:122] Setting up map64_3_relu_after_sum
I0420 10:58:50.245579 28419 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 10:58:50.245581 28419 net.cpp:137] Memory required for data: 430491200
I0420 10:58:50.245584 28419 layer_factory.hpp:77] Creating layer pool_global
I0420 10:58:50.245591 28419 net.cpp:84] Creating Layer pool_global
I0420 10:58:50.245594 28419 net.cpp:406] pool_global <- map64_3_eltsum
I0420 10:58:50.245600 28419 net.cpp:380] pool_global -> pool_global
I0420 10:58:50.245779 28419 net.cpp:122] Setting up pool_global
I0420 10:58:50.245789 28419 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0420 10:58:50.245791 28419 net.cpp:137] Memory required for data: 430516800
I0420 10:58:50.245795 28419 layer_factory.hpp:77] Creating layer score
I0420 10:58:50.245801 28419 net.cpp:84] Creating Layer score
I0420 10:58:50.245805 28419 net.cpp:406] score <- pool_global
I0420 10:58:50.245820 28419 net.cpp:380] score -> score
I0420 10:58:50.245936 28419 net.cpp:122] Setting up score
I0420 10:58:50.245942 28419 net.cpp:129] Top shape: 100 10 (1000)
I0420 10:58:50.245945 28419 net.cpp:137] Memory required for data: 430520800
I0420 10:58:50.245950 28419 layer_factory.hpp:77] Creating layer score_score_0_split
I0420 10:58:50.245955 28419 net.cpp:84] Creating Layer score_score_0_split
I0420 10:58:50.245959 28419 net.cpp:406] score_score_0_split <- score
I0420 10:58:50.245965 28419 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0420 10:58:50.245970 28419 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0420 10:58:50.245975 28419 net.cpp:380] score_score_0_split -> score_score_0_split_2
I0420 10:58:50.246022 28419 net.cpp:122] Setting up score_score_0_split
I0420 10:58:50.246026 28419 net.cpp:129] Top shape: 100 10 (1000)
I0420 10:58:50.246031 28419 net.cpp:129] Top shape: 100 10 (1000)
I0420 10:58:50.246033 28419 net.cpp:129] Top shape: 100 10 (1000)
I0420 10:58:50.246035 28419 net.cpp:137] Memory required for data: 430532800
I0420 10:58:50.246037 28419 layer_factory.hpp:77] Creating layer loss
I0420 10:58:50.246042 28419 net.cpp:84] Creating Layer loss
I0420 10:58:50.246044 28419 net.cpp:406] loss <- score_score_0_split_0
I0420 10:58:50.246047 28419 net.cpp:406] loss <- label_data_1_split_0
I0420 10:58:50.246052 28419 net.cpp:380] loss -> loss
I0420 10:58:50.246059 28419 layer_factory.hpp:77] Creating layer loss
I0420 10:58:50.246292 28419 net.cpp:122] Setting up loss
I0420 10:58:50.246301 28419 net.cpp:129] Top shape: (1)
I0420 10:58:50.246304 28419 net.cpp:132]     with loss weight 1
I0420 10:58:50.246312 28419 net.cpp:137] Memory required for data: 430532804
I0420 10:58:50.246315 28419 layer_factory.hpp:77] Creating layer acc/top1
I0420 10:58:50.246320 28419 net.cpp:84] Creating Layer acc/top1
I0420 10:58:50.246323 28419 net.cpp:406] acc/top1 <- score_score_0_split_1
I0420 10:58:50.246327 28419 net.cpp:406] acc/top1 <- label_data_1_split_1
I0420 10:58:50.246331 28419 net.cpp:380] acc/top1 -> acctop1
I0420 10:58:50.246338 28419 net.cpp:122] Setting up acc/top1
I0420 10:58:50.246342 28419 net.cpp:129] Top shape: (1)
I0420 10:58:50.246343 28419 net.cpp:137] Memory required for data: 430532808
I0420 10:58:50.246346 28419 layer_factory.hpp:77] Creating layer acc/top5
I0420 10:58:50.246351 28419 net.cpp:84] Creating Layer acc/top5
I0420 10:58:50.246354 28419 net.cpp:406] acc/top5 <- score_score_0_split_2
I0420 10:58:50.246358 28419 net.cpp:406] acc/top5 <- label_data_1_split_2
I0420 10:58:50.246362 28419 net.cpp:380] acc/top5 -> acctop5
I0420 10:58:50.246367 28419 net.cpp:122] Setting up acc/top5
I0420 10:58:50.246371 28419 net.cpp:129] Top shape: (1)
I0420 10:58:50.246372 28419 net.cpp:137] Memory required for data: 430532812
I0420 10:58:50.246376 28419 net.cpp:200] acc/top5 does not need backward computation.
I0420 10:58:50.246378 28419 net.cpp:200] acc/top1 does not need backward computation.
I0420 10:58:50.246381 28419 net.cpp:198] loss needs backward computation.
I0420 10:58:50.246384 28419 net.cpp:198] score_score_0_split needs backward computation.
I0420 10:58:50.246387 28419 net.cpp:198] score needs backward computation.
I0420 10:58:50.246389 28419 net.cpp:198] pool_global needs backward computation.
I0420 10:58:50.246392 28419 net.cpp:198] map64_3_relu_after_sum needs backward computation.
I0420 10:58:50.246394 28419 net.cpp:198] map64_3_eltsum needs backward computation.
I0420 10:58:50.246397 28419 net.cpp:198] map64_3_scale_b needs backward computation.
I0420 10:58:50.246399 28419 net.cpp:198] map64_3_bn_b needs backward computation.
I0420 10:58:50.246402 28419 net.cpp:198] map64_3_conv_b needs backward computation.
I0420 10:58:50.246405 28419 net.cpp:198] map64_3_relu_a needs backward computation.
I0420 10:58:50.246407 28419 net.cpp:198] map64_3_scale_a needs backward computation.
I0420 10:58:50.246409 28419 net.cpp:198] map64_3_bn_a needs backward computation.
I0420 10:58:50.246412 28419 net.cpp:198] map64_3_conv_a needs backward computation.
I0420 10:58:50.246424 28419 net.cpp:198] map64_2_eltsum_map64_2_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.246428 28419 net.cpp:198] map64_2_relu_after_sum needs backward computation.
I0420 10:58:50.246429 28419 net.cpp:198] map64_2_eltsum needs backward computation.
I0420 10:58:50.246431 28419 net.cpp:198] map64_2_scale_b needs backward computation.
I0420 10:58:50.246434 28419 net.cpp:198] map64_2_bn_b needs backward computation.
I0420 10:58:50.246436 28419 net.cpp:198] map64_2_conv_b needs backward computation.
I0420 10:58:50.246438 28419 net.cpp:198] map64_2_relu_a needs backward computation.
I0420 10:58:50.246440 28419 net.cpp:198] map64_2_scale_a needs backward computation.
I0420 10:58:50.246443 28419 net.cpp:198] map64_2_bn_a needs backward computation.
I0420 10:58:50.246445 28419 net.cpp:198] map64_2_conv_a needs backward computation.
I0420 10:58:50.246448 28419 net.cpp:198] map64_1_eltsum_map64_1_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.246449 28419 net.cpp:198] map64_1_relu_after_sum needs backward computation.
I0420 10:58:50.246453 28419 net.cpp:198] map64_1_eltsum needs backward computation.
I0420 10:58:50.246455 28419 net.cpp:198] map64_1_scale_b needs backward computation.
I0420 10:58:50.246462 28419 net.cpp:198] map64_1_bn_b needs backward computation.
I0420 10:58:50.246465 28419 net.cpp:198] map64_1_conv_b needs backward computation.
I0420 10:58:50.246467 28419 net.cpp:198] map64_1_relu_a needs backward computation.
I0420 10:58:50.246470 28419 net.cpp:198] map64_1_scale_a needs backward computation.
I0420 10:58:50.246472 28419 net.cpp:198] map64_1_bn_a needs backward computation.
I0420 10:58:50.246474 28419 net.cpp:198] map64_1_conv_a needs backward computation.
I0420 10:58:50.246476 28419 net.cpp:198] map64_1_scale_proj needs backward computation.
I0420 10:58:50.246479 28419 net.cpp:198] map64_1_bn_proj needs backward computation.
I0420 10:58:50.246481 28419 net.cpp:198] map64_1_conv_proj needs backward computation.
I0420 10:58:50.246484 28419 net.cpp:198] map32_3_eltsum_map32_3_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.246486 28419 net.cpp:198] map32_3_relu_after_sum needs backward computation.
I0420 10:58:50.246490 28419 net.cpp:198] map32_3_eltsum needs backward computation.
I0420 10:58:50.246492 28419 net.cpp:198] map32_3_scale_b needs backward computation.
I0420 10:58:50.246495 28419 net.cpp:198] map32_3_bn_b needs backward computation.
I0420 10:58:50.246497 28419 net.cpp:198] map32_3_conv_b needs backward computation.
I0420 10:58:50.246500 28419 net.cpp:198] map32_3_relu_a needs backward computation.
I0420 10:58:50.246501 28419 net.cpp:198] map32_3_scale_a needs backward computation.
I0420 10:58:50.246505 28419 net.cpp:198] map32_3_bn_a needs backward computation.
I0420 10:58:50.246506 28419 net.cpp:198] map32_3_conv_a needs backward computation.
I0420 10:58:50.246508 28419 net.cpp:198] map32_2_eltsum_map32_2_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.246511 28419 net.cpp:198] map32_2_relu_after_sum needs backward computation.
I0420 10:58:50.246513 28419 net.cpp:198] map32_2_eltsum needs backward computation.
I0420 10:58:50.246516 28419 net.cpp:198] map32_2_scale_b needs backward computation.
I0420 10:58:50.246520 28419 net.cpp:198] map32_2_bn_b needs backward computation.
I0420 10:58:50.246521 28419 net.cpp:198] map32_2_conv_b needs backward computation.
I0420 10:58:50.246523 28419 net.cpp:198] map32_2_relu_a needs backward computation.
I0420 10:58:50.246526 28419 net.cpp:198] map32_2_scale_a needs backward computation.
I0420 10:58:50.246528 28419 net.cpp:198] map32_2_bn_a needs backward computation.
I0420 10:58:50.246531 28419 net.cpp:198] map32_2_conv_a needs backward computation.
I0420 10:58:50.246532 28419 net.cpp:198] map32_1_eltsum_map32_1_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.246534 28419 net.cpp:198] map32_1_relu_after_sum needs backward computation.
I0420 10:58:50.246537 28419 net.cpp:198] map32_1_eltsum needs backward computation.
I0420 10:58:50.246539 28419 net.cpp:198] map32_1_scale_b needs backward computation.
I0420 10:58:50.246551 28419 net.cpp:198] map32_1_bn_b needs backward computation.
I0420 10:58:50.246553 28419 net.cpp:198] map32_1_conv_b needs backward computation.
I0420 10:58:50.246556 28419 net.cpp:198] map32_1_relu_a needs backward computation.
I0420 10:58:50.246558 28419 net.cpp:198] map32_1_scale_a needs backward computation.
I0420 10:58:50.246561 28419 net.cpp:198] map32_1_bn_a needs backward computation.
I0420 10:58:50.246562 28419 net.cpp:198] map32_1_conv_a needs backward computation.
I0420 10:58:50.246564 28419 net.cpp:198] map32_1_scale_proj needs backward computation.
I0420 10:58:50.246567 28419 net.cpp:198] map32_1_bn_proj needs backward computation.
I0420 10:58:50.246569 28419 net.cpp:198] map32_1_conv_proj needs backward computation.
I0420 10:58:50.246572 28419 net.cpp:198] map16_3_eltsum_map16_3_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.246575 28419 net.cpp:198] map16_3_relu_after_sum needs backward computation.
I0420 10:58:50.246577 28419 net.cpp:198] map16_3_eltsum needs backward computation.
I0420 10:58:50.246579 28419 net.cpp:198] map16_3_scale_b needs backward computation.
I0420 10:58:50.246582 28419 net.cpp:198] map16_3_bn_b needs backward computation.
I0420 10:58:50.246584 28419 net.cpp:198] map16_3_conv_b needs backward computation.
I0420 10:58:50.246587 28419 net.cpp:198] map16_3_relu_a needs backward computation.
I0420 10:58:50.246588 28419 net.cpp:198] map16_3_scale_a needs backward computation.
I0420 10:58:50.246592 28419 net.cpp:198] map16_3_bn_a needs backward computation.
I0420 10:58:50.246593 28419 net.cpp:198] map16_3_conv_a needs backward computation.
I0420 10:58:50.246597 28419 net.cpp:198] map16_2_eltsum_map16_2_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.246598 28419 net.cpp:198] map16_2_relu_after_sum needs backward computation.
I0420 10:58:50.246601 28419 net.cpp:198] map16_2_eltsum needs backward computation.
I0420 10:58:50.246603 28419 net.cpp:198] map16_2_scale_b needs backward computation.
I0420 10:58:50.246605 28419 net.cpp:198] map16_2_bn_b needs backward computation.
I0420 10:58:50.246608 28419 net.cpp:198] map16_2_conv_b needs backward computation.
I0420 10:58:50.246610 28419 net.cpp:198] map16_2_relu_a needs backward computation.
I0420 10:58:50.246613 28419 net.cpp:198] map16_2_scale_a needs backward computation.
I0420 10:58:50.246614 28419 net.cpp:198] map16_2_bn_a needs backward computation.
I0420 10:58:50.246616 28419 net.cpp:198] map16_2_conv_a needs backward computation.
I0420 10:58:50.246618 28419 net.cpp:198] map16_1_eltsum_map16_1_relu_after_sum_0_split needs backward computation.
I0420 10:58:50.246621 28419 net.cpp:198] map16_1_relu_after_sum needs backward computation.
I0420 10:58:50.246623 28419 net.cpp:198] map16_1_eltsum needs backward computation.
I0420 10:58:50.246626 28419 net.cpp:198] map16_1_scale_b needs backward computation.
I0420 10:58:50.246629 28419 net.cpp:198] map16_1_bn_b needs backward computation.
I0420 10:58:50.246631 28419 net.cpp:198] map16_1_conv_b needs backward computation.
I0420 10:58:50.246634 28419 net.cpp:198] map16_1_relu_a needs backward computation.
I0420 10:58:50.246635 28419 net.cpp:198] map16_1_scale_a needs backward computation.
I0420 10:58:50.246639 28419 net.cpp:198] map16_1_bn_a needs backward computation.
I0420 10:58:50.246640 28419 net.cpp:198] map16_1_conv_a needs backward computation.
I0420 10:58:50.246642 28419 net.cpp:198] conv1_relu_conv1_0_split needs backward computation.
I0420 10:58:50.246645 28419 net.cpp:198] relu_conv1 needs backward computation.
I0420 10:58:50.246649 28419 net.cpp:198] scale_conv1 needs backward computation.
I0420 10:58:50.246650 28419 net.cpp:198] bn_conv1 needs backward computation.
I0420 10:58:50.246654 28419 net.cpp:198] conv1 needs backward computation.
I0420 10:58:50.246656 28419 net.cpp:200] label_data_1_split does not need backward computation.
I0420 10:58:50.246660 28419 net.cpp:200] data does not need backward computation.
I0420 10:58:50.246662 28419 net.cpp:242] This network produces output acctop1
I0420 10:58:50.246670 28419 net.cpp:242] This network produces output acctop5
I0420 10:58:50.246673 28419 net.cpp:242] This network produces output loss
I0420 10:58:50.246745 28419 net.cpp:255] Network initialization done.
I0420 10:58:50.247031 28419 solver.cpp:56] Solver scaffolding done.
I0420 10:58:50.252604 28419 caffe.cpp:155] Finetuning from model/ResNet20_highway_padded_data_iter_80000_quant_0.09.caffemodel
I0420 10:58:50.256093 28419 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: model/ResNet20_highway_padded_data_iter_80000_quant_0.09.caffemodel
I0420 10:58:50.256106 28419 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0420 10:58:50.258196 28419 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: model/ResNet20_highway_padded_data_iter_80000_quant_0.09.caffemodel
I0420 10:58:50.258208 28419 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0420 10:58:50.258524 28419 caffe.cpp:248] Starting Optimization
I0420 10:58:50.258532 28419 solver.cpp:273] Solving 
I0420 10:58:50.258534 28419 solver.cpp:274] Learning Rate Policy: multistep
I0420 10:58:50.261580 28419 solver.cpp:331] Iteration 0, Testing net (#0)
I0420 10:58:52.739766 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 10:58:52.840138 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.1546
I0420 10:58:52.840173 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.5104
I0420 10:58:52.840203 28419 solver.cpp:398]     Test net output #2: loss = 11.479 (* 1 = 11.479 loss)
I0420 10:58:52.959724 28419 solver.cpp:219] Iteration 0 (0 iter/s, 2.7009s/100 iters), loss = 2.05741
I0420 10:58:52.959748 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.523438
I0420 10:58:52.959769 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.921875
I0420 10:58:52.959776 28419 solver.cpp:238]     Train net output #2: loss = 2.05741 (* 1 = 2.05741 loss)
I0420 10:58:52.959794 28419 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0420 10:59:04.525532 28419 solver.cpp:219] Iteration 100 (8.64627 iter/s, 11.5657s/100 iters), loss = 0.470989
I0420 10:59:04.525594 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 10:59:04.525599 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 10:59:04.525606 28419 solver.cpp:238]     Train net output #2: loss = 0.470989 (* 1 = 0.470989 loss)
I0420 10:59:04.525610 28419 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0420 10:59:06.954217 28419 blocking_queue.cpp:49] Waiting for data
I0420 10:59:16.365628 28419 solver.cpp:219] Iteration 200 (8.44595 iter/s, 11.84s/100 iters), loss = 0.536653
I0420 10:59:16.365708 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 10:59:16.365715 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 10:59:16.365721 28419 solver.cpp:238]     Train net output #2: loss = 0.536653 (* 1 = 0.536653 loss)
I0420 10:59:16.365725 28419 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0420 10:59:27.923308 28419 solver.cpp:219] Iteration 300 (8.65235 iter/s, 11.5576s/100 iters), loss = 0.436861
I0420 10:59:27.923480 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 10:59:27.923487 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 10:59:27.923494 28419 solver.cpp:238]     Train net output #2: loss = 0.436861 (* 1 = 0.436861 loss)
I0420 10:59:27.923498 28419 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0420 10:59:37.880287 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 10:59:39.485013 28419 solver.cpp:219] Iteration 400 (8.64937 iter/s, 11.5615s/100 iters), loss = 0.451126
I0420 10:59:39.485069 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 10:59:39.485074 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0420 10:59:39.485081 28419 solver.cpp:238]     Train net output #2: loss = 0.451126 (* 1 = 0.451126 loss)
I0420 10:59:39.485085 28419 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0420 10:59:51.033663 28419 solver.cpp:219] Iteration 500 (8.6593 iter/s, 11.5483s/100 iters), loss = 0.440159
I0420 10:59:51.033715 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 10:59:51.033722 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 10:59:51.033731 28419 solver.cpp:238]     Train net output #2: loss = 0.440159 (* 1 = 0.440159 loss)
I0420 10:59:51.033738 28419 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0420 11:00:02.584179 28419 solver.cpp:219] Iteration 600 (8.65775 iter/s, 11.5503s/100 iters), loss = 0.574946
I0420 11:00:02.584406 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 11:00:02.584414 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:00:02.584422 28419 solver.cpp:238]     Train net output #2: loss = 0.574946 (* 1 = 0.574946 loss)
I0420 11:00:02.584426 28419 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0420 11:00:14.144249 28419 solver.cpp:219] Iteration 700 (8.65078 iter/s, 11.5596s/100 iters), loss = 0.353458
I0420 11:00:14.144312 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:00:14.144318 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:00:14.144325 28419 solver.cpp:238]     Train net output #2: loss = 0.353458 (* 1 = 0.353458 loss)
I0420 11:00:14.144330 28419 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0420 11:00:23.048781 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:00:25.701779 28419 solver.cpp:219] Iteration 800 (8.65245 iter/s, 11.5574s/100 iters), loss = 0.335714
I0420 11:00:25.701839 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:00:25.701845 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:00:25.701851 28419 solver.cpp:238]     Train net output #2: loss = 0.335714 (* 1 = 0.335714 loss)
I0420 11:00:25.701855 28419 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0420 11:00:37.242866 28419 solver.cpp:219] Iteration 900 (8.66476 iter/s, 11.541s/100 iters), loss = 0.505083
I0420 11:00:37.243054 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:00:37.243062 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:00:37.243069 28419 solver.cpp:238]     Train net output #2: loss = 0.505083 (* 1 = 0.505083 loss)
I0420 11:00:37.243073 28419 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0420 11:00:48.692018 28419 solver.cpp:331] Iteration 1000, Testing net (#0)
I0420 11:00:51.142554 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:00:51.242830 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.2839
I0420 11:00:51.242866 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.7201
I0420 11:00:51.242890 28419 solver.cpp:398]     Test net output #2: loss = 3.71817 (* 1 = 3.71817 loss)
I0420 11:00:51.353677 28419 solver.cpp:219] Iteration 1000 (7.08686 iter/s, 14.1106s/100 iters), loss = 0.335225
I0420 11:00:51.353718 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:00:51.353724 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:00:51.353729 28419 solver.cpp:238]     Train net output #2: loss = 0.335225 (* 1 = 0.335225 loss)
I0420 11:00:51.353735 28419 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0420 11:01:02.902071 28419 solver.cpp:219] Iteration 1100 (8.65938 iter/s, 11.5482s/100 iters), loss = 0.457685
I0420 11:01:02.902130 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 11:01:02.902137 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:01:02.902143 28419 solver.cpp:238]     Train net output #2: loss = 0.457685 (* 1 = 0.457685 loss)
I0420 11:01:02.902148 28419 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0420 11:01:10.653983 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:01:14.458238 28419 solver.cpp:219] Iteration 1200 (8.65347 iter/s, 11.5561s/100 iters), loss = 0.345659
I0420 11:01:14.458300 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:01:14.458307 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:01:14.458313 28419 solver.cpp:238]     Train net output #2: loss = 0.345659 (* 1 = 0.345659 loss)
I0420 11:01:14.458318 28419 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0420 11:01:26.033942 28419 solver.cpp:219] Iteration 1300 (8.63891 iter/s, 11.5755s/100 iters), loss = 0.433928
I0420 11:01:26.034001 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:01:26.034008 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:01:26.034013 28419 solver.cpp:238]     Train net output #2: loss = 0.433928 (* 1 = 0.433928 loss)
I0420 11:01:26.034018 28419 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0420 11:01:37.589707 28419 solver.cpp:219] Iteration 1400 (8.65395 iter/s, 11.5554s/100 iters), loss = 0.487027
I0420 11:01:37.589764 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 11:01:37.589771 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:01:37.589776 28419 solver.cpp:238]     Train net output #2: loss = 0.487027 (* 1 = 0.487027 loss)
I0420 11:01:37.589781 28419 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0420 11:01:49.122277 28419 solver.cpp:219] Iteration 1500 (8.67118 iter/s, 11.5325s/100 iters), loss = 0.45756
I0420 11:01:49.122431 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:01:49.122437 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:01:49.122444 28419 solver.cpp:238]     Train net output #2: loss = 0.45756 (* 1 = 0.45756 loss)
I0420 11:01:49.122448 28419 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0420 11:01:55.809082 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:02:00.661460 28419 solver.cpp:219] Iteration 1600 (8.66632 iter/s, 11.5389s/100 iters), loss = 0.38596
I0420 11:02:00.661525 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:02:00.661532 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:02:00.661540 28419 solver.cpp:238]     Train net output #2: loss = 0.38596 (* 1 = 0.38596 loss)
I0420 11:02:00.661543 28419 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0420 11:02:12.211318 28419 solver.cpp:219] Iteration 1700 (8.65817 iter/s, 11.5498s/100 iters), loss = 0.391226
I0420 11:02:12.211391 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:02:12.211397 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:02:12.211405 28419 solver.cpp:238]     Train net output #2: loss = 0.391226 (* 1 = 0.391226 loss)
I0420 11:02:12.211408 28419 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0420 11:02:23.766695 28419 solver.cpp:219] Iteration 1800 (8.65405 iter/s, 11.5553s/100 iters), loss = 0.330702
I0420 11:02:23.766898 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:02:23.766906 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:02:23.766913 28419 solver.cpp:238]     Train net output #2: loss = 0.330702 (* 1 = 0.330702 loss)
I0420 11:02:23.766917 28419 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0420 11:02:35.329898 28419 solver.cpp:219] Iteration 1900 (8.64837 iter/s, 11.5629s/100 iters), loss = 0.424981
I0420 11:02:35.329962 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 11:02:35.329968 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:02:35.329975 28419 solver.cpp:238]     Train net output #2: loss = 0.424981 (* 1 = 0.424981 loss)
I0420 11:02:35.329980 28419 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0420 11:02:41.644145 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:02:47.420070 28419 solver.cpp:331] Iteration 2000, Testing net (#0)
I0420 11:02:49.874663 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:02:49.974248 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.6438
I0420 11:02:49.974283 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.976
I0420 11:02:49.974308 28419 solver.cpp:398]     Test net output #2: loss = 1.19149 (* 1 = 1.19149 loss)
I0420 11:02:50.084697 28419 solver.cpp:219] Iteration 2000 (6.77746 iter/s, 14.7548s/100 iters), loss = 0.39694
I0420 11:02:50.084717 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:02:50.084739 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:02:50.084744 28419 solver.cpp:238]     Train net output #2: loss = 0.39694 (* 1 = 0.39694 loss)
I0420 11:02:50.084750 28419 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0420 11:03:01.643342 28419 solver.cpp:219] Iteration 2100 (8.65157 iter/s, 11.5586s/100 iters), loss = 0.306494
I0420 11:03:01.643527 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:03:01.643551 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:03:01.643559 28419 solver.cpp:238]     Train net output #2: loss = 0.306494 (* 1 = 0.306494 loss)
I0420 11:03:01.643563 28419 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0420 11:03:13.310395 28419 solver.cpp:219] Iteration 2200 (8.57132 iter/s, 11.6668s/100 iters), loss = 0.342362
I0420 11:03:13.310456 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:03:13.310461 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:03:13.310469 28419 solver.cpp:238]     Train net output #2: loss = 0.342362 (* 1 = 0.342362 loss)
I0420 11:03:13.310473 28419 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0420 11:03:24.873085 28419 solver.cpp:219] Iteration 2300 (8.64878 iter/s, 11.5623s/100 iters), loss = 0.393583
I0420 11:03:24.873142 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:03:24.873148 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:03:24.873155 28419 solver.cpp:238]     Train net output #2: loss = 0.393583 (* 1 = 0.393583 loss)
I0420 11:03:24.873159 28419 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0420 11:03:29.393841 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:03:36.426897 28419 solver.cpp:219] Iteration 2400 (8.65528 iter/s, 11.5536s/100 iters), loss = 0.353144
I0420 11:03:36.427105 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:03:36.427114 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:03:36.427120 28419 solver.cpp:238]     Train net output #2: loss = 0.353144 (* 1 = 0.353144 loss)
I0420 11:03:36.427124 28419 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0420 11:03:47.977856 28419 solver.cpp:219] Iteration 2500 (8.65757 iter/s, 11.5506s/100 iters), loss = 0.469942
I0420 11:03:47.977916 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 11:03:47.977921 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:03:47.977927 28419 solver.cpp:238]     Train net output #2: loss = 0.469942 (* 1 = 0.469942 loss)
I0420 11:03:47.977931 28419 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0420 11:03:59.537250 28419 solver.cpp:219] Iteration 2600 (8.65105 iter/s, 11.5593s/100 iters), loss = 0.530652
I0420 11:03:59.537309 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0420 11:03:59.537317 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:03:59.537323 28419 solver.cpp:238]     Train net output #2: loss = 0.530652 (* 1 = 0.530652 loss)
I0420 11:03:59.537328 28419 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0420 11:04:11.076812 28419 solver.cpp:219] Iteration 2700 (8.666 iter/s, 11.5394s/100 iters), loss = 0.40005
I0420 11:04:11.076990 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:04:11.076998 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:04:11.077005 28419 solver.cpp:238]     Train net output #2: loss = 0.40005 (* 1 = 0.40005 loss)
I0420 11:04:11.077010 28419 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0420 11:04:14.542153 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:04:22.626883 28419 solver.cpp:219] Iteration 2800 (8.65815 iter/s, 11.5498s/100 iters), loss = 0.444961
I0420 11:04:22.626932 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 11:04:22.626940 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:04:22.626947 28419 solver.cpp:238]     Train net output #2: loss = 0.444961 (* 1 = 0.444961 loss)
I0420 11:04:22.626952 28419 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0420 11:04:34.191288 28419 solver.cpp:219] Iteration 2900 (8.64731 iter/s, 11.5643s/100 iters), loss = 0.382995
I0420 11:04:34.191345 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:04:34.191350 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:04:34.191357 28419 solver.cpp:238]     Train net output #2: loss = 0.382995 (* 1 = 0.382995 loss)
I0420 11:04:34.191361 28419 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0420 11:04:45.643681 28419 solver.cpp:331] Iteration 3000, Testing net (#0)
I0420 11:04:48.102284 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:04:48.202796 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8077
I0420 11:04:48.202831 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9911
I0420 11:04:48.202855 28419 solver.cpp:398]     Test net output #2: loss = 0.632902 (* 1 = 0.632902 loss)
I0420 11:04:48.313745 28419 solver.cpp:219] Iteration 3000 (7.08096 iter/s, 14.1224s/100 iters), loss = 0.351326
I0420 11:04:48.313765 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:04:48.313786 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:04:48.313791 28419 solver.cpp:238]     Train net output #2: loss = 0.351326 (* 1 = 0.351326 loss)
I0420 11:04:48.313797 28419 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0420 11:04:59.878968 28419 solver.cpp:219] Iteration 3100 (8.64665 iter/s, 11.5652s/100 iters), loss = 0.37084
I0420 11:04:59.879030 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:04:59.879036 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:04:59.879043 28419 solver.cpp:238]     Train net output #2: loss = 0.37084 (* 1 = 0.37084 loss)
I0420 11:04:59.879047 28419 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0420 11:05:02.200809 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:05:11.441426 28419 solver.cpp:219] Iteration 3200 (8.64872 iter/s, 11.5624s/100 iters), loss = 0.289228
I0420 11:05:11.441491 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:05:11.441498 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:05:11.441505 28419 solver.cpp:238]     Train net output #2: loss = 0.289228 (* 1 = 0.289228 loss)
I0420 11:05:11.441509 28419 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0420 11:05:23.002187 28419 solver.cpp:219] Iteration 3300 (8.64999 iter/s, 11.5607s/100 iters), loss = 0.456649
I0420 11:05:23.002393 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:05:23.002400 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:05:23.002408 28419 solver.cpp:238]     Train net output #2: loss = 0.456649 (* 1 = 0.456649 loss)
I0420 11:05:23.002413 28419 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0420 11:05:34.555694 28419 solver.cpp:219] Iteration 3400 (8.65555 iter/s, 11.5533s/100 iters), loss = 0.263558
I0420 11:05:34.555739 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 11:05:34.555744 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:05:34.555752 28419 solver.cpp:238]     Train net output #2: loss = 0.263558 (* 1 = 0.263558 loss)
I0420 11:05:34.555755 28419 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0420 11:05:46.109951 28419 solver.cpp:219] Iteration 3500 (8.65496 iter/s, 11.5541s/100 iters), loss = 0.322901
I0420 11:05:46.109998 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:05:46.110003 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:05:46.110010 28419 solver.cpp:238]     Train net output #2: loss = 0.322901 (* 1 = 0.322901 loss)
I0420 11:05:46.110014 28419 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0420 11:05:47.392664 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:05:57.668840 28419 solver.cpp:219] Iteration 3600 (8.65144 iter/s, 11.5588s/100 iters), loss = 0.408249
I0420 11:05:57.669083 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:05:57.669091 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:05:57.669098 28419 solver.cpp:238]     Train net output #2: loss = 0.408249 (* 1 = 0.408249 loss)
I0420 11:05:57.669104 28419 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0420 11:06:09.220592 28419 solver.cpp:219] Iteration 3700 (8.65693 iter/s, 11.5514s/100 iters), loss = 0.393714
I0420 11:06:09.220652 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:06:09.220660 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:06:09.220666 28419 solver.cpp:238]     Train net output #2: loss = 0.393714 (* 1 = 0.393714 loss)
I0420 11:06:09.220671 28419 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0420 11:06:20.779393 28419 solver.cpp:219] Iteration 3800 (8.65154 iter/s, 11.5586s/100 iters), loss = 0.420498
I0420 11:06:20.779453 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:06:20.779458 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:06:20.779465 28419 solver.cpp:238]     Train net output #2: loss = 0.420498 (* 1 = 0.420498 loss)
I0420 11:06:20.779469 28419 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0420 11:06:32.333892 28419 solver.cpp:219] Iteration 3900 (8.65473 iter/s, 11.5544s/100 iters), loss = 0.299348
I0420 11:06:32.334097 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:06:32.334105 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:06:32.334112 28419 solver.cpp:238]     Train net output #2: loss = 0.299348 (* 1 = 0.299348 loss)
I0420 11:06:32.334117 28419 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0420 11:06:32.574503 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:06:43.775543 28419 solver.cpp:331] Iteration 4000, Testing net (#0)
I0420 11:06:46.228307 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:06:46.329426 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8034
I0420 11:06:46.329463 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9901
I0420 11:06:46.329486 28419 solver.cpp:398]     Test net output #2: loss = 0.644809 (* 1 = 0.644809 loss)
I0420 11:06:46.440054 28419 solver.cpp:219] Iteration 4000 (7.08924 iter/s, 14.1059s/100 iters), loss = 0.388251
I0420 11:06:46.440093 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:06:46.440098 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:06:46.440104 28419 solver.cpp:238]     Train net output #2: loss = 0.388251 (* 1 = 0.388251 loss)
I0420 11:06:46.440109 28419 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0420 11:06:57.995494 28419 solver.cpp:219] Iteration 4100 (8.65401 iter/s, 11.5553s/100 iters), loss = 0.382506
I0420 11:06:57.995551 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:06:57.995556 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:06:57.995563 28419 solver.cpp:238]     Train net output #2: loss = 0.382506 (* 1 = 0.382506 loss)
I0420 11:06:57.995568 28419 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0420 11:07:09.552199 28419 solver.cpp:219] Iteration 4200 (8.65313 iter/s, 11.5565s/100 iters), loss = 0.465596
I0420 11:07:09.552395 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 11:07:09.552402 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:07:09.552409 28419 solver.cpp:238]     Train net output #2: loss = 0.465596 (* 1 = 0.465596 loss)
I0420 11:07:09.552415 28419 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0420 11:07:20.192499 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:07:21.107442 28419 solver.cpp:219] Iteration 4300 (8.65433 iter/s, 11.5549s/100 iters), loss = 0.329695
I0420 11:07:21.107499 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:07:21.107506 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:07:21.107512 28419 solver.cpp:238]     Train net output #2: loss = 0.329695 (* 1 = 0.329695 loss)
I0420 11:07:21.107517 28419 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0420 11:07:32.654633 28419 solver.cpp:219] Iteration 4400 (8.66026 iter/s, 11.547s/100 iters), loss = 0.436099
I0420 11:07:32.654693 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:07:32.654700 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:07:32.654706 28419 solver.cpp:238]     Train net output #2: loss = 0.436099 (* 1 = 0.436099 loss)
I0420 11:07:32.654711 28419 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0420 11:07:44.210383 28419 solver.cpp:219] Iteration 4500 (8.65377 iter/s, 11.5557s/100 iters), loss = 0.229385
I0420 11:07:44.210625 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 11:07:44.210634 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:07:44.210641 28419 solver.cpp:238]     Train net output #2: loss = 0.229385 (* 1 = 0.229385 loss)
I0420 11:07:44.210646 28419 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0420 11:07:55.761771 28419 solver.cpp:219] Iteration 4600 (8.65715 iter/s, 11.5511s/100 iters), loss = 0.314896
I0420 11:07:55.761831 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:07:55.761837 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:07:55.761843 28419 solver.cpp:238]     Train net output #2: loss = 0.314896 (* 1 = 0.314896 loss)
I0420 11:07:55.761847 28419 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0420 11:08:05.354017 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:08:07.306862 28419 solver.cpp:219] Iteration 4700 (8.66177 iter/s, 11.545s/100 iters), loss = 0.321886
I0420 11:08:07.306921 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:08:07.306927 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:08:07.306936 28419 solver.cpp:238]     Train net output #2: loss = 0.321886 (* 1 = 0.321886 loss)
I0420 11:08:07.306939 28419 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0420 11:08:18.856298 28419 solver.cpp:219] Iteration 4800 (8.6587 iter/s, 11.5491s/100 iters), loss = 0.293198
I0420 11:08:18.856490 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:08:18.856499 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:08:18.856506 28419 solver.cpp:238]     Train net output #2: loss = 0.293198 (* 1 = 0.293198 loss)
I0420 11:08:18.856511 28419 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0420 11:08:30.405571 28419 solver.cpp:219] Iteration 4900 (8.6587 iter/s, 11.5491s/100 iters), loss = 0.363773
I0420 11:08:30.405630 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:08:30.405637 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:08:30.405644 28419 solver.cpp:238]     Train net output #2: loss = 0.363773 (* 1 = 0.363773 loss)
I0420 11:08:30.405648 28419 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0420 11:08:41.845788 28419 solver.cpp:331] Iteration 5000, Testing net (#0)
I0420 11:08:44.305690 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:08:44.407946 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8284
I0420 11:08:44.407984 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9916
I0420 11:08:44.408008 28419 solver.cpp:398]     Test net output #2: loss = 0.566229 (* 1 = 0.566229 loss)
I0420 11:08:44.520056 28419 solver.cpp:219] Iteration 5000 (7.08497 iter/s, 14.1144s/100 iters), loss = 0.280149
I0420 11:08:44.520095 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:08:44.520099 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:08:44.520105 28419 solver.cpp:238]     Train net output #2: loss = 0.280149 (* 1 = 0.280149 loss)
I0420 11:08:44.520112 28419 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0420 11:08:53.076375 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:08:56.071388 28419 solver.cpp:219] Iteration 5100 (8.65709 iter/s, 11.5512s/100 iters), loss = 0.345551
I0420 11:08:56.071445 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:08:56.071451 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:08:56.071458 28419 solver.cpp:238]     Train net output #2: loss = 0.345551 (* 1 = 0.345551 loss)
I0420 11:08:56.071462 28419 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0420 11:09:07.624500 28419 solver.cpp:219] Iteration 5200 (8.65597 iter/s, 11.5527s/100 iters), loss = 0.303284
I0420 11:09:07.624557 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:09:07.624563 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:09:07.624569 28419 solver.cpp:238]     Train net output #2: loss = 0.303284 (* 1 = 0.303284 loss)
I0420 11:09:07.624574 28419 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0420 11:09:19.173388 28419 solver.cpp:219] Iteration 5300 (8.65907 iter/s, 11.5486s/100 iters), loss = 0.282657
I0420 11:09:19.173445 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:09:19.173451 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:09:19.173458 28419 solver.cpp:238]     Train net output #2: loss = 0.282657 (* 1 = 0.282657 loss)
I0420 11:09:19.173462 28419 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0420 11:09:30.717033 28419 solver.cpp:219] Iteration 5400 (8.66285 iter/s, 11.5435s/100 iters), loss = 0.265162
I0420 11:09:30.717236 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:09:30.717244 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:09:30.717252 28419 solver.cpp:238]     Train net output #2: loss = 0.265162 (* 1 = 0.265162 loss)
I0420 11:09:30.717257 28419 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0420 11:09:38.127439 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:09:42.281564 28419 solver.cpp:219] Iteration 5500 (8.64732 iter/s, 11.5643s/100 iters), loss = 0.389007
I0420 11:09:42.281626 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:09:42.281631 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:09:42.281639 28419 solver.cpp:238]     Train net output #2: loss = 0.389007 (* 1 = 0.389007 loss)
I0420 11:09:42.281643 28419 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0420 11:09:53.846729 28419 solver.cpp:219] Iteration 5600 (8.64669 iter/s, 11.5651s/100 iters), loss = 0.311059
I0420 11:09:53.846788 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:09:53.846794 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:09:53.846801 28419 solver.cpp:238]     Train net output #2: loss = 0.311059 (* 1 = 0.311059 loss)
I0420 11:09:53.846807 28419 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0420 11:10:05.413805 28419 solver.cpp:219] Iteration 5700 (8.6453 iter/s, 11.567s/100 iters), loss = 0.352913
I0420 11:10:05.414005 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:10:05.414012 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:10:05.414019 28419 solver.cpp:238]     Train net output #2: loss = 0.352913 (* 1 = 0.352913 loss)
I0420 11:10:05.414026 28419 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0420 11:10:16.976238 28419 solver.cpp:219] Iteration 5800 (8.64895 iter/s, 11.5621s/100 iters), loss = 0.280895
I0420 11:10:16.976300 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 11:10:16.976307 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:10:16.976315 28419 solver.cpp:238]     Train net output #2: loss = 0.280895 (* 1 = 0.280895 loss)
I0420 11:10:16.976318 28419 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0420 11:10:23.343454 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:10:28.535912 28419 solver.cpp:219] Iteration 5900 (8.65086 iter/s, 11.5595s/100 iters), loss = 0.439333
I0420 11:10:28.535971 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:10:28.535976 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0420 11:10:28.535984 28419 solver.cpp:238]     Train net output #2: loss = 0.439333 (* 1 = 0.439333 loss)
I0420 11:10:28.535989 28419 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0420 11:10:39.981781 28419 solver.cpp:331] Iteration 6000, Testing net (#0)
I0420 11:10:42.432997 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:10:42.533701 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8271
I0420 11:10:42.533738 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9926
I0420 11:10:42.533762 28419 solver.cpp:398]     Test net output #2: loss = 0.54239 (* 1 = 0.54239 loss)
I0420 11:10:42.643821 28419 solver.cpp:219] Iteration 6000 (7.08824 iter/s, 14.1079s/100 iters), loss = 0.344139
I0420 11:10:42.643841 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:10:42.643862 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:10:42.643868 28419 solver.cpp:238]     Train net output #2: loss = 0.344139 (* 1 = 0.344139 loss)
I0420 11:10:42.643874 28419 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0420 11:10:54.198676 28419 solver.cpp:219] Iteration 6100 (8.65446 iter/s, 11.5547s/100 iters), loss = 0.325034
I0420 11:10:54.198736 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:10:54.198741 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:10:54.198748 28419 solver.cpp:238]     Train net output #2: loss = 0.325034 (* 1 = 0.325034 loss)
I0420 11:10:54.198752 28419 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0420 11:11:05.743193 28419 solver.cpp:219] Iteration 6200 (8.66218 iter/s, 11.5444s/100 iters), loss = 0.244665
I0420 11:11:05.743250 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 11:11:05.743255 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:11:05.743263 28419 solver.cpp:238]     Train net output #2: loss = 0.244665 (* 1 = 0.244665 loss)
I0420 11:11:05.743266 28419 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0420 11:11:10.948268 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:11:17.283826 28419 solver.cpp:219] Iteration 6300 (8.66506 iter/s, 11.5406s/100 iters), loss = 0.477839
I0420 11:11:17.283876 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 11:11:17.283882 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:11:17.283890 28419 solver.cpp:238]     Train net output #2: loss = 0.477839 (* 1 = 0.477839 loss)
I0420 11:11:17.283895 28419 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0420 11:11:28.853726 28419 solver.cpp:219] Iteration 6400 (8.64328 iter/s, 11.5697s/100 iters), loss = 0.313065
I0420 11:11:28.853783 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:11:28.853788 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:11:28.853796 28419 solver.cpp:238]     Train net output #2: loss = 0.313065 (* 1 = 0.313065 loss)
I0420 11:11:28.853801 28419 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0420 11:11:40.410189 28419 solver.cpp:219] Iteration 6500 (8.6532 iter/s, 11.5564s/100 iters), loss = 0.306214
I0420 11:11:40.410245 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:11:40.410250 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:11:40.410257 28419 solver.cpp:238]     Train net output #2: loss = 0.306214 (* 1 = 0.306214 loss)
I0420 11:11:40.410261 28419 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0420 11:11:51.965963 28419 solver.cpp:219] Iteration 6600 (8.65381 iter/s, 11.5556s/100 iters), loss = 0.338696
I0420 11:11:51.966150 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:11:51.966158 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:11:51.966166 28419 solver.cpp:238]     Train net output #2: loss = 0.338696 (* 1 = 0.338696 loss)
I0420 11:11:51.966169 28419 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0420 11:11:56.130511 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:12:03.510020 28419 solver.cpp:219] Iteration 6700 (8.66265 iter/s, 11.5438s/100 iters), loss = 0.319088
I0420 11:12:03.510076 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:12:03.510082 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:12:03.510088 28419 solver.cpp:238]     Train net output #2: loss = 0.319088 (* 1 = 0.319088 loss)
I0420 11:12:03.510092 28419 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0420 11:12:15.055821 28419 solver.cpp:219] Iteration 6800 (8.66125 iter/s, 11.5457s/100 iters), loss = 0.500371
I0420 11:12:15.055884 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:12:15.055889 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:12:15.055896 28419 solver.cpp:238]     Train net output #2: loss = 0.500371 (* 1 = 0.500371 loss)
I0420 11:12:15.055902 28419 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0420 11:12:26.617419 28419 solver.cpp:219] Iteration 6900 (8.6494 iter/s, 11.5615s/100 iters), loss = 0.490659
I0420 11:12:26.617653 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:12:26.617662 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:12:26.617669 28419 solver.cpp:238]     Train net output #2: loss = 0.490659 (* 1 = 0.490659 loss)
I0420 11:12:26.617674 28419 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0420 11:12:38.058476 28419 solver.cpp:331] Iteration 7000, Testing net (#0)
I0420 11:12:40.510406 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:12:40.609432 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8281
I0420 11:12:40.609467 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9891
I0420 11:12:40.609489 28419 solver.cpp:398]     Test net output #2: loss = 0.582328 (* 1 = 0.582328 loss)
I0420 11:12:40.719951 28419 solver.cpp:219] Iteration 7000 (7.09107 iter/s, 14.1023s/100 iters), loss = 0.285714
I0420 11:12:40.719972 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:12:40.719993 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:12:40.719998 28419 solver.cpp:238]     Train net output #2: loss = 0.285714 (* 1 = 0.285714 loss)
I0420 11:12:40.720005 28419 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0420 11:12:43.847538 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:12:52.264914 28419 solver.cpp:219] Iteration 7100 (8.66189 iter/s, 11.5448s/100 iters), loss = 0.347864
I0420 11:12:52.264979 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:12:52.264986 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:12:52.264992 28419 solver.cpp:238]     Train net output #2: loss = 0.347864 (* 1 = 0.347864 loss)
I0420 11:12:52.264997 28419 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0420 11:13:03.812929 28419 solver.cpp:219] Iteration 7200 (8.65958 iter/s, 11.5479s/100 iters), loss = 0.326124
I0420 11:13:03.813104 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:13:03.813112 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:13:03.813119 28419 solver.cpp:238]     Train net output #2: loss = 0.326124 (* 1 = 0.326124 loss)
I0420 11:13:03.813125 28419 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0420 11:13:15.384083 28419 solver.cpp:219] Iteration 7300 (8.64259 iter/s, 11.5706s/100 iters), loss = 0.267579
I0420 11:13:15.384146 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:13:15.384152 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:13:15.384160 28419 solver.cpp:238]     Train net output #2: loss = 0.26758 (* 1 = 0.26758 loss)
I0420 11:13:15.384163 28419 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0420 11:13:26.931330 28419 solver.cpp:219] Iteration 7400 (8.66012 iter/s, 11.5472s/100 iters), loss = 0.271235
I0420 11:13:26.931391 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:13:26.931396 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:13:26.931402 28419 solver.cpp:238]     Train net output #2: loss = 0.271235 (* 1 = 0.271235 loss)
I0420 11:13:26.931406 28419 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0420 11:13:28.904887 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:13:38.493588 28419 solver.cpp:219] Iteration 7500 (8.64897 iter/s, 11.5621s/100 iters), loss = 0.210814
I0420 11:13:38.493829 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 11:13:38.493837 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:13:38.493844 28419 solver.cpp:238]     Train net output #2: loss = 0.210814 (* 1 = 0.210814 loss)
I0420 11:13:38.493849 28419 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0420 11:13:50.050817 28419 solver.cpp:219] Iteration 7600 (8.65289 iter/s, 11.5568s/100 iters), loss = 0.290212
I0420 11:13:50.050880 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 11:13:50.050886 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:13:50.050894 28419 solver.cpp:238]     Train net output #2: loss = 0.290212 (* 1 = 0.290212 loss)
I0420 11:13:50.050897 28419 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0420 11:14:01.603428 28419 solver.cpp:219] Iteration 7700 (8.65613 iter/s, 11.5525s/100 iters), loss = 0.231191
I0420 11:14:01.603487 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 11:14:01.603492 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:14:01.603498 28419 solver.cpp:238]     Train net output #2: loss = 0.231191 (* 1 = 0.231191 loss)
I0420 11:14:01.603502 28419 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0420 11:14:13.163324 28419 solver.cpp:219] Iteration 7800 (8.65068 iter/s, 11.5598s/100 iters), loss = 0.290091
I0420 11:14:13.163537 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 11:14:13.163544 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:14:13.163552 28419 solver.cpp:238]     Train net output #2: loss = 0.290091 (* 1 = 0.290091 loss)
I0420 11:14:13.163558 28419 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0420 11:14:14.093116 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:14:24.724393 28419 solver.cpp:219] Iteration 7900 (8.64998 iter/s, 11.5607s/100 iters), loss = 0.332632
I0420 11:14:24.724447 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:14:24.724453 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:14:24.724459 28419 solver.cpp:238]     Train net output #2: loss = 0.332632 (* 1 = 0.332632 loss)
I0420 11:14:24.724465 28419 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0420 11:14:36.165387 28419 solver.cpp:331] Iteration 8000, Testing net (#0)
I0420 11:14:38.622354 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:14:38.723213 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8467
I0420 11:14:38.723248 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9935
I0420 11:14:38.723273 28419 solver.cpp:398]     Test net output #2: loss = 0.491883 (* 1 = 0.491883 loss)
I0420 11:14:38.832557 28419 solver.cpp:219] Iteration 8000 (7.08813 iter/s, 14.1081s/100 iters), loss = 0.278178
I0420 11:14:38.832578 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:14:38.832599 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:14:38.832605 28419 solver.cpp:238]     Train net output #2: loss = 0.278178 (* 1 = 0.278178 loss)
I0420 11:14:38.832612 28419 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0420 11:14:50.380532 28419 solver.cpp:219] Iteration 8100 (8.65969 iter/s, 11.5478s/100 iters), loss = 0.401115
I0420 11:14:50.380728 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:14:50.380734 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:14:50.380743 28419 solver.cpp:238]     Train net output #2: loss = 0.401115 (* 1 = 0.401115 loss)
I0420 11:14:50.380746 28419 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0420 11:15:01.818354 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:15:01.928881 28419 solver.cpp:219] Iteration 8200 (8.65949 iter/s, 11.548s/100 iters), loss = 0.364364
I0420 11:15:01.928936 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:15:01.928941 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:15:01.928947 28419 solver.cpp:238]     Train net output #2: loss = 0.364364 (* 1 = 0.364364 loss)
I0420 11:15:01.928951 28419 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0420 11:15:13.488193 28419 solver.cpp:219] Iteration 8300 (8.65111 iter/s, 11.5592s/100 iters), loss = 0.341995
I0420 11:15:13.488257 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:15:13.488265 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:15:13.488271 28419 solver.cpp:238]     Train net output #2: loss = 0.341995 (* 1 = 0.341995 loss)
I0420 11:15:13.488276 28419 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0420 11:15:25.059236 28419 solver.cpp:219] Iteration 8400 (8.64234 iter/s, 11.5709s/100 iters), loss = 0.376536
I0420 11:15:25.059476 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 11:15:25.059484 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:15:25.059492 28419 solver.cpp:238]     Train net output #2: loss = 0.376537 (* 1 = 0.376537 loss)
I0420 11:15:25.059496 28419 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0420 11:15:36.622649 28419 solver.cpp:219] Iteration 8500 (8.64827 iter/s, 11.563s/100 iters), loss = 0.486452
I0420 11:15:36.622714 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0420 11:15:36.622720 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:15:36.622726 28419 solver.cpp:238]     Train net output #2: loss = 0.486452 (* 1 = 0.486452 loss)
I0420 11:15:36.622730 28419 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0420 11:15:46.916486 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:15:48.178046 28419 solver.cpp:219] Iteration 8600 (8.65411 iter/s, 11.5552s/100 iters), loss = 0.425552
I0420 11:15:48.178110 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:15:48.178117 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:15:48.178122 28419 solver.cpp:238]     Train net output #2: loss = 0.425552 (* 1 = 0.425552 loss)
I0420 11:15:48.178128 28419 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0420 11:15:59.739784 28419 solver.cpp:219] Iteration 8700 (8.6493 iter/s, 11.5616s/100 iters), loss = 0.411213
I0420 11:15:59.739977 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:15:59.739984 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:15:59.739991 28419 solver.cpp:238]     Train net output #2: loss = 0.411213 (* 1 = 0.411213 loss)
I0420 11:15:59.739996 28419 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0420 11:16:11.303372 28419 solver.cpp:219] Iteration 8800 (8.64809 iter/s, 11.5632s/100 iters), loss = 0.30053
I0420 11:16:11.303431 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:16:11.303436 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:16:11.303442 28419 solver.cpp:238]     Train net output #2: loss = 0.30053 (* 1 = 0.30053 loss)
I0420 11:16:11.303447 28419 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0420 11:16:22.853363 28419 solver.cpp:219] Iteration 8900 (8.65816 iter/s, 11.5498s/100 iters), loss = 0.27954
I0420 11:16:22.853425 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:16:22.853432 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:16:22.853440 28419 solver.cpp:238]     Train net output #2: loss = 0.27954 (* 1 = 0.27954 loss)
I0420 11:16:22.853443 28419 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0420 11:16:32.096909 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:16:34.291085 28419 solver.cpp:331] Iteration 9000, Testing net (#0)
I0420 11:16:36.741081 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:16:36.841444 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8395
I0420 11:16:36.841478 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9914
I0420 11:16:36.841502 28419 solver.cpp:398]     Test net output #2: loss = 0.53631 (* 1 = 0.53631 loss)
I0420 11:16:36.951675 28419 solver.cpp:219] Iteration 9000 (7.09308 iter/s, 14.0982s/100 iters), loss = 0.293374
I0420 11:16:36.951697 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 11:16:36.951719 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:16:36.951723 28419 solver.cpp:238]     Train net output #2: loss = 0.293374 (* 1 = 0.293374 loss)
I0420 11:16:36.951730 28419 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0420 11:16:48.517473 28419 solver.cpp:219] Iteration 9100 (8.64635 iter/s, 11.5656s/100 iters), loss = 0.405593
I0420 11:16:48.517537 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:16:48.517544 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:16:48.517550 28419 solver.cpp:238]     Train net output #2: loss = 0.405593 (* 1 = 0.405593 loss)
I0420 11:16:48.517554 28419 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0420 11:17:00.071986 28419 solver.cpp:219] Iteration 9200 (8.65476 iter/s, 11.5543s/100 iters), loss = 0.336198
I0420 11:17:00.072031 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:17:00.072052 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:17:00.072059 28419 solver.cpp:238]     Train net output #2: loss = 0.336198 (* 1 = 0.336198 loss)
I0420 11:17:00.072064 28419 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0420 11:17:11.620362 28419 solver.cpp:219] Iteration 9300 (8.6593 iter/s, 11.5483s/100 iters), loss = 0.388003
I0420 11:17:11.620558 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:17:11.620565 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:17:11.620573 28419 solver.cpp:238]     Train net output #2: loss = 0.388003 (* 1 = 0.388003 loss)
I0420 11:17:11.620579 28419 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0420 11:17:19.713766 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:17:23.168937 28419 solver.cpp:219] Iteration 9400 (8.6593 iter/s, 11.5483s/100 iters), loss = 0.374393
I0420 11:17:23.169028 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 11:17:23.169034 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:17:23.169044 28419 solver.cpp:238]     Train net output #2: loss = 0.374393 (* 1 = 0.374393 loss)
I0420 11:17:23.169051 28419 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0420 11:17:43.798598 28419 solver.cpp:219] Iteration 9500 (4.84741 iter/s, 20.6296s/100 iters), loss = 0.323075
I0420 11:17:43.798805 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 11:17:43.798813 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:17:43.798820 28419 solver.cpp:238]     Train net output #2: loss = 0.323075 (* 1 = 0.323075 loss)
I0420 11:17:43.798825 28419 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0420 11:18:06.786566 28419 solver.cpp:219] Iteration 9600 (4.35056 iter/s, 22.9855s/100 iters), loss = 0.287111
I0420 11:18:06.786629 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:18:06.786635 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:18:06.786643 28419 solver.cpp:238]     Train net output #2: loss = 0.287112 (* 1 = 0.287112 loss)
I0420 11:18:06.786646 28419 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0420 11:18:29.856142 28419 solver.cpp:219] Iteration 9700 (4.33515 iter/s, 23.0673s/100 iters), loss = 0.394317
I0420 11:18:29.856776 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:18:29.856787 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:18:29.856794 28419 solver.cpp:238]     Train net output #2: loss = 0.394317 (* 1 = 0.394317 loss)
I0420 11:18:29.856799 28419 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0420 11:18:44.007874 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:18:52.933867 28419 solver.cpp:219] Iteration 9800 (4.33329 iter/s, 23.0772s/100 iters), loss = 0.325938
I0420 11:18:52.933931 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:18:52.933936 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:18:52.933943 28419 solver.cpp:238]     Train net output #2: loss = 0.325939 (* 1 = 0.325939 loss)
I0420 11:18:52.933948 28419 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0420 11:19:15.947433 28419 solver.cpp:219] Iteration 9900 (4.34569 iter/s, 23.0113s/100 iters), loss = 0.433237
I0420 11:19:15.947749 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:19:15.947758 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:19:15.947765 28419 solver.cpp:238]     Train net output #2: loss = 0.433237 (* 1 = 0.433237 loss)
I0420 11:19:15.947770 28419 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0420 11:19:38.804720 28419 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_finetune_quant_0.09_iter_10000.caffemodel
I0420 11:19:38.832350 28419 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_finetune_quant_0.09_iter_10000.solverstate
I0420 11:19:38.848076 28419 solver.cpp:331] Iteration 10000, Testing net (#0)
I0420 11:19:43.701635 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:19:43.930390 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8262
I0420 11:19:43.930426 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9891
I0420 11:19:43.930449 28419 solver.cpp:398]     Test net output #2: loss = 0.578185 (* 1 = 0.578185 loss)
I0420 11:19:44.127027 28419 solver.cpp:219] Iteration 10000 (3.54895 iter/s, 28.1774s/100 iters), loss = 0.295174
I0420 11:19:44.127048 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:19:44.127068 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:19:44.127074 28419 solver.cpp:238]     Train net output #2: loss = 0.295174 (* 1 = 0.295174 loss)
I0420 11:19:44.127079 28419 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0420 11:20:07.155457 28419 solver.cpp:219] Iteration 10100 (4.34249 iter/s, 23.0283s/100 iters), loss = 0.372597
I0420 11:20:07.155665 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:20:07.155673 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:20:07.155684 28419 solver.cpp:238]     Train net output #2: loss = 0.372597 (* 1 = 0.372597 loss)
I0420 11:20:07.155689 28419 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0420 11:20:19.187784 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:20:30.155496 28419 solver.cpp:219] Iteration 10200 (4.34824 iter/s, 22.9978s/100 iters), loss = 0.399199
I0420 11:20:30.155560 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:20:30.155565 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:20:30.155572 28419 solver.cpp:238]     Train net output #2: loss = 0.399199 (* 1 = 0.399199 loss)
I0420 11:20:30.155576 28419 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0420 11:20:53.241096 28419 solver.cpp:219] Iteration 10300 (4.33213 iter/s, 23.0833s/100 iters), loss = 0.404773
I0420 11:20:53.241773 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:20:53.241783 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:20:53.241791 28419 solver.cpp:238]     Train net output #2: loss = 0.404773 (* 1 = 0.404773 loss)
I0420 11:20:53.241796 28419 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0420 11:21:16.272027 28419 solver.cpp:219] Iteration 10400 (4.34214 iter/s, 23.0301s/100 iters), loss = 0.208843
I0420 11:21:16.272089 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:21:16.272095 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:21:16.272102 28419 solver.cpp:238]     Train net output #2: loss = 0.208843 (* 1 = 0.208843 loss)
I0420 11:21:16.272107 28419 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0420 11:21:39.254690 28419 solver.cpp:219] Iteration 10500 (4.35154 iter/s, 22.9804s/100 iters), loss = 0.354894
I0420 11:21:39.254865 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:21:39.254873 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:21:39.254897 28419 solver.cpp:238]     Train net output #2: loss = 0.354894 (* 1 = 0.354894 loss)
I0420 11:21:39.254901 28419 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0420 11:21:49.013865 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:22:02.369791 28419 solver.cpp:219] Iteration 10600 (4.3265 iter/s, 23.1134s/100 iters), loss = 0.321169
I0420 11:22:02.369854 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:22:02.369861 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:22:02.369868 28419 solver.cpp:238]     Train net output #2: loss = 0.321169 (* 1 = 0.321169 loss)
I0420 11:22:02.369873 28419 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0420 11:22:25.379062 28419 solver.cpp:219] Iteration 10700 (4.34649 iter/s, 23.0071s/100 iters), loss = 0.285265
I0420 11:22:25.379259 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:22:25.379267 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:22:25.379276 28419 solver.cpp:238]     Train net output #2: loss = 0.285265 (* 1 = 0.285265 loss)
I0420 11:22:25.379279 28419 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0420 11:22:48.377666 28419 solver.cpp:219] Iteration 10800 (4.3485 iter/s, 22.9964s/100 iters), loss = 0.287226
I0420 11:22:48.377741 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:22:48.377748 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:22:48.377754 28419 solver.cpp:238]     Train net output #2: loss = 0.287226 (* 1 = 0.287226 loss)
I0420 11:22:48.377758 28419 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0420 11:23:11.487332 28419 solver.cpp:219] Iteration 10900 (4.32763 iter/s, 23.1074s/100 iters), loss = 0.370256
I0420 11:23:11.487712 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:23:11.487720 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:23:11.487727 28419 solver.cpp:238]     Train net output #2: loss = 0.370256 (* 1 = 0.370256 loss)
I0420 11:23:11.487731 28419 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0420 11:23:19.107959 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:23:34.271754 28419 solver.cpp:331] Iteration 11000, Testing net (#0)
I0420 11:23:39.144811 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:23:39.358991 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.83
I0420 11:23:39.359030 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9903
I0420 11:23:39.359055 28419 solver.cpp:398]     Test net output #2: loss = 0.578586 (* 1 = 0.578586 loss)
I0420 11:23:39.494201 28419 solver.cpp:219] Iteration 11000 (3.57061 iter/s, 28.0064s/100 iters), loss = 0.32131
I0420 11:23:39.494221 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:23:39.494242 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:23:39.494248 28419 solver.cpp:238]     Train net output #2: loss = 0.32131 (* 1 = 0.32131 loss)
I0420 11:23:39.494254 28419 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0420 11:24:02.580080 28419 solver.cpp:219] Iteration 11100 (4.33207 iter/s, 23.0836s/100 iters), loss = 0.228517
I0420 11:24:02.580773 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 11:24:02.580783 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:24:02.580791 28419 solver.cpp:238]     Train net output #2: loss = 0.228517 (* 1 = 0.228517 loss)
I0420 11:24:02.580796 28419 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0420 11:24:25.605105 28419 solver.cpp:219] Iteration 11200 (4.34326 iter/s, 23.0242s/100 iters), loss = 0.493429
I0420 11:24:25.605166 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 11:24:25.605171 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:24:25.605178 28419 solver.cpp:238]     Train net output #2: loss = 0.493429 (* 1 = 0.493429 loss)
I0420 11:24:25.605182 28419 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0420 11:24:48.635308 28419 solver.cpp:219] Iteration 11300 (4.34254 iter/s, 23.028s/100 iters), loss = 0.446394
I0420 11:24:48.635522 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 11:24:48.635530 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:24:48.635537 28419 solver.cpp:238]     Train net output #2: loss = 0.446394 (* 1 = 0.446394 loss)
I0420 11:24:48.635541 28419 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0420 11:24:54.251982 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:25:11.663139 28419 solver.cpp:219] Iteration 11400 (4.343 iter/s, 23.0256s/100 iters), loss = 0.312828
I0420 11:25:11.663202 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:25:11.663206 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:25:11.663213 28419 solver.cpp:238]     Train net output #2: loss = 0.312828 (* 1 = 0.312828 loss)
I0420 11:25:11.663218 28419 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0420 11:25:34.745196 28419 solver.cpp:219] Iteration 11500 (4.33239 iter/s, 23.0819s/100 iters), loss = 0.329154
I0420 11:25:34.745329 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:25:34.745337 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:25:34.745343 28419 solver.cpp:238]     Train net output #2: loss = 0.329154 (* 1 = 0.329154 loss)
I0420 11:25:34.745347 28419 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0420 11:25:57.740293 28419 solver.cpp:219] Iteration 11600 (4.34918 iter/s, 22.9929s/100 iters), loss = 0.345953
I0420 11:25:57.740353 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:25:57.740360 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:25:57.740365 28419 solver.cpp:238]     Train net output #2: loss = 0.345953 (* 1 = 0.345953 loss)
I0420 11:25:57.740370 28419 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0420 11:26:20.744987 28419 solver.cpp:219] Iteration 11700 (4.34737 iter/s, 23.0024s/100 iters), loss = 0.307574
I0420 11:26:20.745190 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:26:20.745198 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:26:20.745205 28419 solver.cpp:238]     Train net output #2: loss = 0.307574 (* 1 = 0.307574 loss)
I0420 11:26:20.745209 28419 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0420 11:26:24.077679 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:26:43.829630 28419 solver.cpp:219] Iteration 11800 (4.33231 iter/s, 23.0824s/100 iters), loss = 0.456563
I0420 11:26:43.829696 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0420 11:26:43.829702 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:26:43.829710 28419 solver.cpp:238]     Train net output #2: loss = 0.456564 (* 1 = 0.456564 loss)
I0420 11:26:43.829715 28419 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0420 11:27:06.785816 28419 solver.cpp:219] Iteration 11900 (4.35615 iter/s, 22.9561s/100 iters), loss = 0.220254
I0420 11:27:06.786520 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 11:27:06.786531 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:27:06.786538 28419 solver.cpp:238]     Train net output #2: loss = 0.220254 (* 1 = 0.220254 loss)
I0420 11:27:06.786543 28419 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0420 11:27:29.638741 28419 solver.cpp:331] Iteration 12000, Testing net (#0)
I0420 11:27:34.446105 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:27:34.620898 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8413
I0420 11:27:34.620935 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9918
I0420 11:27:34.620959 28419 solver.cpp:398]     Test net output #2: loss = 0.527519 (* 1 = 0.527519 loss)
I0420 11:27:34.842085 28419 solver.cpp:219] Iteration 12000 (3.56454 iter/s, 28.0541s/100 iters), loss = 0.275067
I0420 11:27:34.842108 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:27:34.842128 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:27:34.842133 28419 solver.cpp:238]     Train net output #2: loss = 0.275067 (* 1 = 0.275067 loss)
I0420 11:27:34.842139 28419 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0420 11:27:59.103384 28419 solver.cpp:219] Iteration 12100 (4.12218 iter/s, 24.259s/100 iters), loss = 0.227973
I0420 11:27:59.103592 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 11:27:59.103601 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:27:59.103608 28419 solver.cpp:238]     Train net output #2: loss = 0.227973 (* 1 = 0.227973 loss)
I0420 11:27:59.103612 28419 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0420 11:28:00.309340 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:28:22.107321 28419 solver.cpp:219] Iteration 12200 (4.34751 iter/s, 23.0017s/100 iters), loss = 0.273451
I0420 11:28:22.107374 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:28:22.107380 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:28:22.107388 28419 solver.cpp:238]     Train net output #2: loss = 0.273451 (* 1 = 0.273451 loss)
I0420 11:28:22.107391 28419 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0420 11:28:45.148077 28419 solver.cpp:219] Iteration 12300 (4.34056 iter/s, 23.0385s/100 iters), loss = 0.337643
I0420 11:28:45.148282 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:28:45.148289 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:28:45.148296 28419 solver.cpp:238]     Train net output #2: loss = 0.337643 (* 1 = 0.337643 loss)
I0420 11:28:45.148300 28419 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0420 11:29:08.178516 28419 solver.cpp:219] Iteration 12400 (4.34216 iter/s, 23.03s/100 iters), loss = 0.245704
I0420 11:29:08.178580 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 11:29:08.178586 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:29:08.178593 28419 solver.cpp:238]     Train net output #2: loss = 0.245704 (* 1 = 0.245704 loss)
I0420 11:29:08.178597 28419 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0420 11:29:30.058518 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:29:31.142467 28419 solver.cpp:219] Iteration 12500 (4.35507 iter/s, 22.9617s/100 iters), loss = 0.261141
I0420 11:29:31.142529 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:29:31.142534 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:29:31.142541 28419 solver.cpp:238]     Train net output #2: loss = 0.261141 (* 1 = 0.261141 loss)
I0420 11:29:31.142545 28419 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0420 11:29:54.180892 28419 solver.cpp:219] Iteration 12600 (4.341 iter/s, 23.0361s/100 iters), loss = 0.195412
I0420 11:29:54.180953 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 11:29:54.180959 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:29:54.180966 28419 solver.cpp:238]     Train net output #2: loss = 0.195412 (* 1 = 0.195412 loss)
I0420 11:29:54.180970 28419 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0420 11:30:17.193922 28419 solver.cpp:219] Iteration 12700 (4.34539 iter/s, 23.0129s/100 iters), loss = 0.382252
I0420 11:30:17.194131 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:30:17.194139 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:30:17.194147 28419 solver.cpp:238]     Train net output #2: loss = 0.382252 (* 1 = 0.382252 loss)
I0420 11:30:17.194151 28419 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0420 11:30:40.157490 28419 solver.cpp:219] Iteration 12800 (4.35519 iter/s, 22.9611s/100 iters), loss = 0.417553
I0420 11:30:40.157547 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 11:30:40.157552 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:30:40.157559 28419 solver.cpp:238]     Train net output #2: loss = 0.417553 (* 1 = 0.417553 loss)
I0420 11:30:40.157563 28419 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0420 11:30:59.945003 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:31:03.151502 28419 solver.cpp:219] Iteration 12900 (4.34938 iter/s, 22.9918s/100 iters), loss = 0.283149
I0420 11:31:03.151557 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:31:03.151563 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:31:03.151569 28419 solver.cpp:238]     Train net output #2: loss = 0.283149 (* 1 = 0.283149 loss)
I0420 11:31:03.151573 28419 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0420 11:31:25.859627 28419 solver.cpp:331] Iteration 13000, Testing net (#0)
I0420 11:31:30.671181 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:31:30.903949 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8222
I0420 11:31:30.903978 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9913
I0420 11:31:30.904013 28419 solver.cpp:398]     Test net output #2: loss = 0.573837 (* 1 = 0.573837 loss)
I0420 11:31:31.133591 28419 solver.cpp:219] Iteration 13000 (3.57399 iter/s, 27.9799s/100 iters), loss = 0.314596
I0420 11:31:31.133637 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:31:31.133642 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:31:31.133648 28419 solver.cpp:238]     Train net output #2: loss = 0.314596 (* 1 = 0.314596 loss)
I0420 11:31:31.133654 28419 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0420 11:31:54.064144 28419 solver.cpp:219] Iteration 13100 (4.36142 iter/s, 22.9283s/100 iters), loss = 0.41455
I0420 11:31:54.064205 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:31:54.064211 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:31:54.064218 28419 solver.cpp:238]     Train net output #2: loss = 0.41455 (* 1 = 0.41455 loss)
I0420 11:31:54.064224 28419 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0420 11:32:17.091745 28419 solver.cpp:219] Iteration 13200 (4.34303 iter/s, 23.0254s/100 iters), loss = 0.242432
I0420 11:32:17.091907 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:32:17.091914 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:32:17.091922 28419 solver.cpp:238]     Train net output #2: loss = 0.242432 (* 1 = 0.242432 loss)
I0420 11:32:17.091927 28419 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0420 11:32:34.896930 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:32:40.128732 28419 solver.cpp:219] Iteration 13300 (4.34088 iter/s, 23.0368s/100 iters), loss = 0.280546
I0420 11:32:40.128792 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:32:40.128796 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:32:40.128803 28419 solver.cpp:238]     Train net output #2: loss = 0.280546 (* 1 = 0.280546 loss)
I0420 11:32:40.128808 28419 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0420 11:33:03.117482 28419 solver.cpp:219] Iteration 13400 (4.3504 iter/s, 22.9864s/100 iters), loss = 0.327754
I0420 11:33:03.117573 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:33:03.117581 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:33:03.117588 28419 solver.cpp:238]     Train net output #2: loss = 0.327754 (* 1 = 0.327754 loss)
I0420 11:33:03.117593 28419 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0420 11:33:26.213843 28419 solver.cpp:219] Iteration 13500 (4.33012 iter/s, 23.0941s/100 iters), loss = 0.280545
I0420 11:33:26.213901 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:33:26.213908 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:33:26.213915 28419 solver.cpp:238]     Train net output #2: loss = 0.280545 (* 1 = 0.280545 loss)
I0420 11:33:26.213919 28419 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0420 11:33:49.237673 28419 solver.cpp:219] Iteration 13600 (4.34336 iter/s, 23.0236s/100 iters), loss = 0.361238
I0420 11:33:49.237928 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:33:49.237937 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:33:49.237944 28419 solver.cpp:238]     Train net output #2: loss = 0.361238 (* 1 = 0.361238 loss)
I0420 11:33:49.237949 28419 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0420 11:34:04.730929 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:34:12.275571 28419 solver.cpp:219] Iteration 13700 (4.3411 iter/s, 23.0356s/100 iters), loss = 0.262819
I0420 11:34:12.275630 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 11:34:12.275635 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:34:12.275643 28419 solver.cpp:238]     Train net output #2: loss = 0.26282 (* 1 = 0.26282 loss)
I0420 11:34:12.275647 28419 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0420 11:34:35.313400 28419 solver.cpp:219] Iteration 13800 (4.34072 iter/s, 23.0377s/100 iters), loss = 0.344965
I0420 11:34:35.313580 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:34:35.313587 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:34:35.313596 28419 solver.cpp:238]     Train net output #2: loss = 0.344965 (* 1 = 0.344965 loss)
I0420 11:34:35.313599 28419 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0420 11:34:58.383743 28419 solver.cpp:219] Iteration 13900 (4.3346 iter/s, 23.0702s/100 iters), loss = 0.365388
I0420 11:34:58.383805 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:34:58.383810 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:34:58.383817 28419 solver.cpp:238]     Train net output #2: loss = 0.365388 (* 1 = 0.365388 loss)
I0420 11:34:58.383821 28419 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0420 11:35:21.148475 28419 solver.cpp:331] Iteration 14000, Testing net (#0)
I0420 11:35:26.028841 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:35:26.268291 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8321
I0420 11:35:26.268317 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9888
I0420 11:35:26.268340 28419 solver.cpp:398]     Test net output #2: loss = 0.565211 (* 1 = 0.565211 loss)
I0420 11:35:26.421747 28419 solver.cpp:219] Iteration 14000 (3.56687 iter/s, 28.0358s/100 iters), loss = 0.396553
I0420 11:35:26.421768 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 11:35:26.421789 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:35:26.421795 28419 solver.cpp:238]     Train net output #2: loss = 0.396553 (* 1 = 0.396553 loss)
I0420 11:35:26.421802 28419 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0420 11:35:39.852144 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:35:49.516382 28419 solver.cpp:219] Iteration 14100 (4.33005 iter/s, 23.0944s/100 iters), loss = 0.291802
I0420 11:35:49.516443 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:35:49.516448 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:35:49.516454 28419 solver.cpp:238]     Train net output #2: loss = 0.291802 (* 1 = 0.291802 loss)
I0420 11:35:49.516458 28419 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0420 11:36:12.503425 28419 solver.cpp:219] Iteration 14200 (4.35068 iter/s, 22.9849s/100 iters), loss = 0.303292
I0420 11:36:12.503623 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:36:12.503630 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:36:12.503638 28419 solver.cpp:238]     Train net output #2: loss = 0.303292 (* 1 = 0.303292 loss)
I0420 11:36:12.503643 28419 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0420 11:36:35.513170 28419 solver.cpp:219] Iteration 14300 (4.34641 iter/s, 23.0075s/100 iters), loss = 0.39636
I0420 11:36:35.513232 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:36:35.513237 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:36:35.513244 28419 solver.cpp:238]     Train net output #2: loss = 0.39636 (* 1 = 0.39636 loss)
I0420 11:36:35.513248 28419 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0420 11:36:58.616402 28419 solver.cpp:219] Iteration 14400 (4.32883 iter/s, 23.1009s/100 iters), loss = 0.400165
I0420 11:36:58.616533 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:36:58.616541 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:36:58.616549 28419 solver.cpp:238]     Train net output #2: loss = 0.400166 (* 1 = 0.400166 loss)
I0420 11:36:58.616552 28419 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0420 11:37:09.920536 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:37:21.625041 28419 solver.cpp:219] Iteration 14500 (4.34625 iter/s, 23.0084s/100 iters), loss = 0.352879
I0420 11:37:21.625097 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 11:37:21.625102 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:37:21.625109 28419 solver.cpp:238]     Train net output #2: loss = 0.352879 (* 1 = 0.352879 loss)
I0420 11:37:21.625113 28419 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0420 11:37:44.875300 28419 solver.cpp:219] Iteration 14600 (4.30144 iter/s, 23.248s/100 iters), loss = 0.243278
I0420 11:37:44.875394 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 11:37:44.875401 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:37:44.875408 28419 solver.cpp:238]     Train net output #2: loss = 0.243278 (* 1 = 0.243278 loss)
I0420 11:37:44.875413 28419 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0420 11:38:08.928740 28419 solver.cpp:219] Iteration 14700 (4.15782 iter/s, 24.0511s/100 iters), loss = 0.272831
I0420 11:38:08.928802 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:38:08.928807 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:38:08.928814 28419 solver.cpp:238]     Train net output #2: loss = 0.272831 (* 1 = 0.272831 loss)
I0420 11:38:08.928818 28419 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0420 11:38:31.963274 28419 solver.cpp:219] Iteration 14800 (4.3417 iter/s, 23.0325s/100 iters), loss = 0.383629
I0420 11:38:31.963500 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:38:31.963508 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:38:31.963515 28419 solver.cpp:238]     Train net output #2: loss = 0.383629 (* 1 = 0.383629 loss)
I0420 11:38:31.963521 28419 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0420 11:38:40.934329 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:38:55.000980 28419 solver.cpp:219] Iteration 14900 (4.34077 iter/s, 23.0374s/100 iters), loss = 0.237817
I0420 11:38:55.001042 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:38:55.001047 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:38:55.001055 28419 solver.cpp:238]     Train net output #2: loss = 0.237817 (* 1 = 0.237817 loss)
I0420 11:38:55.001058 28419 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0420 11:39:17.777499 28419 solver.cpp:331] Iteration 15000, Testing net (#0)
I0420 11:39:22.634740 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:39:22.870118 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8257
I0420 11:39:22.870141 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9904
I0420 11:39:22.870167 28419 solver.cpp:398]     Test net output #2: loss = 0.582418 (* 1 = 0.582418 loss)
I0420 11:39:23.059612 28419 solver.cpp:219] Iteration 15000 (3.56424 iter/s, 28.0565s/100 iters), loss = 0.314624
I0420 11:39:23.059634 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:39:23.059656 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:39:23.059662 28419 solver.cpp:238]     Train net output #2: loss = 0.314625 (* 1 = 0.314625 loss)
I0420 11:39:23.059669 28419 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0420 11:39:46.115018 28419 solver.cpp:219] Iteration 15100 (4.3374 iter/s, 23.0553s/100 iters), loss = 0.430676
I0420 11:39:46.115077 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0420 11:39:46.115082 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:39:46.115090 28419 solver.cpp:238]     Train net output #2: loss = 0.430676 (* 1 = 0.430676 loss)
I0420 11:39:46.115095 28419 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0420 11:40:09.070875 28419 solver.cpp:219] Iteration 15200 (4.35661 iter/s, 22.9536s/100 iters), loss = 0.367891
I0420 11:40:09.071080 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:40:09.071089 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:40:09.071096 28419 solver.cpp:238]     Train net output #2: loss = 0.367892 (* 1 = 0.367892 loss)
I0420 11:40:09.071101 28419 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0420 11:40:16.021961 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:40:32.110985 28419 solver.cpp:219] Iteration 15300 (4.34067 iter/s, 23.0379s/100 iters), loss = 0.353544
I0420 11:40:32.111047 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 11:40:32.111052 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:40:32.111059 28419 solver.cpp:238]     Train net output #2: loss = 0.353544 (* 1 = 0.353544 loss)
I0420 11:40:32.111063 28419 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0420 11:40:55.164872 28419 solver.cpp:219] Iteration 15400 (4.33768 iter/s, 23.0538s/100 iters), loss = 0.333496
I0420 11:40:55.165009 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:40:55.165017 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:40:55.165024 28419 solver.cpp:238]     Train net output #2: loss = 0.333496 (* 1 = 0.333496 loss)
I0420 11:40:55.165029 28419 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0420 11:41:18.161602 28419 solver.cpp:219] Iteration 15500 (4.34887 iter/s, 22.9945s/100 iters), loss = 0.355235
I0420 11:41:18.161664 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:41:18.161669 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:41:18.161676 28419 solver.cpp:238]     Train net output #2: loss = 0.355235 (* 1 = 0.355235 loss)
I0420 11:41:18.161684 28419 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0420 11:41:41.190078 28419 solver.cpp:219] Iteration 15600 (4.34287 iter/s, 23.0262s/100 iters), loss = 0.294786
I0420 11:41:41.190297 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:41:41.190305 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:41:41.190312 28419 solver.cpp:238]     Train net output #2: loss = 0.294786 (* 1 = 0.294786 loss)
I0420 11:41:41.190316 28419 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0420 11:41:45.865294 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:42:04.292876 28419 solver.cpp:219] Iteration 15700 (4.32891 iter/s, 23.1005s/100 iters), loss = 0.287674
I0420 11:42:04.292939 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:42:04.292944 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:42:04.292951 28419 solver.cpp:238]     Train net output #2: loss = 0.287674 (* 1 = 0.287674 loss)
I0420 11:42:04.292955 28419 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0420 11:42:27.317137 28419 solver.cpp:219] Iteration 15800 (4.34326 iter/s, 23.0242s/100 iters), loss = 0.414364
I0420 11:42:27.317329 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:42:27.317337 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:42:27.317344 28419 solver.cpp:238]     Train net output #2: loss = 0.414364 (* 1 = 0.414364 loss)
I0420 11:42:27.317349 28419 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0420 11:42:50.298671 28419 solver.cpp:219] Iteration 15900 (4.35174 iter/s, 22.9793s/100 iters), loss = 0.275621
I0420 11:42:50.298734 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:42:50.298756 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:42:50.298763 28419 solver.cpp:238]     Train net output #2: loss = 0.275621 (* 1 = 0.275621 loss)
I0420 11:42:50.298768 28419 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0420 11:43:13.217435 28419 solver.cpp:331] Iteration 16000, Testing net (#0)
I0420 11:43:18.017815 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:43:18.211247 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8415
I0420 11:43:18.211272 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9928
I0420 11:43:18.211295 28419 solver.cpp:398]     Test net output #2: loss = 0.509853 (* 1 = 0.509853 loss)
I0420 11:43:18.431602 28419 solver.cpp:219] Iteration 16000 (3.55484 iter/s, 28.1307s/100 iters), loss = 0.232793
I0420 11:43:18.431622 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 11:43:18.431643 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:43:18.431649 28419 solver.cpp:238]     Train net output #2: loss = 0.232793 (* 1 = 0.232793 loss)
I0420 11:43:18.431655 28419 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0420 11:43:20.993842 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:43:41.401984 28419 solver.cpp:219] Iteration 16100 (4.3539 iter/s, 22.9679s/100 iters), loss = 0.30112
I0420 11:43:41.402047 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:43:41.402053 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:43:41.402060 28419 solver.cpp:238]     Train net output #2: loss = 0.30112 (* 1 = 0.30112 loss)
I0420 11:43:41.402065 28419 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0420 11:44:04.467854 28419 solver.cpp:219] Iteration 16200 (4.33585 iter/s, 23.0636s/100 iters), loss = 0.305133
I0420 11:44:04.468019 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:44:04.468027 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:44:04.468034 28419 solver.cpp:238]     Train net output #2: loss = 0.305133 (* 1 = 0.305133 loss)
I0420 11:44:04.468039 28419 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0420 11:44:27.521412 28419 solver.cpp:219] Iteration 16300 (4.33776 iter/s, 23.0534s/100 iters), loss = 0.362748
I0420 11:44:27.521471 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:44:27.521476 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:44:27.521483 28419 solver.cpp:238]     Train net output #2: loss = 0.362748 (* 1 = 0.362748 loss)
I0420 11:44:27.521487 28419 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0420 11:44:50.482843 28419 solver.cpp:219] Iteration 16400 (4.35556 iter/s, 22.9592s/100 iters), loss = 0.31186
I0420 11:44:50.483038 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 11:44:50.483045 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:44:50.483052 28419 solver.cpp:238]     Train net output #2: loss = 0.31186 (* 1 = 0.31186 loss)
I0420 11:44:50.483057 28419 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0420 11:44:50.970082 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:45:13.532073 28419 solver.cpp:219] Iteration 16500 (4.33897 iter/s, 23.0469s/100 iters), loss = 0.342562
I0420 11:45:13.532136 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:45:13.532141 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:45:13.532148 28419 solver.cpp:238]     Train net output #2: loss = 0.342562 (* 1 = 0.342562 loss)
I0420 11:45:13.532152 28419 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0420 11:45:36.490628 28419 solver.cpp:219] Iteration 16600 (4.35571 iter/s, 22.9584s/100 iters), loss = 0.330813
I0420 11:45:36.490869 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:45:36.490878 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:45:36.490885 28419 solver.cpp:238]     Train net output #2: loss = 0.330813 (* 1 = 0.330813 loss)
I0420 11:45:36.490890 28419 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0420 11:45:59.470830 28419 solver.cpp:219] Iteration 16700 (4.35203 iter/s, 22.9778s/100 iters), loss = 0.291897
I0420 11:45:59.470893 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:45:59.470898 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:45:59.470906 28419 solver.cpp:238]     Train net output #2: loss = 0.291897 (* 1 = 0.291897 loss)
I0420 11:45:59.470909 28419 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0420 11:46:20.783457 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:46:22.592375 28419 solver.cpp:219] Iteration 16800 (4.32526 iter/s, 23.12s/100 iters), loss = 0.278985
I0420 11:46:22.592432 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:46:22.592437 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:46:22.592444 28419 solver.cpp:238]     Train net output #2: loss = 0.278985 (* 1 = 0.278985 loss)
I0420 11:46:22.592448 28419 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0420 11:46:45.571432 28419 solver.cpp:219] Iteration 16900 (4.35191 iter/s, 22.9784s/100 iters), loss = 0.292225
I0420 11:46:45.571494 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:46:45.571501 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:46:45.571507 28419 solver.cpp:238]     Train net output #2: loss = 0.292225 (* 1 = 0.292225 loss)
I0420 11:46:45.571511 28419 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0420 11:47:08.420130 28419 solver.cpp:331] Iteration 17000, Testing net (#0)
I0420 11:47:13.225934 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:47:13.463346 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.837
I0420 11:47:13.463373 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9938
I0420 11:47:13.463397 28419 solver.cpp:398]     Test net output #2: loss = 0.527772 (* 1 = 0.527772 loss)
I0420 11:47:13.695767 28419 solver.cpp:219] Iteration 17000 (3.55591 iter/s, 28.1222s/100 iters), loss = 0.295081
I0420 11:47:13.695787 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:47:13.695807 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:47:13.695812 28419 solver.cpp:238]     Train net output #2: loss = 0.295081 (* 1 = 0.295081 loss)
I0420 11:47:13.695818 28419 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0420 11:47:36.685204 28419 solver.cpp:219] Iteration 17100 (4.35025 iter/s, 22.9872s/100 iters), loss = 0.316584
I0420 11:47:36.685267 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:47:36.685276 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:47:36.685281 28419 solver.cpp:238]     Train net output #2: loss = 0.316584 (* 1 = 0.316584 loss)
I0420 11:47:36.685286 28419 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0420 11:47:56.471360 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:48:00.784899 28419 solver.cpp:219] Iteration 17200 (4.14982 iter/s, 24.0974s/100 iters), loss = 0.272611
I0420 11:48:00.784953 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:48:00.784958 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:48:00.784965 28419 solver.cpp:238]     Train net output #2: loss = 0.272611 (* 1 = 0.272611 loss)
I0420 11:48:00.784970 28419 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0420 11:48:23.905019 28419 solver.cpp:219] Iteration 17300 (4.32565 iter/s, 23.1179s/100 iters), loss = 0.274162
I0420 11:48:23.905081 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:48:23.905086 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:48:23.905092 28419 solver.cpp:238]     Train net output #2: loss = 0.274163 (* 1 = 0.274163 loss)
I0420 11:48:23.905097 28419 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0420 11:48:46.975173 28419 solver.cpp:219] Iteration 17400 (4.33463 iter/s, 23.07s/100 iters), loss = 0.435194
I0420 11:48:46.975411 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 11:48:46.975420 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:48:46.975427 28419 solver.cpp:238]     Train net output #2: loss = 0.435194 (* 1 = 0.435194 loss)
I0420 11:48:46.975432 28419 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0420 11:49:09.952493 28419 solver.cpp:219] Iteration 17500 (4.35256 iter/s, 22.975s/100 iters), loss = 0.3135
I0420 11:49:09.952559 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:49:09.952564 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:49:09.952572 28419 solver.cpp:238]     Train net output #2: loss = 0.3135 (* 1 = 0.3135 loss)
I0420 11:49:09.952576 28419 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0420 11:49:27.028781 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:49:32.985574 28419 solver.cpp:219] Iteration 17600 (4.34199 iter/s, 23.0309s/100 iters), loss = 0.289031
I0420 11:49:32.985632 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:49:32.985638 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:49:32.985646 28419 solver.cpp:238]     Train net output #2: loss = 0.289031 (* 1 = 0.289031 loss)
I0420 11:49:32.985651 28419 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0420 11:49:56.022589 28419 solver.cpp:219] Iteration 17700 (4.34088 iter/s, 23.0368s/100 iters), loss = 0.344739
I0420 11:49:56.022653 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:49:56.022660 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:49:56.022665 28419 solver.cpp:238]     Train net output #2: loss = 0.344739 (* 1 = 0.344739 loss)
I0420 11:49:56.022670 28419 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0420 11:50:18.974828 28419 solver.cpp:219] Iteration 17800 (4.3573 iter/s, 22.95s/100 iters), loss = 0.337386
I0420 11:50:18.974920 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:50:18.974928 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:50:18.974936 28419 solver.cpp:238]     Train net output #2: loss = 0.337386 (* 1 = 0.337386 loss)
I0420 11:50:18.974939 28419 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0420 11:50:42.027755 28419 solver.cpp:219] Iteration 17900 (4.33828 iter/s, 23.0506s/100 iters), loss = 0.325758
I0420 11:50:42.027820 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:50:42.027825 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:50:42.027833 28419 solver.cpp:238]     Train net output #2: loss = 0.325758 (* 1 = 0.325758 loss)
I0420 11:50:42.027838 28419 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0420 11:50:56.803150 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:51:04.801714 28419 solver.cpp:331] Iteration 18000, Testing net (#0)
I0420 11:51:09.673995 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:51:09.914106 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8455
I0420 11:51:09.914135 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.992
I0420 11:51:09.914160 28419 solver.cpp:398]     Test net output #2: loss = 0.504431 (* 1 = 0.504431 loss)
I0420 11:51:10.029341 28419 solver.cpp:219] Iteration 18000 (3.57124 iter/s, 28.0015s/100 iters), loss = 0.342801
I0420 11:51:10.029363 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:51:10.029384 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:51:10.029391 28419 solver.cpp:238]     Train net output #2: loss = 0.342801 (* 1 = 0.342801 loss)
I0420 11:51:10.029397 28419 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0420 11:51:33.071261 28419 solver.cpp:219] Iteration 18100 (4.33996 iter/s, 23.0417s/100 iters), loss = 0.382637
I0420 11:51:33.071527 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:51:33.071535 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:51:33.071542 28419 solver.cpp:238]     Train net output #2: loss = 0.382637 (* 1 = 0.382637 loss)
I0420 11:51:33.071547 28419 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0420 11:51:55.947441 28419 solver.cpp:219] Iteration 18200 (4.3718 iter/s, 22.8739s/100 iters), loss = 0.227023
I0420 11:51:55.947496 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:51:55.947502 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:51:55.947510 28419 solver.cpp:238]     Train net output #2: loss = 0.227023 (* 1 = 0.227023 loss)
I0420 11:51:55.947513 28419 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0420 11:52:18.954778 28419 solver.cpp:219] Iteration 18300 (4.34687 iter/s, 23.0051s/100 iters), loss = 0.218153
I0420 11:52:18.954905 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 11:52:18.954911 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:52:18.954917 28419 solver.cpp:238]     Train net output #2: loss = 0.218153 (* 1 = 0.218153 loss)
I0420 11:52:18.954921 28419 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0420 11:52:31.603058 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:52:41.828687 28419 solver.cpp:219] Iteration 18400 (4.37224 iter/s, 22.8716s/100 iters), loss = 0.318114
I0420 11:52:41.828749 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:52:41.828754 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:52:41.828761 28419 solver.cpp:238]     Train net output #2: loss = 0.318115 (* 1 = 0.318115 loss)
I0420 11:52:41.828765 28419 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0420 11:53:04.816175 28419 solver.cpp:219] Iteration 18500 (4.35023 iter/s, 22.9873s/100 iters), loss = 0.232784
I0420 11:53:04.816368 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 11:53:04.816376 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:53:04.816382 28419 solver.cpp:238]     Train net output #2: loss = 0.232784 (* 1 = 0.232784 loss)
I0420 11:53:04.816390 28419 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0420 11:53:27.721436 28419 solver.cpp:219] Iteration 18600 (4.36624 iter/s, 22.903s/100 iters), loss = 0.387684
I0420 11:53:27.721491 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:53:27.721498 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:53:27.721503 28419 solver.cpp:238]     Train net output #2: loss = 0.387684 (* 1 = 0.387684 loss)
I0420 11:53:27.721508 28419 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0420 11:53:50.681349 28419 solver.cpp:219] Iteration 18700 (4.35543 iter/s, 22.9599s/100 iters), loss = 0.215956
I0420 11:53:50.681535 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 11:53:50.681543 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:53:50.681550 28419 solver.cpp:238]     Train net output #2: loss = 0.215956 (* 1 = 0.215956 loss)
I0420 11:53:50.681555 28419 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0420 11:54:01.054023 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:54:13.616107 28419 solver.cpp:219] Iteration 18800 (4.36065 iter/s, 22.9324s/100 iters), loss = 0.295467
I0420 11:54:13.616163 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:54:13.616168 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:54:13.616174 28419 solver.cpp:238]     Train net output #2: loss = 0.295467 (* 1 = 0.295467 loss)
I0420 11:54:13.616178 28419 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0420 11:54:36.579221 28419 solver.cpp:219] Iteration 18900 (4.35483 iter/s, 22.963s/100 iters), loss = 0.219922
I0420 11:54:36.579412 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:54:36.579419 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:54:36.579427 28419 solver.cpp:238]     Train net output #2: loss = 0.219922 (* 1 = 0.219922 loss)
I0420 11:54:36.579430 28419 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0420 11:54:59.347297 28419 solver.cpp:331] Iteration 19000, Testing net (#0)
I0420 11:55:04.172569 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:55:04.334417 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.792
I0420 11:55:04.334445 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9866
I0420 11:55:04.334468 28419 solver.cpp:398]     Test net output #2: loss = 0.758818 (* 1 = 0.758818 loss)
I0420 11:55:04.555831 28419 solver.cpp:219] Iteration 19000 (3.57469 iter/s, 27.9745s/100 iters), loss = 0.263648
I0420 11:55:04.555852 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:55:04.555872 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:55:04.555878 28419 solver.cpp:238]     Train net output #2: loss = 0.263648 (* 1 = 0.263648 loss)
I0420 11:55:04.555884 28419 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0420 11:55:27.491806 28419 solver.cpp:219] Iteration 19100 (4.3604 iter/s, 22.9337s/100 iters), loss = 0.381944
I0420 11:55:27.492048 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:55:27.492056 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:55:27.492063 28419 solver.cpp:238]     Train net output #2: loss = 0.381944 (* 1 = 0.381944 loss)
I0420 11:55:27.492067 28419 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0420 11:55:35.802582 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:55:50.437170 28419 solver.cpp:219] Iteration 19200 (4.35824 iter/s, 22.945s/100 iters), loss = 0.327119
I0420 11:55:50.437225 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 11:55:50.437230 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:55:50.437237 28419 solver.cpp:238]     Train net output #2: loss = 0.327119 (* 1 = 0.327119 loss)
I0420 11:55:50.437240 28419 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0420 11:56:13.383630 28419 solver.cpp:219] Iteration 19300 (4.3584 iter/s, 22.9442s/100 iters), loss = 0.523913
I0420 11:56:13.383827 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 11:56:13.383836 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0420 11:56:13.383841 28419 solver.cpp:238]     Train net output #2: loss = 0.523913 (* 1 = 0.523913 loss)
I0420 11:56:13.383846 28419 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0420 11:56:36.348076 28419 solver.cpp:219] Iteration 19400 (4.35463 iter/s, 22.9641s/100 iters), loss = 0.368929
I0420 11:56:36.348130 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 11:56:36.348136 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:56:36.348142 28419 solver.cpp:238]     Train net output #2: loss = 0.368929 (* 1 = 0.368929 loss)
I0420 11:56:36.348146 28419 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0420 11:56:59.276618 28419 solver.cpp:219] Iteration 19500 (4.36183 iter/s, 22.9262s/100 iters), loss = 0.312062
I0420 11:56:59.276703 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:56:59.276726 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:56:59.276732 28419 solver.cpp:238]     Train net output #2: loss = 0.312062 (* 1 = 0.312062 loss)
I0420 11:56:59.276736 28419 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0420 11:57:05.517093 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:57:22.219552 28419 solver.cpp:219] Iteration 19600 (4.35866 iter/s, 22.9428s/100 iters), loss = 0.356553
I0420 11:57:22.219607 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 11:57:22.219612 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:57:22.219619 28419 solver.cpp:238]     Train net output #2: loss = 0.356553 (* 1 = 0.356553 loss)
I0420 11:57:22.219622 28419 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0420 11:57:45.166167 28419 solver.cpp:219] Iteration 19700 (4.35836 iter/s, 22.9444s/100 iters), loss = 0.328578
I0420 11:57:45.166400 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:57:45.166409 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:57:45.166416 28419 solver.cpp:238]     Train net output #2: loss = 0.328578 (* 1 = 0.328578 loss)
I0420 11:57:45.166422 28419 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0420 11:58:09.229315 28419 solver.cpp:219] Iteration 19800 (4.15579 iter/s, 24.0628s/100 iters), loss = 0.327221
I0420 11:58:09.229368 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 11:58:09.229374 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 11:58:09.229380 28419 solver.cpp:238]     Train net output #2: loss = 0.327221 (* 1 = 0.327221 loss)
I0420 11:58:09.229384 28419 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0420 11:58:32.265692 28419 solver.cpp:219] Iteration 19900 (4.34139 iter/s, 23.0341s/100 iters), loss = 0.282245
I0420 11:58:32.265903 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 11:58:32.265910 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:58:32.265916 28419 solver.cpp:238]     Train net output #2: loss = 0.282245 (* 1 = 0.282245 loss)
I0420 11:58:32.265923 28419 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0420 11:58:36.244129 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:58:55.030827 28419 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_finetune_quant_0.09_iter_20000.caffemodel
I0420 11:58:55.053736 28419 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_finetune_quant_0.09_iter_20000.solverstate
I0420 11:58:55.069284 28419 solver.cpp:331] Iteration 20000, Testing net (#0)
I0420 11:58:59.944916 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 11:59:00.067292 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.824
I0420 11:59:00.067322 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9882
I0420 11:59:00.067345 28419 solver.cpp:398]     Test net output #2: loss = 0.597966 (* 1 = 0.597966 loss)
I0420 11:59:00.289819 28419 solver.cpp:219] Iteration 20000 (3.56864 iter/s, 28.0219s/100 iters), loss = 0.23717
I0420 11:59:00.289840 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 11:59:00.289860 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:59:00.289866 28419 solver.cpp:238]     Train net output #2: loss = 0.23717 (* 1 = 0.23717 loss)
I0420 11:59:00.289873 28419 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0420 11:59:23.265141 28419 solver.cpp:219] Iteration 20100 (4.35292 iter/s, 22.9731s/100 iters), loss = 0.334471
I0420 11:59:23.265302 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 11:59:23.265310 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 11:59:23.265316 28419 solver.cpp:238]     Train net output #2: loss = 0.334471 (* 1 = 0.334471 loss)
I0420 11:59:23.265321 28419 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0420 11:59:46.174147 28419 solver.cpp:219] Iteration 20200 (4.36512 iter/s, 22.9089s/100 iters), loss = 0.267566
I0420 11:59:46.174202 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 11:59:46.174207 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 11:59:46.174214 28419 solver.cpp:238]     Train net output #2: loss = 0.267566 (* 1 = 0.267566 loss)
I0420 11:59:46.174218 28419 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0420 12:00:09.172565 28419 solver.cpp:219] Iteration 20300 (4.34854 iter/s, 22.9962s/100 iters), loss = 0.228658
I0420 12:00:09.172767 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 12:00:09.172775 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:00:09.172781 28419 solver.cpp:238]     Train net output #2: loss = 0.228658 (* 1 = 0.228658 loss)
I0420 12:00:09.172785 28419 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0420 12:00:11.010968 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:00:32.084858 28419 solver.cpp:219] Iteration 20400 (4.3649 iter/s, 22.91s/100 iters), loss = 0.239691
I0420 12:00:32.084914 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:00:32.084919 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:00:32.084928 28419 solver.cpp:238]     Train net output #2: loss = 0.239691 (* 1 = 0.239691 loss)
I0420 12:00:32.084931 28419 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0420 12:00:55.065760 28419 solver.cpp:219] Iteration 20500 (4.3515 iter/s, 22.9806s/100 iters), loss = 0.223877
I0420 12:00:55.065999 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:00:55.066006 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:00:55.066014 28419 solver.cpp:238]     Train net output #2: loss = 0.223877 (* 1 = 0.223877 loss)
I0420 12:00:55.066017 28419 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0420 12:01:17.942508 28419 solver.cpp:219] Iteration 20600 (4.37169 iter/s, 22.8745s/100 iters), loss = 0.311214
I0420 12:01:17.942564 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 12:01:17.942569 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:01:17.942575 28419 solver.cpp:238]     Train net output #2: loss = 0.311214 (* 1 = 0.311214 loss)
I0420 12:01:17.942579 28419 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0420 12:01:40.723271 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:01:40.949535 28419 solver.cpp:219] Iteration 20700 (4.34693 iter/s, 23.0047s/100 iters), loss = 0.308401
I0420 12:01:40.949563 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:01:40.949584 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:01:40.949589 28419 solver.cpp:238]     Train net output #2: loss = 0.308401 (* 1 = 0.308401 loss)
I0420 12:01:40.949594 28419 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0420 12:02:03.816964 28419 solver.cpp:219] Iteration 20800 (4.37345 iter/s, 22.8652s/100 iters), loss = 0.28733
I0420 12:02:03.817019 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:02:03.817024 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:02:03.817031 28419 solver.cpp:238]     Train net output #2: loss = 0.28733 (* 1 = 0.28733 loss)
I0420 12:02:03.817035 28419 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0420 12:02:26.809545 28419 solver.cpp:219] Iteration 20900 (4.34925 iter/s, 22.9925s/100 iters), loss = 0.367444
I0420 12:02:26.809739 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 12:02:26.809746 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 12:02:26.809753 28419 solver.cpp:238]     Train net output #2: loss = 0.367444 (* 1 = 0.367444 loss)
I0420 12:02:26.809758 28419 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0420 12:02:49.570454 28419 solver.cpp:331] Iteration 21000, Testing net (#0)
I0420 12:02:54.376305 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:02:54.567803 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8457
I0420 12:02:54.567831 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9934
I0420 12:02:54.567853 28419 solver.cpp:398]     Test net output #2: loss = 0.51328 (* 1 = 0.51328 loss)
I0420 12:02:54.791215 28419 solver.cpp:219] Iteration 21000 (3.57404 iter/s, 27.9795s/100 iters), loss = 0.34455
I0420 12:02:54.791236 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:02:54.791256 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:02:54.791262 28419 solver.cpp:238]     Train net output #2: loss = 0.34455 (* 1 = 0.34455 loss)
I0420 12:02:54.791268 28419 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0420 12:03:15.222504 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:03:17.671102 28419 solver.cpp:219] Iteration 21100 (4.37108 iter/s, 22.8777s/100 iters), loss = 0.316426
I0420 12:03:17.671156 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:03:17.671161 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:03:17.671169 28419 solver.cpp:238]     Train net output #2: loss = 0.316426 (* 1 = 0.316426 loss)
I0420 12:03:17.671172 28419 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0420 12:03:40.630820 28419 solver.cpp:219] Iteration 21200 (4.35549 iter/s, 22.9595s/100 iters), loss = 0.473232
I0420 12:03:40.630870 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0420 12:03:40.630875 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:03:40.630883 28419 solver.cpp:238]     Train net output #2: loss = 0.473232 (* 1 = 0.473232 loss)
I0420 12:03:40.630887 28419 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0420 12:04:03.578760 28419 solver.cpp:219] Iteration 21300 (4.35815 iter/s, 22.9455s/100 iters), loss = 0.267351
I0420 12:04:03.578985 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 12:04:03.578994 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:04:03.579000 28419 solver.cpp:238]     Train net output #2: loss = 0.267351 (* 1 = 0.267351 loss)
I0420 12:04:03.579005 28419 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0420 12:04:26.510942 28419 solver.cpp:219] Iteration 21400 (4.36076 iter/s, 22.9318s/100 iters), loss = 0.166987
I0420 12:04:26.510998 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 12:04:26.511003 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:04:26.511010 28419 solver.cpp:238]     Train net output #2: loss = 0.166987 (* 1 = 0.166987 loss)
I0420 12:04:26.511014 28419 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0420 12:04:44.891005 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:04:49.480602 28419 solver.cpp:219] Iteration 21500 (4.354 iter/s, 22.9674s/100 iters), loss = 0.284935
I0420 12:04:49.480656 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:04:49.480662 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:04:49.480669 28419 solver.cpp:238]     Train net output #2: loss = 0.284935 (* 1 = 0.284935 loss)
I0420 12:04:49.480672 28419 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0420 12:05:12.381171 28419 solver.cpp:219] Iteration 21600 (4.36672 iter/s, 22.9005s/100 iters), loss = 0.35718
I0420 12:05:12.381223 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 12:05:12.381228 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:05:12.381235 28419 solver.cpp:238]     Train net output #2: loss = 0.35718 (* 1 = 0.35718 loss)
I0420 12:05:12.381239 28419 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0420 12:05:35.374160 28419 solver.cpp:219] Iteration 21700 (4.34917 iter/s, 22.9929s/100 iters), loss = 0.285163
I0420 12:05:35.374361 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:05:35.374367 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:05:35.374374 28419 solver.cpp:238]     Train net output #2: loss = 0.285163 (* 1 = 0.285163 loss)
I0420 12:05:35.374378 28419 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0420 12:05:58.237814 28419 solver.cpp:219] Iteration 21800 (4.37383 iter/s, 22.8633s/100 iters), loss = 0.278551
I0420 12:05:58.237869 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 12:05:58.237874 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:05:58.237881 28419 solver.cpp:238]     Train net output #2: loss = 0.278551 (* 1 = 0.278551 loss)
I0420 12:05:58.237885 28419 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0420 12:06:14.362499 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:06:21.253343 28419 solver.cpp:219] Iteration 21900 (4.34532 iter/s, 23.0133s/100 iters), loss = 0.35787
I0420 12:06:21.253401 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0420 12:06:21.253407 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:06:21.253412 28419 solver.cpp:238]     Train net output #2: loss = 0.35787 (* 1 = 0.35787 loss)
I0420 12:06:21.253417 28419 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0420 12:06:43.961967 28419 solver.cpp:331] Iteration 22000, Testing net (#0)
I0420 12:06:48.775905 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:06:49.010023 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8214
I0420 12:06:49.010046 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9884
I0420 12:06:49.010071 28419 solver.cpp:398]     Test net output #2: loss = 0.588824 (* 1 = 0.588824 loss)
I0420 12:06:49.231762 28419 solver.cpp:219] Iteration 22000 (3.57445 iter/s, 27.9763s/100 iters), loss = 0.266927
I0420 12:06:49.231784 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 12:06:49.231806 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:06:49.231812 28419 solver.cpp:238]     Train net output #2: loss = 0.266927 (* 1 = 0.266927 loss)
I0420 12:06:49.231818 28419 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I0420 12:07:12.105058 28419 solver.cpp:219] Iteration 22100 (4.37194 iter/s, 22.8732s/100 iters), loss = 0.274095
I0420 12:07:12.105115 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:07:12.105123 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:07:12.105129 28419 solver.cpp:238]     Train net output #2: loss = 0.274095 (* 1 = 0.274095 loss)
I0420 12:07:12.105134 28419 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I0420 12:07:35.116906 28419 solver.cpp:219] Iteration 22200 (4.34604 iter/s, 23.0095s/100 iters), loss = 0.472516
I0420 12:07:35.117099 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0420 12:07:35.117105 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:07:35.117112 28419 solver.cpp:238]     Train net output #2: loss = 0.472516 (* 1 = 0.472516 loss)
I0420 12:07:35.117116 28419 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I0420 12:07:49.119212 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:07:58.013231 28419 solver.cpp:219] Iteration 22300 (4.36763 iter/s, 22.8957s/100 iters), loss = 0.247628
I0420 12:07:58.013286 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 12:07:58.013291 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:07:58.013298 28419 solver.cpp:238]     Train net output #2: loss = 0.247628 (* 1 = 0.247628 loss)
I0420 12:07:58.013303 28419 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I0420 12:08:22.163462 28419 solver.cpp:219] Iteration 22400 (4.14077 iter/s, 24.1501s/100 iters), loss = 0.301323
I0420 12:08:22.163585 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 12:08:22.163592 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:08:22.163599 28419 solver.cpp:238]     Train net output #2: loss = 0.301323 (* 1 = 0.301323 loss)
I0420 12:08:22.163602 28419 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I0420 12:08:45.144276 28419 solver.cpp:219] Iteration 22500 (4.35148 iter/s, 22.9807s/100 iters), loss = 0.275688
I0420 12:08:45.144330 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 12:08:45.144335 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:08:45.144341 28419 solver.cpp:238]     Train net output #2: loss = 0.275688 (* 1 = 0.275688 loss)
I0420 12:08:45.144345 28419 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I0420 12:09:08.051942 28419 solver.cpp:219] Iteration 22600 (4.36577 iter/s, 22.9055s/100 iters), loss = 0.279075
I0420 12:09:08.052112 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 12:09:08.052119 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:09:08.052126 28419 solver.cpp:238]     Train net output #2: loss = 0.279075 (* 1 = 0.279075 loss)
I0420 12:09:08.052130 28419 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I0420 12:09:19.987129 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:09:31.017511 28419 solver.cpp:219] Iteration 22700 (4.35437 iter/s, 22.9654s/100 iters), loss = 0.23098
I0420 12:09:31.017568 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 12:09:31.017573 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:09:31.017580 28419 solver.cpp:238]     Train net output #2: loss = 0.23098 (* 1 = 0.23098 loss)
I0420 12:09:31.017585 28419 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I0420 12:09:53.955760 28419 solver.cpp:219] Iteration 22800 (4.35993 iter/s, 22.9361s/100 iters), loss = 0.302026
I0420 12:09:53.956018 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:09:53.956027 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:09:53.956033 28419 solver.cpp:238]     Train net output #2: loss = 0.302026 (* 1 = 0.302026 loss)
I0420 12:09:53.956037 28419 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I0420 12:10:16.890285 28419 solver.cpp:219] Iteration 22900 (4.3603 iter/s, 22.9342s/100 iters), loss = 0.257376
I0420 12:10:16.890337 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:10:16.890342 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:10:16.890350 28419 solver.cpp:238]     Train net output #2: loss = 0.257376 (* 1 = 0.257376 loss)
I0420 12:10:16.890354 28419 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I0420 12:10:39.647742 28419 solver.cpp:331] Iteration 23000, Testing net (#0)
I0420 12:10:44.526489 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:10:44.680145 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8321
I0420 12:10:44.680171 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9893
I0420 12:10:44.680196 28419 solver.cpp:398]     Test net output #2: loss = 0.571349 (* 1 = 0.571349 loss)
I0420 12:10:44.894484 28419 solver.cpp:219] Iteration 23000 (3.57117 iter/s, 28.002s/100 iters), loss = 0.405198
I0420 12:10:44.894522 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 12:10:44.894527 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:10:44.894532 28419 solver.cpp:238]     Train net output #2: loss = 0.405198 (* 1 = 0.405198 loss)
I0420 12:10:44.894538 28419 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I0420 12:10:54.600666 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:11:07.826350 28419 solver.cpp:219] Iteration 23100 (4.36118 iter/s, 22.9296s/100 iters), loss = 0.470564
I0420 12:11:07.826405 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 12:11:07.826409 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:11:07.826416 28419 solver.cpp:238]     Train net output #2: loss = 0.470564 (* 1 = 0.470564 loss)
I0420 12:11:07.826421 28419 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I0420 12:11:30.790949 28419 solver.cpp:219] Iteration 23200 (4.35456 iter/s, 22.9644s/100 iters), loss = 0.326033
I0420 12:11:30.791160 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:11:30.791167 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:11:30.791174 28419 solver.cpp:238]     Train net output #2: loss = 0.326033 (* 1 = 0.326033 loss)
I0420 12:11:30.791179 28419 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I0420 12:11:53.728240 28419 solver.cpp:219] Iteration 23300 (4.36013 iter/s, 22.9351s/100 iters), loss = 0.359645
I0420 12:11:53.728292 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 12:11:53.728298 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:11:53.728304 28419 solver.cpp:238]     Train net output #2: loss = 0.359645 (* 1 = 0.359645 loss)
I0420 12:11:53.728308 28419 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I0420 12:12:16.641904 28419 solver.cpp:219] Iteration 23400 (4.36423 iter/s, 22.9136s/100 iters), loss = 0.321204
I0420 12:12:16.642068 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:12:16.642076 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:12:16.642082 28419 solver.cpp:238]     Train net output #2: loss = 0.321204 (* 1 = 0.321204 loss)
I0420 12:12:16.642086 28419 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I0420 12:12:24.234722 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:12:39.611268 28419 solver.cpp:219] Iteration 23500 (4.35404 iter/s, 22.9672s/100 iters), loss = 0.285995
I0420 12:12:39.611322 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 12:12:39.611327 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:12:39.611335 28419 solver.cpp:238]     Train net output #2: loss = 0.285995 (* 1 = 0.285995 loss)
I0420 12:12:39.611338 28419 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I0420 12:13:02.523777 28419 solver.cpp:219] Iteration 23600 (4.36446 iter/s, 22.9123s/100 iters), loss = 0.277424
I0420 12:13:02.523901 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 12:13:02.523910 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:13:02.523916 28419 solver.cpp:238]     Train net output #2: loss = 0.277424 (* 1 = 0.277424 loss)
I0420 12:13:02.523921 28419 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I0420 12:13:25.506853 28419 solver.cpp:219] Iteration 23700 (4.35144 iter/s, 22.9809s/100 iters), loss = 0.351616
I0420 12:13:25.506891 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 12:13:25.506913 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 12:13:25.506922 28419 solver.cpp:238]     Train net output #2: loss = 0.351616 (* 1 = 0.351616 loss)
I0420 12:13:25.506925 28419 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I0420 12:13:48.400965 28419 solver.cpp:219] Iteration 23800 (4.36796 iter/s, 22.894s/100 iters), loss = 0.37593
I0420 12:13:48.401142 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:13:48.401149 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:13:48.401155 28419 solver.cpp:238]     Train net output #2: loss = 0.37593 (* 1 = 0.37593 loss)
I0420 12:13:48.401160 28419 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I0420 12:13:54.002795 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:14:11.392702 28419 solver.cpp:219] Iteration 23900 (4.34941 iter/s, 22.9916s/100 iters), loss = 0.331125
I0420 12:14:11.392758 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:14:11.392765 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:14:11.392771 28419 solver.cpp:238]     Train net output #2: loss = 0.331124 (* 1 = 0.331124 loss)
I0420 12:14:11.392776 28419 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I0420 12:14:34.100523 28419 solver.cpp:331] Iteration 24000, Testing net (#0)
I0420 12:14:38.961336 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:14:39.190069 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.7785
I0420 12:14:39.190096 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9832
I0420 12:14:39.190120 28419 solver.cpp:398]     Test net output #2: loss = 0.800379 (* 1 = 0.800379 loss)
I0420 12:14:39.378625 28419 solver.cpp:219] Iteration 24000 (3.57349 iter/s, 27.9839s/100 iters), loss = 0.328621
I0420 12:14:39.378646 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 12:14:39.378667 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:14:39.378674 28419 solver.cpp:238]     Train net output #2: loss = 0.328621 (* 1 = 0.328621 loss)
I0420 12:14:39.378679 28419 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I0420 12:15:02.280160 28419 solver.cpp:219] Iteration 24100 (4.36656 iter/s, 22.9013s/100 iters), loss = 0.272774
I0420 12:15:02.280215 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:15:02.280220 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:15:02.280227 28419 solver.cpp:238]     Train net output #2: loss = 0.272774 (* 1 = 0.272774 loss)
I0420 12:15:02.280231 28419 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I0420 12:15:25.275964 28419 solver.cpp:219] Iteration 24200 (4.34903 iter/s, 22.9936s/100 iters), loss = 0.285043
I0420 12:15:25.276165 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:15:25.276173 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:15:25.276180 28419 solver.cpp:238]     Train net output #2: loss = 0.285043 (* 1 = 0.285043 loss)
I0420 12:15:25.276185 28419 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I0420 12:15:28.501544 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:15:48.201776 28419 solver.cpp:219] Iteration 24300 (4.36197 iter/s, 22.9254s/100 iters), loss = 0.388986
I0420 12:15:48.201829 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 12:15:48.201835 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:15:48.201841 28419 solver.cpp:238]     Train net output #2: loss = 0.388986 (* 1 = 0.388986 loss)
I0420 12:15:48.201845 28419 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I0420 12:16:11.209848 28419 solver.cpp:219] Iteration 24400 (4.34633 iter/s, 23.0079s/100 iters), loss = 0.18965
I0420 12:16:11.210021 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 12:16:11.210028 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:16:11.210034 28419 solver.cpp:238]     Train net output #2: loss = 0.18965 (* 1 = 0.18965 loss)
I0420 12:16:11.210039 28419 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I0420 12:16:34.097190 28419 solver.cpp:219] Iteration 24500 (4.36925 iter/s, 22.8872s/100 iters), loss = 0.315883
I0420 12:16:34.097246 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:16:34.097251 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:16:34.097259 28419 solver.cpp:238]     Train net output #2: loss = 0.315883 (* 1 = 0.315883 loss)
I0420 12:16:34.097262 28419 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I0420 12:16:57.086992 28419 solver.cpp:219] Iteration 24600 (4.34978 iter/s, 22.9897s/100 iters), loss = 0.232963
I0420 12:16:57.087074 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 12:16:57.087080 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:16:57.087085 28419 solver.cpp:238]     Train net output #2: loss = 0.232963 (* 1 = 0.232963 loss)
I0420 12:16:57.087090 28419 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I0420 12:16:58.262362 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:17:19.970058 28419 solver.cpp:219] Iteration 24700 (4.37006 iter/s, 22.883s/100 iters), loss = 0.334632
I0420 12:17:19.970113 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:17:19.970118 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:17:19.970125 28419 solver.cpp:238]     Train net output #2: loss = 0.334632 (* 1 = 0.334632 loss)
I0420 12:17:19.970129 28419 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I0420 12:17:42.951786 28419 solver.cpp:219] Iteration 24800 (4.35132 iter/s, 22.9815s/100 iters), loss = 0.341414
I0420 12:17:42.951988 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 12:17:42.951995 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:17:42.952003 28419 solver.cpp:238]     Train net output #2: loss = 0.341414 (* 1 = 0.341414 loss)
I0420 12:17:42.952006 28419 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I0420 12:18:05.851408 28419 solver.cpp:219] Iteration 24900 (4.36693 iter/s, 22.8994s/100 iters), loss = 0.319992
I0420 12:18:05.851464 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:18:05.851469 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:18:05.851475 28419 solver.cpp:238]     Train net output #2: loss = 0.319992 (* 1 = 0.319992 loss)
I0420 12:18:05.851480 28419 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I0420 12:18:28.925285 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:18:29.896970 28419 solver.cpp:331] Iteration 25000, Testing net (#0)
I0420 12:18:34.668622 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:18:34.884292 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8321
I0420 12:18:34.884318 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9922
I0420 12:18:34.884340 28419 solver.cpp:398]     Test net output #2: loss = 0.55658 (* 1 = 0.55658 loss)
I0420 12:18:35.111124 28419 solver.cpp:219] Iteration 25000 (3.41792 iter/s, 29.2576s/100 iters), loss = 0.214104
I0420 12:18:35.111145 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 12:18:35.111166 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:18:35.111172 28419 solver.cpp:238]     Train net output #2: loss = 0.214104 (* 1 = 0.214104 loss)
I0420 12:18:35.111178 28419 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I0420 12:18:57.988819 28419 solver.cpp:219] Iteration 25100 (4.37151 iter/s, 22.8754s/100 iters), loss = 0.227248
I0420 12:18:57.988872 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:18:57.988876 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:18:57.988883 28419 solver.cpp:238]     Train net output #2: loss = 0.227248 (* 1 = 0.227248 loss)
I0420 12:18:57.988886 28419 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I0420 12:19:20.963796 28419 solver.cpp:219] Iteration 25200 (4.35301 iter/s, 22.9726s/100 iters), loss = 0.408259
I0420 12:19:20.964042 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 12:19:20.964051 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:19:20.964056 28419 solver.cpp:238]     Train net output #2: loss = 0.408259 (* 1 = 0.408259 loss)
I0420 12:19:20.964061 28419 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I0420 12:19:43.850958 28419 solver.cpp:219] Iteration 25300 (4.36969 iter/s, 22.8849s/100 iters), loss = 0.368136
I0420 12:19:43.851013 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 12:19:43.851018 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:19:43.851025 28419 solver.cpp:238]     Train net output #2: loss = 0.368136 (* 1 = 0.368136 loss)
I0420 12:19:43.851029 28419 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I0420 12:20:03.636029 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:20:06.825930 28419 solver.cpp:219] Iteration 25400 (4.35298 iter/s, 22.9728s/100 iters), loss = 0.328891
I0420 12:20:06.825984 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:20:06.825990 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:20:06.825997 28419 solver.cpp:238]     Train net output #2: loss = 0.328891 (* 1 = 0.328891 loss)
I0420 12:20:06.826001 28419 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I0420 12:20:29.732482 28419 solver.cpp:219] Iteration 25500 (4.36599 iter/s, 22.9043s/100 iters), loss = 0.3255
I0420 12:20:29.732533 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:20:29.732538 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:20:29.732545 28419 solver.cpp:238]     Train net output #2: loss = 0.3255 (* 1 = 0.3255 loss)
I0420 12:20:29.732549 28419 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I0420 12:20:52.685530 28419 solver.cpp:219] Iteration 25600 (4.35675 iter/s, 22.9529s/100 iters), loss = 0.409678
I0420 12:20:52.685698 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 12:20:52.685706 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:20:52.685712 28419 solver.cpp:238]     Train net output #2: loss = 0.409678 (* 1 = 0.409678 loss)
I0420 12:20:52.685716 28419 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I0420 12:21:15.621469 28419 solver.cpp:219] Iteration 25700 (4.36042 iter/s, 22.9336s/100 iters), loss = 0.2506
I0420 12:21:15.621525 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:21:15.621531 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:21:15.621536 28419 solver.cpp:238]     Train net output #2: loss = 0.2506 (* 1 = 0.2506 loss)
I0420 12:21:15.621541 28419 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I0420 12:21:33.375465 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:21:38.568295 28419 solver.cpp:219] Iteration 25800 (4.35792 iter/s, 22.9467s/100 iters), loss = 0.153993
I0420 12:21:38.568349 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 12:21:38.568354 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:21:38.568361 28419 solver.cpp:238]     Train net output #2: loss = 0.153993 (* 1 = 0.153993 loss)
I0420 12:21:38.568366 28419 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I0420 12:22:01.521173 28419 solver.cpp:219] Iteration 25900 (4.35717 iter/s, 22.9507s/100 iters), loss = 0.448605
I0420 12:22:01.521224 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 12:22:01.521229 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:22:01.521235 28419 solver.cpp:238]     Train net output #2: loss = 0.448605 (* 1 = 0.448605 loss)
I0420 12:22:01.521239 28419 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I0420 12:22:24.187649 28419 solver.cpp:331] Iteration 26000, Testing net (#0)
I0420 12:22:29.039621 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:22:29.268200 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8495
I0420 12:22:29.268226 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9923
I0420 12:22:29.268250 28419 solver.cpp:398]     Test net output #2: loss = 0.500014 (* 1 = 0.500014 loss)
I0420 12:22:29.460937 28419 solver.cpp:219] Iteration 26000 (3.57914 iter/s, 27.9397s/100 iters), loss = 0.282241
I0420 12:22:29.460957 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:22:29.460978 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:22:29.460984 28419 solver.cpp:238]     Train net output #2: loss = 0.282241 (* 1 = 0.282241 loss)
I0420 12:22:29.460990 28419 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I0420 12:22:52.373656 28419 solver.cpp:219] Iteration 26100 (4.36443 iter/s, 22.9125s/100 iters), loss = 0.347771
I0420 12:22:52.373713 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 12:22:52.373720 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:22:52.373726 28419 solver.cpp:238]     Train net output #2: loss = 0.347771 (* 1 = 0.347771 loss)
I0420 12:22:52.373731 28419 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I0420 12:23:07.771184 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:23:15.331446 28419 solver.cpp:219] Iteration 26200 (4.35623 iter/s, 22.9556s/100 iters), loss = 0.255553
I0420 12:23:15.331501 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 12:23:15.331508 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:23:15.331514 28419 solver.cpp:238]     Train net output #2: loss = 0.255553 (* 1 = 0.255553 loss)
I0420 12:23:15.331518 28419 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I0420 12:23:38.249373 28419 solver.cpp:219] Iteration 26300 (4.36343 iter/s, 22.9177s/100 iters), loss = 0.318746
I0420 12:23:38.249580 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 12:23:38.249588 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:23:38.249594 28419 solver.cpp:238]     Train net output #2: loss = 0.318746 (* 1 = 0.318746 loss)
I0420 12:23:38.249600 28419 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I0420 12:24:01.222877 28419 solver.cpp:219] Iteration 26400 (4.35326 iter/s, 22.9713s/100 iters), loss = 0.302967
I0420 12:24:01.222926 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 12:24:01.222931 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:24:01.222939 28419 solver.cpp:238]     Train net output #2: loss = 0.302967 (* 1 = 0.302967 loss)
I0420 12:24:01.222944 28419 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I0420 12:24:24.153656 28419 solver.cpp:219] Iteration 26500 (4.36098 iter/s, 22.9306s/100 iters), loss = 0.303928
I0420 12:24:24.153821 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:24:24.153828 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:24:24.153836 28419 solver.cpp:238]     Train net output #2: loss = 0.303928 (* 1 = 0.303928 loss)
I0420 12:24:24.153842 28419 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I0420 12:24:37.540011 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:24:47.114886 28419 solver.cpp:219] Iteration 26600 (4.35559 iter/s, 22.959s/100 iters), loss = 0.252305
I0420 12:24:47.114940 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 12:24:47.114946 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:24:47.114953 28419 solver.cpp:238]     Train net output #2: loss = 0.252304 (* 1 = 0.252304 loss)
I0420 12:24:47.114956 28419 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I0420 12:25:10.015341 28419 solver.cpp:219] Iteration 26700 (4.36675 iter/s, 22.9003s/100 iters), loss = 0.327947
I0420 12:25:10.015579 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 12:25:10.015588 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:25:10.015594 28419 solver.cpp:238]     Train net output #2: loss = 0.327947 (* 1 = 0.327947 loss)
I0420 12:25:10.015599 28419 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I0420 12:25:33.002774 28419 solver.cpp:219] Iteration 26800 (4.35025 iter/s, 22.9872s/100 iters), loss = 0.325042
I0420 12:25:33.002826 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 12:25:33.002831 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:25:33.002838 28419 solver.cpp:238]     Train net output #2: loss = 0.325042 (* 1 = 0.325042 loss)
I0420 12:25:33.002842 28419 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I0420 12:25:55.880753 28419 solver.cpp:219] Iteration 26900 (4.37143 iter/s, 22.8758s/100 iters), loss = 0.440705
I0420 12:25:55.880944 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 12:25:55.880950 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:25:55.880957 28419 solver.cpp:238]     Train net output #2: loss = 0.440705 (* 1 = 0.440705 loss)
I0420 12:25:55.880961 28419 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I0420 12:26:07.157976 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:26:18.659220 28419 solver.cpp:331] Iteration 27000, Testing net (#0)
I0420 12:26:23.566396 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:26:23.685267 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8501
I0420 12:26:23.685297 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.992
I0420 12:26:23.685322 28419 solver.cpp:398]     Test net output #2: loss = 0.49965 (* 1 = 0.49965 loss)
I0420 12:26:23.904821 28419 solver.cpp:219] Iteration 27000 (3.56864 iter/s, 28.0219s/100 iters), loss = 0.331718
I0420 12:26:23.904844 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 12:26:23.904865 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:26:23.904870 28419 solver.cpp:238]     Train net output #2: loss = 0.331718 (* 1 = 0.331718 loss)
I0420 12:26:23.904876 28419 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I0420 12:26:46.882767 28419 solver.cpp:219] Iteration 27100 (4.35243 iter/s, 22.9757s/100 iters), loss = 0.207079
I0420 12:26:46.882966 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:26:46.882973 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:26:46.882979 28419 solver.cpp:238]     Train net output #2: loss = 0.207079 (* 1 = 0.207079 loss)
I0420 12:26:46.882983 28419 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I0420 12:27:09.790158 28419 solver.cpp:219] Iteration 27200 (4.36543 iter/s, 22.9073s/100 iters), loss = 0.274154
I0420 12:27:09.790213 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 12:27:09.790218 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:27:09.790225 28419 solver.cpp:238]     Train net output #2: loss = 0.274154 (* 1 = 0.274154 loss)
I0420 12:27:09.790230 28419 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I0420 12:27:32.782856 28419 solver.cpp:219] Iteration 27300 (4.34963 iter/s, 22.9905s/100 iters), loss = 0.408197
I0420 12:27:32.783074 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 12:27:32.783082 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:27:32.783088 28419 solver.cpp:238]     Train net output #2: loss = 0.408197 (* 1 = 0.408197 loss)
I0420 12:27:32.783094 28419 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I0420 12:27:41.743374 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:27:55.664721 28419 solver.cpp:219] Iteration 27400 (4.37069 iter/s, 22.8797s/100 iters), loss = 0.261635
I0420 12:27:55.664777 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:27:55.664783 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:27:55.664789 28419 solver.cpp:238]     Train net output #2: loss = 0.261635 (* 1 = 0.261635 loss)
I0420 12:27:55.664793 28419 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I0420 12:28:18.664000 28419 solver.cpp:219] Iteration 27500 (4.34841 iter/s, 22.9969s/100 iters), loss = 0.336802
I0420 12:28:18.664193 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 12:28:18.664201 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:28:18.664207 28419 solver.cpp:238]     Train net output #2: loss = 0.336802 (* 1 = 0.336802 loss)
I0420 12:28:18.664211 28419 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I0420 12:28:42.797114 28419 solver.cpp:219] Iteration 27600 (4.14407 iter/s, 24.1309s/100 iters), loss = 0.442769
I0420 12:28:42.797169 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 12:28:42.797174 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:28:42.797181 28419 solver.cpp:238]     Train net output #2: loss = 0.442769 (* 1 = 0.442769 loss)
I0420 12:28:42.797185 28419 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I0420 12:29:05.732126 28419 solver.cpp:219] Iteration 27700 (4.36056 iter/s, 22.9328s/100 iters), loss = 0.331772
I0420 12:29:05.732295 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 12:29:05.732302 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:29:05.732309 28419 solver.cpp:238]     Train net output #2: loss = 0.331772 (* 1 = 0.331772 loss)
I0420 12:29:05.732313 28419 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I0420 12:29:12.660773 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:29:28.677673 28419 solver.cpp:219] Iteration 27800 (4.35818 iter/s, 22.9454s/100 iters), loss = 0.437169
I0420 12:29:28.677727 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 12:29:28.677732 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:29:28.677738 28419 solver.cpp:238]     Train net output #2: loss = 0.437169 (* 1 = 0.437169 loss)
I0420 12:29:28.677743 28419 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I0420 12:29:51.627339 28419 solver.cpp:219] Iteration 27900 (4.3578 iter/s, 22.9473s/100 iters), loss = 0.285639
I0420 12:29:51.627511 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 12:29:51.627516 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:29:51.627523 28419 solver.cpp:238]     Train net output #2: loss = 0.285639 (* 1 = 0.285639 loss)
I0420 12:29:51.627527 28419 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I0420 12:30:14.345468 28419 solver.cpp:331] Iteration 28000, Testing net (#0)
I0420 12:30:19.224418 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:30:19.457800 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8409
I0420 12:30:19.457828 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9933
I0420 12:30:19.457851 28419 solver.cpp:398]     Test net output #2: loss = 0.512801 (* 1 = 0.512801 loss)
I0420 12:30:19.584056 28419 solver.cpp:219] Iteration 28000 (3.57698 iter/s, 27.9566s/100 iters), loss = 0.297018
I0420 12:30:19.584077 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 12:30:19.584100 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:30:19.584105 28419 solver.cpp:238]     Train net output #2: loss = 0.297018 (* 1 = 0.297018 loss)
I0420 12:30:19.584111 28419 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I0420 12:30:42.569272 28419 solver.cpp:219] Iteration 28100 (4.35066 iter/s, 22.985s/100 iters), loss = 0.286967
I0420 12:30:42.569479 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:30:42.569489 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:30:42.569494 28419 solver.cpp:238]     Train net output #2: loss = 0.286967 (* 1 = 0.286967 loss)
I0420 12:30:42.569499 28419 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I0420 12:30:47.179589 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:31:05.485144 28419 solver.cpp:219] Iteration 28200 (4.3642 iter/s, 22.9137s/100 iters), loss = 0.271399
I0420 12:31:05.485193 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:31:05.485198 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:31:05.485204 28419 solver.cpp:238]     Train net output #2: loss = 0.271399 (* 1 = 0.271399 loss)
I0420 12:31:05.485209 28419 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I0420 12:31:28.473310 28419 solver.cpp:219] Iteration 28300 (4.35013 iter/s, 22.9878s/100 iters), loss = 0.306178
I0420 12:31:28.473500 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:31:28.473506 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:31:28.473513 28419 solver.cpp:238]     Train net output #2: loss = 0.306178 (* 1 = 0.306178 loss)
I0420 12:31:28.473517 28419 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I0420 12:31:51.412911 28419 solver.cpp:219] Iteration 28400 (4.35971 iter/s, 22.9373s/100 iters), loss = 0.24462
I0420 12:31:51.412963 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:31:51.412969 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:31:51.412976 28419 solver.cpp:238]     Train net output #2: loss = 0.24462 (* 1 = 0.24462 loss)
I0420 12:31:51.412982 28419 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I0420 12:32:14.510191 28419 solver.cpp:219] Iteration 28500 (4.32952 iter/s, 23.0972s/100 iters), loss = 0.219934
I0420 12:32:14.510390 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 12:32:14.510397 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:32:14.510403 28419 solver.cpp:238]     Train net output #2: loss = 0.219934 (* 1 = 0.219934 loss)
I0420 12:32:14.510408 28419 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I0420 12:32:17.109756 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:32:37.487869 28419 solver.cpp:219] Iteration 28600 (4.35248 iter/s, 22.9754s/100 iters), loss = 0.40515
I0420 12:32:37.487906 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 12:32:37.487929 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:32:37.487936 28419 solver.cpp:238]     Train net output #2: loss = 0.40515 (* 1 = 0.40515 loss)
I0420 12:32:37.487939 28419 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I0420 12:33:00.407459 28419 solver.cpp:219] Iteration 28700 (4.3635 iter/s, 22.9174s/100 iters), loss = 0.200572
I0420 12:33:00.407588 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 12:33:00.407594 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:33:00.407600 28419 solver.cpp:238]     Train net output #2: loss = 0.200572 (* 1 = 0.200572 loss)
I0420 12:33:00.407605 28419 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I0420 12:33:23.355913 28419 solver.cpp:219] Iteration 28800 (4.35763 iter/s, 22.9482s/100 iters), loss = 0.318734
I0420 12:33:23.355968 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:33:23.355973 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:33:23.355979 28419 solver.cpp:238]     Train net output #2: loss = 0.318734 (* 1 = 0.318734 loss)
I0420 12:33:23.355983 28419 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I0420 12:33:46.359800 28419 solver.cpp:219] Iteration 28900 (4.34751 iter/s, 23.0017s/100 iters), loss = 0.19134
I0420 12:33:46.360014 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 12:33:46.360023 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:33:46.360028 28419 solver.cpp:238]     Train net output #2: loss = 0.19134 (* 1 = 0.19134 loss)
I0420 12:33:46.360033 28419 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I0420 12:33:46.840659 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:34:09.126592 28419 solver.cpp:331] Iteration 29000, Testing net (#0)
I0420 12:34:13.979718 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:34:14.154595 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8058
I0420 12:34:14.154621 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9832
I0420 12:34:14.154645 28419 solver.cpp:398]     Test net output #2: loss = 0.682843 (* 1 = 0.682843 loss)
I0420 12:34:14.323971 28419 solver.cpp:219] Iteration 29000 (3.57629 iter/s, 27.962s/100 iters), loss = 0.292439
I0420 12:34:14.323993 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:34:14.324014 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:34:14.324021 28419 solver.cpp:238]     Train net output #2: loss = 0.292439 (* 1 = 0.292439 loss)
I0420 12:34:14.324026 28419 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I0420 12:34:37.332773 28419 solver.cpp:219] Iteration 29100 (4.3466 iter/s, 23.0065s/100 iters), loss = 0.297715
I0420 12:34:37.332882 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:34:37.332890 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:34:37.332895 28419 solver.cpp:238]     Train net output #2: loss = 0.297715 (* 1 = 0.297715 loss)
I0420 12:34:37.332900 28419 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I0420 12:35:00.568370 28419 solver.cpp:219] Iteration 29200 (4.30415 iter/s, 23.2334s/100 iters), loss = 0.248329
I0420 12:35:00.568425 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:35:00.568431 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:35:00.568437 28419 solver.cpp:238]     Train net output #2: loss = 0.248329 (* 1 = 0.248329 loss)
I0420 12:35:00.568441 28419 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I0420 12:35:21.767693 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:35:23.569689 28419 solver.cpp:219] Iteration 29300 (4.34799 iter/s, 22.9991s/100 iters), loss = 0.270031
I0420 12:35:23.569743 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 12:35:23.569749 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:35:23.569756 28419 solver.cpp:238]     Train net output #2: loss = 0.270031 (* 1 = 0.270031 loss)
I0420 12:35:23.569759 28419 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I0420 12:35:46.444594 28419 solver.cpp:219] Iteration 29400 (4.37167 iter/s, 22.8745s/100 iters), loss = 0.327343
I0420 12:35:46.444645 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 12:35:46.444650 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:35:46.444656 28419 solver.cpp:238]     Train net output #2: loss = 0.327343 (* 1 = 0.327343 loss)
I0420 12:35:46.444660 28419 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I0420 12:36:09.418916 28419 solver.cpp:219] Iteration 29500 (4.35317 iter/s, 22.9718s/100 iters), loss = 0.203971
I0420 12:36:09.419113 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 12:36:09.419121 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:36:09.419127 28419 solver.cpp:238]     Train net output #2: loss = 0.203971 (* 1 = 0.203971 loss)
I0420 12:36:09.419131 28419 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I0420 12:36:32.282065 28419 solver.cpp:219] Iteration 29600 (4.37428 iter/s, 22.8609s/100 iters), loss = 0.214051
I0420 12:36:32.282122 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 12:36:32.282129 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:36:32.282135 28419 solver.cpp:238]     Train net output #2: loss = 0.214051 (* 1 = 0.214051 loss)
I0420 12:36:32.282138 28419 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I0420 12:36:51.382915 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:36:55.278853 28419 solver.cpp:219] Iteration 29700 (4.34886 iter/s, 22.9945s/100 iters), loss = 0.259989
I0420 12:36:55.278908 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:36:55.278913 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:36:55.278919 28419 solver.cpp:238]     Train net output #2: loss = 0.259989 (* 1 = 0.259989 loss)
I0420 12:36:55.278923 28419 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I0420 12:37:18.166589 28419 solver.cpp:219] Iteration 29800 (4.36958 iter/s, 22.8855s/100 iters), loss = 0.470784
I0420 12:37:18.166642 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 12:37:18.166647 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:37:18.166671 28419 solver.cpp:238]     Train net output #2: loss = 0.470784 (* 1 = 0.470784 loss)
I0420 12:37:18.166674 28419 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I0420 12:37:41.114037 28419 solver.cpp:219] Iteration 29900 (4.35822 iter/s, 22.9452s/100 iters), loss = 0.353267
I0420 12:37:41.114126 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 12:37:41.114133 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:37:41.114140 28419 solver.cpp:238]     Train net output #2: loss = 0.353267 (* 1 = 0.353267 loss)
I0420 12:37:41.114145 28419 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I0420 12:38:03.859016 28419 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_finetune_quant_0.09_iter_30000.caffemodel
I0420 12:38:03.884469 28419 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_finetune_quant_0.09_iter_30000.solverstate
I0420 12:38:03.901161 28419 solver.cpp:331] Iteration 30000, Testing net (#0)
I0420 12:38:08.706339 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:38:08.899910 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8297
I0420 12:38:08.899938 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9915
I0420 12:38:08.899962 28419 solver.cpp:398]     Test net output #2: loss = 0.583257 (* 1 = 0.583257 loss)
I0420 12:38:09.122719 28419 solver.cpp:219] Iteration 30000 (3.5706 iter/s, 28.0065s/100 iters), loss = 0.259842
I0420 12:38:09.122738 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:38:09.122758 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:38:09.122764 28419 solver.cpp:238]     Train net output #2: loss = 0.259842 (* 1 = 0.259842 loss)
I0420 12:38:09.122769 28419 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I0420 12:38:26.090095 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:38:32.142998 28419 solver.cpp:219] Iteration 30100 (4.34441 iter/s, 23.0181s/100 iters), loss = 0.210374
I0420 12:38:32.143052 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 12:38:32.143059 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:38:32.143064 28419 solver.cpp:238]     Train net output #2: loss = 0.210374 (* 1 = 0.210374 loss)
I0420 12:38:32.143069 28419 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I0420 12:38:56.240412 28419 solver.cpp:219] Iteration 30200 (4.15023 iter/s, 24.095s/100 iters), loss = 0.403087
I0420 12:38:56.240553 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 12:38:56.240561 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:38:56.240566 28419 solver.cpp:238]     Train net output #2: loss = 0.403087 (* 1 = 0.403087 loss)
I0420 12:38:56.240571 28419 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I0420 12:39:19.109997 28419 solver.cpp:219] Iteration 30300 (4.37305 iter/s, 22.8674s/100 iters), loss = 0.320677
I0420 12:39:19.110049 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 12:39:19.110055 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:39:19.110062 28419 solver.cpp:238]     Train net output #2: loss = 0.320677 (* 1 = 0.320677 loss)
I0420 12:39:19.110066 28419 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I0420 12:39:42.104559 28419 solver.cpp:219] Iteration 30400 (4.3493 iter/s, 22.9922s/100 iters), loss = 0.179252
I0420 12:39:42.104784 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 12:39:42.104791 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:39:42.104799 28419 solver.cpp:238]     Train net output #2: loss = 0.179252 (* 1 = 0.179252 loss)
I0420 12:39:42.104804 28419 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I0420 12:39:56.796459 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:40:04.974758 28419 solver.cpp:219] Iteration 30500 (4.37293 iter/s, 22.868s/100 iters), loss = 0.371109
I0420 12:40:04.974813 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 12:40:04.974818 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:40:04.974825 28419 solver.cpp:238]     Train net output #2: loss = 0.371109 (* 1 = 0.371109 loss)
I0420 12:40:04.974829 28419 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I0420 12:40:27.965193 28419 solver.cpp:219] Iteration 30600 (4.35007 iter/s, 22.9881s/100 iters), loss = 0.346181
I0420 12:40:27.965381 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 12:40:27.965389 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:40:27.965395 28419 solver.cpp:238]     Train net output #2: loss = 0.346181 (* 1 = 0.346181 loss)
I0420 12:40:27.965400 28419 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I0420 12:40:50.850972 28419 solver.cpp:219] Iteration 30700 (4.36994 iter/s, 22.8836s/100 iters), loss = 0.274301
I0420 12:40:50.851039 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 12:40:50.851044 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:40:50.851052 28419 solver.cpp:238]     Train net output #2: loss = 0.274301 (* 1 = 0.274301 loss)
I0420 12:40:50.851055 28419 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I0420 12:41:13.862454 28419 solver.cpp:219] Iteration 30800 (4.34607 iter/s, 23.0093s/100 iters), loss = 0.226775
I0420 12:41:13.862649 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 12:41:13.862656 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:41:13.862663 28419 solver.cpp:238]     Train net output #2: loss = 0.226775 (* 1 = 0.226775 loss)
I0420 12:41:13.862668 28419 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I0420 12:41:26.511420 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:41:36.730957 28419 solver.cpp:219] Iteration 30900 (4.37325 iter/s, 22.8663s/100 iters), loss = 0.468261
I0420 12:41:36.731012 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 12:41:36.731017 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:41:36.731024 28419 solver.cpp:238]     Train net output #2: loss = 0.468261 (* 1 = 0.468261 loss)
I0420 12:41:36.731027 28419 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I0420 12:41:59.501096 28419 solver.cpp:331] Iteration 31000, Testing net (#0)
I0420 12:42:04.368357 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:42:04.589836 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8272
I0420 12:42:04.589862 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9921
I0420 12:42:04.589886 28419 solver.cpp:398]     Test net output #2: loss = 0.5687 (* 1 = 0.5687 loss)
I0420 12:42:04.715523 28419 solver.cpp:219] Iteration 31000 (3.57341 iter/s, 27.9844s/100 iters), loss = 0.215111
I0420 12:42:04.715545 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 12:42:04.715566 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:42:04.715572 28419 solver.cpp:238]     Train net output #2: loss = 0.215111 (* 1 = 0.215111 loss)
I0420 12:42:04.715579 28419 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I0420 12:42:27.689517 28419 solver.cpp:219] Iteration 31100 (4.35317 iter/s, 22.9718s/100 iters), loss = 0.502666
I0420 12:42:27.689566 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 12:42:27.689573 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 12:42:27.689579 28419 solver.cpp:238]     Train net output #2: loss = 0.502666 (* 1 = 0.502666 loss)
I0420 12:42:27.689582 28419 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I0420 12:42:50.585538 28419 solver.cpp:219] Iteration 31200 (4.36799 iter/s, 22.8938s/100 iters), loss = 0.251915
I0420 12:42:50.585716 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:42:50.585741 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:42:50.585747 28419 solver.cpp:238]     Train net output #2: loss = 0.251915 (* 1 = 0.251915 loss)
I0420 12:42:50.585752 28419 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I0420 12:43:00.962016 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:43:13.538465 28419 solver.cpp:219] Iteration 31300 (4.35677 iter/s, 22.9528s/100 iters), loss = 0.352872
I0420 12:43:13.538519 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 12:43:13.538525 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:43:13.538532 28419 solver.cpp:238]     Train net output #2: loss = 0.352872 (* 1 = 0.352872 loss)
I0420 12:43:13.538535 28419 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I0420 12:43:36.487671 28419 solver.cpp:219] Iteration 31400 (4.35787 iter/s, 22.947s/100 iters), loss = 0.233881
I0420 12:43:36.487880 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:43:36.487887 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:43:36.487895 28419 solver.cpp:238]     Train net output #2: loss = 0.233881 (* 1 = 0.233881 loss)
I0420 12:43:36.487900 28419 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I0420 12:43:59.406545 28419 solver.cpp:219] Iteration 31500 (4.36329 iter/s, 22.9185s/100 iters), loss = 0.30971
I0420 12:43:59.406599 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:43:59.406605 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:43:59.406610 28419 solver.cpp:238]     Train net output #2: loss = 0.30971 (* 1 = 0.30971 loss)
I0420 12:43:59.406615 28419 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I0420 12:44:22.366320 28419 solver.cpp:219] Iteration 31600 (4.35584 iter/s, 22.9577s/100 iters), loss = 0.273777
I0420 12:44:22.366482 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 12:44:22.366489 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:44:22.366495 28419 solver.cpp:238]     Train net output #2: loss = 0.273777 (* 1 = 0.273777 loss)
I0420 12:44:22.366500 28419 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I0420 12:44:30.679400 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:44:45.256184 28419 solver.cpp:219] Iteration 31700 (4.3688 iter/s, 22.8896s/100 iters), loss = 0.314515
I0420 12:44:45.256240 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 12:44:45.256245 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:44:45.256252 28419 solver.cpp:238]     Train net output #2: loss = 0.314515 (* 1 = 0.314515 loss)
I0420 12:44:45.256255 28419 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I0420 12:45:08.238766 28419 solver.cpp:219] Iteration 31800 (4.35153 iter/s, 22.9804s/100 iters), loss = 0.32776
I0420 12:45:08.238929 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:45:08.238936 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:45:08.238943 28419 solver.cpp:238]     Train net output #2: loss = 0.32776 (* 1 = 0.32776 loss)
I0420 12:45:08.238947 28419 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I0420 12:45:31.142701 28419 solver.cpp:219] Iteration 31900 (4.36608 iter/s, 22.9038s/100 iters), loss = 0.4126
I0420 12:45:31.142757 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 12:45:31.142762 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:45:31.142769 28419 solver.cpp:238]     Train net output #2: loss = 0.4126 (* 1 = 0.4126 loss)
I0420 12:45:31.142773 28419 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I0420 12:45:53.905345 28419 solver.cpp:331] Iteration 32000, Testing net (#0)
I0420 12:45:58.786517 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:45:58.905124 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8373
I0420 12:45:58.905149 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9905
I0420 12:45:58.905174 28419 solver.cpp:398]     Test net output #2: loss = 0.548133 (* 1 = 0.548133 loss)
I0420 12:45:59.126842 28419 solver.cpp:219] Iteration 32000 (3.57347 iter/s, 27.984s/100 iters), loss = 0.337028
I0420 12:45:59.126863 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:45:59.126884 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:45:59.126890 28419 solver.cpp:238]     Train net output #2: loss = 0.337028 (* 1 = 0.337028 loss)
I0420 12:45:59.126896 28419 sgd_solver.cpp:105] Iteration 32000, lr = 0.01
I0420 12:46:05.383378 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:46:22.097537 28419 solver.cpp:219] Iteration 32100 (4.3538 iter/s, 22.9684s/100 iters), loss = 0.272146
I0420 12:46:22.097589 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:46:22.097594 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:46:22.097600 28419 solver.cpp:238]     Train net output #2: loss = 0.272146 (* 1 = 0.272146 loss)
I0420 12:46:22.097604 28419 sgd_solver.cpp:105] Iteration 32100, lr = 0.01
I0420 12:46:45.004812 28419 solver.cpp:219] Iteration 32200 (4.36545 iter/s, 22.9072s/100 iters), loss = 0.292436
I0420 12:46:45.004937 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:46:45.004946 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:46:45.004952 28419 solver.cpp:238]     Train net output #2: loss = 0.292436 (* 1 = 0.292436 loss)
I0420 12:46:45.004956 28419 sgd_solver.cpp:105] Iteration 32200, lr = 0.01
I0420 12:47:07.996951 28419 solver.cpp:219] Iteration 32300 (4.34933 iter/s, 22.9921s/100 iters), loss = 0.301296
I0420 12:47:07.997007 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:47:07.997012 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:47:07.997018 28419 solver.cpp:238]     Train net output #2: loss = 0.301296 (* 1 = 0.301296 loss)
I0420 12:47:07.997022 28419 sgd_solver.cpp:105] Iteration 32300, lr = 0.01
I0420 12:47:30.888185 28419 solver.cpp:219] Iteration 32400 (4.36851 iter/s, 22.8911s/100 iters), loss = 0.340734
I0420 12:47:30.888370 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 12:47:30.888376 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:47:30.888383 28419 solver.cpp:238]     Train net output #2: loss = 0.340734 (* 1 = 0.340734 loss)
I0420 12:47:30.888388 28419 sgd_solver.cpp:105] Iteration 32400, lr = 0.01
I0420 12:47:34.840260 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:47:53.879317 28419 solver.cpp:219] Iteration 32500 (4.34955 iter/s, 22.9909s/100 iters), loss = 0.217797
I0420 12:47:53.879367 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:47:53.879372 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:47:53.879379 28419 solver.cpp:238]     Train net output #2: loss = 0.217797 (* 1 = 0.217797 loss)
I0420 12:47:53.879384 28419 sgd_solver.cpp:105] Iteration 32500, lr = 0.01
I0420 12:48:16.790488 28419 solver.cpp:219] Iteration 32600 (4.3647 iter/s, 22.9111s/100 iters), loss = 0.361583
I0420 12:48:16.790666 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 12:48:16.790674 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:48:16.790680 28419 solver.cpp:238]     Train net output #2: loss = 0.361583 (* 1 = 0.361583 loss)
I0420 12:48:16.790689 28419 sgd_solver.cpp:105] Iteration 32600, lr = 0.01
I0420 12:48:39.755985 28419 solver.cpp:219] Iteration 32700 (4.35477 iter/s, 22.9633s/100 iters), loss = 0.313417
I0420 12:48:39.756042 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 12:48:39.756047 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:48:39.756054 28419 solver.cpp:238]     Train net output #2: loss = 0.313417 (* 1 = 0.313417 loss)
I0420 12:48:39.756058 28419 sgd_solver.cpp:105] Iteration 32700, lr = 0.01
I0420 12:49:03.876561 28419 solver.cpp:219] Iteration 32800 (4.14623 iter/s, 24.1183s/100 iters), loss = 0.246042
I0420 12:49:03.876765 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 12:49:03.876772 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:49:03.876780 28419 solver.cpp:238]     Train net output #2: loss = 0.246042 (* 1 = 0.246042 loss)
I0420 12:49:03.876783 28419 sgd_solver.cpp:105] Iteration 32800, lr = 0.01
I0420 12:49:05.782162 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:49:26.788951 28419 solver.cpp:219] Iteration 32900 (4.36492 iter/s, 22.9099s/100 iters), loss = 0.309048
I0420 12:49:26.789002 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:49:26.789008 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:49:26.789014 28419 solver.cpp:238]     Train net output #2: loss = 0.309048 (* 1 = 0.309048 loss)
I0420 12:49:26.789018 28419 sgd_solver.cpp:105] Iteration 32900, lr = 0.01
I0420 12:49:49.476438 28419 solver.cpp:331] Iteration 33000, Testing net (#0)
I0420 12:49:54.353632 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:49:54.590921 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.836
I0420 12:49:54.590948 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9898
I0420 12:49:54.590973 28419 solver.cpp:398]     Test net output #2: loss = 0.526053 (* 1 = 0.526053 loss)
I0420 12:49:54.759380 28419 solver.cpp:219] Iteration 33000 (3.57522 iter/s, 27.9703s/100 iters), loss = 0.299136
I0420 12:49:54.759402 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 12:49:54.759424 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:49:54.759430 28419 solver.cpp:238]     Train net output #2: loss = 0.299136 (* 1 = 0.299136 loss)
I0420 12:49:54.759436 28419 sgd_solver.cpp:105] Iteration 33000, lr = 0.01
I0420 12:50:17.673127 28419 solver.cpp:219] Iteration 33100 (4.36423 iter/s, 22.9136s/100 iters), loss = 0.366264
I0420 12:50:17.673184 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 12:50:17.673190 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:50:17.673197 28419 solver.cpp:238]     Train net output #2: loss = 0.366264 (* 1 = 0.366264 loss)
I0420 12:50:17.673200 28419 sgd_solver.cpp:105] Iteration 33100, lr = 0.01
I0420 12:50:40.456320 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:50:40.650208 28419 solver.cpp:219] Iteration 33200 (4.35256 iter/s, 22.975s/100 iters), loss = 0.407481
I0420 12:50:40.650238 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 12:50:40.650259 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:50:40.650264 28419 solver.cpp:238]     Train net output #2: loss = 0.407481 (* 1 = 0.407481 loss)
I0420 12:50:40.650269 28419 sgd_solver.cpp:105] Iteration 33200, lr = 0.01
I0420 12:51:03.556766 28419 solver.cpp:219] Iteration 33300 (4.36559 iter/s, 22.9064s/100 iters), loss = 0.311921
I0420 12:51:03.556821 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:51:03.556828 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:51:03.556833 28419 solver.cpp:238]     Train net output #2: loss = 0.311921 (* 1 = 0.311921 loss)
I0420 12:51:03.556838 28419 sgd_solver.cpp:105] Iteration 33300, lr = 0.01
I0420 12:51:26.544239 28419 solver.cpp:219] Iteration 33400 (4.35022 iter/s, 22.9873s/100 iters), loss = 0.459851
I0420 12:51:26.544467 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 12:51:26.544476 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:51:26.544482 28419 solver.cpp:238]     Train net output #2: loss = 0.459851 (* 1 = 0.459851 loss)
I0420 12:51:26.544488 28419 sgd_solver.cpp:105] Iteration 33400, lr = 0.01
I0420 12:51:49.436874 28419 solver.cpp:219] Iteration 33500 (4.36864 iter/s, 22.8904s/100 iters), loss = 0.337449
I0420 12:51:49.436928 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 12:51:49.436934 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:51:49.436941 28419 solver.cpp:238]     Train net output #2: loss = 0.337449 (* 1 = 0.337449 loss)
I0420 12:51:49.436945 28419 sgd_solver.cpp:105] Iteration 33500, lr = 0.01
I0420 12:52:09.925395 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:52:12.428272 28419 solver.cpp:219] Iteration 33600 (4.34988 iter/s, 22.9891s/100 iters), loss = 0.320074
I0420 12:52:12.428325 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 12:52:12.428330 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:52:12.428336 28419 solver.cpp:238]     Train net output #2: loss = 0.320074 (* 1 = 0.320074 loss)
I0420 12:52:12.428341 28419 sgd_solver.cpp:105] Iteration 33600, lr = 0.01
I0420 12:52:35.298461 28419 solver.cpp:219] Iteration 33700 (4.37294 iter/s, 22.8679s/100 iters), loss = 0.482213
I0420 12:52:35.298516 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 12:52:35.298522 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:52:35.298529 28419 solver.cpp:238]     Train net output #2: loss = 0.482213 (* 1 = 0.482213 loss)
I0420 12:52:35.298533 28419 sgd_solver.cpp:105] Iteration 33700, lr = 0.01
I0420 12:52:58.287693 28419 solver.cpp:219] Iteration 33800 (4.3503 iter/s, 22.9869s/100 iters), loss = 0.232561
I0420 12:52:58.287834 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:52:58.287842 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:52:58.287847 28419 solver.cpp:238]     Train net output #2: loss = 0.232561 (* 1 = 0.232561 loss)
I0420 12:52:58.287853 28419 sgd_solver.cpp:105] Iteration 33800, lr = 0.01
I0420 12:53:21.166517 28419 solver.cpp:219] Iteration 33900 (4.37128 iter/s, 22.8766s/100 iters), loss = 0.229757
I0420 12:53:21.166571 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 12:53:21.166576 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:53:21.166584 28419 solver.cpp:238]     Train net output #2: loss = 0.229757 (* 1 = 0.229757 loss)
I0420 12:53:21.166587 28419 sgd_solver.cpp:105] Iteration 33900, lr = 0.01
I0420 12:53:39.585592 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:53:43.930481 28419 solver.cpp:331] Iteration 34000, Testing net (#0)
I0420 12:53:48.760861 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:53:49.003634 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8245
I0420 12:53:49.003664 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9895
I0420 12:53:49.003690 28419 solver.cpp:398]     Test net output #2: loss = 0.59955 (* 1 = 0.59955 loss)
I0420 12:53:49.121461 28419 solver.cpp:219] Iteration 34000 (3.57746 iter/s, 27.9528s/100 iters), loss = 0.269281
I0420 12:53:49.121481 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:53:49.121502 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:53:49.121507 28419 solver.cpp:238]     Train net output #2: loss = 0.269281 (* 1 = 0.269281 loss)
I0420 12:53:49.121513 28419 sgd_solver.cpp:105] Iteration 34000, lr = 0.01
I0420 12:54:12.090095 28419 solver.cpp:219] Iteration 34100 (4.3538 iter/s, 22.9684s/100 iters), loss = 0.413157
I0420 12:54:12.090245 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 12:54:12.090251 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:54:12.090258 28419 solver.cpp:238]     Train net output #2: loss = 0.413157 (* 1 = 0.413157 loss)
I0420 12:54:12.090262 28419 sgd_solver.cpp:105] Iteration 34100, lr = 0.01
I0420 12:54:34.986369 28419 solver.cpp:219] Iteration 34200 (4.36794 iter/s, 22.8941s/100 iters), loss = 0.27817
I0420 12:54:34.986424 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 12:54:34.986429 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:54:34.986436 28419 solver.cpp:238]     Train net output #2: loss = 0.27817 (* 1 = 0.27817 loss)
I0420 12:54:34.986440 28419 sgd_solver.cpp:105] Iteration 34200, lr = 0.01
I0420 12:54:57.923406 28419 solver.cpp:219] Iteration 34300 (4.35979 iter/s, 22.9369s/100 iters), loss = 0.315639
I0420 12:54:57.923573 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 12:54:57.923596 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:54:57.923604 28419 solver.cpp:238]     Train net output #2: loss = 0.315639 (* 1 = 0.315639 loss)
I0420 12:54:57.923607 28419 sgd_solver.cpp:105] Iteration 34300, lr = 0.01
I0420 12:55:14.026857 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:55:20.871305 28419 solver.cpp:219] Iteration 34400 (4.35811 iter/s, 22.9457s/100 iters), loss = 0.403694
I0420 12:55:20.871361 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 12:55:20.871366 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:55:20.871372 28419 solver.cpp:238]     Train net output #2: loss = 0.403694 (* 1 = 0.403694 loss)
I0420 12:55:20.871376 28419 sgd_solver.cpp:105] Iteration 34400, lr = 0.01
I0420 12:55:43.785392 28419 solver.cpp:219] Iteration 34500 (4.36417 iter/s, 22.9139s/100 iters), loss = 0.311901
I0420 12:55:43.785605 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 12:55:43.785612 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:55:43.785619 28419 solver.cpp:238]     Train net output #2: loss = 0.311901 (* 1 = 0.311901 loss)
I0420 12:55:43.785624 28419 sgd_solver.cpp:105] Iteration 34500, lr = 0.01
I0420 12:56:06.764016 28419 solver.cpp:219] Iteration 34600 (4.35229 iter/s, 22.9764s/100 iters), loss = 0.227655
I0420 12:56:06.764071 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:56:06.764076 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:56:06.764082 28419 solver.cpp:238]     Train net output #2: loss = 0.227655 (* 1 = 0.227655 loss)
I0420 12:56:06.764086 28419 sgd_solver.cpp:105] Iteration 34600, lr = 0.01
I0420 12:56:29.654950 28419 solver.cpp:219] Iteration 34700 (4.36856 iter/s, 22.8909s/100 iters), loss = 0.498852
I0420 12:56:29.655122 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 12:56:29.655129 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:56:29.655136 28419 solver.cpp:238]     Train net output #2: loss = 0.498852 (* 1 = 0.498852 loss)
I0420 12:56:29.655140 28419 sgd_solver.cpp:105] Iteration 34700, lr = 0.01
I0420 12:56:43.705793 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:56:52.630230 28419 solver.cpp:219] Iteration 34800 (4.35294 iter/s, 22.973s/100 iters), loss = 0.29161
I0420 12:56:52.630285 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:56:52.630290 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:56:52.630296 28419 solver.cpp:238]     Train net output #2: loss = 0.29161 (* 1 = 0.29161 loss)
I0420 12:56:52.630300 28419 sgd_solver.cpp:105] Iteration 34800, lr = 0.01
I0420 12:57:15.520730 28419 solver.cpp:219] Iteration 34900 (4.36906 iter/s, 22.8882s/100 iters), loss = 0.408216
I0420 12:57:15.520927 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 12:57:15.520934 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:57:15.520941 28419 solver.cpp:238]     Train net output #2: loss = 0.408216 (* 1 = 0.408216 loss)
I0420 12:57:15.520946 28419 sgd_solver.cpp:105] Iteration 34900, lr = 0.01
I0420 12:57:38.288164 28419 solver.cpp:331] Iteration 35000, Testing net (#0)
I0420 12:57:43.168421 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:57:43.327289 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8216
I0420 12:57:43.327316 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9893
I0420 12:57:43.327339 28419 solver.cpp:398]     Test net output #2: loss = 0.592326 (* 1 = 0.592326 loss)
I0420 12:57:43.523373 28419 solver.cpp:219] Iteration 35000 (3.57139 iter/s, 28.0003s/100 iters), loss = 0.332624
I0420 12:57:43.523394 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 12:57:43.523414 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:57:43.523421 28419 solver.cpp:238]     Train net output #2: loss = 0.332624 (* 1 = 0.332624 loss)
I0420 12:57:43.523427 28419 sgd_solver.cpp:105] Iteration 35000, lr = 0.01
I0420 12:58:06.509272 28419 solver.cpp:219] Iteration 35100 (4.35092 iter/s, 22.9837s/100 iters), loss = 0.428181
I0420 12:58:06.509460 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 12:58:06.509469 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:58:06.509474 28419 solver.cpp:238]     Train net output #2: loss = 0.428181 (* 1 = 0.428181 loss)
I0420 12:58:06.509479 28419 sgd_solver.cpp:105] Iteration 35100, lr = 0.01
I0420 12:58:18.438215 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 12:58:29.406518 28419 solver.cpp:219] Iteration 35200 (4.36736 iter/s, 22.8971s/100 iters), loss = 0.285591
I0420 12:58:29.406569 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 12:58:29.406575 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 12:58:29.406581 28419 solver.cpp:238]     Train net output #2: loss = 0.285591 (* 1 = 0.285591 loss)
I0420 12:58:29.406585 28419 sgd_solver.cpp:105] Iteration 35200, lr = 0.01
I0420 12:58:52.627226 28419 solver.cpp:219] Iteration 35300 (4.30691 iter/s, 23.2185s/100 iters), loss = 0.44521
I0420 12:58:52.627313 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0420 12:58:52.627321 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:58:52.627327 28419 solver.cpp:238]     Train net output #2: loss = 0.44521 (* 1 = 0.44521 loss)
I0420 12:58:52.627331 28419 sgd_solver.cpp:105] Iteration 35300, lr = 0.01
I0420 12:59:16.352455 28419 solver.cpp:219] Iteration 35400 (4.21534 iter/s, 23.7229s/100 iters), loss = 0.322346
I0420 12:59:16.352510 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:59:16.352515 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 12:59:16.352521 28419 solver.cpp:238]     Train net output #2: loss = 0.322346 (* 1 = 0.322346 loss)
I0420 12:59:16.352525 28419 sgd_solver.cpp:105] Iteration 35400, lr = 0.01
I0420 12:59:39.302897 28419 solver.cpp:219] Iteration 35500 (4.35724 iter/s, 22.9503s/100 iters), loss = 0.324488
I0420 12:59:39.303091 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 12:59:39.303097 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 12:59:39.303103 28419 solver.cpp:238]     Train net output #2: loss = 0.324488 (* 1 = 0.324488 loss)
I0420 12:59:39.303108 28419 sgd_solver.cpp:105] Iteration 35500, lr = 0.01
I0420 12:59:49.027845 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:00:02.244724 28419 solver.cpp:219] Iteration 35600 (4.35927 iter/s, 22.9396s/100 iters), loss = 0.336557
I0420 13:00:02.244772 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:00:02.244777 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:00:02.244784 28419 solver.cpp:238]     Train net output #2: loss = 0.336557 (* 1 = 0.336557 loss)
I0420 13:00:02.244788 28419 sgd_solver.cpp:105] Iteration 35600, lr = 0.01
I0420 13:00:25.174458 28419 solver.cpp:219] Iteration 35700 (4.36118 iter/s, 22.9296s/100 iters), loss = 0.376394
I0420 13:00:25.175272 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:00:25.175281 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:00:25.175287 28419 solver.cpp:238]     Train net output #2: loss = 0.376394 (* 1 = 0.376394 loss)
I0420 13:00:25.175292 28419 sgd_solver.cpp:105] Iteration 35700, lr = 0.01
I0420 13:00:48.147120 28419 solver.cpp:219] Iteration 35800 (4.35343 iter/s, 22.9704s/100 iters), loss = 0.281568
I0420 13:00:48.147176 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:00:48.147181 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:00:48.147187 28419 solver.cpp:238]     Train net output #2: loss = 0.281568 (* 1 = 0.281568 loss)
I0420 13:00:48.147192 28419 sgd_solver.cpp:105] Iteration 35800, lr = 0.01
I0420 13:01:11.044545 28419 solver.cpp:219] Iteration 35900 (4.36735 iter/s, 22.8972s/100 iters), loss = 0.394807
I0420 13:01:11.044749 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 13:01:11.044755 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:01:11.044762 28419 solver.cpp:238]     Train net output #2: loss = 0.394807 (* 1 = 0.394807 loss)
I0420 13:01:11.044766 28419 sgd_solver.cpp:105] Iteration 35900, lr = 0.01
I0420 13:01:18.645278 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:01:33.852243 28419 solver.cpp:331] Iteration 36000, Testing net (#0)
I0420 13:01:38.690130 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:01:38.822587 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8478
I0420 13:01:38.822626 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 13:01:38.822651 28419 solver.cpp:398]     Test net output #2: loss = 0.485021 (* 1 = 0.485021 loss)
I0420 13:01:39.028564 28419 solver.cpp:219] Iteration 36000 (3.57376 iter/s, 27.9817s/100 iters), loss = 0.282137
I0420 13:01:39.028627 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:01:39.028633 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:01:39.028640 28419 solver.cpp:238]     Train net output #2: loss = 0.282137 (* 1 = 0.282137 loss)
I0420 13:01:39.028647 28419 sgd_solver.cpp:105] Iteration 36000, lr = 0.01
I0420 13:02:02.024631 28419 solver.cpp:219] Iteration 36100 (4.34899 iter/s, 22.9938s/100 iters), loss = 0.205201
I0420 13:02:02.024734 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 13:02:02.024741 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:02:02.024747 28419 solver.cpp:238]     Train net output #2: loss = 0.205201 (* 1 = 0.205201 loss)
I0420 13:02:02.024751 28419 sgd_solver.cpp:105] Iteration 36100, lr = 0.01
I0420 13:02:24.920004 28419 solver.cpp:219] Iteration 36200 (4.36771 iter/s, 22.8953s/100 iters), loss = 0.415175
I0420 13:02:24.920042 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:02:24.920047 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:02:24.920053 28419 solver.cpp:238]     Train net output #2: loss = 0.415175 (* 1 = 0.415175 loss)
I0420 13:02:24.920056 28419 sgd_solver.cpp:105] Iteration 36200, lr = 0.01
I0420 13:02:47.886626 28419 solver.cpp:219] Iteration 36300 (4.35456 iter/s, 22.9644s/100 iters), loss = 0.358008
I0420 13:02:47.886776 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:02:47.886783 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:02:47.886790 28419 solver.cpp:238]     Train net output #2: loss = 0.358008 (* 1 = 0.358008 loss)
I0420 13:02:47.886795 28419 sgd_solver.cpp:105] Iteration 36300, lr = 0.01
I0420 13:02:53.391603 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:03:10.794971 28419 solver.cpp:219] Iteration 36400 (4.36525 iter/s, 22.9082s/100 iters), loss = 0.36529
I0420 13:03:10.795006 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:03:10.795011 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 13:03:10.795016 28419 solver.cpp:238]     Train net output #2: loss = 0.36529 (* 1 = 0.36529 loss)
I0420 13:03:10.795019 28419 sgd_solver.cpp:105] Iteration 36400, lr = 0.01
I0420 13:03:33.755255 28419 solver.cpp:219] Iteration 36500 (4.35577 iter/s, 22.9581s/100 iters), loss = 0.374484
I0420 13:03:33.755445 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:03:33.755453 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 13:03:33.755460 28419 solver.cpp:238]     Train net output #2: loss = 0.374484 (* 1 = 0.374484 loss)
I0420 13:03:33.755463 28419 sgd_solver.cpp:105] Iteration 36500, lr = 0.01
I0420 13:03:56.652676 28419 solver.cpp:219] Iteration 36600 (4.36734 iter/s, 22.8972s/100 iters), loss = 0.190209
I0420 13:03:56.652716 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 13:03:56.652721 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:03:56.652727 28419 solver.cpp:238]     Train net output #2: loss = 0.190209 (* 1 = 0.190209 loss)
I0420 13:03:56.652731 28419 sgd_solver.cpp:105] Iteration 36600, lr = 0.01
I0420 13:04:19.627269 28419 solver.cpp:219] Iteration 36700 (4.35306 iter/s, 22.9723s/100 iters), loss = 0.385002
I0420 13:04:19.627404 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 13:04:19.627411 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:04:19.627418 28419 solver.cpp:238]     Train net output #2: loss = 0.385002 (* 1 = 0.385002 loss)
I0420 13:04:19.627423 28419 sgd_solver.cpp:105] Iteration 36700, lr = 0.01
I0420 13:04:22.821167 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:04:42.471571 28419 solver.cpp:219] Iteration 36800 (4.37779 iter/s, 22.8426s/100 iters), loss = 0.464438
I0420 13:04:42.471606 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 13:04:42.471611 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:04:42.471616 28419 solver.cpp:238]     Train net output #2: loss = 0.464438 (* 1 = 0.464438 loss)
I0420 13:04:42.471619 28419 sgd_solver.cpp:105] Iteration 36800, lr = 0.01
I0420 13:05:05.464293 28419 solver.cpp:219] Iteration 36900 (4.34962 iter/s, 22.9905s/100 iters), loss = 0.236032
I0420 13:05:05.464459 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:05:05.464467 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:05:05.464473 28419 solver.cpp:238]     Train net output #2: loss = 0.236032 (* 1 = 0.236032 loss)
I0420 13:05:05.464478 28419 sgd_solver.cpp:105] Iteration 36900, lr = 0.01
I0420 13:05:28.177031 28419 solver.cpp:331] Iteration 37000, Testing net (#0)
I0420 13:05:32.944114 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:05:33.143548 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.82
I0420 13:05:33.143575 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9902
I0420 13:05:33.143599 28419 solver.cpp:398]     Test net output #2: loss = 0.59328 (* 1 = 0.59328 loss)
I0420 13:05:33.375692 28419 solver.cpp:219] Iteration 37000 (3.58304 iter/s, 27.9093s/100 iters), loss = 0.317776
I0420 13:05:33.375713 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 13:05:33.375735 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:05:33.375741 28419 solver.cpp:238]     Train net output #2: loss = 0.317776 (* 1 = 0.317776 loss)
I0420 13:05:33.375747 28419 sgd_solver.cpp:105] Iteration 37000, lr = 0.01
I0420 13:05:56.231638 28419 solver.cpp:219] Iteration 37100 (4.37566 iter/s, 22.8537s/100 iters), loss = 0.326188
I0420 13:05:56.231781 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:05:56.231788 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:05:56.231794 28419 solver.cpp:238]     Train net output #2: loss = 0.326188 (* 1 = 0.326188 loss)
I0420 13:05:56.231801 28419 sgd_solver.cpp:105] Iteration 37100, lr = 0.01
I0420 13:05:57.423391 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:06:19.204192 28419 solver.cpp:219] Iteration 37200 (4.3534 iter/s, 22.9706s/100 iters), loss = 0.334898
I0420 13:06:19.204232 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:06:19.204237 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:06:19.204243 28419 solver.cpp:238]     Train net output #2: loss = 0.334898 (* 1 = 0.334898 loss)
I0420 13:06:19.204247 28419 sgd_solver.cpp:105] Iteration 37200, lr = 0.01
I0420 13:06:42.090301 28419 solver.cpp:219] Iteration 37300 (4.36989 iter/s, 22.8839s/100 iters), loss = 0.330911
I0420 13:06:42.090715 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:06:42.090726 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:06:42.090751 28419 solver.cpp:238]     Train net output #2: loss = 0.330911 (* 1 = 0.330911 loss)
I0420 13:06:42.090759 28419 sgd_solver.cpp:105] Iteration 37300, lr = 0.01
I0420 13:07:05.062302 28419 solver.cpp:219] Iteration 37400 (4.3532 iter/s, 22.9716s/100 iters), loss = 0.292912
I0420 13:07:05.062342 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:07:05.062347 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:07:05.062355 28419 solver.cpp:238]     Train net output #2: loss = 0.292912 (* 1 = 0.292912 loss)
I0420 13:07:05.062360 28419 sgd_solver.cpp:105] Iteration 37400, lr = 0.01
I0420 13:07:26.868962 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:07:27.972767 28419 solver.cpp:219] Iteration 37500 (4.36524 iter/s, 22.9082s/100 iters), loss = 0.229697
I0420 13:07:27.972818 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 13:07:27.972825 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:07:27.972831 28419 solver.cpp:238]     Train net output #2: loss = 0.229697 (* 1 = 0.229697 loss)
I0420 13:07:27.972834 28419 sgd_solver.cpp:105] Iteration 37500, lr = 0.01
I0420 13:07:50.937137 28419 solver.cpp:219] Iteration 37600 (4.35459 iter/s, 22.9643s/100 iters), loss = 0.208008
I0420 13:07:50.937192 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:07:50.937197 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:07:50.937204 28419 solver.cpp:238]     Train net output #2: loss = 0.208008 (* 1 = 0.208008 loss)
I0420 13:07:50.937208 28419 sgd_solver.cpp:105] Iteration 37600, lr = 0.01
I0420 13:08:13.875900 28419 solver.cpp:219] Iteration 37700 (4.35985 iter/s, 22.9366s/100 iters), loss = 0.337489
I0420 13:08:13.876041 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:08:13.876049 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:08:13.876055 28419 solver.cpp:238]     Train net output #2: loss = 0.337489 (* 1 = 0.337489 loss)
I0420 13:08:13.876060 28419 sgd_solver.cpp:105] Iteration 37700, lr = 0.01
I0420 13:08:36.797793 28419 solver.cpp:219] Iteration 37800 (4.36267 iter/s, 22.9217s/100 iters), loss = 0.312274
I0420 13:08:36.797849 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:08:36.797854 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:08:36.797861 28419 solver.cpp:238]     Train net output #2: loss = 0.312274 (* 1 = 0.312274 loss)
I0420 13:08:36.797865 28419 sgd_solver.cpp:105] Iteration 37800, lr = 0.01
I0420 13:08:56.586771 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:09:00.104121 28419 solver.cpp:219] Iteration 37900 (4.29108 iter/s, 23.3042s/100 iters), loss = 0.270248
I0420 13:09:00.104176 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:09:00.104181 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:09:00.104187 28419 solver.cpp:238]     Train net output #2: loss = 0.270248 (* 1 = 0.270248 loss)
I0420 13:09:00.104192 28419 sgd_solver.cpp:105] Iteration 37900, lr = 0.01
I0420 13:09:23.713248 28419 solver.cpp:331] Iteration 38000, Testing net (#0)
I0420 13:09:28.526708 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:09:28.766557 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8253
I0420 13:09:28.766583 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9885
I0420 13:09:28.766607 28419 solver.cpp:398]     Test net output #2: loss = 0.586561 (* 1 = 0.586561 loss)
I0420 13:09:28.889624 28419 solver.cpp:219] Iteration 38000 (3.47423 iter/s, 28.7834s/100 iters), loss = 0.336214
I0420 13:09:28.889644 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 13:09:28.889665 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:09:28.889672 28419 solver.cpp:238]     Train net output #2: loss = 0.336214 (* 1 = 0.336214 loss)
I0420 13:09:28.889678 28419 sgd_solver.cpp:105] Iteration 38000, lr = 0.01
I0420 13:09:51.872941 28419 solver.cpp:219] Iteration 38100 (4.35102 iter/s, 22.9831s/100 iters), loss = 0.403414
I0420 13:09:51.872997 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 13:09:51.873003 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:09:51.873008 28419 solver.cpp:238]     Train net output #2: loss = 0.403414 (* 1 = 0.403414 loss)
I0420 13:09:51.873013 28419 sgd_solver.cpp:105] Iteration 38100, lr = 0.01
I0420 13:10:14.812345 28419 solver.cpp:219] Iteration 38200 (4.35973 iter/s, 22.9372s/100 iters), loss = 0.264898
I0420 13:10:14.812464 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:10:14.812471 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:10:14.812477 28419 solver.cpp:238]     Train net output #2: loss = 0.264898 (* 1 = 0.264898 loss)
I0420 13:10:14.812482 28419 sgd_solver.cpp:105] Iteration 38200, lr = 0.01
I0420 13:10:32.551134 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:10:37.755697 28419 solver.cpp:219] Iteration 38300 (4.35858 iter/s, 22.9432s/100 iters), loss = 0.241159
I0420 13:10:37.755750 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 13:10:37.755755 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:10:37.755762 28419 solver.cpp:238]     Train net output #2: loss = 0.241159 (* 1 = 0.241159 loss)
I0420 13:10:37.755766 28419 sgd_solver.cpp:105] Iteration 38300, lr = 0.01
I0420 13:11:00.681872 28419 solver.cpp:219] Iteration 38400 (4.36225 iter/s, 22.9239s/100 iters), loss = 0.320844
I0420 13:11:00.682052 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 13:11:00.682060 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:11:00.682066 28419 solver.cpp:238]     Train net output #2: loss = 0.320844 (* 1 = 0.320844 loss)
I0420 13:11:00.682071 28419 sgd_solver.cpp:105] Iteration 38400, lr = 0.01
I0420 13:11:23.599370 28419 solver.cpp:219] Iteration 38500 (4.36351 iter/s, 22.9173s/100 iters), loss = 0.247944
I0420 13:11:23.599426 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:11:23.599433 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:11:23.599439 28419 solver.cpp:238]     Train net output #2: loss = 0.247944 (* 1 = 0.247944 loss)
I0420 13:11:23.599444 28419 sgd_solver.cpp:105] Iteration 38500, lr = 0.01
I0420 13:11:46.578167 28419 solver.cpp:219] Iteration 38600 (4.35229 iter/s, 22.9764s/100 iters), loss = 0.284035
I0420 13:11:46.578356 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:11:46.578362 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:11:46.578369 28419 solver.cpp:238]     Train net output #2: loss = 0.284035 (* 1 = 0.284035 loss)
I0420 13:11:46.578374 28419 sgd_solver.cpp:105] Iteration 38600, lr = 0.01
I0420 13:12:02.001272 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:12:09.470435 28419 solver.cpp:219] Iteration 38700 (4.36833 iter/s, 22.8921s/100 iters), loss = 0.273991
I0420 13:12:09.470489 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 13:12:09.470495 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:12:09.470501 28419 solver.cpp:238]     Train net output #2: loss = 0.273991 (* 1 = 0.273991 loss)
I0420 13:12:09.470505 28419 sgd_solver.cpp:105] Iteration 38700, lr = 0.01
I0420 13:12:32.455374 28419 solver.cpp:219] Iteration 38800 (4.35109 iter/s, 22.9827s/100 iters), loss = 0.465627
I0420 13:12:32.455591 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0420 13:12:32.455600 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:12:32.455606 28419 solver.cpp:238]     Train net output #2: loss = 0.465627 (* 1 = 0.465627 loss)
I0420 13:12:32.455610 28419 sgd_solver.cpp:105] Iteration 38800, lr = 0.01
I0420 13:12:55.357233 28419 solver.cpp:219] Iteration 38900 (4.36652 iter/s, 22.9016s/100 iters), loss = 0.385937
I0420 13:12:55.357286 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 13:12:55.357291 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:12:55.357298 28419 solver.cpp:238]     Train net output #2: loss = 0.385937 (* 1 = 0.385937 loss)
I0420 13:12:55.357302 28419 sgd_solver.cpp:105] Iteration 38900, lr = 0.01
I0420 13:13:18.137426 28419 solver.cpp:331] Iteration 39000, Testing net (#0)
I0420 13:13:23.007854 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:13:23.162140 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.835
I0420 13:13:23.162165 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9927
I0420 13:13:23.162189 28419 solver.cpp:398]     Test net output #2: loss = 0.542769 (* 1 = 0.542769 loss)
I0420 13:13:23.378811 28419 solver.cpp:219] Iteration 39000 (3.56896 iter/s, 28.0194s/100 iters), loss = 0.284237
I0420 13:13:23.378831 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 13:13:23.378854 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:13:23.378859 28419 solver.cpp:238]     Train net output #2: loss = 0.284237 (* 1 = 0.284237 loss)
I0420 13:13:23.378865 28419 sgd_solver.cpp:105] Iteration 39000, lr = 0.01
I0420 13:13:36.727318 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:13:46.300354 28419 solver.cpp:219] Iteration 39100 (4.36314 iter/s, 22.9193s/100 iters), loss = 0.209353
I0420 13:13:46.300405 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:13:46.300410 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:13:46.300417 28419 solver.cpp:238]     Train net output #2: loss = 0.209353 (* 1 = 0.209353 loss)
I0420 13:13:46.300421 28419 sgd_solver.cpp:105] Iteration 39100, lr = 0.01
I0420 13:14:09.265131 28419 solver.cpp:219] Iteration 39200 (4.35451 iter/s, 22.9647s/100 iters), loss = 0.260013
I0420 13:14:09.265214 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:14:09.265223 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:14:09.265228 28419 solver.cpp:238]     Train net output #2: loss = 0.260013 (* 1 = 0.260013 loss)
I0420 13:14:09.265233 28419 sgd_solver.cpp:105] Iteration 39200, lr = 0.01
I0420 13:14:32.209154 28419 solver.cpp:219] Iteration 39300 (4.35885 iter/s, 22.9418s/100 iters), loss = 0.445915
I0420 13:14:32.209210 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 13:14:32.209215 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:14:32.209221 28419 solver.cpp:238]     Train net output #2: loss = 0.445915 (* 1 = 0.445915 loss)
I0420 13:14:32.209226 28419 sgd_solver.cpp:105] Iteration 39300, lr = 0.01
I0420 13:14:55.161532 28419 solver.cpp:219] Iteration 39400 (4.35687 iter/s, 22.9522s/100 iters), loss = 0.349915
I0420 13:14:55.161743 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 13:14:55.161753 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:14:55.161763 28419 solver.cpp:238]     Train net output #2: loss = 0.349915 (* 1 = 0.349915 loss)
I0420 13:14:55.161770 28419 sgd_solver.cpp:105] Iteration 39400, lr = 0.01
I0420 13:15:06.455237 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:15:18.101572 28419 solver.cpp:219] Iteration 39500 (4.35963 iter/s, 22.9377s/100 iters), loss = 0.419689
I0420 13:15:18.101621 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 13:15:18.101626 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:15:18.101632 28419 solver.cpp:238]     Train net output #2: loss = 0.419689 (* 1 = 0.419689 loss)
I0420 13:15:18.101636 28419 sgd_solver.cpp:105] Iteration 39500, lr = 0.01
I0420 13:15:41.022054 28419 solver.cpp:219] Iteration 39600 (4.36294 iter/s, 22.9203s/100 iters), loss = 0.19562
I0420 13:15:41.022264 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 13:15:41.022272 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:15:41.022279 28419 solver.cpp:238]     Train net output #2: loss = 0.19562 (* 1 = 0.19562 loss)
I0420 13:15:41.022285 28419 sgd_solver.cpp:105] Iteration 39600, lr = 0.01
I0420 13:16:04.011989 28419 solver.cpp:219] Iteration 39700 (4.35015 iter/s, 22.9877s/100 iters), loss = 0.312407
I0420 13:16:04.012042 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:16:04.012048 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:16:04.012054 28419 solver.cpp:238]     Train net output #2: loss = 0.312407 (* 1 = 0.312407 loss)
I0420 13:16:04.012058 28419 sgd_solver.cpp:105] Iteration 39700, lr = 0.01
I0420 13:16:26.892750 28419 solver.cpp:219] Iteration 39800 (4.37054 iter/s, 22.8805s/100 iters), loss = 0.293516
I0420 13:16:26.892936 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 13:16:26.892943 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 13:16:26.892949 28419 solver.cpp:238]     Train net output #2: loss = 0.293516 (* 1 = 0.293516 loss)
I0420 13:16:26.892954 28419 sgd_solver.cpp:105] Iteration 39800, lr = 0.01
I0420 13:16:35.886082 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:16:49.871649 28419 solver.cpp:219] Iteration 39900 (4.35223 iter/s, 22.9767s/100 iters), loss = 0.25039
I0420 13:16:49.871702 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:16:49.871708 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:16:49.871714 28419 solver.cpp:238]     Train net output #2: loss = 0.25039 (* 1 = 0.25039 loss)
I0420 13:16:49.871718 28419 sgd_solver.cpp:105] Iteration 39900, lr = 0.01
I0420 13:17:12.588279 28419 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_finetune_quant_0.09_iter_40000.caffemodel
I0420 13:17:12.635733 28419 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_finetune_quant_0.09_iter_40000.solverstate
I0420 13:17:12.666311 28419 solver.cpp:331] Iteration 40000, Testing net (#0)
I0420 13:17:17.560387 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:17:17.762184 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8176
I0420 13:17:17.762209 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9888
I0420 13:17:17.762233 28419 solver.cpp:398]     Test net output #2: loss = 0.637463 (* 1 = 0.637463 loss)
I0420 13:17:17.910480 28419 solver.cpp:219] Iteration 40000 (3.56676 iter/s, 28.0367s/100 iters), loss = 0.419601
I0420 13:17:17.910500 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0420 13:17:17.910519 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:17:17.910526 28419 solver.cpp:238]     Train net output #2: loss = 0.419601 (* 1 = 0.419601 loss)
I0420 13:17:17.910531 28419 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0420 13:17:40.892554 28419 solver.cpp:219] Iteration 40100 (4.35166 iter/s, 22.9797s/100 iters), loss = 0.408878
I0420 13:17:40.892611 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 13:17:40.892616 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:17:40.892621 28419 solver.cpp:238]     Train net output #2: loss = 0.408878 (* 1 = 0.408878 loss)
I0420 13:17:40.892627 28419 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0420 13:18:03.764598 28419 solver.cpp:219] Iteration 40200 (4.37258 iter/s, 22.8698s/100 iters), loss = 0.368254
I0420 13:18:03.764801 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:18:03.764807 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 13:18:03.764814 28419 solver.cpp:238]     Train net output #2: loss = 0.368254 (* 1 = 0.368254 loss)
I0420 13:18:03.764818 28419 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0420 13:18:10.757067 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:18:26.735007 28419 solver.cpp:219] Iteration 40300 (4.35384 iter/s, 22.9682s/100 iters), loss = 0.349548
I0420 13:18:26.735061 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:18:26.735066 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:18:26.735072 28419 solver.cpp:238]     Train net output #2: loss = 0.349548 (* 1 = 0.349548 loss)
I0420 13:18:26.735076 28419 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0420 13:18:49.645643 28419 solver.cpp:219] Iteration 40400 (4.3652 iter/s, 22.9085s/100 iters), loss = 0.407031
I0420 13:18:49.645911 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 13:18:49.645920 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:18:49.645926 28419 solver.cpp:238]     Train net output #2: loss = 0.407031 (* 1 = 0.407031 loss)
I0420 13:18:49.645931 28419 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0420 13:19:13.409286 28419 solver.cpp:219] Iteration 40500 (4.20818 iter/s, 23.7633s/100 iters), loss = 0.214868
I0420 13:19:13.409339 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 13:19:13.409344 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:19:13.409350 28419 solver.cpp:238]     Train net output #2: loss = 0.214868 (* 1 = 0.214868 loss)
I0420 13:19:13.409354 28419 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0420 13:19:36.718816 28419 solver.cpp:219] Iteration 40600 (4.29011 iter/s, 23.3094s/100 iters), loss = 0.246387
I0420 13:19:36.718992 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 13:19:36.719000 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:19:36.719007 28419 solver.cpp:238]     Train net output #2: loss = 0.246387 (* 1 = 0.246387 loss)
I0420 13:19:36.719012 28419 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0420 13:19:41.372313 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:19:59.705442 28419 solver.cpp:219] Iteration 40700 (4.3508 iter/s, 22.9843s/100 iters), loss = 0.290638
I0420 13:19:59.705479 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:19:59.705502 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:19:59.705507 28419 solver.cpp:238]     Train net output #2: loss = 0.290637 (* 1 = 0.290637 loss)
I0420 13:19:59.705512 28419 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0420 13:20:22.576985 28419 solver.cpp:219] Iteration 40800 (4.37267 iter/s, 22.8693s/100 iters), loss = 0.360579
I0420 13:20:22.577078 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 13:20:22.577086 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:20:22.577092 28419 solver.cpp:238]     Train net output #2: loss = 0.360579 (* 1 = 0.360579 loss)
I0420 13:20:22.577096 28419 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0420 13:20:45.564321 28419 solver.cpp:219] Iteration 40900 (4.35066 iter/s, 22.985s/100 iters), loss = 0.338978
I0420 13:20:45.564375 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:20:45.564380 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:20:45.564386 28419 solver.cpp:238]     Train net output #2: loss = 0.338978 (* 1 = 0.338978 loss)
I0420 13:20:45.564390 28419 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0420 13:21:08.355906 28419 solver.cpp:331] Iteration 41000, Testing net (#0)
I0420 13:21:13.148725 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:21:13.380316 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8397
I0420 13:21:13.380343 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9935
I0420 13:21:13.380367 28419 solver.cpp:398]     Test net output #2: loss = 0.530432 (* 1 = 0.530432 loss)
I0420 13:21:13.610121 28419 solver.cpp:219] Iteration 41000 (3.56587 iter/s, 28.0437s/100 iters), loss = 0.345506
I0420 13:21:13.610141 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 13:21:13.610162 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:21:13.610167 28419 solver.cpp:238]     Train net output #2: loss = 0.345506 (* 1 = 0.345506 loss)
I0420 13:21:13.610173 28419 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0420 13:21:16.106544 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:21:36.493686 28419 solver.cpp:219] Iteration 41100 (4.37038 iter/s, 22.8813s/100 iters), loss = 0.373441
I0420 13:21:36.493741 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 13:21:36.493746 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:21:36.493753 28419 solver.cpp:238]     Train net output #2: loss = 0.373441 (* 1 = 0.373441 loss)
I0420 13:21:36.493757 28419 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0420 13:21:59.460424 28419 solver.cpp:219] Iteration 41200 (4.3546 iter/s, 22.9642s/100 iters), loss = 0.197551
I0420 13:21:59.460649 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 13:21:59.460656 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:21:59.460664 28419 solver.cpp:238]     Train net output #2: loss = 0.197551 (* 1 = 0.197551 loss)
I0420 13:21:59.460669 28419 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0420 13:22:22.316861 28419 solver.cpp:219] Iteration 41300 (4.37557 iter/s, 22.8542s/100 iters), loss = 0.305201
I0420 13:22:22.316915 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 13:22:22.316921 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:22:22.316928 28419 solver.cpp:238]     Train net output #2: loss = 0.305201 (* 1 = 0.305201 loss)
I0420 13:22:22.316932 28419 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0420 13:22:45.298060 28419 solver.cpp:219] Iteration 41400 (4.3518 iter/s, 22.979s/100 iters), loss = 0.334748
I0420 13:22:45.298259 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:22:45.298265 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:22:45.298272 28419 solver.cpp:238]     Train net output #2: loss = 0.334748 (* 1 = 0.334748 loss)
I0420 13:22:45.298276 28419 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0420 13:22:45.788439 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:23:08.223367 28419 solver.cpp:219] Iteration 41500 (4.36242 iter/s, 22.923s/100 iters), loss = 0.370517
I0420 13:23:08.223422 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:23:08.223428 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:23:08.223433 28419 solver.cpp:238]     Train net output #2: loss = 0.370517 (* 1 = 0.370517 loss)
I0420 13:23:08.223438 28419 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0420 13:23:31.178824 28419 solver.cpp:219] Iteration 41600 (4.35629 iter/s, 22.9553s/100 iters), loss = 0.269907
I0420 13:23:31.178988 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 13:23:31.178995 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:23:31.179003 28419 solver.cpp:238]     Train net output #2: loss = 0.269907 (* 1 = 0.269907 loss)
I0420 13:23:31.179006 28419 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0420 13:23:54.107182 28419 solver.cpp:219] Iteration 41700 (4.36184 iter/s, 22.9261s/100 iters), loss = 0.283392
I0420 13:23:54.107234 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:23:54.107239 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:23:54.107246 28419 solver.cpp:238]     Train net output #2: loss = 0.283392 (* 1 = 0.283392 loss)
I0420 13:23:54.107250 28419 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0420 13:24:15.240268 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:24:17.015542 28419 solver.cpp:219] Iteration 41800 (4.36524 iter/s, 22.9083s/100 iters), loss = 0.260084
I0420 13:24:17.015595 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:24:17.015601 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:24:17.015609 28419 solver.cpp:238]     Train net output #2: loss = 0.260084 (* 1 = 0.260084 loss)
I0420 13:24:17.015612 28419 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0420 13:24:39.995048 28419 solver.cpp:219] Iteration 41900 (4.35213 iter/s, 22.9772s/100 iters), loss = 0.317904
I0420 13:24:39.995101 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:24:39.995106 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:24:39.995115 28419 solver.cpp:238]     Train net output #2: loss = 0.317904 (* 1 = 0.317904 loss)
I0420 13:24:39.995118 28419 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0420 13:25:02.687144 28419 solver.cpp:331] Iteration 42000, Testing net (#0)
I0420 13:25:07.561725 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:25:07.798955 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8444
I0420 13:25:07.798981 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9916
I0420 13:25:07.799005 28419 solver.cpp:398]     Test net output #2: loss = 0.506186 (* 1 = 0.506186 loss)
I0420 13:25:07.973888 28419 solver.cpp:219] Iteration 42000 (3.57415 iter/s, 27.9787s/100 iters), loss = 0.251356
I0420 13:25:07.973908 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 13:25:07.973928 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:25:07.973934 28419 solver.cpp:238]     Train net output #2: loss = 0.251356 (* 1 = 0.251356 loss)
I0420 13:25:07.973940 28419 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0420 13:25:30.889660 28419 solver.cpp:219] Iteration 42100 (4.3638 iter/s, 22.9158s/100 iters), loss = 0.247965
I0420 13:25:30.889711 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:25:30.889717 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:25:30.889724 28419 solver.cpp:238]     Train net output #2: loss = 0.247965 (* 1 = 0.247965 loss)
I0420 13:25:30.889727 28419 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0420 13:25:49.969885 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:25:53.863507 28419 solver.cpp:219] Iteration 42200 (4.35321 iter/s, 22.9716s/100 iters), loss = 0.283352
I0420 13:25:53.863561 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:25:53.863566 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:25:53.863572 28419 solver.cpp:238]     Train net output #2: loss = 0.283352 (* 1 = 0.283352 loss)
I0420 13:25:53.863576 28419 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0420 13:26:16.717919 28419 solver.cpp:219] Iteration 42300 (4.37555 iter/s, 22.8543s/100 iters), loss = 0.313303
I0420 13:26:16.717974 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:26:16.717980 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:26:16.717986 28419 solver.cpp:238]     Train net output #2: loss = 0.313303 (* 1 = 0.313303 loss)
I0420 13:26:16.717991 28419 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0420 13:26:39.724019 28419 solver.cpp:219] Iteration 42400 (4.34711 iter/s, 23.0038s/100 iters), loss = 0.385297
I0420 13:26:39.724238 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:26:39.724246 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:26:39.724251 28419 solver.cpp:238]     Train net output #2: loss = 0.385297 (* 1 = 0.385297 loss)
I0420 13:26:39.724256 28419 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0420 13:27:02.596901 28419 solver.cpp:219] Iteration 42500 (4.3724 iter/s, 22.8707s/100 iters), loss = 0.292954
I0420 13:27:02.596956 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 13:27:02.596961 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 13:27:02.596967 28419 solver.cpp:238]     Train net output #2: loss = 0.292954 (* 1 = 0.292954 loss)
I0420 13:27:02.596971 28419 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0420 13:27:19.669245 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:27:25.579016 28419 solver.cpp:219] Iteration 42600 (4.35165 iter/s, 22.9798s/100 iters), loss = 0.377077
I0420 13:27:25.579066 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:27:25.579071 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:27:25.579077 28419 solver.cpp:238]     Train net output #2: loss = 0.377077 (* 1 = 0.377077 loss)
I0420 13:27:25.579082 28419 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0420 13:27:48.471611 28419 solver.cpp:219] Iteration 42700 (4.36866 iter/s, 22.8903s/100 iters), loss = 0.301742
I0420 13:27:48.471663 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:27:48.471669 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:27:48.471675 28419 solver.cpp:238]     Train net output #2: loss = 0.301742 (* 1 = 0.301742 loss)
I0420 13:27:48.471679 28419 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0420 13:28:11.483409 28419 solver.cpp:219] Iteration 42800 (4.34602 iter/s, 23.0095s/100 iters), loss = 0.416695
I0420 13:28:11.483497 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:28:11.483506 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:28:11.483512 28419 solver.cpp:238]     Train net output #2: loss = 0.416695 (* 1 = 0.416695 loss)
I0420 13:28:11.483516 28419 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0420 13:28:34.351491 28419 solver.cpp:219] Iteration 42900 (4.37335 iter/s, 22.8658s/100 iters), loss = 0.297691
I0420 13:28:34.351547 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:28:34.351552 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:28:34.351558 28419 solver.cpp:238]     Train net output #2: loss = 0.297691 (* 1 = 0.297691 loss)
I0420 13:28:34.351562 28419 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0420 13:28:49.151723 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:28:57.128423 28419 solver.cpp:331] Iteration 43000, Testing net (#0)
I0420 13:29:01.995235 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:29:02.204082 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8182
I0420 13:29:02.204104 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9915
I0420 13:29:02.204128 28419 solver.cpp:398]     Test net output #2: loss = 0.614052 (* 1 = 0.614052 loss)
I0420 13:29:02.343921 28419 solver.cpp:219] Iteration 43000 (3.57259 iter/s, 27.9909s/100 iters), loss = 0.345249
I0420 13:29:02.343958 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:29:02.343962 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 13:29:02.343968 28419 solver.cpp:238]     Train net output #2: loss = 0.345249 (* 1 = 0.345249 loss)
I0420 13:29:02.343974 28419 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0420 13:29:26.581055 28419 solver.cpp:219] Iteration 43100 (4.12627 iter/s, 24.2349s/100 iters), loss = 0.336897
I0420 13:29:26.581225 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:29:26.581233 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:29:26.581239 28419 solver.cpp:238]     Train net output #2: loss = 0.336897 (* 1 = 0.336897 loss)
I0420 13:29:26.581243 28419 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0420 13:29:49.575490 28419 solver.cpp:219] Iteration 43200 (4.34933 iter/s, 22.9921s/100 iters), loss = 0.298095
I0420 13:29:49.575547 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:29:49.575553 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:29:49.575561 28419 solver.cpp:238]     Train net output #2: loss = 0.298095 (* 1 = 0.298095 loss)
I0420 13:29:49.575564 28419 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0420 13:30:12.461307 28419 solver.cpp:219] Iteration 43300 (4.36994 iter/s, 22.8836s/100 iters), loss = 0.332383
I0420 13:30:12.461498 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 13:30:12.461504 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:30:12.461511 28419 solver.cpp:238]     Train net output #2: loss = 0.332383 (* 1 = 0.332383 loss)
I0420 13:30:12.461515 28419 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0420 13:30:25.145402 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:30:35.447134 28419 solver.cpp:219] Iteration 43400 (4.35081 iter/s, 22.9842s/100 iters), loss = 0.301957
I0420 13:30:35.447187 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:30:35.447192 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:30:35.447199 28419 solver.cpp:238]     Train net output #2: loss = 0.301957 (* 1 = 0.301957 loss)
I0420 13:30:35.447203 28419 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0420 13:30:58.358268 28419 solver.cpp:219] Iteration 43500 (4.36511 iter/s, 22.909s/100 iters), loss = 0.19924
I0420 13:30:58.358460 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 13:30:58.358469 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:30:58.358474 28419 solver.cpp:238]     Train net output #2: loss = 0.19924 (* 1 = 0.19924 loss)
I0420 13:30:58.358479 28419 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0420 13:31:21.316259 28419 solver.cpp:219] Iteration 43600 (4.35583 iter/s, 22.9578s/100 iters), loss = 0.424173
I0420 13:31:21.316315 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0420 13:31:21.316320 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:31:21.316328 28419 solver.cpp:238]     Train net output #2: loss = 0.424173 (* 1 = 0.424173 loss)
I0420 13:31:21.316331 28419 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0420 13:31:44.279798 28419 solver.cpp:219] Iteration 43700 (4.35519 iter/s, 22.9611s/100 iters), loss = 0.223389
I0420 13:31:44.280730 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 13:31:44.280738 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:31:44.280746 28419 solver.cpp:238]     Train net output #2: loss = 0.223389 (* 1 = 0.223389 loss)
I0420 13:31:44.280755 28419 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0420 13:31:54.634119 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:32:07.206037 28419 solver.cpp:219] Iteration 43800 (4.362 iter/s, 22.9252s/100 iters), loss = 0.267487
I0420 13:32:07.206094 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:32:07.206099 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:32:07.206105 28419 solver.cpp:238]     Train net output #2: loss = 0.267487 (* 1 = 0.267487 loss)
I0420 13:32:07.206110 28419 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0420 13:32:30.184559 28419 solver.cpp:219] Iteration 43900 (4.35229 iter/s, 22.9764s/100 iters), loss = 0.205527
I0420 13:32:30.184754 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 13:32:30.184762 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:32:30.184769 28419 solver.cpp:238]     Train net output #2: loss = 0.205527 (* 1 = 0.205527 loss)
I0420 13:32:30.184773 28419 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0420 13:32:52.878340 28419 solver.cpp:331] Iteration 44000, Testing net (#0)
I0420 13:32:57.768249 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:32:58.005826 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8312
I0420 13:32:58.005851 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9902
I0420 13:32:58.005875 28419 solver.cpp:398]     Test net output #2: loss = 0.579001 (* 1 = 0.579001 loss)
I0420 13:32:58.157807 28419 solver.cpp:219] Iteration 44000 (3.57489 iter/s, 27.9729s/100 iters), loss = 0.369602
I0420 13:32:58.157827 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 13:32:58.157848 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:32:58.157853 28419 solver.cpp:238]     Train net output #2: loss = 0.369601 (* 1 = 0.369601 loss)
I0420 13:32:58.157860 28419 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0420 13:33:21.100095 28419 solver.cpp:219] Iteration 44100 (4.35879 iter/s, 22.9422s/100 iters), loss = 0.355362
I0420 13:33:21.100311 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 13:33:21.100319 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:33:21.100327 28419 solver.cpp:238]     Train net output #2: loss = 0.355361 (* 1 = 0.355361 loss)
I0420 13:33:21.100330 28419 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0420 13:33:29.382230 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:33:44.031141 28419 solver.cpp:219] Iteration 44200 (4.36132 iter/s, 22.9289s/100 iters), loss = 0.302091
I0420 13:33:44.031198 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:33:44.031203 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:33:44.031208 28419 solver.cpp:238]     Train net output #2: loss = 0.302091 (* 1 = 0.302091 loss)
I0420 13:33:44.031213 28419 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0420 13:34:06.923224 28419 solver.cpp:219] Iteration 44300 (4.36835 iter/s, 22.8919s/100 iters), loss = 0.315718
I0420 13:34:06.923399 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:34:06.923406 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:34:06.923413 28419 solver.cpp:238]     Train net output #2: loss = 0.315718 (* 1 = 0.315718 loss)
I0420 13:34:06.923418 28419 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0420 13:34:30.054643 28419 solver.cpp:219] Iteration 44400 (4.32316 iter/s, 23.1312s/100 iters), loss = 0.319721
I0420 13:34:30.054699 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 13:34:30.054707 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:34:30.054713 28419 solver.cpp:238]     Train net output #2: loss = 0.319721 (* 1 = 0.319721 loss)
I0420 13:34:30.054718 28419 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0420 13:34:53.042352 28419 solver.cpp:219] Iteration 44500 (4.35059 iter/s, 22.9854s/100 iters), loss = 0.339345
I0420 13:34:53.042549 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:34:53.042557 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:34:53.042562 28419 solver.cpp:238]     Train net output #2: loss = 0.339345 (* 1 = 0.339345 loss)
I0420 13:34:53.042567 28419 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0420 13:34:59.255050 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:35:15.962792 28419 solver.cpp:219] Iteration 44600 (4.36296 iter/s, 22.9202s/100 iters), loss = 0.26861
I0420 13:35:15.962847 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 13:35:15.962852 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:35:15.962858 28419 solver.cpp:238]     Train net output #2: loss = 0.26861 (* 1 = 0.26861 loss)
I0420 13:35:15.962862 28419 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0420 13:35:38.954064 28419 solver.cpp:219] Iteration 44700 (4.3499 iter/s, 22.989s/100 iters), loss = 0.31605
I0420 13:35:38.954238 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:35:38.954246 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:35:38.954252 28419 solver.cpp:238]     Train net output #2: loss = 0.31605 (* 1 = 0.31605 loss)
I0420 13:35:38.954257 28419 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0420 13:36:01.850538 28419 solver.cpp:219] Iteration 44800 (4.36792 iter/s, 22.8942s/100 iters), loss = 0.371063
I0420 13:36:01.850592 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:36:01.850597 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:36:01.850603 28419 solver.cpp:238]     Train net output #2: loss = 0.371063 (* 1 = 0.371063 loss)
I0420 13:36:01.850607 28419 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0420 13:36:24.850437 28419 solver.cpp:219] Iteration 44900 (4.34827 iter/s, 22.9976s/100 iters), loss = 0.235477
I0420 13:36:24.850602 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:36:24.850626 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:36:24.850632 28419 solver.cpp:238]     Train net output #2: loss = 0.235477 (* 1 = 0.235477 loss)
I0420 13:36:24.850638 28419 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0420 13:36:28.745182 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:36:47.587988 28419 solver.cpp:331] Iteration 45000, Testing net (#0)
I0420 13:36:52.373441 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:36:52.604768 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.829
I0420 13:36:52.604794 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9906
I0420 13:36:52.604818 28419 solver.cpp:398]     Test net output #2: loss = 0.564162 (* 1 = 0.564162 loss)
I0420 13:36:52.836673 28419 solver.cpp:219] Iteration 45000 (3.57345 iter/s, 27.9841s/100 iters), loss = 0.242292
I0420 13:36:52.836712 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:36:52.836716 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:36:52.836740 28419 solver.cpp:238]     Train net output #2: loss = 0.242292 (* 1 = 0.242292 loss)
I0420 13:36:52.836746 28419 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0420 13:37:15.718578 28419 solver.cpp:219] Iteration 45100 (4.37072 iter/s, 22.8795s/100 iters), loss = 0.449056
I0420 13:37:15.718762 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 13:37:15.718770 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:37:15.718777 28419 solver.cpp:238]     Train net output #2: loss = 0.449056 (* 1 = 0.449056 loss)
I0420 13:37:15.718783 28419 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0420 13:37:38.718565 28419 solver.cpp:219] Iteration 45200 (4.34826 iter/s, 22.9977s/100 iters), loss = 0.238055
I0420 13:37:38.718616 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 13:37:38.718621 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:37:38.718628 28419 solver.cpp:238]     Train net output #2: loss = 0.238055 (* 1 = 0.238055 loss)
I0420 13:37:38.718632 28419 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0420 13:38:01.602210 28419 solver.cpp:219] Iteration 45300 (4.37037 iter/s, 22.8814s/100 iters), loss = 0.320323
I0420 13:38:01.602416 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 13:38:01.602422 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 13:38:01.602428 28419 solver.cpp:238]     Train net output #2: loss = 0.320323 (* 1 = 0.320323 loss)
I0420 13:38:01.602433 28419 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0420 13:38:03.499166 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:38:24.617760 28419 solver.cpp:219] Iteration 45400 (4.34532 iter/s, 23.0133s/100 iters), loss = 0.230105
I0420 13:38:24.617815 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:38:24.617820 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:38:24.617825 28419 solver.cpp:238]     Train net output #2: loss = 0.230105 (* 1 = 0.230105 loss)
I0420 13:38:24.617831 28419 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0420 13:38:47.509145 28419 solver.cpp:219] Iteration 45500 (4.36887 iter/s, 22.8892s/100 iters), loss = 0.283131
I0420 13:38:47.509363 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:38:47.509371 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:38:47.509377 28419 solver.cpp:238]     Train net output #2: loss = 0.283131 (* 1 = 0.283131 loss)
I0420 13:38:47.509382 28419 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0420 13:39:10.481524 28419 solver.cpp:219] Iteration 45600 (4.35351 iter/s, 22.97s/100 iters), loss = 0.310574
I0420 13:39:10.481576 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:39:10.481581 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:39:10.481587 28419 solver.cpp:238]     Train net output #2: loss = 0.310574 (* 1 = 0.310574 loss)
I0420 13:39:10.481591 28419 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0420 13:39:34.461261 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:39:34.620607 28419 solver.cpp:219] Iteration 45700 (4.14304 iter/s, 24.1368s/100 iters), loss = 0.32281
I0420 13:39:34.620638 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:39:34.620661 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:39:34.620667 28419 solver.cpp:238]     Train net output #2: loss = 0.32281 (* 1 = 0.32281 loss)
I0420 13:39:34.620671 28419 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0420 13:39:57.576725 28419 solver.cpp:219] Iteration 45800 (4.35657 iter/s, 22.9538s/100 iters), loss = 0.328602
I0420 13:39:57.576778 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 13:39:57.576784 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:39:57.576791 28419 solver.cpp:238]     Train net output #2: loss = 0.328602 (* 1 = 0.328602 loss)
I0420 13:39:57.576794 28419 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0420 13:40:20.486249 28419 solver.cpp:219] Iteration 45900 (4.36541 iter/s, 22.9073s/100 iters), loss = 0.412035
I0420 13:40:20.486335 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 13:40:20.486341 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:40:20.486347 28419 solver.cpp:238]     Train net output #2: loss = 0.412034 (* 1 = 0.412034 loss)
I0420 13:40:20.486351 28419 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0420 13:40:43.208887 28419 solver.cpp:331] Iteration 46000, Testing net (#0)
I0420 13:40:48.080718 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:40:48.323187 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8497
I0420 13:40:48.323213 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9934
I0420 13:40:48.323237 28419 solver.cpp:398]     Test net output #2: loss = 0.499103 (* 1 = 0.499103 loss)
I0420 13:40:48.485103 28419 solver.cpp:219] Iteration 46000 (3.57161 iter/s, 27.9985s/100 iters), loss = 0.406975
I0420 13:40:48.485123 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 13:40:48.485144 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 13:40:48.485149 28419 solver.cpp:238]     Train net output #2: loss = 0.406975 (* 1 = 0.406975 loss)
I0420 13:40:48.485155 28419 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0420 13:41:08.945287 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:41:11.443766 28419 solver.cpp:219] Iteration 46100 (4.35567 iter/s, 22.9586s/100 iters), loss = 0.379597
I0420 13:41:11.443817 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 13:41:11.443822 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:41:11.443830 28419 solver.cpp:238]     Train net output #2: loss = 0.379597 (* 1 = 0.379597 loss)
I0420 13:41:11.443833 28419 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0420 13:41:34.391890 28419 solver.cpp:219] Iteration 46200 (4.35808 iter/s, 22.9459s/100 iters), loss = 0.325749
I0420 13:41:34.391943 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 13:41:34.391948 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:41:34.391954 28419 solver.cpp:238]     Train net output #2: loss = 0.325749 (* 1 = 0.325749 loss)
I0420 13:41:34.391958 28419 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0420 13:41:57.320621 28419 solver.cpp:219] Iteration 46300 (4.36136 iter/s, 22.9286s/100 iters), loss = 0.28974
I0420 13:41:57.320868 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:41:57.320874 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:41:57.320881 28419 solver.cpp:238]     Train net output #2: loss = 0.28974 (* 1 = 0.28974 loss)
I0420 13:41:57.320885 28419 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0420 13:42:20.257391 28419 solver.cpp:219] Iteration 46400 (4.36024 iter/s, 22.9345s/100 iters), loss = 0.279601
I0420 13:42:20.257447 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:42:20.257452 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:42:20.257458 28419 solver.cpp:238]     Train net output #2: loss = 0.2796 (* 1 = 0.2796 loss)
I0420 13:42:20.257462 28419 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0420 13:42:38.684023 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:42:43.182250 28419 solver.cpp:219] Iteration 46500 (4.36211 iter/s, 22.9247s/100 iters), loss = 0.330526
I0420 13:42:43.182302 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 13:42:43.182307 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:42:43.182313 28419 solver.cpp:238]     Train net output #2: loss = 0.330526 (* 1 = 0.330526 loss)
I0420 13:42:43.182318 28419 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0420 13:43:06.161851 28419 solver.cpp:219] Iteration 46600 (4.35211 iter/s, 22.9774s/100 iters), loss = 0.364221
I0420 13:43:06.161906 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:43:06.161911 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:43:06.161916 28419 solver.cpp:238]     Train net output #2: loss = 0.364221 (* 1 = 0.364221 loss)
I0420 13:43:06.161921 28419 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0420 13:43:29.075868 28419 solver.cpp:219] Iteration 46700 (4.36418 iter/s, 22.9138s/100 iters), loss = 0.259737
I0420 13:43:29.076066 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 13:43:29.076072 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:43:29.076078 28419 solver.cpp:238]     Train net output #2: loss = 0.259737 (* 1 = 0.259737 loss)
I0420 13:43:29.076083 28419 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0420 13:43:52.064003 28419 solver.cpp:219] Iteration 46800 (4.35053 iter/s, 22.9857s/100 iters), loss = 0.281018
I0420 13:43:52.064060 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 13:43:52.064065 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:43:52.064072 28419 solver.cpp:238]     Train net output #2: loss = 0.281017 (* 1 = 0.281017 loss)
I0420 13:43:52.064091 28419 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0420 13:44:08.164355 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:44:14.968830 28419 solver.cpp:219] Iteration 46900 (4.36635 iter/s, 22.9024s/100 iters), loss = 0.321497
I0420 13:44:14.968880 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 13:44:14.968885 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:44:14.968891 28419 solver.cpp:238]     Train net output #2: loss = 0.321497 (* 1 = 0.321497 loss)
I0420 13:44:14.968896 28419 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0420 13:44:37.730211 28419 solver.cpp:331] Iteration 47000, Testing net (#0)
I0420 13:44:42.596505 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:44:42.731320 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8025
I0420 13:44:42.731345 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9887
I0420 13:44:42.731369 28419 solver.cpp:398]     Test net output #2: loss = 0.691854 (* 1 = 0.691854 loss)
I0420 13:44:42.938419 28419 solver.cpp:219] Iteration 47000 (3.57532 iter/s, 27.9695s/100 iters), loss = 0.237846
I0420 13:44:42.938439 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:44:42.938460 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:44:42.938467 28419 solver.cpp:238]     Train net output #2: loss = 0.237846 (* 1 = 0.237846 loss)
I0420 13:44:42.938472 28419 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0420 13:45:05.938184 28419 solver.cpp:219] Iteration 47100 (4.34828 iter/s, 22.9976s/100 iters), loss = 0.200653
I0420 13:45:05.938236 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 13:45:05.938241 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:45:05.938247 28419 solver.cpp:238]     Train net output #2: loss = 0.200653 (* 1 = 0.200653 loss)
I0420 13:45:05.938251 28419 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0420 13:45:28.838661 28419 solver.cpp:219] Iteration 47200 (4.3671 iter/s, 22.8985s/100 iters), loss = 0.405069
I0420 13:45:28.838907 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:45:28.838915 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 13:45:28.838922 28419 solver.cpp:238]     Train net output #2: loss = 0.405069 (* 1 = 0.405069 loss)
I0420 13:45:28.838927 28419 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0420 13:45:42.910218 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:45:51.804963 28419 solver.cpp:219] Iteration 47300 (4.35458 iter/s, 22.9643s/100 iters), loss = 0.248582
I0420 13:45:51.805001 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 13:45:51.805022 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:45:51.805028 28419 solver.cpp:238]     Train net output #2: loss = 0.248582 (* 1 = 0.248582 loss)
I0420 13:45:51.805033 28419 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0420 13:46:14.677362 28419 solver.cpp:219] Iteration 47400 (4.3725 iter/s, 22.8702s/100 iters), loss = 0.336486
I0420 13:46:14.677525 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:46:14.677531 28419 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 13:46:14.677538 28419 solver.cpp:238]     Train net output #2: loss = 0.336486 (* 1 = 0.336486 loss)
I0420 13:46:14.677542 28419 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0420 13:46:37.669761 28419 solver.cpp:219] Iteration 47500 (4.34971 iter/s, 22.99s/100 iters), loss = 0.252499
I0420 13:46:37.669800 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:46:37.669821 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:46:37.669829 28419 solver.cpp:238]     Train net output #2: loss = 0.252499 (* 1 = 0.252499 loss)
I0420 13:46:37.669833 28419 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0420 13:47:00.558921 28419 solver.cpp:219] Iteration 47600 (4.3693 iter/s, 22.887s/100 iters), loss = 0.356492
I0420 13:47:00.559088 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 13:47:00.559095 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:47:00.559103 28419 solver.cpp:238]     Train net output #2: loss = 0.356492 (* 1 = 0.356492 loss)
I0420 13:47:00.559106 28419 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0420 13:47:12.522433 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:47:23.530067 28419 solver.cpp:219] Iteration 47700 (4.35372 iter/s, 22.9689s/100 iters), loss = 0.346553
I0420 13:47:23.530123 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:47:23.530129 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:47:23.530135 28419 solver.cpp:238]     Train net output #2: loss = 0.346553 (* 1 = 0.346553 loss)
I0420 13:47:23.530139 28419 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0420 13:47:46.432214 28419 solver.cpp:219] Iteration 47800 (4.36683 iter/s, 22.8999s/100 iters), loss = 0.259296
I0420 13:47:46.432389 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:47:46.432396 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:47:46.432404 28419 solver.cpp:238]     Train net output #2: loss = 0.259295 (* 1 = 0.259295 loss)
I0420 13:47:46.432410 28419 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0420 13:48:09.399312 28419 solver.cpp:219] Iteration 47900 (4.35408 iter/s, 22.967s/100 iters), loss = 0.207941
I0420 13:48:09.399366 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 13:48:09.399371 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:48:09.399377 28419 solver.cpp:238]     Train net output #2: loss = 0.20794 (* 1 = 0.20794 loss)
I0420 13:48:09.399381 28419 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0420 13:48:32.168447 28419 solver.cpp:331] Iteration 48000, Testing net (#0)
I0420 13:48:36.974516 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:48:37.185204 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8345
I0420 13:48:37.185231 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9896
I0420 13:48:37.185256 28419 solver.cpp:398]     Test net output #2: loss = 0.556374 (* 1 = 0.556374 loss)
I0420 13:48:37.412411 28419 solver.cpp:219] Iteration 48000 (3.57003 iter/s, 28.011s/100 iters), loss = 0.255294
I0420 13:48:37.412432 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:48:37.412453 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:48:37.412458 28419 solver.cpp:238]     Train net output #2: loss = 0.255294 (* 1 = 0.255294 loss)
I0420 13:48:37.412463 28419 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 1
I0420 13:48:37.412467 28419 sgd_solver.cpp:105] Iteration 48000, lr = 0.001
I0420 13:48:47.069058 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:49:00.286346 28419 solver.cpp:219] Iteration 48100 (4.37221 iter/s, 22.8717s/100 iters), loss = 0.389983
I0420 13:49:00.286402 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 13:49:00.286407 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:49:00.286413 28419 solver.cpp:238]     Train net output #2: loss = 0.389983 (* 1 = 0.389983 loss)
I0420 13:49:00.286417 28419 sgd_solver.cpp:105] Iteration 48100, lr = 0.001
I0420 13:49:23.235971 28419 solver.cpp:219] Iteration 48200 (4.35739 iter/s, 22.9495s/100 iters), loss = 0.269789
I0420 13:49:23.236169 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 13:49:23.236176 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:49:23.236183 28419 solver.cpp:238]     Train net output #2: loss = 0.269789 (* 1 = 0.269789 loss)
I0420 13:49:23.236187 28419 sgd_solver.cpp:105] Iteration 48200, lr = 0.001
I0420 13:49:47.390954 28419 solver.cpp:219] Iteration 48300 (4.14031 iter/s, 24.1528s/100 iters), loss = 0.244719
I0420 13:49:47.391019 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:49:47.391024 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:49:47.391031 28419 solver.cpp:238]     Train net output #2: loss = 0.244719 (* 1 = 0.244719 loss)
I0420 13:49:47.391034 28419 sgd_solver.cpp:105] Iteration 48300, lr = 0.001
I0420 13:50:10.380085 28419 solver.cpp:219] Iteration 48400 (4.35031 iter/s, 22.9869s/100 iters), loss = 0.280921
I0420 13:50:10.380275 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:50:10.380281 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:50:10.380288 28419 solver.cpp:238]     Train net output #2: loss = 0.280921 (* 1 = 0.280921 loss)
I0420 13:50:10.380292 28419 sgd_solver.cpp:105] Iteration 48400, lr = 0.001
I0420 13:50:17.971916 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:50:33.266711 28419 solver.cpp:219] Iteration 48500 (4.36981 iter/s, 22.8843s/100 iters), loss = 0.278714
I0420 13:50:33.266767 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 13:50:33.266772 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:50:33.266778 28419 solver.cpp:238]     Train net output #2: loss = 0.278714 (* 1 = 0.278714 loss)
I0420 13:50:33.266782 28419 sgd_solver.cpp:105] Iteration 48500, lr = 0.001
I0420 13:50:56.250661 28419 solver.cpp:219] Iteration 48600 (4.35131 iter/s, 22.9816s/100 iters), loss = 0.256509
I0420 13:50:56.250752 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 13:50:56.250758 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:50:56.250766 28419 solver.cpp:238]     Train net output #2: loss = 0.256509 (* 1 = 0.256509 loss)
I0420 13:50:56.250769 28419 sgd_solver.cpp:105] Iteration 48600, lr = 0.001
I0420 13:51:19.121660 28419 solver.cpp:219] Iteration 48700 (4.37277 iter/s, 22.8688s/100 iters), loss = 0.340889
I0420 13:51:19.121713 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 13:51:19.121718 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:51:19.121724 28419 solver.cpp:238]     Train net output #2: loss = 0.340889 (* 1 = 0.340889 loss)
I0420 13:51:19.121728 28419 sgd_solver.cpp:105] Iteration 48700, lr = 0.001
I0420 13:51:42.131247 28419 solver.cpp:219] Iteration 48800 (4.34645 iter/s, 23.0073s/100 iters), loss = 0.376249
I0420 13:51:42.131490 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 13:51:42.131498 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:51:42.131505 28419 solver.cpp:238]     Train net output #2: loss = 0.376249 (* 1 = 0.376249 loss)
I0420 13:51:42.131510 28419 sgd_solver.cpp:105] Iteration 48800, lr = 0.001
I0420 13:51:47.653527 28423 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:52:05.015501 28419 solver.cpp:219] Iteration 48900 (4.37023 iter/s, 22.8821s/100 iters), loss = 0.206078
I0420 13:52:05.015555 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 13:52:05.015561 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:52:05.015568 28419 solver.cpp:238]     Train net output #2: loss = 0.206078 (* 1 = 0.206078 loss)
I0420 13:52:05.015571 28419 sgd_solver.cpp:105] Iteration 48900, lr = 0.001
I0420 13:52:27.773591 28419 solver.cpp:331] Iteration 49000, Testing net (#0)
I0420 13:52:32.655961 28424 data_layer.cpp:73] Restarting data prefetching from start.
I0420 13:52:32.847544 28419 solver.cpp:398]     Test net output #0: acctop1 = 0.8658
I0420 13:52:32.847570 28419 solver.cpp:398]     Test net output #1: acctop5 = 0.9941
I0420 13:52:32.847594 28419 solver.cpp:398]     Test net output #2: loss = 0.429933 (* 1 = 0.429933 loss)
I0420 13:52:32.997237 28419 solver.cpp:219] Iteration 49000 (3.57404 iter/s, 27.9795s/100 iters), loss = 0.250513
I0420 13:52:32.997258 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 13:52:32.997280 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:52:32.997287 28419 solver.cpp:238]     Train net output #2: loss = 0.250513 (* 1 = 0.250513 loss)
I0420 13:52:32.997292 28419 sgd_solver.cpp:105] Iteration 49000, lr = 0.001
I0420 13:52:55.981444 28419 solver.cpp:219] Iteration 49100 (4.35126 iter/s, 22.9818s/100 iters), loss = 0.172966
I0420 13:52:55.981498 28419 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 13:52:55.981504 28419 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 13:52:55.981510 28419 solver.cpp:238]     Train net output #2: loss = 0.172966 (* 1 = 0.172966 loss)
I0420 13:52:55.981514 28419 sgd_solver.cpp:105] Iteration 49100, lr = 0.001
I0420 13:58:44.287677 32892 caffe.cpp:218] Using GPUs 0
I0420 13:58:44.293470 32892 caffe.cpp:223] GPU 0: Tesla P100-PCIE-16GB
I0420 13:58:45.159144 32892 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "model/ResNet20_finetune_quant_0.09"
solver_mode: GPU
device_id: 0
net: "resnet20_relu_msra_cifar10_fix_pattern.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 12000
stepvalue: 24000
I0420 13:58:45.161550 32892 solver.cpp:87] Creating training net from net file: resnet20_relu_msra_cifar10_fix_pattern.prototxt
I0420 13:58:45.163954 32892 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet20_relu_msra_cifar10_fix_pattern.prototxt
I0420 13:58:45.163966 32892 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0420 13:58:45.164168 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0420 13:58:45.164180 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv1
I0420 13:58:45.164186 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_1_bn_a
I0420 13:58:45.164191 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_1_bn_b
I0420 13:58:45.164196 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_2_bn_a
I0420 13:58:45.164201 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_2_bn_b
I0420 13:58:45.164206 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_3_bn_a
I0420 13:58:45.164209 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_3_bn_b
I0420 13:58:45.164214 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_proj
I0420 13:58:45.164219 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_a
I0420 13:58:45.164223 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_b
I0420 13:58:45.164227 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_2_bn_a
I0420 13:58:45.164232 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_2_bn_b
I0420 13:58:45.164238 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_3_bn_a
I0420 13:58:45.164242 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_3_bn_b
I0420 13:58:45.164247 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_proj
I0420 13:58:45.164252 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_a
I0420 13:58:45.164260 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_b
I0420 13:58:45.164266 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_2_bn_a
I0420 13:58:45.164270 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_2_bn_b
I0420 13:58:45.164275 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_3_bn_a
I0420 13:58:45.164280 32892 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_3_bn_b
I0420 13:58:45.164733 32892 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
    mean_file: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/paddedmean.binaryproto"
  }
  data_param {
    source: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_full_train_leveldb_padded/"
    batch_size: 128
    backend: LEVELDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "map16_1_conv_a"
  type: "Convolution"
  bottom: "conv1"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_a"
  type: "BatchNorm"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_1_scale_a"
  type: "Scale"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_relu_a"
  type: "ReLU"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
}
layer {
  name: "map16_1_conv_b"
  type: "Convolution"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_b"
  type: "BatchNorm"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_1_scale_b"
  type: "Scale"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_eltsum"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "map16_1_conv_b"
  top: "map16_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_1_relu_after_sum"
  type: "ReLU"
  bottom: "map16_1_eltsum"
  top: "map16_1_eltsum"
}
layer {
  name: "map16_2_conv_a"
  type: "Convolution"
  bottom: "map16_1_eltsum"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_a"
  type: "BatchNorm"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_2_scale_a"
  type: "Scale"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_relu_a"
  type: "ReLU"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
}
layer {
  name: "map16_2_conv_b"
  type: "Convolution"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_b"
  type: "BatchNorm"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_2_scale_b"
  type: "Scale"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_eltsum"
  type: "Eltwise"
  bottom: "map16_1_eltsum"
  bottom: "map16_2_conv_b"
  top: "map16_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_2_relu_after_sum"
  type: "ReLU"
  bottom: "map16_2_eltsum"
  top: "map16_2_eltsum"
}
layer {
  name: "map16_3_conv_a"
  type: "Convolution"
  bottom: "map16_2_eltsum"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_a"
  type: "BatchNorm"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_3_scale_a"
  type: "Scale"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_relu_a"
  type: "ReLU"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
}
layer {
  name: "map16_3_conv_b"
  type: "Convolution"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_b"
  type: "BatchNorm"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_3_scale_b"
  type: "Scale"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_eltsum"
  type: "Eltwise"
  bottom: "map16_2_eltsum"
  bottom: "map16_3_conv_b"
  top: "map16_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_3_relu_after_sum"
  type: "ReLU"
  bottom: "map16_3_eltsum"
  top: "map16_3_eltsum"
}
layer {
  name: "map32_1_conv_proj"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_proj"
  type: "BatchNorm"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_proj"
  type: "Scale"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_conv_a"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_a"
  type: "BatchNorm"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_a"
  type: "Scale"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_relu_a"
  type: "ReLU"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
}
layer {
  name: "map32_1_conv_b"
  type: "Convolution"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_b"
  type: "BatchNorm"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_b"
  type: "Scale"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_eltsum"
  type: "Eltwise"
  bottom: "map32_1_conv_proj"
  bottom: "map32_1_conv_b"
  top: "map32_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_1_relu_after_sum"
  type: "ReLU"
  bottom: "map32_1_eltsum"
  top: "map32_1_eltsum"
}
layer {
  name: "map32_2_conv_a"
  type: "Convolution"
  bottom: "map32_1_eltsum"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_a"
  type: "BatchNorm"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_2_scale_a"
  type: "Scale"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_relu_a"
  type: "ReLU"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
}
layer {
  name: "map32_2_conv_b"
  type: "Convolution"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_b"
  type: "BatchNorm"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_2_scale_b"
  type: "Scale"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_eltsum"
  type: "Eltwise"
  bottom: "map32_1_eltsum"
  bottom: "map32_2_conv_b"
  top: "map32_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_2_relu_after_sum"
  type: "ReLU"
  bottom: "map32_2_eltsum"
  top: "map32_2_eltsum"
}
layer {
  name: "map32_3_conv_a"
  type: "Convolution"
  bottom: "map32_2_eltsum"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_a"
  type: "BatchNorm"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_3_scale_a"
  type: "Scale"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_relu_a"
  type: "ReLU"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
}
layer {
  name: "map32_3_conv_b"
  type: "Convolution"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_b"
  type: "BatchNorm"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_3_scale_b"
  type: "Scale"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_eltsum"
  type: "Eltwise"
  bottom: "map32_2_eltsum"
  bottom: "map32_3_conv_b"
  top: "map32_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_3_relu_after_sum"
  type: "ReLU"
  bottom: "map32_3_eltsum"
  top: "map32_3_eltsum"
}
layer {
  name: "map64_1_conv_proj"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_proj"
  type: "BatchNorm"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_proj"
  type: "Scale"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_conv_a"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_a"
  type: "BatchNorm"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_a"
  type: "Scale"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_relu_a"
  type: "ReLU"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
}
layer {
  name: "map64_1_conv_b"
  type: "Convolution"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_b"
  type: "BatchNorm"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_b"
  type: "Scale"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_eltsum"
  type: "Eltwise"
  bottom: "map64_1_conv_proj"
  bottom: "map64_1_conv_b"
  top: "map64_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_1_relu_after_sum"
  type: "ReLU"
  bottom: "map64_1_eltsum"
  top: "map64_1_eltsum"
}
layer {
  name: "map64_2_conv_a"
  type: "Convolution"
  bottom: "map64_1_eltsum"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_a"
  type: "BatchNorm"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_2_scale_a"
  type: "Scale"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_relu_a"
  type: "ReLU"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
}
layer {
  name: "map64_2_conv_b"
  type: "Convolution"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_b"
  type: "BatchNorm"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_2_scale_b"
  type: "Scale"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_eltsum"
  type: "Eltwise"
  bottom: "map64_1_eltsum"
  bottom: "map64_2_conv_b"
  top: "map64_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_2_relu_after_sum"
  type: "ReLU"
  bottom: "map64_2_eltsum"
  top: "map64_2_eltsum"
}
layer {
  name: "map64_3_conv_a"
  type: "Convolution"
  bottom: "map64_2_eltsum"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_a"
  type: "BatchNorm"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_3_scale_a"
  type: "Scale"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_relu_a"
  type: "ReLU"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
}
layer {
  name: "map64_3_conv_b"
  type: "Convolution"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_b"
  type: "BatchNorm"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_3_scale_b"
  type: "Scale"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_eltsum"
  type: "Eltwise"
  bottom: "map64_2_eltsum"
  bottom: "map64_3_conv_b"
  top: "map64_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_3_relu_after_sum"
  type: "ReLU"
  bottom: "map64_3_eltsum"
  top: "map64_3_eltsum"
}
layer {
  name: "pool_global"
  type: "Pooling"
  bottom: "map64_3_eltsum"
  top: "pool_global"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_global"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc/top1"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc/top5"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop5"
  accuracy_param {
    top_k: 5
  }
}
I0420 13:58:45.165143 32892 layer_factory.hpp:77] Creating layer data
I0420 13:58:45.198895 32892 db_leveldb.cpp:18] Opened leveldb /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_full_train_leveldb_padded/
I0420 13:58:45.200048 32892 net.cpp:84] Creating Layer data
I0420 13:58:45.200080 32892 net.cpp:380] data -> data
I0420 13:58:45.200111 32892 net.cpp:380] data -> label
I0420 13:58:45.200143 32892 data_transformer.cpp:25] Loading mean file from: /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/paddedmean.binaryproto
I0420 13:58:45.203225 32892 data_layer.cpp:45] output data size: 128,3,32,32
I0420 13:58:45.226505 32892 net.cpp:122] Setting up data
I0420 13:58:45.226521 32892 net.cpp:129] Top shape: 128 3 32 32 (393216)
I0420 13:58:45.226523 32892 net.cpp:129] Top shape: 128 (128)
I0420 13:58:45.226547 32892 net.cpp:137] Memory required for data: 1573376
I0420 13:58:45.226554 32892 layer_factory.hpp:77] Creating layer label_data_1_split
I0420 13:58:45.226563 32892 net.cpp:84] Creating Layer label_data_1_split
I0420 13:58:45.226569 32892 net.cpp:406] label_data_1_split <- label
I0420 13:58:45.226582 32892 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0420 13:58:45.226589 32892 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0420 13:58:45.226594 32892 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0420 13:58:45.226661 32892 net.cpp:122] Setting up label_data_1_split
I0420 13:58:45.226666 32892 net.cpp:129] Top shape: 128 (128)
I0420 13:58:45.226670 32892 net.cpp:129] Top shape: 128 (128)
I0420 13:58:45.226696 32892 net.cpp:129] Top shape: 128 (128)
I0420 13:58:45.226699 32892 net.cpp:137] Memory required for data: 1574912
I0420 13:58:45.226702 32892 layer_factory.hpp:77] Creating layer conv1
I0420 13:58:45.226717 32892 net.cpp:84] Creating Layer conv1
I0420 13:58:45.226722 32892 net.cpp:406] conv1 <- data
I0420 13:58:45.226725 32892 net.cpp:380] conv1 -> conv1
I0420 13:58:45.889914 32892 net.cpp:122] Setting up conv1
I0420 13:58:45.889984 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.889989 32892 net.cpp:137] Memory required for data: 9963520
I0420 13:58:45.890028 32892 layer_factory.hpp:77] Creating layer bn_conv1
I0420 13:58:45.890079 32892 net.cpp:84] Creating Layer bn_conv1
I0420 13:58:45.890086 32892 net.cpp:406] bn_conv1 <- conv1
I0420 13:58:45.890101 32892 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0420 13:58:45.890275 32892 net.cpp:122] Setting up bn_conv1
I0420 13:58:45.890282 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.890285 32892 net.cpp:137] Memory required for data: 18352128
I0420 13:58:45.890295 32892 layer_factory.hpp:77] Creating layer scale_conv1
I0420 13:58:45.890321 32892 net.cpp:84] Creating Layer scale_conv1
I0420 13:58:45.890326 32892 net.cpp:406] scale_conv1 <- conv1
I0420 13:58:45.890331 32892 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0420 13:58:45.890369 32892 layer_factory.hpp:77] Creating layer scale_conv1
I0420 13:58:45.890468 32892 net.cpp:122] Setting up scale_conv1
I0420 13:58:45.890475 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.890477 32892 net.cpp:137] Memory required for data: 26740736
I0420 13:58:45.890483 32892 layer_factory.hpp:77] Creating layer relu_conv1
I0420 13:58:45.890496 32892 net.cpp:84] Creating Layer relu_conv1
I0420 13:58:45.890501 32892 net.cpp:406] relu_conv1 <- conv1
I0420 13:58:45.890503 32892 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0420 13:58:45.891865 32892 net.cpp:122] Setting up relu_conv1
I0420 13:58:45.891875 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.891878 32892 net.cpp:137] Memory required for data: 35129344
I0420 13:58:45.891886 32892 layer_factory.hpp:77] Creating layer conv1_relu_conv1_0_split
I0420 13:58:45.891893 32892 net.cpp:84] Creating Layer conv1_relu_conv1_0_split
I0420 13:58:45.891897 32892 net.cpp:406] conv1_relu_conv1_0_split <- conv1
I0420 13:58:45.891901 32892 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_0
I0420 13:58:45.891908 32892 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_1
I0420 13:58:45.891944 32892 net.cpp:122] Setting up conv1_relu_conv1_0_split
I0420 13:58:45.891950 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.891954 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.891957 32892 net.cpp:137] Memory required for data: 51906560
I0420 13:58:45.891959 32892 layer_factory.hpp:77] Creating layer map16_1_conv_a
I0420 13:58:45.891973 32892 net.cpp:84] Creating Layer map16_1_conv_a
I0420 13:58:45.891978 32892 net.cpp:406] map16_1_conv_a <- conv1_relu_conv1_0_split_0
I0420 13:58:45.891983 32892 net.cpp:380] map16_1_conv_a -> map16_1_conv_a
I0420 13:58:45.899160 32892 net.cpp:122] Setting up map16_1_conv_a
I0420 13:58:45.899174 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.899178 32892 net.cpp:137] Memory required for data: 60295168
I0420 13:58:45.899188 32892 layer_factory.hpp:77] Creating layer map16_1_bn_a
I0420 13:58:45.899196 32892 net.cpp:84] Creating Layer map16_1_bn_a
I0420 13:58:45.899200 32892 net.cpp:406] map16_1_bn_a <- map16_1_conv_a
I0420 13:58:45.899211 32892 net.cpp:367] map16_1_bn_a -> map16_1_conv_a (in-place)
I0420 13:58:45.899369 32892 net.cpp:122] Setting up map16_1_bn_a
I0420 13:58:45.899376 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.899379 32892 net.cpp:137] Memory required for data: 68683776
I0420 13:58:45.899386 32892 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0420 13:58:45.899400 32892 net.cpp:84] Creating Layer map16_1_scale_a
I0420 13:58:45.899405 32892 net.cpp:406] map16_1_scale_a <- map16_1_conv_a
I0420 13:58:45.899436 32892 net.cpp:367] map16_1_scale_a -> map16_1_conv_a (in-place)
I0420 13:58:45.899471 32892 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0420 13:58:45.899559 32892 net.cpp:122] Setting up map16_1_scale_a
I0420 13:58:45.899565 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.899569 32892 net.cpp:137] Memory required for data: 77072384
I0420 13:58:45.899574 32892 layer_factory.hpp:77] Creating layer map16_1_relu_a
I0420 13:58:45.899580 32892 net.cpp:84] Creating Layer map16_1_relu_a
I0420 13:58:45.899583 32892 net.cpp:406] map16_1_relu_a <- map16_1_conv_a
I0420 13:58:45.899592 32892 net.cpp:367] map16_1_relu_a -> map16_1_conv_a (in-place)
I0420 13:58:45.901484 32892 net.cpp:122] Setting up map16_1_relu_a
I0420 13:58:45.901495 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.901499 32892 net.cpp:137] Memory required for data: 85460992
I0420 13:58:45.901502 32892 layer_factory.hpp:77] Creating layer map16_1_conv_b
I0420 13:58:45.901512 32892 net.cpp:84] Creating Layer map16_1_conv_b
I0420 13:58:45.901516 32892 net.cpp:406] map16_1_conv_b <- map16_1_conv_a
I0420 13:58:45.901521 32892 net.cpp:380] map16_1_conv_b -> map16_1_conv_b
I0420 13:58:45.908583 32892 net.cpp:122] Setting up map16_1_conv_b
I0420 13:58:45.908594 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.908597 32892 net.cpp:137] Memory required for data: 93849600
I0420 13:58:45.908603 32892 layer_factory.hpp:77] Creating layer map16_1_bn_b
I0420 13:58:45.908617 32892 net.cpp:84] Creating Layer map16_1_bn_b
I0420 13:58:45.908622 32892 net.cpp:406] map16_1_bn_b <- map16_1_conv_b
I0420 13:58:45.908627 32892 net.cpp:367] map16_1_bn_b -> map16_1_conv_b (in-place)
I0420 13:58:45.908808 32892 net.cpp:122] Setting up map16_1_bn_b
I0420 13:58:45.908816 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.908819 32892 net.cpp:137] Memory required for data: 102238208
I0420 13:58:45.908834 32892 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0420 13:58:45.908841 32892 net.cpp:84] Creating Layer map16_1_scale_b
I0420 13:58:45.908845 32892 net.cpp:406] map16_1_scale_b <- map16_1_conv_b
I0420 13:58:45.908849 32892 net.cpp:367] map16_1_scale_b -> map16_1_conv_b (in-place)
I0420 13:58:45.908882 32892 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0420 13:58:45.908974 32892 net.cpp:122] Setting up map16_1_scale_b
I0420 13:58:45.908980 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.908983 32892 net.cpp:137] Memory required for data: 110626816
I0420 13:58:45.909005 32892 layer_factory.hpp:77] Creating layer map16_1_eltsum
I0420 13:58:45.909019 32892 net.cpp:84] Creating Layer map16_1_eltsum
I0420 13:58:45.909024 32892 net.cpp:406] map16_1_eltsum <- conv1_relu_conv1_0_split_1
I0420 13:58:45.909030 32892 net.cpp:406] map16_1_eltsum <- map16_1_conv_b
I0420 13:58:45.909035 32892 net.cpp:380] map16_1_eltsum -> map16_1_eltsum
I0420 13:58:45.909063 32892 net.cpp:122] Setting up map16_1_eltsum
I0420 13:58:45.909070 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.909072 32892 net.cpp:137] Memory required for data: 119015424
I0420 13:58:45.909075 32892 layer_factory.hpp:77] Creating layer map16_1_relu_after_sum
I0420 13:58:45.909078 32892 net.cpp:84] Creating Layer map16_1_relu_after_sum
I0420 13:58:45.909082 32892 net.cpp:406] map16_1_relu_after_sum <- map16_1_eltsum
I0420 13:58:45.909085 32892 net.cpp:367] map16_1_relu_after_sum -> map16_1_eltsum (in-place)
I0420 13:58:45.910965 32892 net.cpp:122] Setting up map16_1_relu_after_sum
I0420 13:58:45.910976 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.910980 32892 net.cpp:137] Memory required for data: 127404032
I0420 13:58:45.910984 32892 layer_factory.hpp:77] Creating layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 13:58:45.910991 32892 net.cpp:84] Creating Layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 13:58:45.910995 32892 net.cpp:406] map16_1_eltsum_map16_1_relu_after_sum_0_split <- map16_1_eltsum
I0420 13:58:45.911013 32892 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0420 13:58:45.911021 32892 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0420 13:58:45.911056 32892 net.cpp:122] Setting up map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 13:58:45.911062 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.911067 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.911069 32892 net.cpp:137] Memory required for data: 144181248
I0420 13:58:45.911079 32892 layer_factory.hpp:77] Creating layer map16_2_conv_a
I0420 13:58:45.911087 32892 net.cpp:84] Creating Layer map16_2_conv_a
I0420 13:58:45.911092 32892 net.cpp:406] map16_2_conv_a <- map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0420 13:58:45.911097 32892 net.cpp:380] map16_2_conv_a -> map16_2_conv_a
I0420 13:58:45.912077 32892 net.cpp:122] Setting up map16_2_conv_a
I0420 13:58:45.912089 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.912093 32892 net.cpp:137] Memory required for data: 152569856
I0420 13:58:45.912099 32892 layer_factory.hpp:77] Creating layer map16_2_bn_a
I0420 13:58:45.912113 32892 net.cpp:84] Creating Layer map16_2_bn_a
I0420 13:58:45.912117 32892 net.cpp:406] map16_2_bn_a <- map16_2_conv_a
I0420 13:58:45.912122 32892 net.cpp:367] map16_2_bn_a -> map16_2_conv_a (in-place)
I0420 13:58:45.912281 32892 net.cpp:122] Setting up map16_2_bn_a
I0420 13:58:45.912286 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.912288 32892 net.cpp:137] Memory required for data: 160958464
I0420 13:58:45.912295 32892 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0420 13:58:45.912300 32892 net.cpp:84] Creating Layer map16_2_scale_a
I0420 13:58:45.912304 32892 net.cpp:406] map16_2_scale_a <- map16_2_conv_a
I0420 13:58:45.912308 32892 net.cpp:367] map16_2_scale_a -> map16_2_conv_a (in-place)
I0420 13:58:45.912336 32892 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0420 13:58:45.912425 32892 net.cpp:122] Setting up map16_2_scale_a
I0420 13:58:45.912431 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.912433 32892 net.cpp:137] Memory required for data: 169347072
I0420 13:58:45.912438 32892 layer_factory.hpp:77] Creating layer map16_2_relu_a
I0420 13:58:45.912452 32892 net.cpp:84] Creating Layer map16_2_relu_a
I0420 13:58:45.912456 32892 net.cpp:406] map16_2_relu_a <- map16_2_conv_a
I0420 13:58:45.912463 32892 net.cpp:367] map16_2_relu_a -> map16_2_conv_a (in-place)
I0420 13:58:45.914382 32892 net.cpp:122] Setting up map16_2_relu_a
I0420 13:58:45.914391 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.914394 32892 net.cpp:137] Memory required for data: 177735680
I0420 13:58:45.914398 32892 layer_factory.hpp:77] Creating layer map16_2_conv_b
I0420 13:58:45.914407 32892 net.cpp:84] Creating Layer map16_2_conv_b
I0420 13:58:45.914410 32892 net.cpp:406] map16_2_conv_b <- map16_2_conv_a
I0420 13:58:45.914415 32892 net.cpp:380] map16_2_conv_b -> map16_2_conv_b
I0420 13:58:45.921542 32892 net.cpp:122] Setting up map16_2_conv_b
I0420 13:58:45.921555 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.921558 32892 net.cpp:137] Memory required for data: 186124288
I0420 13:58:45.921564 32892 layer_factory.hpp:77] Creating layer map16_2_bn_b
I0420 13:58:45.921571 32892 net.cpp:84] Creating Layer map16_2_bn_b
I0420 13:58:45.921576 32892 net.cpp:406] map16_2_bn_b <- map16_2_conv_b
I0420 13:58:45.921587 32892 net.cpp:367] map16_2_bn_b -> map16_2_conv_b (in-place)
I0420 13:58:45.921753 32892 net.cpp:122] Setting up map16_2_bn_b
I0420 13:58:45.921761 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.921764 32892 net.cpp:137] Memory required for data: 194512896
I0420 13:58:45.921774 32892 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0420 13:58:45.921785 32892 net.cpp:84] Creating Layer map16_2_scale_b
I0420 13:58:45.921789 32892 net.cpp:406] map16_2_scale_b <- map16_2_conv_b
I0420 13:58:45.921793 32892 net.cpp:367] map16_2_scale_b -> map16_2_conv_b (in-place)
I0420 13:58:45.921840 32892 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0420 13:58:45.921931 32892 net.cpp:122] Setting up map16_2_scale_b
I0420 13:58:45.921938 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.921941 32892 net.cpp:137] Memory required for data: 202901504
I0420 13:58:45.921952 32892 layer_factory.hpp:77] Creating layer map16_2_eltsum
I0420 13:58:45.921957 32892 net.cpp:84] Creating Layer map16_2_eltsum
I0420 13:58:45.921962 32892 net.cpp:406] map16_2_eltsum <- map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0420 13:58:45.921965 32892 net.cpp:406] map16_2_eltsum <- map16_2_conv_b
I0420 13:58:45.921970 32892 net.cpp:380] map16_2_eltsum -> map16_2_eltsum
I0420 13:58:45.921991 32892 net.cpp:122] Setting up map16_2_eltsum
I0420 13:58:45.921998 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.921999 32892 net.cpp:137] Memory required for data: 211290112
I0420 13:58:45.922003 32892 layer_factory.hpp:77] Creating layer map16_2_relu_after_sum
I0420 13:58:45.922011 32892 net.cpp:84] Creating Layer map16_2_relu_after_sum
I0420 13:58:45.922015 32892 net.cpp:406] map16_2_relu_after_sum <- map16_2_eltsum
I0420 13:58:45.922019 32892 net.cpp:367] map16_2_relu_after_sum -> map16_2_eltsum (in-place)
I0420 13:58:45.923877 32892 net.cpp:122] Setting up map16_2_relu_after_sum
I0420 13:58:45.923885 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.923888 32892 net.cpp:137] Memory required for data: 219678720
I0420 13:58:45.923892 32892 layer_factory.hpp:77] Creating layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 13:58:45.923897 32892 net.cpp:84] Creating Layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 13:58:45.923900 32892 net.cpp:406] map16_2_eltsum_map16_2_relu_after_sum_0_split <- map16_2_eltsum
I0420 13:58:45.923904 32892 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0420 13:58:45.923913 32892 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0420 13:58:45.923946 32892 net.cpp:122] Setting up map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 13:58:45.923952 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.923956 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.923959 32892 net.cpp:137] Memory required for data: 236455936
I0420 13:58:45.923961 32892 layer_factory.hpp:77] Creating layer map16_3_conv_a
I0420 13:58:45.923969 32892 net.cpp:84] Creating Layer map16_3_conv_a
I0420 13:58:45.923972 32892 net.cpp:406] map16_3_conv_a <- map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0420 13:58:45.923977 32892 net.cpp:380] map16_3_conv_a -> map16_3_conv_a
I0420 13:58:45.931115 32892 net.cpp:122] Setting up map16_3_conv_a
I0420 13:58:45.931128 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.931130 32892 net.cpp:137] Memory required for data: 244844544
I0420 13:58:45.931143 32892 layer_factory.hpp:77] Creating layer map16_3_bn_a
I0420 13:58:45.931151 32892 net.cpp:84] Creating Layer map16_3_bn_a
I0420 13:58:45.931155 32892 net.cpp:406] map16_3_bn_a <- map16_3_conv_a
I0420 13:58:45.931160 32892 net.cpp:367] map16_3_bn_a -> map16_3_conv_a (in-place)
I0420 13:58:45.931320 32892 net.cpp:122] Setting up map16_3_bn_a
I0420 13:58:45.931327 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.931330 32892 net.cpp:137] Memory required for data: 253233152
I0420 13:58:45.931336 32892 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0420 13:58:45.931347 32892 net.cpp:84] Creating Layer map16_3_scale_a
I0420 13:58:45.931351 32892 net.cpp:406] map16_3_scale_a <- map16_3_conv_a
I0420 13:58:45.931355 32892 net.cpp:367] map16_3_scale_a -> map16_3_conv_a (in-place)
I0420 13:58:45.931390 32892 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0420 13:58:45.931486 32892 net.cpp:122] Setting up map16_3_scale_a
I0420 13:58:45.931493 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.931495 32892 net.cpp:137] Memory required for data: 261621760
I0420 13:58:45.931514 32892 layer_factory.hpp:77] Creating layer map16_3_relu_a
I0420 13:58:45.931524 32892 net.cpp:84] Creating Layer map16_3_relu_a
I0420 13:58:45.931529 32892 net.cpp:406] map16_3_relu_a <- map16_3_conv_a
I0420 13:58:45.931532 32892 net.cpp:367] map16_3_relu_a -> map16_3_conv_a (in-place)
I0420 13:58:45.933434 32892 net.cpp:122] Setting up map16_3_relu_a
I0420 13:58:45.933444 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.933446 32892 net.cpp:137] Memory required for data: 270010368
I0420 13:58:45.933449 32892 layer_factory.hpp:77] Creating layer map16_3_conv_b
I0420 13:58:45.933460 32892 net.cpp:84] Creating Layer map16_3_conv_b
I0420 13:58:45.933465 32892 net.cpp:406] map16_3_conv_b <- map16_3_conv_a
I0420 13:58:45.933470 32892 net.cpp:380] map16_3_conv_b -> map16_3_conv_b
I0420 13:58:45.940788 32892 net.cpp:122] Setting up map16_3_conv_b
I0420 13:58:45.940799 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.940804 32892 net.cpp:137] Memory required for data: 278398976
I0420 13:58:45.940815 32892 layer_factory.hpp:77] Creating layer map16_3_bn_b
I0420 13:58:45.940826 32892 net.cpp:84] Creating Layer map16_3_bn_b
I0420 13:58:45.940831 32892 net.cpp:406] map16_3_bn_b <- map16_3_conv_b
I0420 13:58:45.940840 32892 net.cpp:367] map16_3_bn_b -> map16_3_conv_b (in-place)
I0420 13:58:45.941015 32892 net.cpp:122] Setting up map16_3_bn_b
I0420 13:58:45.941022 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.941025 32892 net.cpp:137] Memory required for data: 286787584
I0420 13:58:45.941030 32892 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0420 13:58:45.941043 32892 net.cpp:84] Creating Layer map16_3_scale_b
I0420 13:58:45.941047 32892 net.cpp:406] map16_3_scale_b <- map16_3_conv_b
I0420 13:58:45.941051 32892 net.cpp:367] map16_3_scale_b -> map16_3_conv_b (in-place)
I0420 13:58:45.941083 32892 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0420 13:58:45.941184 32892 net.cpp:122] Setting up map16_3_scale_b
I0420 13:58:45.941192 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.941195 32892 net.cpp:137] Memory required for data: 295176192
I0420 13:58:45.941200 32892 layer_factory.hpp:77] Creating layer map16_3_eltsum
I0420 13:58:45.941205 32892 net.cpp:84] Creating Layer map16_3_eltsum
I0420 13:58:45.941210 32892 net.cpp:406] map16_3_eltsum <- map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0420 13:58:45.941213 32892 net.cpp:406] map16_3_eltsum <- map16_3_conv_b
I0420 13:58:45.941218 32892 net.cpp:380] map16_3_eltsum -> map16_3_eltsum
I0420 13:58:45.941243 32892 net.cpp:122] Setting up map16_3_eltsum
I0420 13:58:45.941248 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.941251 32892 net.cpp:137] Memory required for data: 303564800
I0420 13:58:45.941254 32892 layer_factory.hpp:77] Creating layer map16_3_relu_after_sum
I0420 13:58:45.941270 32892 net.cpp:84] Creating Layer map16_3_relu_after_sum
I0420 13:58:45.941274 32892 net.cpp:406] map16_3_relu_after_sum <- map16_3_eltsum
I0420 13:58:45.941279 32892 net.cpp:367] map16_3_relu_after_sum -> map16_3_eltsum (in-place)
I0420 13:58:45.943141 32892 net.cpp:122] Setting up map16_3_relu_after_sum
I0420 13:58:45.943150 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.943153 32892 net.cpp:137] Memory required for data: 311953408
I0420 13:58:45.943156 32892 layer_factory.hpp:77] Creating layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 13:58:45.943162 32892 net.cpp:84] Creating Layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 13:58:45.943166 32892 net.cpp:406] map16_3_eltsum_map16_3_relu_after_sum_0_split <- map16_3_eltsum
I0420 13:58:45.943172 32892 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0420 13:58:45.943178 32892 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0420 13:58:45.943217 32892 net.cpp:122] Setting up map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 13:58:45.943236 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.943241 32892 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 13:58:45.943244 32892 net.cpp:137] Memory required for data: 328730624
I0420 13:58:45.943248 32892 layer_factory.hpp:77] Creating layer map32_1_conv_proj
I0420 13:58:45.943256 32892 net.cpp:84] Creating Layer map32_1_conv_proj
I0420 13:58:45.943261 32892 net.cpp:406] map32_1_conv_proj <- map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0420 13:58:45.943269 32892 net.cpp:380] map32_1_conv_proj -> map32_1_conv_proj
I0420 13:58:45.950655 32892 net.cpp:122] Setting up map32_1_conv_proj
I0420 13:58:45.950669 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.950671 32892 net.cpp:137] Memory required for data: 332924928
I0420 13:58:45.950678 32892 layer_factory.hpp:77] Creating layer map32_1_bn_proj
I0420 13:58:45.950691 32892 net.cpp:84] Creating Layer map32_1_bn_proj
I0420 13:58:45.950696 32892 net.cpp:406] map32_1_bn_proj <- map32_1_conv_proj
I0420 13:58:45.950701 32892 net.cpp:367] map32_1_bn_proj -> map32_1_conv_proj (in-place)
I0420 13:58:45.950873 32892 net.cpp:122] Setting up map32_1_bn_proj
I0420 13:58:45.950881 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.950883 32892 net.cpp:137] Memory required for data: 337119232
I0420 13:58:45.950897 32892 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0420 13:58:45.950909 32892 net.cpp:84] Creating Layer map32_1_scale_proj
I0420 13:58:45.950913 32892 net.cpp:406] map32_1_scale_proj <- map32_1_conv_proj
I0420 13:58:45.950917 32892 net.cpp:367] map32_1_scale_proj -> map32_1_conv_proj (in-place)
I0420 13:58:45.950951 32892 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0420 13:58:45.951056 32892 net.cpp:122] Setting up map32_1_scale_proj
I0420 13:58:45.951062 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.951066 32892 net.cpp:137] Memory required for data: 341313536
I0420 13:58:45.951071 32892 layer_factory.hpp:77] Creating layer map32_1_conv_a
I0420 13:58:45.951079 32892 net.cpp:84] Creating Layer map32_1_conv_a
I0420 13:58:45.951086 32892 net.cpp:406] map32_1_conv_a <- map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0420 13:58:45.951092 32892 net.cpp:380] map32_1_conv_a -> map32_1_conv_a
I0420 13:58:45.957569 32892 net.cpp:122] Setting up map32_1_conv_a
I0420 13:58:45.957582 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.957586 32892 net.cpp:137] Memory required for data: 345507840
I0420 13:58:45.957592 32892 layer_factory.hpp:77] Creating layer map32_1_bn_a
I0420 13:58:45.957607 32892 net.cpp:84] Creating Layer map32_1_bn_a
I0420 13:58:45.957612 32892 net.cpp:406] map32_1_bn_a <- map32_1_conv_a
I0420 13:58:45.957618 32892 net.cpp:367] map32_1_bn_a -> map32_1_conv_a (in-place)
I0420 13:58:45.957795 32892 net.cpp:122] Setting up map32_1_bn_a
I0420 13:58:45.957803 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.957806 32892 net.cpp:137] Memory required for data: 349702144
I0420 13:58:45.957813 32892 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0420 13:58:45.957818 32892 net.cpp:84] Creating Layer map32_1_scale_a
I0420 13:58:45.957823 32892 net.cpp:406] map32_1_scale_a <- map32_1_conv_a
I0420 13:58:45.957828 32892 net.cpp:367] map32_1_scale_a -> map32_1_conv_a (in-place)
I0420 13:58:45.957860 32892 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0420 13:58:45.957962 32892 net.cpp:122] Setting up map32_1_scale_a
I0420 13:58:45.957969 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.957973 32892 net.cpp:137] Memory required for data: 353896448
I0420 13:58:45.957983 32892 layer_factory.hpp:77] Creating layer map32_1_relu_a
I0420 13:58:45.957993 32892 net.cpp:84] Creating Layer map32_1_relu_a
I0420 13:58:45.957998 32892 net.cpp:406] map32_1_relu_a <- map32_1_conv_a
I0420 13:58:45.958001 32892 net.cpp:367] map32_1_relu_a -> map32_1_conv_a (in-place)
I0420 13:58:45.959913 32892 net.cpp:122] Setting up map32_1_relu_a
I0420 13:58:45.959923 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.959940 32892 net.cpp:137] Memory required for data: 358090752
I0420 13:58:45.959945 32892 layer_factory.hpp:77] Creating layer map32_1_conv_b
I0420 13:58:45.959954 32892 net.cpp:84] Creating Layer map32_1_conv_b
I0420 13:58:45.959957 32892 net.cpp:406] map32_1_conv_b <- map32_1_conv_a
I0420 13:58:45.959966 32892 net.cpp:380] map32_1_conv_b -> map32_1_conv_b
I0420 13:58:45.967329 32892 net.cpp:122] Setting up map32_1_conv_b
I0420 13:58:45.967341 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.967344 32892 net.cpp:137] Memory required for data: 362285056
I0420 13:58:45.967360 32892 layer_factory.hpp:77] Creating layer map32_1_bn_b
I0420 13:58:45.967370 32892 net.cpp:84] Creating Layer map32_1_bn_b
I0420 13:58:45.967375 32892 net.cpp:406] map32_1_bn_b <- map32_1_conv_b
I0420 13:58:45.967381 32892 net.cpp:367] map32_1_bn_b -> map32_1_conv_b (in-place)
I0420 13:58:45.967547 32892 net.cpp:122] Setting up map32_1_bn_b
I0420 13:58:45.967555 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.967557 32892 net.cpp:137] Memory required for data: 366479360
I0420 13:58:45.967571 32892 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0420 13:58:45.967583 32892 net.cpp:84] Creating Layer map32_1_scale_b
I0420 13:58:45.967587 32892 net.cpp:406] map32_1_scale_b <- map32_1_conv_b
I0420 13:58:45.967592 32892 net.cpp:367] map32_1_scale_b -> map32_1_conv_b (in-place)
I0420 13:58:45.967627 32892 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0420 13:58:45.967730 32892 net.cpp:122] Setting up map32_1_scale_b
I0420 13:58:45.967737 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.967741 32892 net.cpp:137] Memory required for data: 370673664
I0420 13:58:45.967746 32892 layer_factory.hpp:77] Creating layer map32_1_eltsum
I0420 13:58:45.967751 32892 net.cpp:84] Creating Layer map32_1_eltsum
I0420 13:58:45.967756 32892 net.cpp:406] map32_1_eltsum <- map32_1_conv_proj
I0420 13:58:45.967761 32892 net.cpp:406] map32_1_eltsum <- map32_1_conv_b
I0420 13:58:45.967767 32892 net.cpp:380] map32_1_eltsum -> map32_1_eltsum
I0420 13:58:45.967784 32892 net.cpp:122] Setting up map32_1_eltsum
I0420 13:58:45.967792 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.967794 32892 net.cpp:137] Memory required for data: 374867968
I0420 13:58:45.967797 32892 layer_factory.hpp:77] Creating layer map32_1_relu_after_sum
I0420 13:58:45.967806 32892 net.cpp:84] Creating Layer map32_1_relu_after_sum
I0420 13:58:45.967810 32892 net.cpp:406] map32_1_relu_after_sum <- map32_1_eltsum
I0420 13:58:45.967813 32892 net.cpp:367] map32_1_relu_after_sum -> map32_1_eltsum (in-place)
I0420 13:58:45.969573 32892 net.cpp:122] Setting up map32_1_relu_after_sum
I0420 13:58:45.969586 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.969589 32892 net.cpp:137] Memory required for data: 379062272
I0420 13:58:45.969594 32892 layer_factory.hpp:77] Creating layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 13:58:45.969599 32892 net.cpp:84] Creating Layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 13:58:45.969604 32892 net.cpp:406] map32_1_eltsum_map32_1_relu_after_sum_0_split <- map32_1_eltsum
I0420 13:58:45.969607 32892 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0420 13:58:45.969616 32892 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0420 13:58:45.969656 32892 net.cpp:122] Setting up map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 13:58:45.969662 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.969666 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.969668 32892 net.cpp:137] Memory required for data: 387450880
I0420 13:58:45.969678 32892 layer_factory.hpp:77] Creating layer map32_2_conv_a
I0420 13:58:45.969692 32892 net.cpp:84] Creating Layer map32_2_conv_a
I0420 13:58:45.969697 32892 net.cpp:406] map32_2_conv_a <- map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0420 13:58:45.969717 32892 net.cpp:380] map32_2_conv_a -> map32_2_conv_a
I0420 13:58:45.976807 32892 net.cpp:122] Setting up map32_2_conv_a
I0420 13:58:45.976817 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.976821 32892 net.cpp:137] Memory required for data: 391645184
I0420 13:58:45.976827 32892 layer_factory.hpp:77] Creating layer map32_2_bn_a
I0420 13:58:45.976836 32892 net.cpp:84] Creating Layer map32_2_bn_a
I0420 13:58:45.976840 32892 net.cpp:406] map32_2_bn_a <- map32_2_conv_a
I0420 13:58:45.976846 32892 net.cpp:367] map32_2_bn_a -> map32_2_conv_a (in-place)
I0420 13:58:45.977012 32892 net.cpp:122] Setting up map32_2_bn_a
I0420 13:58:45.977020 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.977022 32892 net.cpp:137] Memory required for data: 395839488
I0420 13:58:45.977028 32892 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0420 13:58:45.977042 32892 net.cpp:84] Creating Layer map32_2_scale_a
I0420 13:58:45.977046 32892 net.cpp:406] map32_2_scale_a <- map32_2_conv_a
I0420 13:58:45.977051 32892 net.cpp:367] map32_2_scale_a -> map32_2_conv_a (in-place)
I0420 13:58:45.977083 32892 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0420 13:58:45.977183 32892 net.cpp:122] Setting up map32_2_scale_a
I0420 13:58:45.977191 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.977195 32892 net.cpp:137] Memory required for data: 400033792
I0420 13:58:45.977200 32892 layer_factory.hpp:77] Creating layer map32_2_relu_a
I0420 13:58:45.977205 32892 net.cpp:84] Creating Layer map32_2_relu_a
I0420 13:58:45.977207 32892 net.cpp:406] map32_2_relu_a <- map32_2_conv_a
I0420 13:58:45.977210 32892 net.cpp:367] map32_2_relu_a -> map32_2_conv_a (in-place)
I0420 13:58:45.979066 32892 net.cpp:122] Setting up map32_2_relu_a
I0420 13:58:45.979079 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.979082 32892 net.cpp:137] Memory required for data: 404228096
I0420 13:58:45.979091 32892 layer_factory.hpp:77] Creating layer map32_2_conv_b
I0420 13:58:45.979106 32892 net.cpp:84] Creating Layer map32_2_conv_b
I0420 13:58:45.979110 32892 net.cpp:406] map32_2_conv_b <- map32_2_conv_a
I0420 13:58:45.979117 32892 net.cpp:380] map32_2_conv_b -> map32_2_conv_b
I0420 13:58:45.986179 32892 net.cpp:122] Setting up map32_2_conv_b
I0420 13:58:45.986192 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.986196 32892 net.cpp:137] Memory required for data: 408422400
I0420 13:58:45.986202 32892 layer_factory.hpp:77] Creating layer map32_2_bn_b
I0420 13:58:45.986210 32892 net.cpp:84] Creating Layer map32_2_bn_b
I0420 13:58:45.986215 32892 net.cpp:406] map32_2_bn_b <- map32_2_conv_b
I0420 13:58:45.986222 32892 net.cpp:367] map32_2_bn_b -> map32_2_conv_b (in-place)
I0420 13:58:45.986394 32892 net.cpp:122] Setting up map32_2_bn_b
I0420 13:58:45.986402 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.986404 32892 net.cpp:137] Memory required for data: 412616704
I0420 13:58:45.986412 32892 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0420 13:58:45.986423 32892 net.cpp:84] Creating Layer map32_2_scale_b
I0420 13:58:45.986428 32892 net.cpp:406] map32_2_scale_b <- map32_2_conv_b
I0420 13:58:45.986433 32892 net.cpp:367] map32_2_scale_b -> map32_2_conv_b (in-place)
I0420 13:58:45.986466 32892 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0420 13:58:45.986565 32892 net.cpp:122] Setting up map32_2_scale_b
I0420 13:58:45.986573 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.986577 32892 net.cpp:137] Memory required for data: 416811008
I0420 13:58:45.986582 32892 layer_factory.hpp:77] Creating layer map32_2_eltsum
I0420 13:58:45.986594 32892 net.cpp:84] Creating Layer map32_2_eltsum
I0420 13:58:45.986598 32892 net.cpp:406] map32_2_eltsum <- map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0420 13:58:45.986603 32892 net.cpp:406] map32_2_eltsum <- map32_2_conv_b
I0420 13:58:45.986608 32892 net.cpp:380] map32_2_eltsum -> map32_2_eltsum
I0420 13:58:45.986627 32892 net.cpp:122] Setting up map32_2_eltsum
I0420 13:58:45.986634 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.986649 32892 net.cpp:137] Memory required for data: 421005312
I0420 13:58:45.986656 32892 layer_factory.hpp:77] Creating layer map32_2_relu_after_sum
I0420 13:58:45.986668 32892 net.cpp:84] Creating Layer map32_2_relu_after_sum
I0420 13:58:45.986672 32892 net.cpp:406] map32_2_relu_after_sum <- map32_2_eltsum
I0420 13:58:45.986678 32892 net.cpp:367] map32_2_relu_after_sum -> map32_2_eltsum (in-place)
I0420 13:58:45.988505 32892 net.cpp:122] Setting up map32_2_relu_after_sum
I0420 13:58:45.988514 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.988517 32892 net.cpp:137] Memory required for data: 425199616
I0420 13:58:45.988520 32892 layer_factory.hpp:77] Creating layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 13:58:45.988526 32892 net.cpp:84] Creating Layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 13:58:45.988530 32892 net.cpp:406] map32_2_eltsum_map32_2_relu_after_sum_0_split <- map32_2_eltsum
I0420 13:58:45.988536 32892 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0420 13:58:45.988545 32892 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0420 13:58:45.988584 32892 net.cpp:122] Setting up map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 13:58:45.988590 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.988595 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.988596 32892 net.cpp:137] Memory required for data: 433588224
I0420 13:58:45.988600 32892 layer_factory.hpp:77] Creating layer map32_3_conv_a
I0420 13:58:45.988608 32892 net.cpp:84] Creating Layer map32_3_conv_a
I0420 13:58:45.988612 32892 net.cpp:406] map32_3_conv_a <- map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0420 13:58:45.988618 32892 net.cpp:380] map32_3_conv_a -> map32_3_conv_a
I0420 13:58:45.995784 32892 net.cpp:122] Setting up map32_3_conv_a
I0420 13:58:45.995795 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.995800 32892 net.cpp:137] Memory required for data: 437782528
I0420 13:58:45.995805 32892 layer_factory.hpp:77] Creating layer map32_3_bn_a
I0420 13:58:45.995820 32892 net.cpp:84] Creating Layer map32_3_bn_a
I0420 13:58:45.995826 32892 net.cpp:406] map32_3_bn_a <- map32_3_conv_a
I0420 13:58:45.995831 32892 net.cpp:367] map32_3_bn_a -> map32_3_conv_a (in-place)
I0420 13:58:45.996002 32892 net.cpp:122] Setting up map32_3_bn_a
I0420 13:58:45.996008 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.996012 32892 net.cpp:137] Memory required for data: 441976832
I0420 13:58:45.996018 32892 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0420 13:58:45.996031 32892 net.cpp:84] Creating Layer map32_3_scale_a
I0420 13:58:45.996034 32892 net.cpp:406] map32_3_scale_a <- map32_3_conv_a
I0420 13:58:45.996042 32892 net.cpp:367] map32_3_scale_a -> map32_3_conv_a (in-place)
I0420 13:58:45.996073 32892 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0420 13:58:45.996172 32892 net.cpp:122] Setting up map32_3_scale_a
I0420 13:58:45.996179 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.996182 32892 net.cpp:137] Memory required for data: 446171136
I0420 13:58:45.996187 32892 layer_factory.hpp:77] Creating layer map32_3_relu_a
I0420 13:58:45.996194 32892 net.cpp:84] Creating Layer map32_3_relu_a
I0420 13:58:45.996198 32892 net.cpp:406] map32_3_relu_a <- map32_3_conv_a
I0420 13:58:45.996201 32892 net.cpp:367] map32_3_relu_a -> map32_3_conv_a (in-place)
I0420 13:58:45.998083 32892 net.cpp:122] Setting up map32_3_relu_a
I0420 13:58:45.998092 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:45.998095 32892 net.cpp:137] Memory required for data: 450365440
I0420 13:58:45.998098 32892 layer_factory.hpp:77] Creating layer map32_3_conv_b
I0420 13:58:45.998122 32892 net.cpp:84] Creating Layer map32_3_conv_b
I0420 13:58:45.998126 32892 net.cpp:406] map32_3_conv_b <- map32_3_conv_a
I0420 13:58:45.998132 32892 net.cpp:380] map32_3_conv_b -> map32_3_conv_b
I0420 13:58:46.005329 32892 net.cpp:122] Setting up map32_3_conv_b
I0420 13:58:46.005343 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:46.005347 32892 net.cpp:137] Memory required for data: 454559744
I0420 13:58:46.005359 32892 layer_factory.hpp:77] Creating layer map32_3_bn_b
I0420 13:58:46.005367 32892 net.cpp:84] Creating Layer map32_3_bn_b
I0420 13:58:46.005372 32892 net.cpp:406] map32_3_bn_b <- map32_3_conv_b
I0420 13:58:46.005379 32892 net.cpp:367] map32_3_bn_b -> map32_3_conv_b (in-place)
I0420 13:58:46.005551 32892 net.cpp:122] Setting up map32_3_bn_b
I0420 13:58:46.005558 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:46.005561 32892 net.cpp:137] Memory required for data: 458754048
I0420 13:58:46.005568 32892 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0420 13:58:46.005578 32892 net.cpp:84] Creating Layer map32_3_scale_b
I0420 13:58:46.005583 32892 net.cpp:406] map32_3_scale_b <- map32_3_conv_b
I0420 13:58:46.005586 32892 net.cpp:367] map32_3_scale_b -> map32_3_conv_b (in-place)
I0420 13:58:46.005620 32892 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0420 13:58:46.005735 32892 net.cpp:122] Setting up map32_3_scale_b
I0420 13:58:46.005743 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:46.005746 32892 net.cpp:137] Memory required for data: 462948352
I0420 13:58:46.005751 32892 layer_factory.hpp:77] Creating layer map32_3_eltsum
I0420 13:58:46.005756 32892 net.cpp:84] Creating Layer map32_3_eltsum
I0420 13:58:46.005760 32892 net.cpp:406] map32_3_eltsum <- map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0420 13:58:46.005764 32892 net.cpp:406] map32_3_eltsum <- map32_3_conv_b
I0420 13:58:46.005771 32892 net.cpp:380] map32_3_eltsum -> map32_3_eltsum
I0420 13:58:46.005789 32892 net.cpp:122] Setting up map32_3_eltsum
I0420 13:58:46.005795 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:46.005798 32892 net.cpp:137] Memory required for data: 467142656
I0420 13:58:46.005800 32892 layer_factory.hpp:77] Creating layer map32_3_relu_after_sum
I0420 13:58:46.005812 32892 net.cpp:84] Creating Layer map32_3_relu_after_sum
I0420 13:58:46.005815 32892 net.cpp:406] map32_3_relu_after_sum <- map32_3_eltsum
I0420 13:58:46.005821 32892 net.cpp:367] map32_3_relu_after_sum -> map32_3_eltsum (in-place)
I0420 13:58:46.007657 32892 net.cpp:122] Setting up map32_3_relu_after_sum
I0420 13:58:46.007664 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:46.007668 32892 net.cpp:137] Memory required for data: 471336960
I0420 13:58:46.007671 32892 layer_factory.hpp:77] Creating layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 13:58:46.007676 32892 net.cpp:84] Creating Layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 13:58:46.007684 32892 net.cpp:406] map32_3_eltsum_map32_3_relu_after_sum_0_split <- map32_3_eltsum
I0420 13:58:46.007690 32892 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0420 13:58:46.007697 32892 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0420 13:58:46.007737 32892 net.cpp:122] Setting up map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 13:58:46.007743 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:46.007747 32892 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 13:58:46.007750 32892 net.cpp:137] Memory required for data: 479725568
I0420 13:58:46.007753 32892 layer_factory.hpp:77] Creating layer map64_1_conv_proj
I0420 13:58:46.007766 32892 net.cpp:84] Creating Layer map64_1_conv_proj
I0420 13:58:46.007771 32892 net.cpp:406] map64_1_conv_proj <- map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0420 13:58:46.007778 32892 net.cpp:380] map64_1_conv_proj -> map64_1_conv_proj
I0420 13:58:46.014844 32892 net.cpp:122] Setting up map64_1_conv_proj
I0420 13:58:46.014859 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.014863 32892 net.cpp:137] Memory required for data: 481822720
I0420 13:58:46.014869 32892 layer_factory.hpp:77] Creating layer map64_1_bn_proj
I0420 13:58:46.014889 32892 net.cpp:84] Creating Layer map64_1_bn_proj
I0420 13:58:46.014894 32892 net.cpp:406] map64_1_bn_proj <- map64_1_conv_proj
I0420 13:58:46.014900 32892 net.cpp:367] map64_1_bn_proj -> map64_1_conv_proj (in-place)
I0420 13:58:46.015076 32892 net.cpp:122] Setting up map64_1_bn_proj
I0420 13:58:46.015082 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.015086 32892 net.cpp:137] Memory required for data: 483919872
I0420 13:58:46.015110 32892 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0420 13:58:46.015120 32892 net.cpp:84] Creating Layer map64_1_scale_proj
I0420 13:58:46.015123 32892 net.cpp:406] map64_1_scale_proj <- map64_1_conv_proj
I0420 13:58:46.015127 32892 net.cpp:367] map64_1_scale_proj -> map64_1_conv_proj (in-place)
I0420 13:58:46.015163 32892 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0420 13:58:46.015265 32892 net.cpp:122] Setting up map64_1_scale_proj
I0420 13:58:46.015272 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.015275 32892 net.cpp:137] Memory required for data: 486017024
I0420 13:58:46.015280 32892 layer_factory.hpp:77] Creating layer map64_1_conv_a
I0420 13:58:46.015291 32892 net.cpp:84] Creating Layer map64_1_conv_a
I0420 13:58:46.015296 32892 net.cpp:406] map64_1_conv_a <- map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0420 13:58:46.015301 32892 net.cpp:380] map64_1_conv_a -> map64_1_conv_a
I0420 13:58:46.021963 32892 net.cpp:122] Setting up map64_1_conv_a
I0420 13:58:46.021977 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.021981 32892 net.cpp:137] Memory required for data: 488114176
I0420 13:58:46.021987 32892 layer_factory.hpp:77] Creating layer map64_1_bn_a
I0420 13:58:46.022001 32892 net.cpp:84] Creating Layer map64_1_bn_a
I0420 13:58:46.022007 32892 net.cpp:406] map64_1_bn_a <- map64_1_conv_a
I0420 13:58:46.022013 32892 net.cpp:367] map64_1_bn_a -> map64_1_conv_a (in-place)
I0420 13:58:46.022198 32892 net.cpp:122] Setting up map64_1_bn_a
I0420 13:58:46.022205 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.022208 32892 net.cpp:137] Memory required for data: 490211328
I0420 13:58:46.022214 32892 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0420 13:58:46.022229 32892 net.cpp:84] Creating Layer map64_1_scale_a
I0420 13:58:46.022233 32892 net.cpp:406] map64_1_scale_a <- map64_1_conv_a
I0420 13:58:46.022238 32892 net.cpp:367] map64_1_scale_a -> map64_1_conv_a (in-place)
I0420 13:58:46.022274 32892 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0420 13:58:46.022380 32892 net.cpp:122] Setting up map64_1_scale_a
I0420 13:58:46.022387 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.022390 32892 net.cpp:137] Memory required for data: 492308480
I0420 13:58:46.022395 32892 layer_factory.hpp:77] Creating layer map64_1_relu_a
I0420 13:58:46.022403 32892 net.cpp:84] Creating Layer map64_1_relu_a
I0420 13:58:46.022406 32892 net.cpp:406] map64_1_relu_a <- map64_1_conv_a
I0420 13:58:46.022409 32892 net.cpp:367] map64_1_relu_a -> map64_1_conv_a (in-place)
I0420 13:58:46.024299 32892 net.cpp:122] Setting up map64_1_relu_a
I0420 13:58:46.024309 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.024312 32892 net.cpp:137] Memory required for data: 494405632
I0420 13:58:46.024315 32892 layer_factory.hpp:77] Creating layer map64_1_conv_b
I0420 13:58:46.024330 32892 net.cpp:84] Creating Layer map64_1_conv_b
I0420 13:58:46.024335 32892 net.cpp:406] map64_1_conv_b <- map64_1_conv_a
I0420 13:58:46.024340 32892 net.cpp:380] map64_1_conv_b -> map64_1_conv_b
I0420 13:58:46.031993 32892 net.cpp:122] Setting up map64_1_conv_b
I0420 13:58:46.032006 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.032009 32892 net.cpp:137] Memory required for data: 496502784
I0420 13:58:46.032016 32892 layer_factory.hpp:77] Creating layer map64_1_bn_b
I0420 13:58:46.032025 32892 net.cpp:84] Creating Layer map64_1_bn_b
I0420 13:58:46.032029 32892 net.cpp:406] map64_1_bn_b <- map64_1_conv_b
I0420 13:58:46.032042 32892 net.cpp:367] map64_1_bn_b -> map64_1_conv_b (in-place)
I0420 13:58:46.032234 32892 net.cpp:122] Setting up map64_1_bn_b
I0420 13:58:46.032243 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.032245 32892 net.cpp:137] Memory required for data: 498599936
I0420 13:58:46.032253 32892 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0420 13:58:46.032270 32892 net.cpp:84] Creating Layer map64_1_scale_b
I0420 13:58:46.032274 32892 net.cpp:406] map64_1_scale_b <- map64_1_conv_b
I0420 13:58:46.032280 32892 net.cpp:367] map64_1_scale_b -> map64_1_conv_b (in-place)
I0420 13:58:46.032317 32892 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0420 13:58:46.032421 32892 net.cpp:122] Setting up map64_1_scale_b
I0420 13:58:46.032428 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.032431 32892 net.cpp:137] Memory required for data: 500697088
I0420 13:58:46.032438 32892 layer_factory.hpp:77] Creating layer map64_1_eltsum
I0420 13:58:46.032444 32892 net.cpp:84] Creating Layer map64_1_eltsum
I0420 13:58:46.032449 32892 net.cpp:406] map64_1_eltsum <- map64_1_conv_proj
I0420 13:58:46.032451 32892 net.cpp:406] map64_1_eltsum <- map64_1_conv_b
I0420 13:58:46.032456 32892 net.cpp:380] map64_1_eltsum -> map64_1_eltsum
I0420 13:58:46.032476 32892 net.cpp:122] Setting up map64_1_eltsum
I0420 13:58:46.032481 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.032485 32892 net.cpp:137] Memory required for data: 502794240
I0420 13:58:46.032487 32892 layer_factory.hpp:77] Creating layer map64_1_relu_after_sum
I0420 13:58:46.032491 32892 net.cpp:84] Creating Layer map64_1_relu_after_sum
I0420 13:58:46.032495 32892 net.cpp:406] map64_1_relu_after_sum <- map64_1_eltsum
I0420 13:58:46.032498 32892 net.cpp:367] map64_1_relu_after_sum -> map64_1_eltsum (in-place)
I0420 13:58:46.034059 32892 net.cpp:122] Setting up map64_1_relu_after_sum
I0420 13:58:46.034067 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.034070 32892 net.cpp:137] Memory required for data: 504891392
I0420 13:58:46.034073 32892 layer_factory.hpp:77] Creating layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 13:58:46.034080 32892 net.cpp:84] Creating Layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 13:58:46.034083 32892 net.cpp:406] map64_1_eltsum_map64_1_relu_after_sum_0_split <- map64_1_eltsum
I0420 13:58:46.034090 32892 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0420 13:58:46.034096 32892 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0420 13:58:46.034137 32892 net.cpp:122] Setting up map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 13:58:46.034143 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.034147 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.034150 32892 net.cpp:137] Memory required for data: 509085696
I0420 13:58:46.034153 32892 layer_factory.hpp:77] Creating layer map64_2_conv_a
I0420 13:58:46.034173 32892 net.cpp:84] Creating Layer map64_2_conv_a
I0420 13:58:46.034176 32892 net.cpp:406] map64_2_conv_a <- map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0420 13:58:46.034183 32892 net.cpp:380] map64_2_conv_a -> map64_2_conv_a
I0420 13:58:46.041409 32892 net.cpp:122] Setting up map64_2_conv_a
I0420 13:58:46.041424 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.041427 32892 net.cpp:137] Memory required for data: 511182848
I0420 13:58:46.041434 32892 layer_factory.hpp:77] Creating layer map64_2_bn_a
I0420 13:58:46.041441 32892 net.cpp:84] Creating Layer map64_2_bn_a
I0420 13:58:46.041447 32892 net.cpp:406] map64_2_bn_a <- map64_2_conv_a
I0420 13:58:46.041453 32892 net.cpp:367] map64_2_bn_a -> map64_2_conv_a (in-place)
I0420 13:58:46.041633 32892 net.cpp:122] Setting up map64_2_bn_a
I0420 13:58:46.041640 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.041643 32892 net.cpp:137] Memory required for data: 513280000
I0420 13:58:46.041649 32892 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0420 13:58:46.041661 32892 net.cpp:84] Creating Layer map64_2_scale_a
I0420 13:58:46.041678 32892 net.cpp:406] map64_2_scale_a <- map64_2_conv_a
I0420 13:58:46.041689 32892 net.cpp:367] map64_2_scale_a -> map64_2_conv_a (in-place)
I0420 13:58:46.041728 32892 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0420 13:58:46.041836 32892 net.cpp:122] Setting up map64_2_scale_a
I0420 13:58:46.041842 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.041846 32892 net.cpp:137] Memory required for data: 515377152
I0420 13:58:46.041851 32892 layer_factory.hpp:77] Creating layer map64_2_relu_a
I0420 13:58:46.041857 32892 net.cpp:84] Creating Layer map64_2_relu_a
I0420 13:58:46.041862 32892 net.cpp:406] map64_2_relu_a <- map64_2_conv_a
I0420 13:58:46.041865 32892 net.cpp:367] map64_2_relu_a -> map64_2_conv_a (in-place)
I0420 13:58:46.043725 32892 net.cpp:122] Setting up map64_2_relu_a
I0420 13:58:46.043736 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.043740 32892 net.cpp:137] Memory required for data: 517474304
I0420 13:58:46.043750 32892 layer_factory.hpp:77] Creating layer map64_2_conv_b
I0420 13:58:46.043761 32892 net.cpp:84] Creating Layer map64_2_conv_b
I0420 13:58:46.043766 32892 net.cpp:406] map64_2_conv_b <- map64_2_conv_a
I0420 13:58:46.043772 32892 net.cpp:380] map64_2_conv_b -> map64_2_conv_b
I0420 13:58:46.051247 32892 net.cpp:122] Setting up map64_2_conv_b
I0420 13:58:46.051259 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.051264 32892 net.cpp:137] Memory required for data: 519571456
I0420 13:58:46.051270 32892 layer_factory.hpp:77] Creating layer map64_2_bn_b
I0420 13:58:46.051285 32892 net.cpp:84] Creating Layer map64_2_bn_b
I0420 13:58:46.051290 32892 net.cpp:406] map64_2_bn_b <- map64_2_conv_b
I0420 13:58:46.051296 32892 net.cpp:367] map64_2_bn_b -> map64_2_conv_b (in-place)
I0420 13:58:46.051484 32892 net.cpp:122] Setting up map64_2_bn_b
I0420 13:58:46.051492 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.051496 32892 net.cpp:137] Memory required for data: 521668608
I0420 13:58:46.051517 32892 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0420 13:58:46.051528 32892 net.cpp:84] Creating Layer map64_2_scale_b
I0420 13:58:46.051533 32892 net.cpp:406] map64_2_scale_b <- map64_2_conv_b
I0420 13:58:46.051537 32892 net.cpp:367] map64_2_scale_b -> map64_2_conv_b (in-place)
I0420 13:58:46.051575 32892 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0420 13:58:46.051688 32892 net.cpp:122] Setting up map64_2_scale_b
I0420 13:58:46.051695 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.051698 32892 net.cpp:137] Memory required for data: 523765760
I0420 13:58:46.051703 32892 layer_factory.hpp:77] Creating layer map64_2_eltsum
I0420 13:58:46.051709 32892 net.cpp:84] Creating Layer map64_2_eltsum
I0420 13:58:46.051714 32892 net.cpp:406] map64_2_eltsum <- map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0420 13:58:46.051718 32892 net.cpp:406] map64_2_eltsum <- map64_2_conv_b
I0420 13:58:46.051723 32892 net.cpp:380] map64_2_eltsum -> map64_2_eltsum
I0420 13:58:46.051743 32892 net.cpp:122] Setting up map64_2_eltsum
I0420 13:58:46.051748 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.051750 32892 net.cpp:137] Memory required for data: 525862912
I0420 13:58:46.051759 32892 layer_factory.hpp:77] Creating layer map64_2_relu_after_sum
I0420 13:58:46.051764 32892 net.cpp:84] Creating Layer map64_2_relu_after_sum
I0420 13:58:46.051767 32892 net.cpp:406] map64_2_relu_after_sum <- map64_2_eltsum
I0420 13:58:46.051770 32892 net.cpp:367] map64_2_relu_after_sum -> map64_2_eltsum (in-place)
I0420 13:58:46.053313 32892 net.cpp:122] Setting up map64_2_relu_after_sum
I0420 13:58:46.053323 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.053326 32892 net.cpp:137] Memory required for data: 527960064
I0420 13:58:46.053328 32892 layer_factory.hpp:77] Creating layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 13:58:46.053334 32892 net.cpp:84] Creating Layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 13:58:46.053339 32892 net.cpp:406] map64_2_eltsum_map64_2_relu_after_sum_0_split <- map64_2_eltsum
I0420 13:58:46.053357 32892 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0420 13:58:46.053364 32892 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0420 13:58:46.053408 32892 net.cpp:122] Setting up map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 13:58:46.053414 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.053418 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.053421 32892 net.cpp:137] Memory required for data: 532154368
I0420 13:58:46.053424 32892 layer_factory.hpp:77] Creating layer map64_3_conv_a
I0420 13:58:46.053434 32892 net.cpp:84] Creating Layer map64_3_conv_a
I0420 13:58:46.053438 32892 net.cpp:406] map64_3_conv_a <- map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0420 13:58:46.053444 32892 net.cpp:380] map64_3_conv_a -> map64_3_conv_a
I0420 13:58:46.060766 32892 net.cpp:122] Setting up map64_3_conv_a
I0420 13:58:46.060780 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.060783 32892 net.cpp:137] Memory required for data: 534251520
I0420 13:58:46.060789 32892 layer_factory.hpp:77] Creating layer map64_3_bn_a
I0420 13:58:46.060806 32892 net.cpp:84] Creating Layer map64_3_bn_a
I0420 13:58:46.060811 32892 net.cpp:406] map64_3_bn_a <- map64_3_conv_a
I0420 13:58:46.060818 32892 net.cpp:367] map64_3_bn_a -> map64_3_conv_a (in-place)
I0420 13:58:46.061002 32892 net.cpp:122] Setting up map64_3_bn_a
I0420 13:58:46.061009 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.061012 32892 net.cpp:137] Memory required for data: 536348672
I0420 13:58:46.061019 32892 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0420 13:58:46.061031 32892 net.cpp:84] Creating Layer map64_3_scale_a
I0420 13:58:46.061035 32892 net.cpp:406] map64_3_scale_a <- map64_3_conv_a
I0420 13:58:46.061040 32892 net.cpp:367] map64_3_scale_a -> map64_3_conv_a (in-place)
I0420 13:58:46.061077 32892 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0420 13:58:46.061187 32892 net.cpp:122] Setting up map64_3_scale_a
I0420 13:58:46.061192 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.061195 32892 net.cpp:137] Memory required for data: 538445824
I0420 13:58:46.061200 32892 layer_factory.hpp:77] Creating layer map64_3_relu_a
I0420 13:58:46.061208 32892 net.cpp:84] Creating Layer map64_3_relu_a
I0420 13:58:46.061213 32892 net.cpp:406] map64_3_relu_a <- map64_3_conv_a
I0420 13:58:46.061215 32892 net.cpp:367] map64_3_relu_a -> map64_3_conv_a (in-place)
I0420 13:58:46.063051 32892 net.cpp:122] Setting up map64_3_relu_a
I0420 13:58:46.063060 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.063063 32892 net.cpp:137] Memory required for data: 540542976
I0420 13:58:46.063071 32892 layer_factory.hpp:77] Creating layer map64_3_conv_b
I0420 13:58:46.063087 32892 net.cpp:84] Creating Layer map64_3_conv_b
I0420 13:58:46.063092 32892 net.cpp:406] map64_3_conv_b <- map64_3_conv_a
I0420 13:58:46.063098 32892 net.cpp:380] map64_3_conv_b -> map64_3_conv_b
I0420 13:58:46.070457 32892 net.cpp:122] Setting up map64_3_conv_b
I0420 13:58:46.070472 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.070477 32892 net.cpp:137] Memory required for data: 542640128
I0420 13:58:46.070482 32892 layer_factory.hpp:77] Creating layer map64_3_bn_b
I0420 13:58:46.070497 32892 net.cpp:84] Creating Layer map64_3_bn_b
I0420 13:58:46.070502 32892 net.cpp:406] map64_3_bn_b <- map64_3_conv_b
I0420 13:58:46.070508 32892 net.cpp:367] map64_3_bn_b -> map64_3_conv_b (in-place)
I0420 13:58:46.070705 32892 net.cpp:122] Setting up map64_3_bn_b
I0420 13:58:46.070713 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.070716 32892 net.cpp:137] Memory required for data: 544737280
I0420 13:58:46.070722 32892 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0420 13:58:46.070729 32892 net.cpp:84] Creating Layer map64_3_scale_b
I0420 13:58:46.070732 32892 net.cpp:406] map64_3_scale_b <- map64_3_conv_b
I0420 13:58:46.070752 32892 net.cpp:367] map64_3_scale_b -> map64_3_conv_b (in-place)
I0420 13:58:46.070791 32892 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0420 13:58:46.070897 32892 net.cpp:122] Setting up map64_3_scale_b
I0420 13:58:46.070905 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.070909 32892 net.cpp:137] Memory required for data: 546834432
I0420 13:58:46.070914 32892 layer_factory.hpp:77] Creating layer map64_3_eltsum
I0420 13:58:46.070924 32892 net.cpp:84] Creating Layer map64_3_eltsum
I0420 13:58:46.070929 32892 net.cpp:406] map64_3_eltsum <- map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0420 13:58:46.070933 32892 net.cpp:406] map64_3_eltsum <- map64_3_conv_b
I0420 13:58:46.070938 32892 net.cpp:380] map64_3_eltsum -> map64_3_eltsum
I0420 13:58:46.070960 32892 net.cpp:122] Setting up map64_3_eltsum
I0420 13:58:46.070966 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.070968 32892 net.cpp:137] Memory required for data: 548931584
I0420 13:58:46.070971 32892 layer_factory.hpp:77] Creating layer map64_3_relu_after_sum
I0420 13:58:46.070976 32892 net.cpp:84] Creating Layer map64_3_relu_after_sum
I0420 13:58:46.070978 32892 net.cpp:406] map64_3_relu_after_sum <- map64_3_eltsum
I0420 13:58:46.070983 32892 net.cpp:367] map64_3_relu_after_sum -> map64_3_eltsum (in-place)
I0420 13:58:46.072495 32892 net.cpp:122] Setting up map64_3_relu_after_sum
I0420 13:58:46.072504 32892 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 13:58:46.072506 32892 net.cpp:137] Memory required for data: 551028736
I0420 13:58:46.072511 32892 layer_factory.hpp:77] Creating layer pool_global
I0420 13:58:46.072525 32892 net.cpp:84] Creating Layer pool_global
I0420 13:58:46.072528 32892 net.cpp:406] pool_global <- map64_3_eltsum
I0420 13:58:46.072535 32892 net.cpp:380] pool_global -> pool_global
I0420 13:58:46.074857 32892 net.cpp:122] Setting up pool_global
I0420 13:58:46.074867 32892 net.cpp:129] Top shape: 128 64 1 1 (8192)
I0420 13:58:46.074870 32892 net.cpp:137] Memory required for data: 551061504
I0420 13:58:46.074873 32892 layer_factory.hpp:77] Creating layer score
I0420 13:58:46.074882 32892 net.cpp:84] Creating Layer score
I0420 13:58:46.074887 32892 net.cpp:406] score <- pool_global
I0420 13:58:46.074892 32892 net.cpp:380] score -> score
I0420 13:58:46.075013 32892 net.cpp:122] Setting up score
I0420 13:58:46.075019 32892 net.cpp:129] Top shape: 128 10 (1280)
I0420 13:58:46.075023 32892 net.cpp:137] Memory required for data: 551066624
I0420 13:58:46.075028 32892 layer_factory.hpp:77] Creating layer score_score_0_split
I0420 13:58:46.075033 32892 net.cpp:84] Creating Layer score_score_0_split
I0420 13:58:46.075037 32892 net.cpp:406] score_score_0_split <- score
I0420 13:58:46.075043 32892 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0420 13:58:46.075049 32892 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0420 13:58:46.075055 32892 net.cpp:380] score_score_0_split -> score_score_0_split_2
I0420 13:58:46.075096 32892 net.cpp:122] Setting up score_score_0_split
I0420 13:58:46.075101 32892 net.cpp:129] Top shape: 128 10 (1280)
I0420 13:58:46.075105 32892 net.cpp:129] Top shape: 128 10 (1280)
I0420 13:58:46.075109 32892 net.cpp:129] Top shape: 128 10 (1280)
I0420 13:58:46.075111 32892 net.cpp:137] Memory required for data: 551081984
I0420 13:58:46.075114 32892 layer_factory.hpp:77] Creating layer loss
I0420 13:58:46.075126 32892 net.cpp:84] Creating Layer loss
I0420 13:58:46.075130 32892 net.cpp:406] loss <- score_score_0_split_0
I0420 13:58:46.075134 32892 net.cpp:406] loss <- label_data_1_split_0
I0420 13:58:46.075139 32892 net.cpp:380] loss -> loss
I0420 13:58:46.075151 32892 layer_factory.hpp:77] Creating layer loss
I0420 13:58:46.077270 32892 net.cpp:122] Setting up loss
I0420 13:58:46.077281 32892 net.cpp:129] Top shape: (1)
I0420 13:58:46.077285 32892 net.cpp:132]     with loss weight 1
I0420 13:58:46.077317 32892 net.cpp:137] Memory required for data: 551081988
I0420 13:58:46.077322 32892 layer_factory.hpp:77] Creating layer acc/top1
I0420 13:58:46.077342 32892 net.cpp:84] Creating Layer acc/top1
I0420 13:58:46.077347 32892 net.cpp:406] acc/top1 <- score_score_0_split_1
I0420 13:58:46.077352 32892 net.cpp:406] acc/top1 <- label_data_1_split_1
I0420 13:58:46.077363 32892 net.cpp:380] acc/top1 -> acctop1
I0420 13:58:46.077378 32892 net.cpp:122] Setting up acc/top1
I0420 13:58:46.077383 32892 net.cpp:129] Top shape: (1)
I0420 13:58:46.077385 32892 net.cpp:137] Memory required for data: 551081992
I0420 13:58:46.077389 32892 layer_factory.hpp:77] Creating layer acc/top5
I0420 13:58:46.077392 32892 net.cpp:84] Creating Layer acc/top5
I0420 13:58:46.077396 32892 net.cpp:406] acc/top5 <- score_score_0_split_2
I0420 13:58:46.077399 32892 net.cpp:406] acc/top5 <- label_data_1_split_2
I0420 13:58:46.077406 32892 net.cpp:380] acc/top5 -> acctop5
I0420 13:58:46.077414 32892 net.cpp:122] Setting up acc/top5
I0420 13:58:46.077417 32892 net.cpp:129] Top shape: (1)
I0420 13:58:46.077419 32892 net.cpp:137] Memory required for data: 551081996
I0420 13:58:46.077425 32892 net.cpp:200] acc/top5 does not need backward computation.
I0420 13:58:46.077428 32892 net.cpp:200] acc/top1 does not need backward computation.
I0420 13:58:46.077431 32892 net.cpp:198] loss needs backward computation.
I0420 13:58:46.077435 32892 net.cpp:198] score_score_0_split needs backward computation.
I0420 13:58:46.077437 32892 net.cpp:198] score needs backward computation.
I0420 13:58:46.077440 32892 net.cpp:198] pool_global needs backward computation.
I0420 13:58:46.077443 32892 net.cpp:198] map64_3_relu_after_sum needs backward computation.
I0420 13:58:46.077445 32892 net.cpp:198] map64_3_eltsum needs backward computation.
I0420 13:58:46.077448 32892 net.cpp:198] map64_3_scale_b needs backward computation.
I0420 13:58:46.077451 32892 net.cpp:198] map64_3_bn_b needs backward computation.
I0420 13:58:46.077453 32892 net.cpp:198] map64_3_conv_b needs backward computation.
I0420 13:58:46.077456 32892 net.cpp:198] map64_3_relu_a needs backward computation.
I0420 13:58:46.077460 32892 net.cpp:198] map64_3_scale_a needs backward computation.
I0420 13:58:46.077461 32892 net.cpp:198] map64_3_bn_a needs backward computation.
I0420 13:58:46.077463 32892 net.cpp:198] map64_3_conv_a needs backward computation.
I0420 13:58:46.077466 32892 net.cpp:198] map64_2_eltsum_map64_2_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.077469 32892 net.cpp:198] map64_2_relu_after_sum needs backward computation.
I0420 13:58:46.077471 32892 net.cpp:198] map64_2_eltsum needs backward computation.
I0420 13:58:46.077474 32892 net.cpp:198] map64_2_scale_b needs backward computation.
I0420 13:58:46.077477 32892 net.cpp:198] map64_2_bn_b needs backward computation.
I0420 13:58:46.077479 32892 net.cpp:198] map64_2_conv_b needs backward computation.
I0420 13:58:46.077481 32892 net.cpp:198] map64_2_relu_a needs backward computation.
I0420 13:58:46.077483 32892 net.cpp:198] map64_2_scale_a needs backward computation.
I0420 13:58:46.077486 32892 net.cpp:198] map64_2_bn_a needs backward computation.
I0420 13:58:46.077488 32892 net.cpp:198] map64_2_conv_a needs backward computation.
I0420 13:58:46.077491 32892 net.cpp:198] map64_1_eltsum_map64_1_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.077494 32892 net.cpp:198] map64_1_relu_after_sum needs backward computation.
I0420 13:58:46.077497 32892 net.cpp:198] map64_1_eltsum needs backward computation.
I0420 13:58:46.077499 32892 net.cpp:198] map64_1_scale_b needs backward computation.
I0420 13:58:46.077502 32892 net.cpp:198] map64_1_bn_b needs backward computation.
I0420 13:58:46.077504 32892 net.cpp:198] map64_1_conv_b needs backward computation.
I0420 13:58:46.077507 32892 net.cpp:198] map64_1_relu_a needs backward computation.
I0420 13:58:46.077509 32892 net.cpp:198] map64_1_scale_a needs backward computation.
I0420 13:58:46.077512 32892 net.cpp:198] map64_1_bn_a needs backward computation.
I0420 13:58:46.077514 32892 net.cpp:198] map64_1_conv_a needs backward computation.
I0420 13:58:46.077517 32892 net.cpp:198] map64_1_scale_proj needs backward computation.
I0420 13:58:46.077528 32892 net.cpp:198] map64_1_bn_proj needs backward computation.
I0420 13:58:46.077530 32892 net.cpp:198] map64_1_conv_proj needs backward computation.
I0420 13:58:46.077533 32892 net.cpp:198] map32_3_eltsum_map32_3_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.077536 32892 net.cpp:198] map32_3_relu_after_sum needs backward computation.
I0420 13:58:46.077539 32892 net.cpp:198] map32_3_eltsum needs backward computation.
I0420 13:58:46.077541 32892 net.cpp:198] map32_3_scale_b needs backward computation.
I0420 13:58:46.077543 32892 net.cpp:198] map32_3_bn_b needs backward computation.
I0420 13:58:46.077546 32892 net.cpp:198] map32_3_conv_b needs backward computation.
I0420 13:58:46.077549 32892 net.cpp:198] map32_3_relu_a needs backward computation.
I0420 13:58:46.077551 32892 net.cpp:198] map32_3_scale_a needs backward computation.
I0420 13:58:46.077553 32892 net.cpp:198] map32_3_bn_a needs backward computation.
I0420 13:58:46.077555 32892 net.cpp:198] map32_3_conv_a needs backward computation.
I0420 13:58:46.077559 32892 net.cpp:198] map32_2_eltsum_map32_2_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.077561 32892 net.cpp:198] map32_2_relu_after_sum needs backward computation.
I0420 13:58:46.077564 32892 net.cpp:198] map32_2_eltsum needs backward computation.
I0420 13:58:46.077567 32892 net.cpp:198] map32_2_scale_b needs backward computation.
I0420 13:58:46.077570 32892 net.cpp:198] map32_2_bn_b needs backward computation.
I0420 13:58:46.077572 32892 net.cpp:198] map32_2_conv_b needs backward computation.
I0420 13:58:46.077574 32892 net.cpp:198] map32_2_relu_a needs backward computation.
I0420 13:58:46.077576 32892 net.cpp:198] map32_2_scale_a needs backward computation.
I0420 13:58:46.077579 32892 net.cpp:198] map32_2_bn_a needs backward computation.
I0420 13:58:46.077580 32892 net.cpp:198] map32_2_conv_a needs backward computation.
I0420 13:58:46.077582 32892 net.cpp:198] map32_1_eltsum_map32_1_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.077586 32892 net.cpp:198] map32_1_relu_after_sum needs backward computation.
I0420 13:58:46.077589 32892 net.cpp:198] map32_1_eltsum needs backward computation.
I0420 13:58:46.077590 32892 net.cpp:198] map32_1_scale_b needs backward computation.
I0420 13:58:46.077594 32892 net.cpp:198] map32_1_bn_b needs backward computation.
I0420 13:58:46.077595 32892 net.cpp:198] map32_1_conv_b needs backward computation.
I0420 13:58:46.077599 32892 net.cpp:198] map32_1_relu_a needs backward computation.
I0420 13:58:46.077600 32892 net.cpp:198] map32_1_scale_a needs backward computation.
I0420 13:58:46.077603 32892 net.cpp:198] map32_1_bn_a needs backward computation.
I0420 13:58:46.077605 32892 net.cpp:198] map32_1_conv_a needs backward computation.
I0420 13:58:46.077608 32892 net.cpp:198] map32_1_scale_proj needs backward computation.
I0420 13:58:46.077615 32892 net.cpp:198] map32_1_bn_proj needs backward computation.
I0420 13:58:46.077616 32892 net.cpp:198] map32_1_conv_proj needs backward computation.
I0420 13:58:46.077620 32892 net.cpp:198] map16_3_eltsum_map16_3_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.077622 32892 net.cpp:198] map16_3_relu_after_sum needs backward computation.
I0420 13:58:46.077625 32892 net.cpp:198] map16_3_eltsum needs backward computation.
I0420 13:58:46.077627 32892 net.cpp:198] map16_3_scale_b needs backward computation.
I0420 13:58:46.077630 32892 net.cpp:198] map16_3_bn_b needs backward computation.
I0420 13:58:46.077632 32892 net.cpp:198] map16_3_conv_b needs backward computation.
I0420 13:58:46.077636 32892 net.cpp:198] map16_3_relu_a needs backward computation.
I0420 13:58:46.077637 32892 net.cpp:198] map16_3_scale_a needs backward computation.
I0420 13:58:46.077641 32892 net.cpp:198] map16_3_bn_a needs backward computation.
I0420 13:58:46.077642 32892 net.cpp:198] map16_3_conv_a needs backward computation.
I0420 13:58:46.077644 32892 net.cpp:198] map16_2_eltsum_map16_2_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.077648 32892 net.cpp:198] map16_2_relu_after_sum needs backward computation.
I0420 13:58:46.077656 32892 net.cpp:198] map16_2_eltsum needs backward computation.
I0420 13:58:46.077659 32892 net.cpp:198] map16_2_scale_b needs backward computation.
I0420 13:58:46.077662 32892 net.cpp:198] map16_2_bn_b needs backward computation.
I0420 13:58:46.077664 32892 net.cpp:198] map16_2_conv_b needs backward computation.
I0420 13:58:46.077666 32892 net.cpp:198] map16_2_relu_a needs backward computation.
I0420 13:58:46.077669 32892 net.cpp:198] map16_2_scale_a needs backward computation.
I0420 13:58:46.077672 32892 net.cpp:198] map16_2_bn_a needs backward computation.
I0420 13:58:46.077674 32892 net.cpp:198] map16_2_conv_a needs backward computation.
I0420 13:58:46.077677 32892 net.cpp:198] map16_1_eltsum_map16_1_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.077679 32892 net.cpp:198] map16_1_relu_after_sum needs backward computation.
I0420 13:58:46.077687 32892 net.cpp:198] map16_1_eltsum needs backward computation.
I0420 13:58:46.077690 32892 net.cpp:198] map16_1_scale_b needs backward computation.
I0420 13:58:46.077692 32892 net.cpp:198] map16_1_bn_b needs backward computation.
I0420 13:58:46.077695 32892 net.cpp:198] map16_1_conv_b needs backward computation.
I0420 13:58:46.077697 32892 net.cpp:198] map16_1_relu_a needs backward computation.
I0420 13:58:46.077699 32892 net.cpp:198] map16_1_scale_a needs backward computation.
I0420 13:58:46.077702 32892 net.cpp:198] map16_1_bn_a needs backward computation.
I0420 13:58:46.077704 32892 net.cpp:198] map16_1_conv_a needs backward computation.
I0420 13:58:46.077708 32892 net.cpp:198] conv1_relu_conv1_0_split needs backward computation.
I0420 13:58:46.077711 32892 net.cpp:198] relu_conv1 needs backward computation.
I0420 13:58:46.077713 32892 net.cpp:198] scale_conv1 needs backward computation.
I0420 13:58:46.077715 32892 net.cpp:198] bn_conv1 needs backward computation.
I0420 13:58:46.077718 32892 net.cpp:198] conv1 needs backward computation.
I0420 13:58:46.077723 32892 net.cpp:200] label_data_1_split does not need backward computation.
I0420 13:58:46.077726 32892 net.cpp:200] data does not need backward computation.
I0420 13:58:46.077729 32892 net.cpp:242] This network produces output acctop1
I0420 13:58:46.077733 32892 net.cpp:242] This network produces output acctop5
I0420 13:58:46.077735 32892 net.cpp:242] This network produces output loss
I0420 13:58:46.077786 32892 net.cpp:255] Network initialization done.
I0420 13:58:46.080795 32892 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet20_relu_msra_cifar10_fix_pattern.prototxt
I0420 13:58:46.080808 32892 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0420 13:58:46.080816 32892 solver.cpp:173] Creating test net (#0) specified by net file: resnet20_relu_msra_cifar10_fix_pattern.prototxt
I0420 13:58:46.080935 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0420 13:58:46.080942 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv1
I0420 13:58:46.080950 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_1_bn_a
I0420 13:58:46.080955 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_1_bn_b
I0420 13:58:46.080962 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_2_bn_a
I0420 13:58:46.080967 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_2_bn_b
I0420 13:58:46.080973 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_3_bn_a
I0420 13:58:46.080979 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_3_bn_b
I0420 13:58:46.080986 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_proj
I0420 13:58:46.081003 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_a
I0420 13:58:46.081010 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_b
I0420 13:58:46.081017 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_2_bn_a
I0420 13:58:46.081022 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_2_bn_b
I0420 13:58:46.081028 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_3_bn_a
I0420 13:58:46.081033 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_3_bn_b
I0420 13:58:46.081039 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_proj
I0420 13:58:46.081045 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_a
I0420 13:58:46.081051 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_b
I0420 13:58:46.081058 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_2_bn_a
I0420 13:58:46.081063 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_2_bn_b
I0420 13:58:46.081068 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_3_bn_a
I0420 13:58:46.081073 32892 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_3_bn_b
I0420 13:58:46.081532 32892 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 32
    mean_file: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/mean.binaryproto"
  }
  data_param {
    source: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_test_leveldb_copy/"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "map16_1_conv_a"
  type: "Convolution"
  bottom: "conv1"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_a"
  type: "BatchNorm"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_1_scale_a"
  type: "Scale"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_relu_a"
  type: "ReLU"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
}
layer {
  name: "map16_1_conv_b"
  type: "Convolution"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_b"
  type: "BatchNorm"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_1_scale_b"
  type: "Scale"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_eltsum"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "map16_1_conv_b"
  top: "map16_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_1_relu_after_sum"
  type: "ReLU"
  bottom: "map16_1_eltsum"
  top: "map16_1_eltsum"
}
layer {
  name: "map16_2_conv_a"
  type: "Convolution"
  bottom: "map16_1_eltsum"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_a"
  type: "BatchNorm"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_2_scale_a"
  type: "Scale"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_relu_a"
  type: "ReLU"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
}
layer {
  name: "map16_2_conv_b"
  type: "Convolution"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_b"
  type: "BatchNorm"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_2_scale_b"
  type: "Scale"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_eltsum"
  type: "Eltwise"
  bottom: "map16_1_eltsum"
  bottom: "map16_2_conv_b"
  top: "map16_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_2_relu_after_sum"
  type: "ReLU"
  bottom: "map16_2_eltsum"
  top: "map16_2_eltsum"
}
layer {
  name: "map16_3_conv_a"
  type: "Convolution"
  bottom: "map16_2_eltsum"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_a"
  type: "BatchNorm"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_3_scale_a"
  type: "Scale"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_relu_a"
  type: "ReLU"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
}
layer {
  name: "map16_3_conv_b"
  type: "Convolution"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_b"
  type: "BatchNorm"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_3_scale_b"
  type: "Scale"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_eltsum"
  type: "Eltwise"
  bottom: "map16_2_eltsum"
  bottom: "map16_3_conv_b"
  top: "map16_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_3_relu_after_sum"
  type: "ReLU"
  bottom: "map16_3_eltsum"
  top: "map16_3_eltsum"
}
layer {
  name: "map32_1_conv_proj"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_proj"
  type: "BatchNorm"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_proj"
  type: "Scale"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_conv_a"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_a"
  type: "BatchNorm"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_a"
  type: "Scale"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_relu_a"
  type: "ReLU"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
}
layer {
  name: "map32_1_conv_b"
  type: "Convolution"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_b"
  type: "BatchNorm"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_b"
  type: "Scale"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_eltsum"
  type: "Eltwise"
  bottom: "map32_1_conv_proj"
  bottom: "map32_1_conv_b"
  top: "map32_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_1_relu_after_sum"
  type: "ReLU"
  bottom: "map32_1_eltsum"
  top: "map32_1_eltsum"
}
layer {
  name: "map32_2_conv_a"
  type: "Convolution"
  bottom: "map32_1_eltsum"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_a"
  type: "BatchNorm"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_2_scale_a"
  type: "Scale"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_relu_a"
  type: "ReLU"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
}
layer {
  name: "map32_2_conv_b"
  type: "Convolution"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_b"
  type: "BatchNorm"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_2_scale_b"
  type: "Scale"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_eltsum"
  type: "Eltwise"
  bottom: "map32_1_eltsum"
  bottom: "map32_2_conv_b"
  top: "map32_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_2_relu_after_sum"
  type: "ReLU"
  bottom: "map32_2_eltsum"
  top: "map32_2_eltsum"
}
layer {
  name: "map32_3_conv_a"
  type: "Convolution"
  bottom: "map32_2_eltsum"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_a"
  type: "BatchNorm"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_3_scale_a"
  type: "Scale"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_relu_a"
  type: "ReLU"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
}
layer {
  name: "map32_3_conv_b"
  type: "Convolution"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_b"
  type: "BatchNorm"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_3_scale_b"
  type: "Scale"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_eltsum"
  type: "Eltwise"
  bottom: "map32_2_eltsum"
  bottom: "map32_3_conv_b"
  top: "map32_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_3_relu_after_sum"
  type: "ReLU"
  bottom: "map32_3_eltsum"
  top: "map32_3_eltsum"
}
layer {
  name: "map64_1_conv_proj"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_proj"
  type: "BatchNorm"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_proj"
  type: "Scale"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_conv_a"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_a"
  type: "BatchNorm"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_a"
  type: "Scale"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_relu_a"
  type: "ReLU"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
}
layer {
  name: "map64_1_conv_b"
  type: "Convolution"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_b"
  type: "BatchNorm"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_b"
  type: "Scale"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_eltsum"
  type: "Eltwise"
  bottom: "map64_1_conv_proj"
  bottom: "map64_1_conv_b"
  top: "map64_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_1_relu_after_sum"
  type: "ReLU"
  bottom: "map64_1_eltsum"
  top: "map64_1_eltsum"
}
layer {
  name: "map64_2_conv_a"
  type: "Convolution"
  bottom: "map64_1_eltsum"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_a"
  type: "BatchNorm"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_2_scale_a"
  type: "Scale"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_relu_a"
  type: "ReLU"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
}
layer {
  name: "map64_2_conv_b"
  type: "Convolution"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_b"
  type: "BatchNorm"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_2_scale_b"
  type: "Scale"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_eltsum"
  type: "Eltwise"
  bottom: "map64_1_eltsum"
  bottom: "map64_2_conv_b"
  top: "map64_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_2_relu_after_sum"
  type: "ReLU"
  bottom: "map64_2_eltsum"
  top: "map64_2_eltsum"
}
layer {
  name: "map64_3_conv_a"
  type: "Convolution"
  bottom: "map64_2_eltsum"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_a"
  type: "BatchNorm"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_3_scale_a"
  type: "Scale"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_relu_a"
  type: "ReLU"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
}
layer {
  name: "map64_3_conv_b"
  type: "Convolution"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_b"
  type: "BatchNorm"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_3_scale_b"
  type: "Scale"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_eltsum"
  type: "Eltwise"
  bottom: "map64_2_eltsum"
  bottom: "map64_3_conv_b"
  top: "map64_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_3_relu_after_sum"
  type: "ReLU"
  bottom: "map64_3_eltsum"
  top: "map64_3_eltsum"
}
layer {
  name: "pool_global"
  type: "Pooling"
  bottom: "map64_3_eltsum"
  top: "pool_global"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_global"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc/top1"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc/top5"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop5"
  accuracy_param {
    top_k: 5
  }
}
I0420 13:58:46.081892 32892 layer_factory.hpp:77] Creating layer data
I0420 13:58:46.094506 32892 db_leveldb.cpp:18] Opened leveldb /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_test_leveldb_copy/
I0420 13:58:46.095933 32892 net.cpp:84] Creating Layer data
I0420 13:58:46.095945 32892 net.cpp:380] data -> data
I0420 13:58:46.095973 32892 net.cpp:380] data -> label
I0420 13:58:46.095979 32892 data_transformer.cpp:25] Loading mean file from: /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/mean.binaryproto
I0420 13:58:46.096529 32892 data_layer.cpp:45] output data size: 100,3,32,32
I0420 13:58:46.110093 32892 net.cpp:122] Setting up data
I0420 13:58:46.110105 32892 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0420 13:58:46.110127 32892 net.cpp:129] Top shape: 100 (100)
I0420 13:58:46.110131 32892 net.cpp:137] Memory required for data: 1229200
I0420 13:58:46.110134 32892 layer_factory.hpp:77] Creating layer label_data_1_split
I0420 13:58:46.110141 32892 net.cpp:84] Creating Layer label_data_1_split
I0420 13:58:46.110146 32892 net.cpp:406] label_data_1_split <- label
I0420 13:58:46.110152 32892 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0420 13:58:46.110160 32892 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0420 13:58:46.110167 32892 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0420 13:58:46.110311 32892 net.cpp:122] Setting up label_data_1_split
I0420 13:58:46.110318 32892 net.cpp:129] Top shape: 100 (100)
I0420 13:58:46.110322 32892 net.cpp:129] Top shape: 100 (100)
I0420 13:58:46.110325 32892 net.cpp:129] Top shape: 100 (100)
I0420 13:58:46.110327 32892 net.cpp:137] Memory required for data: 1230400
I0420 13:58:46.110330 32892 layer_factory.hpp:77] Creating layer conv1
I0420 13:58:46.110343 32892 net.cpp:84] Creating Layer conv1
I0420 13:58:46.110347 32892 net.cpp:406] conv1 <- data
I0420 13:58:46.110354 32892 net.cpp:380] conv1 -> conv1
I0420 13:58:46.117528 32892 net.cpp:122] Setting up conv1
I0420 13:58:46.117542 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.117547 32892 net.cpp:137] Memory required for data: 7784000
I0420 13:58:46.117555 32892 layer_factory.hpp:77] Creating layer bn_conv1
I0420 13:58:46.117566 32892 net.cpp:84] Creating Layer bn_conv1
I0420 13:58:46.117571 32892 net.cpp:406] bn_conv1 <- conv1
I0420 13:58:46.117579 32892 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0420 13:58:46.117781 32892 net.cpp:122] Setting up bn_conv1
I0420 13:58:46.117789 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.117794 32892 net.cpp:137] Memory required for data: 14337600
I0420 13:58:46.117802 32892 layer_factory.hpp:77] Creating layer scale_conv1
I0420 13:58:46.117812 32892 net.cpp:84] Creating Layer scale_conv1
I0420 13:58:46.117816 32892 net.cpp:406] scale_conv1 <- conv1
I0420 13:58:46.117820 32892 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0420 13:58:46.117862 32892 layer_factory.hpp:77] Creating layer scale_conv1
I0420 13:58:46.117981 32892 net.cpp:122] Setting up scale_conv1
I0420 13:58:46.118001 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.118005 32892 net.cpp:137] Memory required for data: 20891200
I0420 13:58:46.118010 32892 layer_factory.hpp:77] Creating layer relu_conv1
I0420 13:58:46.118016 32892 net.cpp:84] Creating Layer relu_conv1
I0420 13:58:46.118019 32892 net.cpp:406] relu_conv1 <- conv1
I0420 13:58:46.118023 32892 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0420 13:58:46.119645 32892 net.cpp:122] Setting up relu_conv1
I0420 13:58:46.119655 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.119658 32892 net.cpp:137] Memory required for data: 27444800
I0420 13:58:46.119662 32892 layer_factory.hpp:77] Creating layer conv1_relu_conv1_0_split
I0420 13:58:46.119668 32892 net.cpp:84] Creating Layer conv1_relu_conv1_0_split
I0420 13:58:46.119688 32892 net.cpp:406] conv1_relu_conv1_0_split <- conv1
I0420 13:58:46.119695 32892 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_0
I0420 13:58:46.119704 32892 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_1
I0420 13:58:46.119746 32892 net.cpp:122] Setting up conv1_relu_conv1_0_split
I0420 13:58:46.119755 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.119758 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.119760 32892 net.cpp:137] Memory required for data: 40552000
I0420 13:58:46.119765 32892 layer_factory.hpp:77] Creating layer map16_1_conv_a
I0420 13:58:46.119773 32892 net.cpp:84] Creating Layer map16_1_conv_a
I0420 13:58:46.119777 32892 net.cpp:406] map16_1_conv_a <- conv1_relu_conv1_0_split_0
I0420 13:58:46.119782 32892 net.cpp:380] map16_1_conv_a -> map16_1_conv_a
I0420 13:58:46.123965 32892 net.cpp:122] Setting up map16_1_conv_a
I0420 13:58:46.123981 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.123986 32892 net.cpp:137] Memory required for data: 47105600
I0420 13:58:46.124001 32892 layer_factory.hpp:77] Creating layer map16_1_bn_a
I0420 13:58:46.124011 32892 net.cpp:84] Creating Layer map16_1_bn_a
I0420 13:58:46.124014 32892 net.cpp:406] map16_1_bn_a <- map16_1_conv_a
I0420 13:58:46.124019 32892 net.cpp:367] map16_1_bn_a -> map16_1_conv_a (in-place)
I0420 13:58:46.124234 32892 net.cpp:122] Setting up map16_1_bn_a
I0420 13:58:46.124241 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.124244 32892 net.cpp:137] Memory required for data: 53659200
I0420 13:58:46.124253 32892 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0420 13:58:46.124259 32892 net.cpp:84] Creating Layer map16_1_scale_a
I0420 13:58:46.124263 32892 net.cpp:406] map16_1_scale_a <- map16_1_conv_a
I0420 13:58:46.124266 32892 net.cpp:367] map16_1_scale_a -> map16_1_conv_a (in-place)
I0420 13:58:46.124394 32892 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0420 13:58:46.124510 32892 net.cpp:122] Setting up map16_1_scale_a
I0420 13:58:46.124516 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.124519 32892 net.cpp:137] Memory required for data: 60212800
I0420 13:58:46.124524 32892 layer_factory.hpp:77] Creating layer map16_1_relu_a
I0420 13:58:46.124531 32892 net.cpp:84] Creating Layer map16_1_relu_a
I0420 13:58:46.124536 32892 net.cpp:406] map16_1_relu_a <- map16_1_conv_a
I0420 13:58:46.124546 32892 net.cpp:367] map16_1_relu_a -> map16_1_conv_a (in-place)
I0420 13:58:46.124745 32892 net.cpp:122] Setting up map16_1_relu_a
I0420 13:58:46.124755 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.124758 32892 net.cpp:137] Memory required for data: 66766400
I0420 13:58:46.124761 32892 layer_factory.hpp:77] Creating layer map16_1_conv_b
I0420 13:58:46.124774 32892 net.cpp:84] Creating Layer map16_1_conv_b
I0420 13:58:46.124778 32892 net.cpp:406] map16_1_conv_b <- map16_1_conv_a
I0420 13:58:46.124783 32892 net.cpp:380] map16_1_conv_b -> map16_1_conv_b
I0420 13:58:46.125954 32892 net.cpp:122] Setting up map16_1_conv_b
I0420 13:58:46.125968 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.125972 32892 net.cpp:137] Memory required for data: 73320000
I0420 13:58:46.125978 32892 layer_factory.hpp:77] Creating layer map16_1_bn_b
I0420 13:58:46.125988 32892 net.cpp:84] Creating Layer map16_1_bn_b
I0420 13:58:46.125993 32892 net.cpp:406] map16_1_bn_b <- map16_1_conv_b
I0420 13:58:46.126000 32892 net.cpp:367] map16_1_bn_b -> map16_1_conv_b (in-place)
I0420 13:58:46.126204 32892 net.cpp:122] Setting up map16_1_bn_b
I0420 13:58:46.126211 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.126214 32892 net.cpp:137] Memory required for data: 79873600
I0420 13:58:46.126245 32892 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0420 13:58:46.126252 32892 net.cpp:84] Creating Layer map16_1_scale_b
I0420 13:58:46.126257 32892 net.cpp:406] map16_1_scale_b <- map16_1_conv_b
I0420 13:58:46.126262 32892 net.cpp:367] map16_1_scale_b -> map16_1_conv_b (in-place)
I0420 13:58:46.126320 32892 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0420 13:58:46.126432 32892 net.cpp:122] Setting up map16_1_scale_b
I0420 13:58:46.126440 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.126443 32892 net.cpp:137] Memory required for data: 86427200
I0420 13:58:46.126448 32892 layer_factory.hpp:77] Creating layer map16_1_eltsum
I0420 13:58:46.126456 32892 net.cpp:84] Creating Layer map16_1_eltsum
I0420 13:58:46.126459 32892 net.cpp:406] map16_1_eltsum <- conv1_relu_conv1_0_split_1
I0420 13:58:46.126462 32892 net.cpp:406] map16_1_eltsum <- map16_1_conv_b
I0420 13:58:46.126469 32892 net.cpp:380] map16_1_eltsum -> map16_1_eltsum
I0420 13:58:46.126495 32892 net.cpp:122] Setting up map16_1_eltsum
I0420 13:58:46.126500 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.126503 32892 net.cpp:137] Memory required for data: 92980800
I0420 13:58:46.126507 32892 layer_factory.hpp:77] Creating layer map16_1_relu_after_sum
I0420 13:58:46.126510 32892 net.cpp:84] Creating Layer map16_1_relu_after_sum
I0420 13:58:46.126513 32892 net.cpp:406] map16_1_relu_after_sum <- map16_1_eltsum
I0420 13:58:46.126518 32892 net.cpp:367] map16_1_relu_after_sum -> map16_1_eltsum (in-place)
I0420 13:58:46.126723 32892 net.cpp:122] Setting up map16_1_relu_after_sum
I0420 13:58:46.126730 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.126734 32892 net.cpp:137] Memory required for data: 99534400
I0420 13:58:46.126737 32892 layer_factory.hpp:77] Creating layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 13:58:46.126744 32892 net.cpp:84] Creating Layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 13:58:46.126747 32892 net.cpp:406] map16_1_eltsum_map16_1_relu_after_sum_0_split <- map16_1_eltsum
I0420 13:58:46.126754 32892 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0420 13:58:46.126760 32892 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0420 13:58:46.126978 32892 net.cpp:122] Setting up map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 13:58:46.126988 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.126992 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.126994 32892 net.cpp:137] Memory required for data: 112641600
I0420 13:58:46.126998 32892 layer_factory.hpp:77] Creating layer map16_2_conv_a
I0420 13:58:46.127009 32892 net.cpp:84] Creating Layer map16_2_conv_a
I0420 13:58:46.127013 32892 net.cpp:406] map16_2_conv_a <- map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0420 13:58:46.127019 32892 net.cpp:380] map16_2_conv_a -> map16_2_conv_a
I0420 13:58:46.128303 32892 net.cpp:122] Setting up map16_2_conv_a
I0420 13:58:46.128316 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.128319 32892 net.cpp:137] Memory required for data: 119195200
I0420 13:58:46.128326 32892 layer_factory.hpp:77] Creating layer map16_2_bn_a
I0420 13:58:46.128336 32892 net.cpp:84] Creating Layer map16_2_bn_a
I0420 13:58:46.128341 32892 net.cpp:406] map16_2_bn_a <- map16_2_conv_a
I0420 13:58:46.128350 32892 net.cpp:367] map16_2_bn_a -> map16_2_conv_a (in-place)
I0420 13:58:46.128545 32892 net.cpp:122] Setting up map16_2_bn_a
I0420 13:58:46.128552 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.128557 32892 net.cpp:137] Memory required for data: 125748800
I0420 13:58:46.128564 32892 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0420 13:58:46.128572 32892 net.cpp:84] Creating Layer map16_2_scale_a
I0420 13:58:46.128576 32892 net.cpp:406] map16_2_scale_a <- map16_2_conv_a
I0420 13:58:46.128581 32892 net.cpp:367] map16_2_scale_a -> map16_2_conv_a (in-place)
I0420 13:58:46.128623 32892 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0420 13:58:46.128751 32892 net.cpp:122] Setting up map16_2_scale_a
I0420 13:58:46.128762 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.128764 32892 net.cpp:137] Memory required for data: 132302400
I0420 13:58:46.128782 32892 layer_factory.hpp:77] Creating layer map16_2_relu_a
I0420 13:58:46.128787 32892 net.cpp:84] Creating Layer map16_2_relu_a
I0420 13:58:46.128792 32892 net.cpp:406] map16_2_relu_a <- map16_2_conv_a
I0420 13:58:46.128795 32892 net.cpp:367] map16_2_relu_a -> map16_2_conv_a (in-place)
I0420 13:58:46.128978 32892 net.cpp:122] Setting up map16_2_relu_a
I0420 13:58:46.128986 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.128989 32892 net.cpp:137] Memory required for data: 138856000
I0420 13:58:46.128993 32892 layer_factory.hpp:77] Creating layer map16_2_conv_b
I0420 13:58:46.129004 32892 net.cpp:84] Creating Layer map16_2_conv_b
I0420 13:58:46.129006 32892 net.cpp:406] map16_2_conv_b <- map16_2_conv_a
I0420 13:58:46.129012 32892 net.cpp:380] map16_2_conv_b -> map16_2_conv_b
I0420 13:58:46.130524 32892 net.cpp:122] Setting up map16_2_conv_b
I0420 13:58:46.130538 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.130542 32892 net.cpp:137] Memory required for data: 145409600
I0420 13:58:46.130548 32892 layer_factory.hpp:77] Creating layer map16_2_bn_b
I0420 13:58:46.130558 32892 net.cpp:84] Creating Layer map16_2_bn_b
I0420 13:58:46.130561 32892 net.cpp:406] map16_2_bn_b <- map16_2_conv_b
I0420 13:58:46.130568 32892 net.cpp:367] map16_2_bn_b -> map16_2_conv_b (in-place)
I0420 13:58:46.130765 32892 net.cpp:122] Setting up map16_2_bn_b
I0420 13:58:46.130774 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.130776 32892 net.cpp:137] Memory required for data: 151963200
I0420 13:58:46.130789 32892 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0420 13:58:46.130795 32892 net.cpp:84] Creating Layer map16_2_scale_b
I0420 13:58:46.130798 32892 net.cpp:406] map16_2_scale_b <- map16_2_conv_b
I0420 13:58:46.130802 32892 net.cpp:367] map16_2_scale_b -> map16_2_conv_b (in-place)
I0420 13:58:46.130843 32892 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0420 13:58:46.130950 32892 net.cpp:122] Setting up map16_2_scale_b
I0420 13:58:46.130957 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.130960 32892 net.cpp:137] Memory required for data: 158516800
I0420 13:58:46.130965 32892 layer_factory.hpp:77] Creating layer map16_2_eltsum
I0420 13:58:46.130972 32892 net.cpp:84] Creating Layer map16_2_eltsum
I0420 13:58:46.130976 32892 net.cpp:406] map16_2_eltsum <- map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0420 13:58:46.130980 32892 net.cpp:406] map16_2_eltsum <- map16_2_conv_b
I0420 13:58:46.130985 32892 net.cpp:380] map16_2_eltsum -> map16_2_eltsum
I0420 13:58:46.131009 32892 net.cpp:122] Setting up map16_2_eltsum
I0420 13:58:46.131014 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.131017 32892 net.cpp:137] Memory required for data: 165070400
I0420 13:58:46.131021 32892 layer_factory.hpp:77] Creating layer map16_2_relu_after_sum
I0420 13:58:46.131024 32892 net.cpp:84] Creating Layer map16_2_relu_after_sum
I0420 13:58:46.131027 32892 net.cpp:406] map16_2_relu_after_sum <- map16_2_eltsum
I0420 13:58:46.131031 32892 net.cpp:367] map16_2_relu_after_sum -> map16_2_eltsum (in-place)
I0420 13:58:46.131487 32892 net.cpp:122] Setting up map16_2_relu_after_sum
I0420 13:58:46.131498 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.131501 32892 net.cpp:137] Memory required for data: 171624000
I0420 13:58:46.131505 32892 layer_factory.hpp:77] Creating layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 13:58:46.131510 32892 net.cpp:84] Creating Layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 13:58:46.131515 32892 net.cpp:406] map16_2_eltsum_map16_2_relu_after_sum_0_split <- map16_2_eltsum
I0420 13:58:46.131520 32892 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0420 13:58:46.131530 32892 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0420 13:58:46.131572 32892 net.cpp:122] Setting up map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 13:58:46.131592 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.131597 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.131598 32892 net.cpp:137] Memory required for data: 184731200
I0420 13:58:46.131603 32892 layer_factory.hpp:77] Creating layer map16_3_conv_a
I0420 13:58:46.131613 32892 net.cpp:84] Creating Layer map16_3_conv_a
I0420 13:58:46.131616 32892 net.cpp:406] map16_3_conv_a <- map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0420 13:58:46.131621 32892 net.cpp:380] map16_3_conv_a -> map16_3_conv_a
I0420 13:58:46.132652 32892 net.cpp:122] Setting up map16_3_conv_a
I0420 13:58:46.132663 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.132666 32892 net.cpp:137] Memory required for data: 191284800
I0420 13:58:46.132673 32892 layer_factory.hpp:77] Creating layer map16_3_bn_a
I0420 13:58:46.132684 32892 net.cpp:84] Creating Layer map16_3_bn_a
I0420 13:58:46.132689 32892 net.cpp:406] map16_3_bn_a <- map16_3_conv_a
I0420 13:58:46.132697 32892 net.cpp:367] map16_3_bn_a -> map16_3_conv_a (in-place)
I0420 13:58:46.132890 32892 net.cpp:122] Setting up map16_3_bn_a
I0420 13:58:46.132897 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.132900 32892 net.cpp:137] Memory required for data: 197838400
I0420 13:58:46.132906 32892 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0420 13:58:46.132912 32892 net.cpp:84] Creating Layer map16_3_scale_a
I0420 13:58:46.132915 32892 net.cpp:406] map16_3_scale_a <- map16_3_conv_a
I0420 13:58:46.132920 32892 net.cpp:367] map16_3_scale_a -> map16_3_conv_a (in-place)
I0420 13:58:46.132957 32892 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0420 13:58:46.133064 32892 net.cpp:122] Setting up map16_3_scale_a
I0420 13:58:46.133070 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.133074 32892 net.cpp:137] Memory required for data: 204392000
I0420 13:58:46.133078 32892 layer_factory.hpp:77] Creating layer map16_3_relu_a
I0420 13:58:46.133085 32892 net.cpp:84] Creating Layer map16_3_relu_a
I0420 13:58:46.133088 32892 net.cpp:406] map16_3_relu_a <- map16_3_conv_a
I0420 13:58:46.133092 32892 net.cpp:367] map16_3_relu_a -> map16_3_conv_a (in-place)
I0420 13:58:46.133496 32892 net.cpp:122] Setting up map16_3_relu_a
I0420 13:58:46.133507 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.133512 32892 net.cpp:137] Memory required for data: 210945600
I0420 13:58:46.133514 32892 layer_factory.hpp:77] Creating layer map16_3_conv_b
I0420 13:58:46.133527 32892 net.cpp:84] Creating Layer map16_3_conv_b
I0420 13:58:46.133533 32892 net.cpp:406] map16_3_conv_b <- map16_3_conv_a
I0420 13:58:46.133539 32892 net.cpp:380] map16_3_conv_b -> map16_3_conv_b
I0420 13:58:46.134665 32892 net.cpp:122] Setting up map16_3_conv_b
I0420 13:58:46.134680 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.134688 32892 net.cpp:137] Memory required for data: 217499200
I0420 13:58:46.134696 32892 layer_factory.hpp:77] Creating layer map16_3_bn_b
I0420 13:58:46.134706 32892 net.cpp:84] Creating Layer map16_3_bn_b
I0420 13:58:46.134711 32892 net.cpp:406] map16_3_bn_b <- map16_3_conv_b
I0420 13:58:46.134716 32892 net.cpp:367] map16_3_bn_b -> map16_3_conv_b (in-place)
I0420 13:58:46.134910 32892 net.cpp:122] Setting up map16_3_bn_b
I0420 13:58:46.134917 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.134920 32892 net.cpp:137] Memory required for data: 224052800
I0420 13:58:46.134927 32892 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0420 13:58:46.134933 32892 net.cpp:84] Creating Layer map16_3_scale_b
I0420 13:58:46.134937 32892 net.cpp:406] map16_3_scale_b <- map16_3_conv_b
I0420 13:58:46.134944 32892 net.cpp:367] map16_3_scale_b -> map16_3_conv_b (in-place)
I0420 13:58:46.134982 32892 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0420 13:58:46.135089 32892 net.cpp:122] Setting up map16_3_scale_b
I0420 13:58:46.135097 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.135100 32892 net.cpp:137] Memory required for data: 230606400
I0420 13:58:46.135118 32892 layer_factory.hpp:77] Creating layer map16_3_eltsum
I0420 13:58:46.135124 32892 net.cpp:84] Creating Layer map16_3_eltsum
I0420 13:58:46.135128 32892 net.cpp:406] map16_3_eltsum <- map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0420 13:58:46.135133 32892 net.cpp:406] map16_3_eltsum <- map16_3_conv_b
I0420 13:58:46.135138 32892 net.cpp:380] map16_3_eltsum -> map16_3_eltsum
I0420 13:58:46.135164 32892 net.cpp:122] Setting up map16_3_eltsum
I0420 13:58:46.135169 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.135172 32892 net.cpp:137] Memory required for data: 237160000
I0420 13:58:46.135174 32892 layer_factory.hpp:77] Creating layer map16_3_relu_after_sum
I0420 13:58:46.135179 32892 net.cpp:84] Creating Layer map16_3_relu_after_sum
I0420 13:58:46.135182 32892 net.cpp:406] map16_3_relu_after_sum <- map16_3_eltsum
I0420 13:58:46.135187 32892 net.cpp:367] map16_3_relu_after_sum -> map16_3_eltsum (in-place)
I0420 13:58:46.135354 32892 net.cpp:122] Setting up map16_3_relu_after_sum
I0420 13:58:46.135362 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.135365 32892 net.cpp:137] Memory required for data: 243713600
I0420 13:58:46.135368 32892 layer_factory.hpp:77] Creating layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 13:58:46.135375 32892 net.cpp:84] Creating Layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 13:58:46.135380 32892 net.cpp:406] map16_3_eltsum_map16_3_relu_after_sum_0_split <- map16_3_eltsum
I0420 13:58:46.135383 32892 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0420 13:58:46.135390 32892 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0420 13:58:46.135432 32892 net.cpp:122] Setting up map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 13:58:46.135437 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.135440 32892 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 13:58:46.135442 32892 net.cpp:137] Memory required for data: 256820800
I0420 13:58:46.135445 32892 layer_factory.hpp:77] Creating layer map32_1_conv_proj
I0420 13:58:46.135458 32892 net.cpp:84] Creating Layer map32_1_conv_proj
I0420 13:58:46.135462 32892 net.cpp:406] map32_1_conv_proj <- map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0420 13:58:46.135469 32892 net.cpp:380] map32_1_conv_proj -> map32_1_conv_proj
I0420 13:58:46.136505 32892 net.cpp:122] Setting up map32_1_conv_proj
I0420 13:58:46.136518 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.136521 32892 net.cpp:137] Memory required for data: 260097600
I0420 13:58:46.136528 32892 layer_factory.hpp:77] Creating layer map32_1_bn_proj
I0420 13:58:46.136536 32892 net.cpp:84] Creating Layer map32_1_bn_proj
I0420 13:58:46.136540 32892 net.cpp:406] map32_1_bn_proj <- map32_1_conv_proj
I0420 13:58:46.136548 32892 net.cpp:367] map32_1_bn_proj -> map32_1_conv_proj (in-place)
I0420 13:58:46.136739 32892 net.cpp:122] Setting up map32_1_bn_proj
I0420 13:58:46.136746 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.136749 32892 net.cpp:137] Memory required for data: 263374400
I0420 13:58:46.136755 32892 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0420 13:58:46.136761 32892 net.cpp:84] Creating Layer map32_1_scale_proj
I0420 13:58:46.136765 32892 net.cpp:406] map32_1_scale_proj <- map32_1_conv_proj
I0420 13:58:46.136770 32892 net.cpp:367] map32_1_scale_proj -> map32_1_conv_proj (in-place)
I0420 13:58:46.136808 32892 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0420 13:58:46.136919 32892 net.cpp:122] Setting up map32_1_scale_proj
I0420 13:58:46.136924 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.136927 32892 net.cpp:137] Memory required for data: 266651200
I0420 13:58:46.136932 32892 layer_factory.hpp:77] Creating layer map32_1_conv_a
I0420 13:58:46.136941 32892 net.cpp:84] Creating Layer map32_1_conv_a
I0420 13:58:46.136945 32892 net.cpp:406] map32_1_conv_a <- map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0420 13:58:46.136963 32892 net.cpp:380] map32_1_conv_a -> map32_1_conv_a
I0420 13:58:46.138924 32892 net.cpp:122] Setting up map32_1_conv_a
I0420 13:58:46.138938 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.138942 32892 net.cpp:137] Memory required for data: 269928000
I0420 13:58:46.138948 32892 layer_factory.hpp:77] Creating layer map32_1_bn_a
I0420 13:58:46.138955 32892 net.cpp:84] Creating Layer map32_1_bn_a
I0420 13:58:46.138960 32892 net.cpp:406] map32_1_bn_a <- map32_1_conv_a
I0420 13:58:46.138968 32892 net.cpp:367] map32_1_bn_a -> map32_1_conv_a (in-place)
I0420 13:58:46.139163 32892 net.cpp:122] Setting up map32_1_bn_a
I0420 13:58:46.139169 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.139173 32892 net.cpp:137] Memory required for data: 273204800
I0420 13:58:46.139178 32892 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0420 13:58:46.139184 32892 net.cpp:84] Creating Layer map32_1_scale_a
I0420 13:58:46.139189 32892 net.cpp:406] map32_1_scale_a <- map32_1_conv_a
I0420 13:58:46.139192 32892 net.cpp:367] map32_1_scale_a -> map32_1_conv_a (in-place)
I0420 13:58:46.139235 32892 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0420 13:58:46.139349 32892 net.cpp:122] Setting up map32_1_scale_a
I0420 13:58:46.139356 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.139358 32892 net.cpp:137] Memory required for data: 276481600
I0420 13:58:46.139364 32892 layer_factory.hpp:77] Creating layer map32_1_relu_a
I0420 13:58:46.139370 32892 net.cpp:84] Creating Layer map32_1_relu_a
I0420 13:58:46.139374 32892 net.cpp:406] map32_1_relu_a <- map32_1_conv_a
I0420 13:58:46.139379 32892 net.cpp:367] map32_1_relu_a -> map32_1_conv_a (in-place)
I0420 13:58:46.139551 32892 net.cpp:122] Setting up map32_1_relu_a
I0420 13:58:46.139559 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.139564 32892 net.cpp:137] Memory required for data: 279758400
I0420 13:58:46.139566 32892 layer_factory.hpp:77] Creating layer map32_1_conv_b
I0420 13:58:46.139576 32892 net.cpp:84] Creating Layer map32_1_conv_b
I0420 13:58:46.139580 32892 net.cpp:406] map32_1_conv_b <- map32_1_conv_a
I0420 13:58:46.139590 32892 net.cpp:380] map32_1_conv_b -> map32_1_conv_b
I0420 13:58:46.147148 32892 net.cpp:122] Setting up map32_1_conv_b
I0420 13:58:46.147161 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.147164 32892 net.cpp:137] Memory required for data: 283035200
I0420 13:58:46.147181 32892 layer_factory.hpp:77] Creating layer map32_1_bn_b
I0420 13:58:46.147193 32892 net.cpp:84] Creating Layer map32_1_bn_b
I0420 13:58:46.147197 32892 net.cpp:406] map32_1_bn_b <- map32_1_conv_b
I0420 13:58:46.147203 32892 net.cpp:367] map32_1_bn_b -> map32_1_conv_b (in-place)
I0420 13:58:46.147388 32892 net.cpp:122] Setting up map32_1_bn_b
I0420 13:58:46.147395 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.147398 32892 net.cpp:137] Memory required for data: 286312000
I0420 13:58:46.147404 32892 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0420 13:58:46.147413 32892 net.cpp:84] Creating Layer map32_1_scale_b
I0420 13:58:46.147416 32892 net.cpp:406] map32_1_scale_b <- map32_1_conv_b
I0420 13:58:46.147420 32892 net.cpp:367] map32_1_scale_b -> map32_1_conv_b (in-place)
I0420 13:58:46.147462 32892 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0420 13:58:46.147573 32892 net.cpp:122] Setting up map32_1_scale_b
I0420 13:58:46.147580 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.147583 32892 net.cpp:137] Memory required for data: 289588800
I0420 13:58:46.147588 32892 layer_factory.hpp:77] Creating layer map32_1_eltsum
I0420 13:58:46.147593 32892 net.cpp:84] Creating Layer map32_1_eltsum
I0420 13:58:46.147598 32892 net.cpp:406] map32_1_eltsum <- map32_1_conv_proj
I0420 13:58:46.147603 32892 net.cpp:406] map32_1_eltsum <- map32_1_conv_b
I0420 13:58:46.147608 32892 net.cpp:380] map32_1_eltsum -> map32_1_eltsum
I0420 13:58:46.147626 32892 net.cpp:122] Setting up map32_1_eltsum
I0420 13:58:46.147634 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.147650 32892 net.cpp:137] Memory required for data: 292865600
I0420 13:58:46.147653 32892 layer_factory.hpp:77] Creating layer map32_1_relu_after_sum
I0420 13:58:46.147658 32892 net.cpp:84] Creating Layer map32_1_relu_after_sum
I0420 13:58:46.147662 32892 net.cpp:406] map32_1_relu_after_sum <- map32_1_eltsum
I0420 13:58:46.147666 32892 net.cpp:367] map32_1_relu_after_sum -> map32_1_eltsum (in-place)
I0420 13:58:46.149466 32892 net.cpp:122] Setting up map32_1_relu_after_sum
I0420 13:58:46.149477 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.149479 32892 net.cpp:137] Memory required for data: 296142400
I0420 13:58:46.149482 32892 layer_factory.hpp:77] Creating layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 13:58:46.149488 32892 net.cpp:84] Creating Layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 13:58:46.149492 32892 net.cpp:406] map32_1_eltsum_map32_1_relu_after_sum_0_split <- map32_1_eltsum
I0420 13:58:46.149497 32892 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0420 13:58:46.149502 32892 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0420 13:58:46.149545 32892 net.cpp:122] Setting up map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 13:58:46.149551 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.149555 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.149557 32892 net.cpp:137] Memory required for data: 302696000
I0420 13:58:46.149560 32892 layer_factory.hpp:77] Creating layer map32_2_conv_a
I0420 13:58:46.149569 32892 net.cpp:84] Creating Layer map32_2_conv_a
I0420 13:58:46.149574 32892 net.cpp:406] map32_2_conv_a <- map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0420 13:58:46.149580 32892 net.cpp:380] map32_2_conv_a -> map32_2_conv_a
I0420 13:58:46.157009 32892 net.cpp:122] Setting up map32_2_conv_a
I0420 13:58:46.157022 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.157027 32892 net.cpp:137] Memory required for data: 305972800
I0420 13:58:46.157032 32892 layer_factory.hpp:77] Creating layer map32_2_bn_a
I0420 13:58:46.157042 32892 net.cpp:84] Creating Layer map32_2_bn_a
I0420 13:58:46.157045 32892 net.cpp:406] map32_2_bn_a <- map32_2_conv_a
I0420 13:58:46.157052 32892 net.cpp:367] map32_2_bn_a -> map32_2_conv_a (in-place)
I0420 13:58:46.157248 32892 net.cpp:122] Setting up map32_2_bn_a
I0420 13:58:46.157255 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.157258 32892 net.cpp:137] Memory required for data: 309249600
I0420 13:58:46.157264 32892 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0420 13:58:46.157270 32892 net.cpp:84] Creating Layer map32_2_scale_a
I0420 13:58:46.157274 32892 net.cpp:406] map32_2_scale_a <- map32_2_conv_a
I0420 13:58:46.157279 32892 net.cpp:367] map32_2_scale_a -> map32_2_conv_a (in-place)
I0420 13:58:46.157320 32892 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0420 13:58:46.157428 32892 net.cpp:122] Setting up map32_2_scale_a
I0420 13:58:46.157434 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.157438 32892 net.cpp:137] Memory required for data: 312526400
I0420 13:58:46.157443 32892 layer_factory.hpp:77] Creating layer map32_2_relu_a
I0420 13:58:46.157449 32892 net.cpp:84] Creating Layer map32_2_relu_a
I0420 13:58:46.157454 32892 net.cpp:406] map32_2_relu_a <- map32_2_conv_a
I0420 13:58:46.157457 32892 net.cpp:367] map32_2_relu_a -> map32_2_conv_a (in-place)
I0420 13:58:46.159106 32892 net.cpp:122] Setting up map32_2_relu_a
I0420 13:58:46.159114 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.159117 32892 net.cpp:137] Memory required for data: 315803200
I0420 13:58:46.159121 32892 layer_factory.hpp:77] Creating layer map32_2_conv_b
I0420 13:58:46.159132 32892 net.cpp:84] Creating Layer map32_2_conv_b
I0420 13:58:46.159137 32892 net.cpp:406] map32_2_conv_b <- map32_2_conv_a
I0420 13:58:46.159143 32892 net.cpp:380] map32_2_conv_b -> map32_2_conv_b
I0420 13:58:46.166671 32892 net.cpp:122] Setting up map32_2_conv_b
I0420 13:58:46.166697 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.166702 32892 net.cpp:137] Memory required for data: 319080000
I0420 13:58:46.166707 32892 layer_factory.hpp:77] Creating layer map32_2_bn_b
I0420 13:58:46.166718 32892 net.cpp:84] Creating Layer map32_2_bn_b
I0420 13:58:46.166721 32892 net.cpp:406] map32_2_bn_b <- map32_2_conv_b
I0420 13:58:46.166728 32892 net.cpp:367] map32_2_bn_b -> map32_2_conv_b (in-place)
I0420 13:58:46.166923 32892 net.cpp:122] Setting up map32_2_bn_b
I0420 13:58:46.166929 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.166932 32892 net.cpp:137] Memory required for data: 322356800
I0420 13:58:46.166939 32892 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0420 13:58:46.166946 32892 net.cpp:84] Creating Layer map32_2_scale_b
I0420 13:58:46.166950 32892 net.cpp:406] map32_2_scale_b <- map32_2_conv_b
I0420 13:58:46.166954 32892 net.cpp:367] map32_2_scale_b -> map32_2_conv_b (in-place)
I0420 13:58:46.166995 32892 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0420 13:58:46.167106 32892 net.cpp:122] Setting up map32_2_scale_b
I0420 13:58:46.167112 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.167115 32892 net.cpp:137] Memory required for data: 325633600
I0420 13:58:46.167120 32892 layer_factory.hpp:77] Creating layer map32_2_eltsum
I0420 13:58:46.167126 32892 net.cpp:84] Creating Layer map32_2_eltsum
I0420 13:58:46.167130 32892 net.cpp:406] map32_2_eltsum <- map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0420 13:58:46.167134 32892 net.cpp:406] map32_2_eltsum <- map32_2_conv_b
I0420 13:58:46.167140 32892 net.cpp:380] map32_2_eltsum -> map32_2_eltsum
I0420 13:58:46.167158 32892 net.cpp:122] Setting up map32_2_eltsum
I0420 13:58:46.167165 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.167167 32892 net.cpp:137] Memory required for data: 328910400
I0420 13:58:46.167170 32892 layer_factory.hpp:77] Creating layer map32_2_relu_after_sum
I0420 13:58:46.167176 32892 net.cpp:84] Creating Layer map32_2_relu_after_sum
I0420 13:58:46.167181 32892 net.cpp:406] map32_2_relu_after_sum <- map32_2_eltsum
I0420 13:58:46.167183 32892 net.cpp:367] map32_2_relu_after_sum -> map32_2_eltsum (in-place)
I0420 13:58:46.168848 32892 net.cpp:122] Setting up map32_2_relu_after_sum
I0420 13:58:46.168856 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.168859 32892 net.cpp:137] Memory required for data: 332187200
I0420 13:58:46.168862 32892 layer_factory.hpp:77] Creating layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 13:58:46.168869 32892 net.cpp:84] Creating Layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 13:58:46.168874 32892 net.cpp:406] map32_2_eltsum_map32_2_relu_after_sum_0_split <- map32_2_eltsum
I0420 13:58:46.168879 32892 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0420 13:58:46.168889 32892 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0420 13:58:46.168931 32892 net.cpp:122] Setting up map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 13:58:46.168937 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.168941 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.168943 32892 net.cpp:137] Memory required for data: 338740800
I0420 13:58:46.168946 32892 layer_factory.hpp:77] Creating layer map32_3_conv_a
I0420 13:58:46.168958 32892 net.cpp:84] Creating Layer map32_3_conv_a
I0420 13:58:46.168962 32892 net.cpp:406] map32_3_conv_a <- map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0420 13:58:46.168967 32892 net.cpp:380] map32_3_conv_a -> map32_3_conv_a
I0420 13:58:46.176262 32892 net.cpp:122] Setting up map32_3_conv_a
I0420 13:58:46.176275 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.176280 32892 net.cpp:137] Memory required for data: 342017600
I0420 13:58:46.176285 32892 layer_factory.hpp:77] Creating layer map32_3_bn_a
I0420 13:58:46.176293 32892 net.cpp:84] Creating Layer map32_3_bn_a
I0420 13:58:46.176308 32892 net.cpp:406] map32_3_bn_a <- map32_3_conv_a
I0420 13:58:46.176316 32892 net.cpp:367] map32_3_bn_a -> map32_3_conv_a (in-place)
I0420 13:58:46.176512 32892 net.cpp:122] Setting up map32_3_bn_a
I0420 13:58:46.176518 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.176522 32892 net.cpp:137] Memory required for data: 345294400
I0420 13:58:46.176527 32892 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0420 13:58:46.176535 32892 net.cpp:84] Creating Layer map32_3_scale_a
I0420 13:58:46.176539 32892 net.cpp:406] map32_3_scale_a <- map32_3_conv_a
I0420 13:58:46.176543 32892 net.cpp:367] map32_3_scale_a -> map32_3_conv_a (in-place)
I0420 13:58:46.176584 32892 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0420 13:58:46.176702 32892 net.cpp:122] Setting up map32_3_scale_a
I0420 13:58:46.176708 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.176712 32892 net.cpp:137] Memory required for data: 348571200
I0420 13:58:46.176717 32892 layer_factory.hpp:77] Creating layer map32_3_relu_a
I0420 13:58:46.176723 32892 net.cpp:84] Creating Layer map32_3_relu_a
I0420 13:58:46.176726 32892 net.cpp:406] map32_3_relu_a <- map32_3_conv_a
I0420 13:58:46.176731 32892 net.cpp:367] map32_3_relu_a -> map32_3_conv_a (in-place)
I0420 13:58:46.178632 32892 net.cpp:122] Setting up map32_3_relu_a
I0420 13:58:46.178643 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.178647 32892 net.cpp:137] Memory required for data: 351848000
I0420 13:58:46.178650 32892 layer_factory.hpp:77] Creating layer map32_3_conv_b
I0420 13:58:46.178668 32892 net.cpp:84] Creating Layer map32_3_conv_b
I0420 13:58:46.178671 32892 net.cpp:406] map32_3_conv_b <- map32_3_conv_a
I0420 13:58:46.178678 32892 net.cpp:380] map32_3_conv_b -> map32_3_conv_b
I0420 13:58:46.186049 32892 net.cpp:122] Setting up map32_3_conv_b
I0420 13:58:46.186064 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.186066 32892 net.cpp:137] Memory required for data: 355124800
I0420 13:58:46.186074 32892 layer_factory.hpp:77] Creating layer map32_3_bn_b
I0420 13:58:46.186081 32892 net.cpp:84] Creating Layer map32_3_bn_b
I0420 13:58:46.186085 32892 net.cpp:406] map32_3_bn_b <- map32_3_conv_b
I0420 13:58:46.186091 32892 net.cpp:367] map32_3_bn_b -> map32_3_conv_b (in-place)
I0420 13:58:46.186291 32892 net.cpp:122] Setting up map32_3_bn_b
I0420 13:58:46.186298 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.186301 32892 net.cpp:137] Memory required for data: 358401600
I0420 13:58:46.186307 32892 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0420 13:58:46.186314 32892 net.cpp:84] Creating Layer map32_3_scale_b
I0420 13:58:46.186318 32892 net.cpp:406] map32_3_scale_b <- map32_3_conv_b
I0420 13:58:46.186321 32892 net.cpp:367] map32_3_scale_b -> map32_3_conv_b (in-place)
I0420 13:58:46.186362 32892 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0420 13:58:46.186473 32892 net.cpp:122] Setting up map32_3_scale_b
I0420 13:58:46.186480 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.186482 32892 net.cpp:137] Memory required for data: 361678400
I0420 13:58:46.186487 32892 layer_factory.hpp:77] Creating layer map32_3_eltsum
I0420 13:58:46.186493 32892 net.cpp:84] Creating Layer map32_3_eltsum
I0420 13:58:46.186496 32892 net.cpp:406] map32_3_eltsum <- map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0420 13:58:46.186501 32892 net.cpp:406] map32_3_eltsum <- map32_3_conv_b
I0420 13:58:46.186507 32892 net.cpp:380] map32_3_eltsum -> map32_3_eltsum
I0420 13:58:46.186527 32892 net.cpp:122] Setting up map32_3_eltsum
I0420 13:58:46.186532 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.186534 32892 net.cpp:137] Memory required for data: 364955200
I0420 13:58:46.186537 32892 layer_factory.hpp:77] Creating layer map32_3_relu_after_sum
I0420 13:58:46.186542 32892 net.cpp:84] Creating Layer map32_3_relu_after_sum
I0420 13:58:46.186544 32892 net.cpp:406] map32_3_relu_after_sum <- map32_3_eltsum
I0420 13:58:46.186550 32892 net.cpp:367] map32_3_relu_after_sum -> map32_3_eltsum (in-place)
I0420 13:58:46.188221 32892 net.cpp:122] Setting up map32_3_relu_after_sum
I0420 13:58:46.188230 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.188232 32892 net.cpp:137] Memory required for data: 368232000
I0420 13:58:46.188235 32892 layer_factory.hpp:77] Creating layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 13:58:46.188244 32892 net.cpp:84] Creating Layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 13:58:46.188247 32892 net.cpp:406] map32_3_eltsum_map32_3_relu_after_sum_0_split <- map32_3_eltsum
I0420 13:58:46.188252 32892 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0420 13:58:46.188258 32892 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0420 13:58:46.188302 32892 net.cpp:122] Setting up map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 13:58:46.188308 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.188313 32892 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 13:58:46.188314 32892 net.cpp:137] Memory required for data: 374785600
I0420 13:58:46.188318 32892 layer_factory.hpp:77] Creating layer map64_1_conv_proj
I0420 13:58:46.188326 32892 net.cpp:84] Creating Layer map64_1_conv_proj
I0420 13:58:46.188330 32892 net.cpp:406] map64_1_conv_proj <- map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0420 13:58:46.188338 32892 net.cpp:380] map64_1_conv_proj -> map64_1_conv_proj
I0420 13:58:46.195638 32892 net.cpp:122] Setting up map64_1_conv_proj
I0420 13:58:46.195650 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.195653 32892 net.cpp:137] Memory required for data: 376424000
I0420 13:58:46.195659 32892 layer_factory.hpp:77] Creating layer map64_1_bn_proj
I0420 13:58:46.195669 32892 net.cpp:84] Creating Layer map64_1_bn_proj
I0420 13:58:46.195673 32892 net.cpp:406] map64_1_bn_proj <- map64_1_conv_proj
I0420 13:58:46.195679 32892 net.cpp:367] map64_1_bn_proj -> map64_1_conv_proj (in-place)
I0420 13:58:46.195888 32892 net.cpp:122] Setting up map64_1_bn_proj
I0420 13:58:46.195894 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.195897 32892 net.cpp:137] Memory required for data: 378062400
I0420 13:58:46.195904 32892 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0420 13:58:46.195910 32892 net.cpp:84] Creating Layer map64_1_scale_proj
I0420 13:58:46.195914 32892 net.cpp:406] map64_1_scale_proj <- map64_1_conv_proj
I0420 13:58:46.195917 32892 net.cpp:367] map64_1_scale_proj -> map64_1_conv_proj (in-place)
I0420 13:58:46.195960 32892 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0420 13:58:46.196079 32892 net.cpp:122] Setting up map64_1_scale_proj
I0420 13:58:46.196086 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.196089 32892 net.cpp:137] Memory required for data: 379700800
I0420 13:58:46.196094 32892 layer_factory.hpp:77] Creating layer map64_1_conv_a
I0420 13:58:46.196107 32892 net.cpp:84] Creating Layer map64_1_conv_a
I0420 13:58:46.196111 32892 net.cpp:406] map64_1_conv_a <- map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0420 13:58:46.196118 32892 net.cpp:380] map64_1_conv_a -> map64_1_conv_a
I0420 13:58:46.203061 32892 net.cpp:122] Setting up map64_1_conv_a
I0420 13:58:46.203074 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.203078 32892 net.cpp:137] Memory required for data: 381339200
I0420 13:58:46.203083 32892 layer_factory.hpp:77] Creating layer map64_1_bn_a
I0420 13:58:46.203092 32892 net.cpp:84] Creating Layer map64_1_bn_a
I0420 13:58:46.203097 32892 net.cpp:406] map64_1_bn_a <- map64_1_conv_a
I0420 13:58:46.203104 32892 net.cpp:367] map64_1_bn_a -> map64_1_conv_a (in-place)
I0420 13:58:46.203303 32892 net.cpp:122] Setting up map64_1_bn_a
I0420 13:58:46.203310 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.203313 32892 net.cpp:137] Memory required for data: 382977600
I0420 13:58:46.203320 32892 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0420 13:58:46.203339 32892 net.cpp:84] Creating Layer map64_1_scale_a
I0420 13:58:46.203343 32892 net.cpp:406] map64_1_scale_a <- map64_1_conv_a
I0420 13:58:46.203348 32892 net.cpp:367] map64_1_scale_a -> map64_1_conv_a (in-place)
I0420 13:58:46.203392 32892 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0420 13:58:46.203507 32892 net.cpp:122] Setting up map64_1_scale_a
I0420 13:58:46.203513 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.203516 32892 net.cpp:137] Memory required for data: 384616000
I0420 13:58:46.203521 32892 layer_factory.hpp:77] Creating layer map64_1_relu_a
I0420 13:58:46.203529 32892 net.cpp:84] Creating Layer map64_1_relu_a
I0420 13:58:46.203532 32892 net.cpp:406] map64_1_relu_a <- map64_1_conv_a
I0420 13:58:46.203536 32892 net.cpp:367] map64_1_relu_a -> map64_1_conv_a (in-place)
I0420 13:58:46.205413 32892 net.cpp:122] Setting up map64_1_relu_a
I0420 13:58:46.205421 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.205425 32892 net.cpp:137] Memory required for data: 386254400
I0420 13:58:46.205427 32892 layer_factory.hpp:77] Creating layer map64_1_conv_b
I0420 13:58:46.205445 32892 net.cpp:84] Creating Layer map64_1_conv_b
I0420 13:58:46.205448 32892 net.cpp:406] map64_1_conv_b <- map64_1_conv_a
I0420 13:58:46.205453 32892 net.cpp:380] map64_1_conv_b -> map64_1_conv_b
I0420 13:58:46.212903 32892 net.cpp:122] Setting up map64_1_conv_b
I0420 13:58:46.212915 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.212919 32892 net.cpp:137] Memory required for data: 387892800
I0420 13:58:46.212925 32892 layer_factory.hpp:77] Creating layer map64_1_bn_b
I0420 13:58:46.212935 32892 net.cpp:84] Creating Layer map64_1_bn_b
I0420 13:58:46.212939 32892 net.cpp:406] map64_1_bn_b <- map64_1_conv_b
I0420 13:58:46.212945 32892 net.cpp:367] map64_1_bn_b -> map64_1_conv_b (in-place)
I0420 13:58:46.213148 32892 net.cpp:122] Setting up map64_1_bn_b
I0420 13:58:46.213155 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.213158 32892 net.cpp:137] Memory required for data: 389531200
I0420 13:58:46.213165 32892 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0420 13:58:46.213172 32892 net.cpp:84] Creating Layer map64_1_scale_b
I0420 13:58:46.213176 32892 net.cpp:406] map64_1_scale_b <- map64_1_conv_b
I0420 13:58:46.213181 32892 net.cpp:367] map64_1_scale_b -> map64_1_conv_b (in-place)
I0420 13:58:46.213223 32892 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0420 13:58:46.213338 32892 net.cpp:122] Setting up map64_1_scale_b
I0420 13:58:46.213346 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.213348 32892 net.cpp:137] Memory required for data: 391169600
I0420 13:58:46.213353 32892 layer_factory.hpp:77] Creating layer map64_1_eltsum
I0420 13:58:46.213361 32892 net.cpp:84] Creating Layer map64_1_eltsum
I0420 13:58:46.213364 32892 net.cpp:406] map64_1_eltsum <- map64_1_conv_proj
I0420 13:58:46.213367 32892 net.cpp:406] map64_1_eltsum <- map64_1_conv_b
I0420 13:58:46.213372 32892 net.cpp:380] map64_1_eltsum -> map64_1_eltsum
I0420 13:58:46.213398 32892 net.cpp:122] Setting up map64_1_eltsum
I0420 13:58:46.213404 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.213407 32892 net.cpp:137] Memory required for data: 392808000
I0420 13:58:46.213409 32892 layer_factory.hpp:77] Creating layer map64_1_relu_after_sum
I0420 13:58:46.213413 32892 net.cpp:84] Creating Layer map64_1_relu_after_sum
I0420 13:58:46.213418 32892 net.cpp:406] map64_1_relu_after_sum <- map64_1_eltsum
I0420 13:58:46.213423 32892 net.cpp:367] map64_1_relu_after_sum -> map64_1_eltsum (in-place)
I0420 13:58:46.215241 32892 net.cpp:122] Setting up map64_1_relu_after_sum
I0420 13:58:46.215250 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.215253 32892 net.cpp:137] Memory required for data: 394446400
I0420 13:58:46.215256 32892 layer_factory.hpp:77] Creating layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 13:58:46.215265 32892 net.cpp:84] Creating Layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 13:58:46.215268 32892 net.cpp:406] map64_1_eltsum_map64_1_relu_after_sum_0_split <- map64_1_eltsum
I0420 13:58:46.215286 32892 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0420 13:58:46.215292 32892 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0420 13:58:46.215340 32892 net.cpp:122] Setting up map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 13:58:46.215347 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.215350 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.215353 32892 net.cpp:137] Memory required for data: 397723200
I0420 13:58:46.215356 32892 layer_factory.hpp:77] Creating layer map64_2_conv_a
I0420 13:58:46.215365 32892 net.cpp:84] Creating Layer map64_2_conv_a
I0420 13:58:46.215369 32892 net.cpp:406] map64_2_conv_a <- map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0420 13:58:46.215376 32892 net.cpp:380] map64_2_conv_a -> map64_2_conv_a
I0420 13:58:46.222811 32892 net.cpp:122] Setting up map64_2_conv_a
I0420 13:58:46.222823 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.222827 32892 net.cpp:137] Memory required for data: 399361600
I0420 13:58:46.222833 32892 layer_factory.hpp:77] Creating layer map64_2_bn_a
I0420 13:58:46.222843 32892 net.cpp:84] Creating Layer map64_2_bn_a
I0420 13:58:46.222847 32892 net.cpp:406] map64_2_bn_a <- map64_2_conv_a
I0420 13:58:46.222852 32892 net.cpp:367] map64_2_bn_a -> map64_2_conv_a (in-place)
I0420 13:58:46.223050 32892 net.cpp:122] Setting up map64_2_bn_a
I0420 13:58:46.223057 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.223060 32892 net.cpp:137] Memory required for data: 401000000
I0420 13:58:46.223067 32892 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0420 13:58:46.223073 32892 net.cpp:84] Creating Layer map64_2_scale_a
I0420 13:58:46.223076 32892 net.cpp:406] map64_2_scale_a <- map64_2_conv_a
I0420 13:58:46.223080 32892 net.cpp:367] map64_2_scale_a -> map64_2_conv_a (in-place)
I0420 13:58:46.223124 32892 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0420 13:58:46.223239 32892 net.cpp:122] Setting up map64_2_scale_a
I0420 13:58:46.223248 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.223251 32892 net.cpp:137] Memory required for data: 402638400
I0420 13:58:46.223256 32892 layer_factory.hpp:77] Creating layer map64_2_relu_a
I0420 13:58:46.223261 32892 net.cpp:84] Creating Layer map64_2_relu_a
I0420 13:58:46.223265 32892 net.cpp:406] map64_2_relu_a <- map64_2_conv_a
I0420 13:58:46.223269 32892 net.cpp:367] map64_2_relu_a -> map64_2_conv_a (in-place)
I0420 13:58:46.225036 32892 net.cpp:122] Setting up map64_2_relu_a
I0420 13:58:46.225046 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.225049 32892 net.cpp:137] Memory required for data: 404276800
I0420 13:58:46.225052 32892 layer_factory.hpp:77] Creating layer map64_2_conv_b
I0420 13:58:46.225064 32892 net.cpp:84] Creating Layer map64_2_conv_b
I0420 13:58:46.225067 32892 net.cpp:406] map64_2_conv_b <- map64_2_conv_a
I0420 13:58:46.225072 32892 net.cpp:380] map64_2_conv_b -> map64_2_conv_b
I0420 13:58:46.232378 32892 net.cpp:122] Setting up map64_2_conv_b
I0420 13:58:46.232393 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.232395 32892 net.cpp:137] Memory required for data: 405915200
I0420 13:58:46.232401 32892 layer_factory.hpp:77] Creating layer map64_2_bn_b
I0420 13:58:46.232409 32892 net.cpp:84] Creating Layer map64_2_bn_b
I0420 13:58:46.232414 32892 net.cpp:406] map64_2_bn_b <- map64_2_conv_b
I0420 13:58:46.232421 32892 net.cpp:367] map64_2_bn_b -> map64_2_conv_b (in-place)
I0420 13:58:46.232620 32892 net.cpp:122] Setting up map64_2_bn_b
I0420 13:58:46.232626 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.232630 32892 net.cpp:137] Memory required for data: 407553600
I0420 13:58:46.232648 32892 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0420 13:58:46.232656 32892 net.cpp:84] Creating Layer map64_2_scale_b
I0420 13:58:46.232661 32892 net.cpp:406] map64_2_scale_b <- map64_2_conv_b
I0420 13:58:46.232676 32892 net.cpp:367] map64_2_scale_b -> map64_2_conv_b (in-place)
I0420 13:58:46.232730 32892 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0420 13:58:46.232846 32892 net.cpp:122] Setting up map64_2_scale_b
I0420 13:58:46.232852 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.232856 32892 net.cpp:137] Memory required for data: 409192000
I0420 13:58:46.232861 32892 layer_factory.hpp:77] Creating layer map64_2_eltsum
I0420 13:58:46.232866 32892 net.cpp:84] Creating Layer map64_2_eltsum
I0420 13:58:46.232869 32892 net.cpp:406] map64_2_eltsum <- map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0420 13:58:46.232873 32892 net.cpp:406] map64_2_eltsum <- map64_2_conv_b
I0420 13:58:46.232878 32892 net.cpp:380] map64_2_eltsum -> map64_2_eltsum
I0420 13:58:46.232904 32892 net.cpp:122] Setting up map64_2_eltsum
I0420 13:58:46.232910 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.232913 32892 net.cpp:137] Memory required for data: 410830400
I0420 13:58:46.232915 32892 layer_factory.hpp:77] Creating layer map64_2_relu_after_sum
I0420 13:58:46.232919 32892 net.cpp:84] Creating Layer map64_2_relu_after_sum
I0420 13:58:46.232923 32892 net.cpp:406] map64_2_relu_after_sum <- map64_2_eltsum
I0420 13:58:46.232929 32892 net.cpp:367] map64_2_relu_after_sum -> map64_2_eltsum (in-place)
I0420 13:58:46.234335 32892 net.cpp:122] Setting up map64_2_relu_after_sum
I0420 13:58:46.234344 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.234346 32892 net.cpp:137] Memory required for data: 412468800
I0420 13:58:46.234349 32892 layer_factory.hpp:77] Creating layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 13:58:46.234354 32892 net.cpp:84] Creating Layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 13:58:46.234360 32892 net.cpp:406] map64_2_eltsum_map64_2_relu_after_sum_0_split <- map64_2_eltsum
I0420 13:58:46.234364 32892 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0420 13:58:46.234371 32892 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0420 13:58:46.234413 32892 net.cpp:122] Setting up map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 13:58:46.234419 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.234423 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.234426 32892 net.cpp:137] Memory required for data: 415745600
I0420 13:58:46.234429 32892 layer_factory.hpp:77] Creating layer map64_3_conv_a
I0420 13:58:46.234438 32892 net.cpp:84] Creating Layer map64_3_conv_a
I0420 13:58:46.234442 32892 net.cpp:406] map64_3_conv_a <- map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0420 13:58:46.234452 32892 net.cpp:380] map64_3_conv_a -> map64_3_conv_a
I0420 13:58:46.240288 32892 net.cpp:122] Setting up map64_3_conv_a
I0420 13:58:46.240303 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.240306 32892 net.cpp:137] Memory required for data: 417384000
I0420 13:58:46.240314 32892 layer_factory.hpp:77] Creating layer map64_3_bn_a
I0420 13:58:46.240324 32892 net.cpp:84] Creating Layer map64_3_bn_a
I0420 13:58:46.240327 32892 net.cpp:406] map64_3_bn_a <- map64_3_conv_a
I0420 13:58:46.240332 32892 net.cpp:367] map64_3_bn_a -> map64_3_conv_a (in-place)
I0420 13:58:46.240535 32892 net.cpp:122] Setting up map64_3_bn_a
I0420 13:58:46.240541 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.240545 32892 net.cpp:137] Memory required for data: 419022400
I0420 13:58:46.240550 32892 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0420 13:58:46.240556 32892 net.cpp:84] Creating Layer map64_3_scale_a
I0420 13:58:46.240561 32892 net.cpp:406] map64_3_scale_a <- map64_3_conv_a
I0420 13:58:46.240564 32892 net.cpp:367] map64_3_scale_a -> map64_3_conv_a (in-place)
I0420 13:58:46.240607 32892 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0420 13:58:46.240728 32892 net.cpp:122] Setting up map64_3_scale_a
I0420 13:58:46.240736 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.240749 32892 net.cpp:137] Memory required for data: 420660800
I0420 13:58:46.240756 32892 layer_factory.hpp:77] Creating layer map64_3_relu_a
I0420 13:58:46.240761 32892 net.cpp:84] Creating Layer map64_3_relu_a
I0420 13:58:46.240764 32892 net.cpp:406] map64_3_relu_a <- map64_3_conv_a
I0420 13:58:46.240770 32892 net.cpp:367] map64_3_relu_a -> map64_3_conv_a (in-place)
I0420 13:58:46.242285 32892 net.cpp:122] Setting up map64_3_relu_a
I0420 13:58:46.242297 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.242300 32892 net.cpp:137] Memory required for data: 422299200
I0420 13:58:46.242303 32892 layer_factory.hpp:77] Creating layer map64_3_conv_b
I0420 13:58:46.242316 32892 net.cpp:84] Creating Layer map64_3_conv_b
I0420 13:58:46.242319 32892 net.cpp:406] map64_3_conv_b <- map64_3_conv_a
I0420 13:58:46.242327 32892 net.cpp:380] map64_3_conv_b -> map64_3_conv_b
I0420 13:58:46.249601 32892 net.cpp:122] Setting up map64_3_conv_b
I0420 13:58:46.249614 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.249616 32892 net.cpp:137] Memory required for data: 423937600
I0420 13:58:46.249622 32892 layer_factory.hpp:77] Creating layer map64_3_bn_b
I0420 13:58:46.249630 32892 net.cpp:84] Creating Layer map64_3_bn_b
I0420 13:58:46.249634 32892 net.cpp:406] map64_3_bn_b <- map64_3_conv_b
I0420 13:58:46.249642 32892 net.cpp:367] map64_3_bn_b -> map64_3_conv_b (in-place)
I0420 13:58:46.249847 32892 net.cpp:122] Setting up map64_3_bn_b
I0420 13:58:46.249855 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.249857 32892 net.cpp:137] Memory required for data: 425576000
I0420 13:58:46.249863 32892 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0420 13:58:46.249871 32892 net.cpp:84] Creating Layer map64_3_scale_b
I0420 13:58:46.249874 32892 net.cpp:406] map64_3_scale_b <- map64_3_conv_b
I0420 13:58:46.249877 32892 net.cpp:367] map64_3_scale_b -> map64_3_conv_b (in-place)
I0420 13:58:46.249920 32892 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0420 13:58:46.250036 32892 net.cpp:122] Setting up map64_3_scale_b
I0420 13:58:46.250043 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.250046 32892 net.cpp:137] Memory required for data: 427214400
I0420 13:58:46.250051 32892 layer_factory.hpp:77] Creating layer map64_3_eltsum
I0420 13:58:46.250057 32892 net.cpp:84] Creating Layer map64_3_eltsum
I0420 13:58:46.250061 32892 net.cpp:406] map64_3_eltsum <- map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0420 13:58:46.250064 32892 net.cpp:406] map64_3_eltsum <- map64_3_conv_b
I0420 13:58:46.250069 32892 net.cpp:380] map64_3_eltsum -> map64_3_eltsum
I0420 13:58:46.250097 32892 net.cpp:122] Setting up map64_3_eltsum
I0420 13:58:46.250102 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.250105 32892 net.cpp:137] Memory required for data: 428852800
I0420 13:58:46.250108 32892 layer_factory.hpp:77] Creating layer map64_3_relu_after_sum
I0420 13:58:46.250113 32892 net.cpp:84] Creating Layer map64_3_relu_after_sum
I0420 13:58:46.250118 32892 net.cpp:406] map64_3_relu_after_sum <- map64_3_eltsum
I0420 13:58:46.250120 32892 net.cpp:367] map64_3_relu_after_sum -> map64_3_eltsum (in-place)
I0420 13:58:46.251840 32892 net.cpp:122] Setting up map64_3_relu_after_sum
I0420 13:58:46.251852 32892 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 13:58:46.251855 32892 net.cpp:137] Memory required for data: 430491200
I0420 13:58:46.251858 32892 layer_factory.hpp:77] Creating layer pool_global
I0420 13:58:46.251868 32892 net.cpp:84] Creating Layer pool_global
I0420 13:58:46.251871 32892 net.cpp:406] pool_global <- map64_3_eltsum
I0420 13:58:46.251878 32892 net.cpp:380] pool_global -> pool_global
I0420 13:58:46.254271 32892 net.cpp:122] Setting up pool_global
I0420 13:58:46.254279 32892 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0420 13:58:46.254283 32892 net.cpp:137] Memory required for data: 430516800
I0420 13:58:46.254287 32892 layer_factory.hpp:77] Creating layer score
I0420 13:58:46.254294 32892 net.cpp:84] Creating Layer score
I0420 13:58:46.254297 32892 net.cpp:406] score <- pool_global
I0420 13:58:46.254317 32892 net.cpp:380] score -> score
I0420 13:58:46.254443 32892 net.cpp:122] Setting up score
I0420 13:58:46.254451 32892 net.cpp:129] Top shape: 100 10 (1000)
I0420 13:58:46.254453 32892 net.cpp:137] Memory required for data: 430520800
I0420 13:58:46.254458 32892 layer_factory.hpp:77] Creating layer score_score_0_split
I0420 13:58:46.254467 32892 net.cpp:84] Creating Layer score_score_0_split
I0420 13:58:46.254470 32892 net.cpp:406] score_score_0_split <- score
I0420 13:58:46.254474 32892 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0420 13:58:46.254480 32892 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0420 13:58:46.254488 32892 net.cpp:380] score_score_0_split -> score_score_0_split_2
I0420 13:58:46.254536 32892 net.cpp:122] Setting up score_score_0_split
I0420 13:58:46.254542 32892 net.cpp:129] Top shape: 100 10 (1000)
I0420 13:58:46.254546 32892 net.cpp:129] Top shape: 100 10 (1000)
I0420 13:58:46.254549 32892 net.cpp:129] Top shape: 100 10 (1000)
I0420 13:58:46.254551 32892 net.cpp:137] Memory required for data: 430532800
I0420 13:58:46.254554 32892 layer_factory.hpp:77] Creating layer loss
I0420 13:58:46.254559 32892 net.cpp:84] Creating Layer loss
I0420 13:58:46.254562 32892 net.cpp:406] loss <- score_score_0_split_0
I0420 13:58:46.254566 32892 net.cpp:406] loss <- label_data_1_split_0
I0420 13:58:46.254572 32892 net.cpp:380] loss -> loss
I0420 13:58:46.254580 32892 layer_factory.hpp:77] Creating layer loss
I0420 13:58:46.256672 32892 net.cpp:122] Setting up loss
I0420 13:58:46.256685 32892 net.cpp:129] Top shape: (1)
I0420 13:58:46.256688 32892 net.cpp:132]     with loss weight 1
I0420 13:58:46.256698 32892 net.cpp:137] Memory required for data: 430532804
I0420 13:58:46.256701 32892 layer_factory.hpp:77] Creating layer acc/top1
I0420 13:58:46.256707 32892 net.cpp:84] Creating Layer acc/top1
I0420 13:58:46.256712 32892 net.cpp:406] acc/top1 <- score_score_0_split_1
I0420 13:58:46.256717 32892 net.cpp:406] acc/top1 <- label_data_1_split_1
I0420 13:58:46.256724 32892 net.cpp:380] acc/top1 -> acctop1
I0420 13:58:46.256733 32892 net.cpp:122] Setting up acc/top1
I0420 13:58:46.256738 32892 net.cpp:129] Top shape: (1)
I0420 13:58:46.256742 32892 net.cpp:137] Memory required for data: 430532808
I0420 13:58:46.256743 32892 layer_factory.hpp:77] Creating layer acc/top5
I0420 13:58:46.256747 32892 net.cpp:84] Creating Layer acc/top5
I0420 13:58:46.256752 32892 net.cpp:406] acc/top5 <- score_score_0_split_2
I0420 13:58:46.256754 32892 net.cpp:406] acc/top5 <- label_data_1_split_2
I0420 13:58:46.256760 32892 net.cpp:380] acc/top5 -> acctop5
I0420 13:58:46.256767 32892 net.cpp:122] Setting up acc/top5
I0420 13:58:46.256772 32892 net.cpp:129] Top shape: (1)
I0420 13:58:46.256773 32892 net.cpp:137] Memory required for data: 430532812
I0420 13:58:46.256778 32892 net.cpp:200] acc/top5 does not need backward computation.
I0420 13:58:46.256780 32892 net.cpp:200] acc/top1 does not need backward computation.
I0420 13:58:46.256783 32892 net.cpp:198] loss needs backward computation.
I0420 13:58:46.256786 32892 net.cpp:198] score_score_0_split needs backward computation.
I0420 13:58:46.256789 32892 net.cpp:198] score needs backward computation.
I0420 13:58:46.256793 32892 net.cpp:198] pool_global needs backward computation.
I0420 13:58:46.256795 32892 net.cpp:198] map64_3_relu_after_sum needs backward computation.
I0420 13:58:46.256798 32892 net.cpp:198] map64_3_eltsum needs backward computation.
I0420 13:58:46.256800 32892 net.cpp:198] map64_3_scale_b needs backward computation.
I0420 13:58:46.256803 32892 net.cpp:198] map64_3_bn_b needs backward computation.
I0420 13:58:46.256806 32892 net.cpp:198] map64_3_conv_b needs backward computation.
I0420 13:58:46.256808 32892 net.cpp:198] map64_3_relu_a needs backward computation.
I0420 13:58:46.256810 32892 net.cpp:198] map64_3_scale_a needs backward computation.
I0420 13:58:46.256814 32892 net.cpp:198] map64_3_bn_a needs backward computation.
I0420 13:58:46.256815 32892 net.cpp:198] map64_3_conv_a needs backward computation.
I0420 13:58:46.256832 32892 net.cpp:198] map64_2_eltsum_map64_2_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.256835 32892 net.cpp:198] map64_2_relu_after_sum needs backward computation.
I0420 13:58:46.256837 32892 net.cpp:198] map64_2_eltsum needs backward computation.
I0420 13:58:46.256840 32892 net.cpp:198] map64_2_scale_b needs backward computation.
I0420 13:58:46.256844 32892 net.cpp:198] map64_2_bn_b needs backward computation.
I0420 13:58:46.256845 32892 net.cpp:198] map64_2_conv_b needs backward computation.
I0420 13:58:46.256847 32892 net.cpp:198] map64_2_relu_a needs backward computation.
I0420 13:58:46.256850 32892 net.cpp:198] map64_2_scale_a needs backward computation.
I0420 13:58:46.256852 32892 net.cpp:198] map64_2_bn_a needs backward computation.
I0420 13:58:46.256855 32892 net.cpp:198] map64_2_conv_a needs backward computation.
I0420 13:58:46.256857 32892 net.cpp:198] map64_1_eltsum_map64_1_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.256860 32892 net.cpp:198] map64_1_relu_after_sum needs backward computation.
I0420 13:58:46.256862 32892 net.cpp:198] map64_1_eltsum needs backward computation.
I0420 13:58:46.256865 32892 net.cpp:198] map64_1_scale_b needs backward computation.
I0420 13:58:46.256868 32892 net.cpp:198] map64_1_bn_b needs backward computation.
I0420 13:58:46.256870 32892 net.cpp:198] map64_1_conv_b needs backward computation.
I0420 13:58:46.256873 32892 net.cpp:198] map64_1_relu_a needs backward computation.
I0420 13:58:46.256875 32892 net.cpp:198] map64_1_scale_a needs backward computation.
I0420 13:58:46.256877 32892 net.cpp:198] map64_1_bn_a needs backward computation.
I0420 13:58:46.256880 32892 net.cpp:198] map64_1_conv_a needs backward computation.
I0420 13:58:46.256882 32892 net.cpp:198] map64_1_scale_proj needs backward computation.
I0420 13:58:46.256884 32892 net.cpp:198] map64_1_bn_proj needs backward computation.
I0420 13:58:46.256887 32892 net.cpp:198] map64_1_conv_proj needs backward computation.
I0420 13:58:46.256889 32892 net.cpp:198] map32_3_eltsum_map32_3_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.256892 32892 net.cpp:198] map32_3_relu_after_sum needs backward computation.
I0420 13:58:46.256896 32892 net.cpp:198] map32_3_eltsum needs backward computation.
I0420 13:58:46.256898 32892 net.cpp:198] map32_3_scale_b needs backward computation.
I0420 13:58:46.256901 32892 net.cpp:198] map32_3_bn_b needs backward computation.
I0420 13:58:46.256902 32892 net.cpp:198] map32_3_conv_b needs backward computation.
I0420 13:58:46.256906 32892 net.cpp:198] map32_3_relu_a needs backward computation.
I0420 13:58:46.256907 32892 net.cpp:198] map32_3_scale_a needs backward computation.
I0420 13:58:46.256909 32892 net.cpp:198] map32_3_bn_a needs backward computation.
I0420 13:58:46.256913 32892 net.cpp:198] map32_3_conv_a needs backward computation.
I0420 13:58:46.256916 32892 net.cpp:198] map32_2_eltsum_map32_2_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.256917 32892 net.cpp:198] map32_2_relu_after_sum needs backward computation.
I0420 13:58:46.256920 32892 net.cpp:198] map32_2_eltsum needs backward computation.
I0420 13:58:46.256923 32892 net.cpp:198] map32_2_scale_b needs backward computation.
I0420 13:58:46.256927 32892 net.cpp:198] map32_2_bn_b needs backward computation.
I0420 13:58:46.256928 32892 net.cpp:198] map32_2_conv_b needs backward computation.
I0420 13:58:46.256932 32892 net.cpp:198] map32_2_relu_a needs backward computation.
I0420 13:58:46.256934 32892 net.cpp:198] map32_2_scale_a needs backward computation.
I0420 13:58:46.256937 32892 net.cpp:198] map32_2_bn_a needs backward computation.
I0420 13:58:46.256938 32892 net.cpp:198] map32_2_conv_a needs backward computation.
I0420 13:58:46.256940 32892 net.cpp:198] map32_1_eltsum_map32_1_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.256943 32892 net.cpp:198] map32_1_relu_after_sum needs backward computation.
I0420 13:58:46.256947 32892 net.cpp:198] map32_1_eltsum needs backward computation.
I0420 13:58:46.256949 32892 net.cpp:198] map32_1_scale_b needs backward computation.
I0420 13:58:46.256960 32892 net.cpp:198] map32_1_bn_b needs backward computation.
I0420 13:58:46.256963 32892 net.cpp:198] map32_1_conv_b needs backward computation.
I0420 13:58:46.256966 32892 net.cpp:198] map32_1_relu_a needs backward computation.
I0420 13:58:46.256968 32892 net.cpp:198] map32_1_scale_a needs backward computation.
I0420 13:58:46.256970 32892 net.cpp:198] map32_1_bn_a needs backward computation.
I0420 13:58:46.256973 32892 net.cpp:198] map32_1_conv_a needs backward computation.
I0420 13:58:46.256976 32892 net.cpp:198] map32_1_scale_proj needs backward computation.
I0420 13:58:46.256978 32892 net.cpp:198] map32_1_bn_proj needs backward computation.
I0420 13:58:46.256981 32892 net.cpp:198] map32_1_conv_proj needs backward computation.
I0420 13:58:46.256984 32892 net.cpp:198] map16_3_eltsum_map16_3_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.256988 32892 net.cpp:198] map16_3_relu_after_sum needs backward computation.
I0420 13:58:46.256989 32892 net.cpp:198] map16_3_eltsum needs backward computation.
I0420 13:58:46.256992 32892 net.cpp:198] map16_3_scale_b needs backward computation.
I0420 13:58:46.256994 32892 net.cpp:198] map16_3_bn_b needs backward computation.
I0420 13:58:46.256997 32892 net.cpp:198] map16_3_conv_b needs backward computation.
I0420 13:58:46.257000 32892 net.cpp:198] map16_3_relu_a needs backward computation.
I0420 13:58:46.257002 32892 net.cpp:198] map16_3_scale_a needs backward computation.
I0420 13:58:46.257005 32892 net.cpp:198] map16_3_bn_a needs backward computation.
I0420 13:58:46.257007 32892 net.cpp:198] map16_3_conv_a needs backward computation.
I0420 13:58:46.257010 32892 net.cpp:198] map16_2_eltsum_map16_2_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.257014 32892 net.cpp:198] map16_2_relu_after_sum needs backward computation.
I0420 13:58:46.257015 32892 net.cpp:198] map16_2_eltsum needs backward computation.
I0420 13:58:46.257019 32892 net.cpp:198] map16_2_scale_b needs backward computation.
I0420 13:58:46.257021 32892 net.cpp:198] map16_2_bn_b needs backward computation.
I0420 13:58:46.257024 32892 net.cpp:198] map16_2_conv_b needs backward computation.
I0420 13:58:46.257025 32892 net.cpp:198] map16_2_relu_a needs backward computation.
I0420 13:58:46.257028 32892 net.cpp:198] map16_2_scale_a needs backward computation.
I0420 13:58:46.257030 32892 net.cpp:198] map16_2_bn_a needs backward computation.
I0420 13:58:46.257032 32892 net.cpp:198] map16_2_conv_a needs backward computation.
I0420 13:58:46.257035 32892 net.cpp:198] map16_1_eltsum_map16_1_relu_after_sum_0_split needs backward computation.
I0420 13:58:46.257038 32892 net.cpp:198] map16_1_relu_after_sum needs backward computation.
I0420 13:58:46.257040 32892 net.cpp:198] map16_1_eltsum needs backward computation.
I0420 13:58:46.257045 32892 net.cpp:198] map16_1_scale_b needs backward computation.
I0420 13:58:46.257046 32892 net.cpp:198] map16_1_bn_b needs backward computation.
I0420 13:58:46.257050 32892 net.cpp:198] map16_1_conv_b needs backward computation.
I0420 13:58:46.257051 32892 net.cpp:198] map16_1_relu_a needs backward computation.
I0420 13:58:46.257055 32892 net.cpp:198] map16_1_scale_a needs backward computation.
I0420 13:58:46.257057 32892 net.cpp:198] map16_1_bn_a needs backward computation.
I0420 13:58:46.257060 32892 net.cpp:198] map16_1_conv_a needs backward computation.
I0420 13:58:46.257064 32892 net.cpp:198] conv1_relu_conv1_0_split needs backward computation.
I0420 13:58:46.257068 32892 net.cpp:198] relu_conv1 needs backward computation.
I0420 13:58:46.257071 32892 net.cpp:198] scale_conv1 needs backward computation.
I0420 13:58:46.257074 32892 net.cpp:198] bn_conv1 needs backward computation.
I0420 13:58:46.257076 32892 net.cpp:198] conv1 needs backward computation.
I0420 13:58:46.257081 32892 net.cpp:200] label_data_1_split does not need backward computation.
I0420 13:58:46.257084 32892 net.cpp:200] data does not need backward computation.
I0420 13:58:46.257086 32892 net.cpp:242] This network produces output acctop1
I0420 13:58:46.257095 32892 net.cpp:242] This network produces output acctop5
I0420 13:58:46.257098 32892 net.cpp:242] This network produces output loss
I0420 13:58:46.257151 32892 net.cpp:255] Network initialization done.
I0420 13:58:46.257462 32892 solver.cpp:56] Solver scaffolding done.
I0420 13:58:46.262622 32892 caffe.cpp:155] Finetuning from model/ResNet20_finetune_quant_0.09_iter_10000.solverstate
F0420 13:58:46.264183 32892 upgrade_proto.cpp:95] Check failed: ReadProtoFromBinaryFile(param_file, param) Failed to parse NetParameter file: model/ResNet20_finetune_quant_0.09_iter_10000.solverstate
*** Check failure stack trace: ***
    @     0x2ac018dee14d  google::LogMessage::Fail()
    @     0x2ac018deffcf  google::LogMessage::SendToLog()
    @     0x2ac018dedce3  google::LogMessage::Flush()
    @     0x2ac018df08ee  google::LogMessageFatal::~LogMessageFatal()
    @     0x2ac01180b8ee  caffe::ReadNetParamsFromBinaryFileOrDie()
    @     0x2ac011943ae7  caffe::Net<>::CopyTrainedLayersFromBinaryProto()
    @     0x2ac011943b88  caffe::Net<>::CopyTrainedLayersFrom()
    @           0x40aa35  CopyLayers()
    @           0x40ca03  train()
    @           0x40997c  main
    @     0x2ac026ba7b35  __libc_start_main
    @           0x40a3d3  (unknown)
I0420 14:16:47.186414 38983 caffe.cpp:218] Using GPUs 0
I0420 14:16:47.192348 38983 caffe.cpp:223] GPU 0: Tesla P100-PCIE-16GB
I0420 14:16:48.049671 38983 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "model/ResNet20_finetune_quant_0.09"
solver_mode: GPU
device_id: 0
net: "resnet20_relu_msra_cifar10_fix_pattern.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 12000
stepvalue: 24000
I0420 14:16:48.052359 38983 solver.cpp:87] Creating training net from net file: resnet20_relu_msra_cifar10_fix_pattern.prototxt
I0420 14:16:48.054903 38983 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet20_relu_msra_cifar10_fix_pattern.prototxt
I0420 14:16:48.054914 38983 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0420 14:16:48.055155 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0420 14:16:48.055166 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv1
I0420 14:16:48.055173 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_1_bn_a
I0420 14:16:48.055181 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_1_bn_b
I0420 14:16:48.055191 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_2_bn_a
I0420 14:16:48.055197 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_2_bn_b
I0420 14:16:48.055202 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_3_bn_a
I0420 14:16:48.055209 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_3_bn_b
I0420 14:16:48.055214 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_proj
I0420 14:16:48.055219 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_a
I0420 14:16:48.055224 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_b
I0420 14:16:48.055229 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_2_bn_a
I0420 14:16:48.055234 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_2_bn_b
I0420 14:16:48.055239 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_3_bn_a
I0420 14:16:48.055244 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_3_bn_b
I0420 14:16:48.055249 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_proj
I0420 14:16:48.055253 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_a
I0420 14:16:48.055261 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_b
I0420 14:16:48.055268 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_2_bn_a
I0420 14:16:48.055272 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_2_bn_b
I0420 14:16:48.055277 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_3_bn_a
I0420 14:16:48.055282 38983 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_3_bn_b
I0420 14:16:48.055796 38983 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
    mean_file: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/paddedmean.binaryproto"
  }
  data_param {
    source: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_full_train_leveldb_padded/"
    batch_size: 128
    backend: LEVELDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "map16_1_conv_a"
  type: "Convolution"
  bottom: "conv1"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_a"
  type: "BatchNorm"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_1_scale_a"
  type: "Scale"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_relu_a"
  type: "ReLU"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
}
layer {
  name: "map16_1_conv_b"
  type: "Convolution"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_b"
  type: "BatchNorm"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_1_scale_b"
  type: "Scale"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_eltsum"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "map16_1_conv_b"
  top: "map16_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_1_relu_after_sum"
  type: "ReLU"
  bottom: "map16_1_eltsum"
  top: "map16_1_eltsum"
}
layer {
  name: "map16_2_conv_a"
  type: "Convolution"
  bottom: "map16_1_eltsum"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_a"
  type: "BatchNorm"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_2_scale_a"
  type: "Scale"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_relu_a"
  type: "ReLU"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
}
layer {
  name: "map16_2_conv_b"
  type: "Convolution"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_b"
  type: "BatchNorm"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_2_scale_b"
  type: "Scale"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_eltsum"
  type: "Eltwise"
  bottom: "map16_1_eltsum"
  bottom: "map16_2_conv_b"
  top: "map16_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_2_relu_after_sum"
  type: "ReLU"
  bottom: "map16_2_eltsum"
  top: "map16_2_eltsum"
}
layer {
  name: "map16_3_conv_a"
  type: "Convolution"
  bottom: "map16_2_eltsum"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_a"
  type: "BatchNorm"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_3_scale_a"
  type: "Scale"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_relu_a"
  type: "ReLU"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
}
layer {
  name: "map16_3_conv_b"
  type: "Convolution"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_b"
  type: "BatchNorm"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_3_scale_b"
  type: "Scale"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_eltsum"
  type: "Eltwise"
  bottom: "map16_2_eltsum"
  bottom: "map16_3_conv_b"
  top: "map16_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_3_relu_after_sum"
  type: "ReLU"
  bottom: "map16_3_eltsum"
  top: "map16_3_eltsum"
}
layer {
  name: "map32_1_conv_proj"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_proj"
  type: "BatchNorm"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_proj"
  type: "Scale"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_conv_a"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_a"
  type: "BatchNorm"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_a"
  type: "Scale"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_relu_a"
  type: "ReLU"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
}
layer {
  name: "map32_1_conv_b"
  type: "Convolution"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_b"
  type: "BatchNorm"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_b"
  type: "Scale"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_eltsum"
  type: "Eltwise"
  bottom: "map32_1_conv_proj"
  bottom: "map32_1_conv_b"
  top: "map32_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_1_relu_after_sum"
  type: "ReLU"
  bottom: "map32_1_eltsum"
  top: "map32_1_eltsum"
}
layer {
  name: "map32_2_conv_a"
  type: "Convolution"
  bottom: "map32_1_eltsum"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_a"
  type: "BatchNorm"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_2_scale_a"
  type: "Scale"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_relu_a"
  type: "ReLU"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
}
layer {
  name: "map32_2_conv_b"
  type: "Convolution"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_b"
  type: "BatchNorm"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_2_scale_b"
  type: "Scale"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_eltsum"
  type: "Eltwise"
  bottom: "map32_1_eltsum"
  bottom: "map32_2_conv_b"
  top: "map32_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_2_relu_after_sum"
  type: "ReLU"
  bottom: "map32_2_eltsum"
  top: "map32_2_eltsum"
}
layer {
  name: "map32_3_conv_a"
  type: "Convolution"
  bottom: "map32_2_eltsum"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_a"
  type: "BatchNorm"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_3_scale_a"
  type: "Scale"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_relu_a"
  type: "ReLU"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
}
layer {
  name: "map32_3_conv_b"
  type: "Convolution"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_b"
  type: "BatchNorm"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_3_scale_b"
  type: "Scale"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_eltsum"
  type: "Eltwise"
  bottom: "map32_2_eltsum"
  bottom: "map32_3_conv_b"
  top: "map32_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_3_relu_after_sum"
  type: "ReLU"
  bottom: "map32_3_eltsum"
  top: "map32_3_eltsum"
}
layer {
  name: "map64_1_conv_proj"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_proj"
  type: "BatchNorm"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_proj"
  type: "Scale"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_conv_a"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_a"
  type: "BatchNorm"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_a"
  type: "Scale"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_relu_a"
  type: "ReLU"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
}
layer {
  name: "map64_1_conv_b"
  type: "Convolution"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_b"
  type: "BatchNorm"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_b"
  type: "Scale"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_eltsum"
  type: "Eltwise"
  bottom: "map64_1_conv_proj"
  bottom: "map64_1_conv_b"
  top: "map64_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_1_relu_after_sum"
  type: "ReLU"
  bottom: "map64_1_eltsum"
  top: "map64_1_eltsum"
}
layer {
  name: "map64_2_conv_a"
  type: "Convolution"
  bottom: "map64_1_eltsum"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_a"
  type: "BatchNorm"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_2_scale_a"
  type: "Scale"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_relu_a"
  type: "ReLU"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
}
layer {
  name: "map64_2_conv_b"
  type: "Convolution"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_b"
  type: "BatchNorm"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_2_scale_b"
  type: "Scale"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_eltsum"
  type: "Eltwise"
  bottom: "map64_1_eltsum"
  bottom: "map64_2_conv_b"
  top: "map64_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_2_relu_after_sum"
  type: "ReLU"
  bottom: "map64_2_eltsum"
  top: "map64_2_eltsum"
}
layer {
  name: "map64_3_conv_a"
  type: "Convolution"
  bottom: "map64_2_eltsum"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_a"
  type: "BatchNorm"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_3_scale_a"
  type: "Scale"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_relu_a"
  type: "ReLU"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
}
layer {
  name: "map64_3_conv_b"
  type: "Convolution"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_b"
  type: "BatchNorm"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_3_scale_b"
  type: "Scale"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_eltsum"
  type: "Eltwise"
  bottom: "map64_2_eltsum"
  bottom: "map64_3_conv_b"
  top: "map64_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_3_relu_after_sum"
  type: "ReLU"
  bottom: "map64_3_eltsum"
  top: "map64_3_eltsum"
}
layer {
  name: "pool_global"
  type: "Pooling"
  bottom: "map64_3_eltsum"
  top: "pool_global"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_global"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc/top1"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc/top5"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop5"
  accuracy_param {
    top_k: 5
  }
}
I0420 14:16:48.056239 38983 layer_factory.hpp:77] Creating layer data
I0420 14:16:48.094576 38983 db_leveldb.cpp:18] Opened leveldb /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_full_train_leveldb_padded/
I0420 14:16:48.095685 38983 net.cpp:84] Creating Layer data
I0420 14:16:48.095716 38983 net.cpp:380] data -> data
I0420 14:16:48.095749 38983 net.cpp:380] data -> label
I0420 14:16:48.095767 38983 data_transformer.cpp:25] Loading mean file from: /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/paddedmean.binaryproto
I0420 14:16:48.098837 38983 data_layer.cpp:45] output data size: 128,3,32,32
I0420 14:16:48.122117 38983 net.cpp:122] Setting up data
I0420 14:16:48.122148 38983 net.cpp:129] Top shape: 128 3 32 32 (393216)
I0420 14:16:48.122151 38983 net.cpp:129] Top shape: 128 (128)
I0420 14:16:48.122154 38983 net.cpp:137] Memory required for data: 1573376
I0420 14:16:48.122162 38983 layer_factory.hpp:77] Creating layer label_data_1_split
I0420 14:16:48.122228 38983 net.cpp:84] Creating Layer label_data_1_split
I0420 14:16:48.122243 38983 net.cpp:406] label_data_1_split <- label
I0420 14:16:48.122256 38983 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0420 14:16:48.122265 38983 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0420 14:16:48.122272 38983 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0420 14:16:48.122386 38983 net.cpp:122] Setting up label_data_1_split
I0420 14:16:48.122395 38983 net.cpp:129] Top shape: 128 (128)
I0420 14:16:48.122397 38983 net.cpp:129] Top shape: 128 (128)
I0420 14:16:48.122416 38983 net.cpp:129] Top shape: 128 (128)
I0420 14:16:48.122419 38983 net.cpp:137] Memory required for data: 1574912
I0420 14:16:48.122422 38983 layer_factory.hpp:77] Creating layer conv1
I0420 14:16:48.122438 38983 net.cpp:84] Creating Layer conv1
I0420 14:16:48.122442 38983 net.cpp:406] conv1 <- data
I0420 14:16:48.122447 38983 net.cpp:380] conv1 -> conv1
I0420 14:16:48.798746 38983 net.cpp:122] Setting up conv1
I0420 14:16:48.798780 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.798784 38983 net.cpp:137] Memory required for data: 9963520
I0420 14:16:48.798812 38983 layer_factory.hpp:77] Creating layer bn_conv1
I0420 14:16:48.798835 38983 net.cpp:84] Creating Layer bn_conv1
I0420 14:16:48.798840 38983 net.cpp:406] bn_conv1 <- conv1
I0420 14:16:48.798848 38983 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0420 14:16:48.799005 38983 net.cpp:122] Setting up bn_conv1
I0420 14:16:48.799012 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.799015 38983 net.cpp:137] Memory required for data: 18352128
I0420 14:16:48.799026 38983 layer_factory.hpp:77] Creating layer scale_conv1
I0420 14:16:48.799036 38983 net.cpp:84] Creating Layer scale_conv1
I0420 14:16:48.799041 38983 net.cpp:406] scale_conv1 <- conv1
I0420 14:16:48.799043 38983 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0420 14:16:48.799077 38983 layer_factory.hpp:77] Creating layer scale_conv1
I0420 14:16:48.799167 38983 net.cpp:122] Setting up scale_conv1
I0420 14:16:48.799172 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.799175 38983 net.cpp:137] Memory required for data: 26740736
I0420 14:16:48.799180 38983 layer_factory.hpp:77] Creating layer relu_conv1
I0420 14:16:48.799187 38983 net.cpp:84] Creating Layer relu_conv1
I0420 14:16:48.799190 38983 net.cpp:406] relu_conv1 <- conv1
I0420 14:16:48.799193 38983 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0420 14:16:48.800694 38983 net.cpp:122] Setting up relu_conv1
I0420 14:16:48.800703 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.800705 38983 net.cpp:137] Memory required for data: 35129344
I0420 14:16:48.800709 38983 layer_factory.hpp:77] Creating layer conv1_relu_conv1_0_split
I0420 14:16:48.800714 38983 net.cpp:84] Creating Layer conv1_relu_conv1_0_split
I0420 14:16:48.800717 38983 net.cpp:406] conv1_relu_conv1_0_split <- conv1
I0420 14:16:48.800722 38983 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_0
I0420 14:16:48.800729 38983 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_1
I0420 14:16:48.800760 38983 net.cpp:122] Setting up conv1_relu_conv1_0_split
I0420 14:16:48.800765 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.800768 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.800770 38983 net.cpp:137] Memory required for data: 51906560
I0420 14:16:48.800773 38983 layer_factory.hpp:77] Creating layer map16_1_conv_a
I0420 14:16:48.800786 38983 net.cpp:84] Creating Layer map16_1_conv_a
I0420 14:16:48.800788 38983 net.cpp:406] map16_1_conv_a <- conv1_relu_conv1_0_split_0
I0420 14:16:48.800793 38983 net.cpp:380] map16_1_conv_a -> map16_1_conv_a
I0420 14:16:48.808012 38983 net.cpp:122] Setting up map16_1_conv_a
I0420 14:16:48.808023 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.808027 38983 net.cpp:137] Memory required for data: 60295168
I0420 14:16:48.808037 38983 layer_factory.hpp:77] Creating layer map16_1_bn_a
I0420 14:16:48.808045 38983 net.cpp:84] Creating Layer map16_1_bn_a
I0420 14:16:48.808048 38983 net.cpp:406] map16_1_bn_a <- map16_1_conv_a
I0420 14:16:48.808053 38983 net.cpp:367] map16_1_bn_a -> map16_1_conv_a (in-place)
I0420 14:16:48.808193 38983 net.cpp:122] Setting up map16_1_bn_a
I0420 14:16:48.808199 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.808202 38983 net.cpp:137] Memory required for data: 68683776
I0420 14:16:48.808208 38983 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0420 14:16:48.808214 38983 net.cpp:84] Creating Layer map16_1_scale_a
I0420 14:16:48.808218 38983 net.cpp:406] map16_1_scale_a <- map16_1_conv_a
I0420 14:16:48.808248 38983 net.cpp:367] map16_1_scale_a -> map16_1_conv_a (in-place)
I0420 14:16:48.808277 38983 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0420 14:16:48.808354 38983 net.cpp:122] Setting up map16_1_scale_a
I0420 14:16:48.808359 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.808362 38983 net.cpp:137] Memory required for data: 77072384
I0420 14:16:48.808367 38983 layer_factory.hpp:77] Creating layer map16_1_relu_a
I0420 14:16:48.808372 38983 net.cpp:84] Creating Layer map16_1_relu_a
I0420 14:16:48.808375 38983 net.cpp:406] map16_1_relu_a <- map16_1_conv_a
I0420 14:16:48.808378 38983 net.cpp:367] map16_1_relu_a -> map16_1_conv_a (in-place)
I0420 14:16:48.810374 38983 net.cpp:122] Setting up map16_1_relu_a
I0420 14:16:48.810384 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.810387 38983 net.cpp:137] Memory required for data: 85460992
I0420 14:16:48.810392 38983 layer_factory.hpp:77] Creating layer map16_1_conv_b
I0420 14:16:48.810401 38983 net.cpp:84] Creating Layer map16_1_conv_b
I0420 14:16:48.810405 38983 net.cpp:406] map16_1_conv_b <- map16_1_conv_a
I0420 14:16:48.810410 38983 net.cpp:380] map16_1_conv_b -> map16_1_conv_b
I0420 14:16:48.817554 38983 net.cpp:122] Setting up map16_1_conv_b
I0420 14:16:48.817564 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.817567 38983 net.cpp:137] Memory required for data: 93849600
I0420 14:16:48.817572 38983 layer_factory.hpp:77] Creating layer map16_1_bn_b
I0420 14:16:48.817579 38983 net.cpp:84] Creating Layer map16_1_bn_b
I0420 14:16:48.817582 38983 net.cpp:406] map16_1_bn_b <- map16_1_conv_b
I0420 14:16:48.817589 38983 net.cpp:367] map16_1_bn_b -> map16_1_conv_b (in-place)
I0420 14:16:48.817728 38983 net.cpp:122] Setting up map16_1_bn_b
I0420 14:16:48.817734 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.817736 38983 net.cpp:137] Memory required for data: 102238208
I0420 14:16:48.817745 38983 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0420 14:16:48.817751 38983 net.cpp:84] Creating Layer map16_1_scale_b
I0420 14:16:48.817755 38983 net.cpp:406] map16_1_scale_b <- map16_1_conv_b
I0420 14:16:48.817759 38983 net.cpp:367] map16_1_scale_b -> map16_1_conv_b (in-place)
I0420 14:16:48.817785 38983 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0420 14:16:48.817860 38983 net.cpp:122] Setting up map16_1_scale_b
I0420 14:16:48.817865 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.817868 38983 net.cpp:137] Memory required for data: 110626816
I0420 14:16:48.817873 38983 layer_factory.hpp:77] Creating layer map16_1_eltsum
I0420 14:16:48.817881 38983 net.cpp:84] Creating Layer map16_1_eltsum
I0420 14:16:48.817884 38983 net.cpp:406] map16_1_eltsum <- conv1_relu_conv1_0_split_1
I0420 14:16:48.817888 38983 net.cpp:406] map16_1_eltsum <- map16_1_conv_b
I0420 14:16:48.817893 38983 net.cpp:380] map16_1_eltsum -> map16_1_eltsum
I0420 14:16:48.817915 38983 net.cpp:122] Setting up map16_1_eltsum
I0420 14:16:48.817920 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.817924 38983 net.cpp:137] Memory required for data: 119015424
I0420 14:16:48.817926 38983 layer_factory.hpp:77] Creating layer map16_1_relu_after_sum
I0420 14:16:48.817931 38983 net.cpp:84] Creating Layer map16_1_relu_after_sum
I0420 14:16:48.817934 38983 net.cpp:406] map16_1_relu_after_sum <- map16_1_eltsum
I0420 14:16:48.817937 38983 net.cpp:367] map16_1_relu_after_sum -> map16_1_eltsum (in-place)
I0420 14:16:48.819931 38983 net.cpp:122] Setting up map16_1_relu_after_sum
I0420 14:16:48.819941 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.819943 38983 net.cpp:137] Memory required for data: 127404032
I0420 14:16:48.819947 38983 layer_factory.hpp:77] Creating layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 14:16:48.819953 38983 net.cpp:84] Creating Layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 14:16:48.819957 38983 net.cpp:406] map16_1_eltsum_map16_1_relu_after_sum_0_split <- map16_1_eltsum
I0420 14:16:48.819973 38983 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0420 14:16:48.819980 38983 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0420 14:16:48.820013 38983 net.cpp:122] Setting up map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 14:16:48.820017 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.820021 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.820024 38983 net.cpp:137] Memory required for data: 144181248
I0420 14:16:48.820026 38983 layer_factory.hpp:77] Creating layer map16_2_conv_a
I0420 14:16:48.820036 38983 net.cpp:84] Creating Layer map16_2_conv_a
I0420 14:16:48.820039 38983 net.cpp:406] map16_2_conv_a <- map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0420 14:16:48.820044 38983 net.cpp:380] map16_2_conv_a -> map16_2_conv_a
I0420 14:16:48.827184 38983 net.cpp:122] Setting up map16_2_conv_a
I0420 14:16:48.827194 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.827198 38983 net.cpp:137] Memory required for data: 152569856
I0420 14:16:48.827203 38983 layer_factory.hpp:77] Creating layer map16_2_bn_a
I0420 14:16:48.827210 38983 net.cpp:84] Creating Layer map16_2_bn_a
I0420 14:16:48.827214 38983 net.cpp:406] map16_2_bn_a <- map16_2_conv_a
I0420 14:16:48.827220 38983 net.cpp:367] map16_2_bn_a -> map16_2_conv_a (in-place)
I0420 14:16:48.827361 38983 net.cpp:122] Setting up map16_2_bn_a
I0420 14:16:48.827366 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.827369 38983 net.cpp:137] Memory required for data: 160958464
I0420 14:16:48.827375 38983 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0420 14:16:48.827383 38983 net.cpp:84] Creating Layer map16_2_scale_a
I0420 14:16:48.827385 38983 net.cpp:406] map16_2_scale_a <- map16_2_conv_a
I0420 14:16:48.827389 38983 net.cpp:367] map16_2_scale_a -> map16_2_conv_a (in-place)
I0420 14:16:48.827414 38983 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0420 14:16:48.827491 38983 net.cpp:122] Setting up map16_2_scale_a
I0420 14:16:48.827497 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.827499 38983 net.cpp:137] Memory required for data: 169347072
I0420 14:16:48.827503 38983 layer_factory.hpp:77] Creating layer map16_2_relu_a
I0420 14:16:48.827509 38983 net.cpp:84] Creating Layer map16_2_relu_a
I0420 14:16:48.827512 38983 net.cpp:406] map16_2_relu_a <- map16_2_conv_a
I0420 14:16:48.827515 38983 net.cpp:367] map16_2_relu_a -> map16_2_conv_a (in-place)
I0420 14:16:48.829447 38983 net.cpp:122] Setting up map16_2_relu_a
I0420 14:16:48.829453 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.829457 38983 net.cpp:137] Memory required for data: 177735680
I0420 14:16:48.829459 38983 layer_factory.hpp:77] Creating layer map16_2_conv_b
I0420 14:16:48.829468 38983 net.cpp:84] Creating Layer map16_2_conv_b
I0420 14:16:48.829471 38983 net.cpp:406] map16_2_conv_b <- map16_2_conv_a
I0420 14:16:48.829475 38983 net.cpp:380] map16_2_conv_b -> map16_2_conv_b
I0420 14:16:48.836690 38983 net.cpp:122] Setting up map16_2_conv_b
I0420 14:16:48.836700 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.836704 38983 net.cpp:137] Memory required for data: 186124288
I0420 14:16:48.836709 38983 layer_factory.hpp:77] Creating layer map16_2_bn_b
I0420 14:16:48.836719 38983 net.cpp:84] Creating Layer map16_2_bn_b
I0420 14:16:48.836721 38983 net.cpp:406] map16_2_bn_b <- map16_2_conv_b
I0420 14:16:48.836726 38983 net.cpp:367] map16_2_bn_b -> map16_2_conv_b (in-place)
I0420 14:16:48.836872 38983 net.cpp:122] Setting up map16_2_bn_b
I0420 14:16:48.836877 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.836880 38983 net.cpp:137] Memory required for data: 194512896
I0420 14:16:48.836890 38983 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0420 14:16:48.836896 38983 net.cpp:84] Creating Layer map16_2_scale_b
I0420 14:16:48.836899 38983 net.cpp:406] map16_2_scale_b <- map16_2_conv_b
I0420 14:16:48.836904 38983 net.cpp:367] map16_2_scale_b -> map16_2_conv_b (in-place)
I0420 14:16:48.836942 38983 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0420 14:16:48.837023 38983 net.cpp:122] Setting up map16_2_scale_b
I0420 14:16:48.837028 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.837030 38983 net.cpp:137] Memory required for data: 202901504
I0420 14:16:48.837035 38983 layer_factory.hpp:77] Creating layer map16_2_eltsum
I0420 14:16:48.837040 38983 net.cpp:84] Creating Layer map16_2_eltsum
I0420 14:16:48.837044 38983 net.cpp:406] map16_2_eltsum <- map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0420 14:16:48.837049 38983 net.cpp:406] map16_2_eltsum <- map16_2_conv_b
I0420 14:16:48.837052 38983 net.cpp:380] map16_2_eltsum -> map16_2_eltsum
I0420 14:16:48.837070 38983 net.cpp:122] Setting up map16_2_eltsum
I0420 14:16:48.837074 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.837077 38983 net.cpp:137] Memory required for data: 211290112
I0420 14:16:48.837080 38983 layer_factory.hpp:77] Creating layer map16_2_relu_after_sum
I0420 14:16:48.837083 38983 net.cpp:84] Creating Layer map16_2_relu_after_sum
I0420 14:16:48.837086 38983 net.cpp:406] map16_2_relu_after_sum <- map16_2_eltsum
I0420 14:16:48.837090 38983 net.cpp:367] map16_2_relu_after_sum -> map16_2_eltsum (in-place)
I0420 14:16:48.839184 38983 net.cpp:122] Setting up map16_2_relu_after_sum
I0420 14:16:48.839191 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.839195 38983 net.cpp:137] Memory required for data: 219678720
I0420 14:16:48.839196 38983 layer_factory.hpp:77] Creating layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 14:16:48.839203 38983 net.cpp:84] Creating Layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 14:16:48.839206 38983 net.cpp:406] map16_2_eltsum_map16_2_relu_after_sum_0_split <- map16_2_eltsum
I0420 14:16:48.839210 38983 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0420 14:16:48.839217 38983 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0420 14:16:48.839247 38983 net.cpp:122] Setting up map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 14:16:48.839252 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.839256 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.839257 38983 net.cpp:137] Memory required for data: 236455936
I0420 14:16:48.839260 38983 layer_factory.hpp:77] Creating layer map16_3_conv_a
I0420 14:16:48.839268 38983 net.cpp:84] Creating Layer map16_3_conv_a
I0420 14:16:48.839272 38983 net.cpp:406] map16_3_conv_a <- map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0420 14:16:48.839275 38983 net.cpp:380] map16_3_conv_a -> map16_3_conv_a
I0420 14:16:48.846267 38983 net.cpp:122] Setting up map16_3_conv_a
I0420 14:16:48.846278 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.846282 38983 net.cpp:137] Memory required for data: 244844544
I0420 14:16:48.846287 38983 layer_factory.hpp:77] Creating layer map16_3_bn_a
I0420 14:16:48.846294 38983 net.cpp:84] Creating Layer map16_3_bn_a
I0420 14:16:48.846297 38983 net.cpp:406] map16_3_bn_a <- map16_3_conv_a
I0420 14:16:48.846302 38983 net.cpp:367] map16_3_bn_a -> map16_3_conv_a (in-place)
I0420 14:16:48.846448 38983 net.cpp:122] Setting up map16_3_bn_a
I0420 14:16:48.846453 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.846457 38983 net.cpp:137] Memory required for data: 253233152
I0420 14:16:48.846462 38983 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0420 14:16:48.846467 38983 net.cpp:84] Creating Layer map16_3_scale_a
I0420 14:16:48.846470 38983 net.cpp:406] map16_3_scale_a <- map16_3_conv_a
I0420 14:16:48.846473 38983 net.cpp:367] map16_3_scale_a -> map16_3_conv_a (in-place)
I0420 14:16:48.846499 38983 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0420 14:16:48.846581 38983 net.cpp:122] Setting up map16_3_scale_a
I0420 14:16:48.846585 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.846588 38983 net.cpp:137] Memory required for data: 261621760
I0420 14:16:48.846606 38983 layer_factory.hpp:77] Creating layer map16_3_relu_a
I0420 14:16:48.846612 38983 net.cpp:84] Creating Layer map16_3_relu_a
I0420 14:16:48.846616 38983 net.cpp:406] map16_3_relu_a <- map16_3_conv_a
I0420 14:16:48.846619 38983 net.cpp:367] map16_3_relu_a -> map16_3_conv_a (in-place)
I0420 14:16:48.848541 38983 net.cpp:122] Setting up map16_3_relu_a
I0420 14:16:48.848548 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.848551 38983 net.cpp:137] Memory required for data: 270010368
I0420 14:16:48.848553 38983 layer_factory.hpp:77] Creating layer map16_3_conv_b
I0420 14:16:48.848562 38983 net.cpp:84] Creating Layer map16_3_conv_b
I0420 14:16:48.848564 38983 net.cpp:406] map16_3_conv_b <- map16_3_conv_a
I0420 14:16:48.848568 38983 net.cpp:380] map16_3_conv_b -> map16_3_conv_b
I0420 14:16:48.855929 38983 net.cpp:122] Setting up map16_3_conv_b
I0420 14:16:48.855940 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.855943 38983 net.cpp:137] Memory required for data: 278398976
I0420 14:16:48.855949 38983 layer_factory.hpp:77] Creating layer map16_3_bn_b
I0420 14:16:48.855960 38983 net.cpp:84] Creating Layer map16_3_bn_b
I0420 14:16:48.855963 38983 net.cpp:406] map16_3_bn_b <- map16_3_conv_b
I0420 14:16:48.855968 38983 net.cpp:367] map16_3_bn_b -> map16_3_conv_b (in-place)
I0420 14:16:48.856115 38983 net.cpp:122] Setting up map16_3_bn_b
I0420 14:16:48.856120 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.856123 38983 net.cpp:137] Memory required for data: 286787584
I0420 14:16:48.856128 38983 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0420 14:16:48.856134 38983 net.cpp:84] Creating Layer map16_3_scale_b
I0420 14:16:48.856138 38983 net.cpp:406] map16_3_scale_b <- map16_3_conv_b
I0420 14:16:48.856142 38983 net.cpp:367] map16_3_scale_b -> map16_3_conv_b (in-place)
I0420 14:16:48.856168 38983 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0420 14:16:48.856250 38983 net.cpp:122] Setting up map16_3_scale_b
I0420 14:16:48.856254 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.856257 38983 net.cpp:137] Memory required for data: 295176192
I0420 14:16:48.856261 38983 layer_factory.hpp:77] Creating layer map16_3_eltsum
I0420 14:16:48.856268 38983 net.cpp:84] Creating Layer map16_3_eltsum
I0420 14:16:48.856271 38983 net.cpp:406] map16_3_eltsum <- map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0420 14:16:48.856276 38983 net.cpp:406] map16_3_eltsum <- map16_3_conv_b
I0420 14:16:48.856279 38983 net.cpp:380] map16_3_eltsum -> map16_3_eltsum
I0420 14:16:48.856297 38983 net.cpp:122] Setting up map16_3_eltsum
I0420 14:16:48.856302 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.856304 38983 net.cpp:137] Memory required for data: 303564800
I0420 14:16:48.856307 38983 layer_factory.hpp:77] Creating layer map16_3_relu_after_sum
I0420 14:16:48.856312 38983 net.cpp:84] Creating Layer map16_3_relu_after_sum
I0420 14:16:48.856314 38983 net.cpp:406] map16_3_relu_after_sum <- map16_3_eltsum
I0420 14:16:48.856317 38983 net.cpp:367] map16_3_relu_after_sum -> map16_3_eltsum (in-place)
I0420 14:16:48.858197 38983 net.cpp:122] Setting up map16_3_relu_after_sum
I0420 14:16:48.858204 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.858207 38983 net.cpp:137] Memory required for data: 311953408
I0420 14:16:48.858211 38983 layer_factory.hpp:77] Creating layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 14:16:48.858214 38983 net.cpp:84] Creating Layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 14:16:48.858218 38983 net.cpp:406] map16_3_eltsum_map16_3_relu_after_sum_0_split <- map16_3_eltsum
I0420 14:16:48.858222 38983 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0420 14:16:48.858227 38983 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0420 14:16:48.858258 38983 net.cpp:122] Setting up map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 14:16:48.858273 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.858278 38983 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0420 14:16:48.858279 38983 net.cpp:137] Memory required for data: 328730624
I0420 14:16:48.858283 38983 layer_factory.hpp:77] Creating layer map32_1_conv_proj
I0420 14:16:48.858289 38983 net.cpp:84] Creating Layer map32_1_conv_proj
I0420 14:16:48.858294 38983 net.cpp:406] map32_1_conv_proj <- map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0420 14:16:48.858297 38983 net.cpp:380] map32_1_conv_proj -> map32_1_conv_proj
I0420 14:16:48.865452 38983 net.cpp:122] Setting up map32_1_conv_proj
I0420 14:16:48.865463 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.865465 38983 net.cpp:137] Memory required for data: 332924928
I0420 14:16:48.865471 38983 layer_factory.hpp:77] Creating layer map32_1_bn_proj
I0420 14:16:48.865480 38983 net.cpp:84] Creating Layer map32_1_bn_proj
I0420 14:16:48.865484 38983 net.cpp:406] map32_1_bn_proj <- map32_1_conv_proj
I0420 14:16:48.865489 38983 net.cpp:367] map32_1_bn_proj -> map32_1_conv_proj (in-place)
I0420 14:16:48.865633 38983 net.cpp:122] Setting up map32_1_bn_proj
I0420 14:16:48.865638 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.865641 38983 net.cpp:137] Memory required for data: 337119232
I0420 14:16:48.865646 38983 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0420 14:16:48.865653 38983 net.cpp:84] Creating Layer map32_1_scale_proj
I0420 14:16:48.865655 38983 net.cpp:406] map32_1_scale_proj <- map32_1_conv_proj
I0420 14:16:48.865658 38983 net.cpp:367] map32_1_scale_proj -> map32_1_conv_proj (in-place)
I0420 14:16:48.865690 38983 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0420 14:16:48.865792 38983 net.cpp:122] Setting up map32_1_scale_proj
I0420 14:16:48.865797 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.865799 38983 net.cpp:137] Memory required for data: 341313536
I0420 14:16:48.865804 38983 layer_factory.hpp:77] Creating layer map32_1_conv_a
I0420 14:16:48.865813 38983 net.cpp:84] Creating Layer map32_1_conv_a
I0420 14:16:48.865816 38983 net.cpp:406] map32_1_conv_a <- map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0420 14:16:48.865821 38983 net.cpp:380] map32_1_conv_a -> map32_1_conv_a
I0420 14:16:48.872371 38983 net.cpp:122] Setting up map32_1_conv_a
I0420 14:16:48.872382 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.872385 38983 net.cpp:137] Memory required for data: 345507840
I0420 14:16:48.872392 38983 layer_factory.hpp:77] Creating layer map32_1_bn_a
I0420 14:16:48.872400 38983 net.cpp:84] Creating Layer map32_1_bn_a
I0420 14:16:48.872403 38983 net.cpp:406] map32_1_bn_a <- map32_1_conv_a
I0420 14:16:48.872407 38983 net.cpp:367] map32_1_bn_a -> map32_1_conv_a (in-place)
I0420 14:16:48.872552 38983 net.cpp:122] Setting up map32_1_bn_a
I0420 14:16:48.872558 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.872560 38983 net.cpp:137] Memory required for data: 349702144
I0420 14:16:48.872566 38983 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0420 14:16:48.872572 38983 net.cpp:84] Creating Layer map32_1_scale_a
I0420 14:16:48.872576 38983 net.cpp:406] map32_1_scale_a <- map32_1_conv_a
I0420 14:16:48.872580 38983 net.cpp:367] map32_1_scale_a -> map32_1_conv_a (in-place)
I0420 14:16:48.872606 38983 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0420 14:16:48.872690 38983 net.cpp:122] Setting up map32_1_scale_a
I0420 14:16:48.872695 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.872699 38983 net.cpp:137] Memory required for data: 353896448
I0420 14:16:48.872704 38983 layer_factory.hpp:77] Creating layer map32_1_relu_a
I0420 14:16:48.872709 38983 net.cpp:84] Creating Layer map32_1_relu_a
I0420 14:16:48.872711 38983 net.cpp:406] map32_1_relu_a <- map32_1_conv_a
I0420 14:16:48.872714 38983 net.cpp:367] map32_1_relu_a -> map32_1_conv_a (in-place)
I0420 14:16:48.874572 38983 net.cpp:122] Setting up map32_1_relu_a
I0420 14:16:48.874578 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.874591 38983 net.cpp:137] Memory required for data: 358090752
I0420 14:16:48.874594 38983 layer_factory.hpp:77] Creating layer map32_1_conv_b
I0420 14:16:48.874603 38983 net.cpp:84] Creating Layer map32_1_conv_b
I0420 14:16:48.874608 38983 net.cpp:406] map32_1_conv_b <- map32_1_conv_a
I0420 14:16:48.874613 38983 net.cpp:380] map32_1_conv_b -> map32_1_conv_b
I0420 14:16:48.881894 38983 net.cpp:122] Setting up map32_1_conv_b
I0420 14:16:48.881906 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.881909 38983 net.cpp:137] Memory required for data: 362285056
I0420 14:16:48.881920 38983 layer_factory.hpp:77] Creating layer map32_1_bn_b
I0420 14:16:48.881929 38983 net.cpp:84] Creating Layer map32_1_bn_b
I0420 14:16:48.881933 38983 net.cpp:406] map32_1_bn_b <- map32_1_conv_b
I0420 14:16:48.881937 38983 net.cpp:367] map32_1_bn_b -> map32_1_conv_b (in-place)
I0420 14:16:48.882098 38983 net.cpp:122] Setting up map32_1_bn_b
I0420 14:16:48.882103 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.882107 38983 net.cpp:137] Memory required for data: 366479360
I0420 14:16:48.882112 38983 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0420 14:16:48.882118 38983 net.cpp:84] Creating Layer map32_1_scale_b
I0420 14:16:48.882122 38983 net.cpp:406] map32_1_scale_b <- map32_1_conv_b
I0420 14:16:48.882127 38983 net.cpp:367] map32_1_scale_b -> map32_1_conv_b (in-place)
I0420 14:16:48.882153 38983 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0420 14:16:48.882233 38983 net.cpp:122] Setting up map32_1_scale_b
I0420 14:16:48.882238 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.882241 38983 net.cpp:137] Memory required for data: 370673664
I0420 14:16:48.882246 38983 layer_factory.hpp:77] Creating layer map32_1_eltsum
I0420 14:16:48.882251 38983 net.cpp:84] Creating Layer map32_1_eltsum
I0420 14:16:48.882253 38983 net.cpp:406] map32_1_eltsum <- map32_1_conv_proj
I0420 14:16:48.882257 38983 net.cpp:406] map32_1_eltsum <- map32_1_conv_b
I0420 14:16:48.882261 38983 net.cpp:380] map32_1_eltsum -> map32_1_eltsum
I0420 14:16:48.882275 38983 net.cpp:122] Setting up map32_1_eltsum
I0420 14:16:48.882280 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.882282 38983 net.cpp:137] Memory required for data: 374867968
I0420 14:16:48.882285 38983 layer_factory.hpp:77] Creating layer map32_1_relu_after_sum
I0420 14:16:48.882289 38983 net.cpp:84] Creating Layer map32_1_relu_after_sum
I0420 14:16:48.882292 38983 net.cpp:406] map32_1_relu_after_sum <- map32_1_eltsum
I0420 14:16:48.882295 38983 net.cpp:367] map32_1_relu_after_sum -> map32_1_eltsum (in-place)
I0420 14:16:48.884228 38983 net.cpp:122] Setting up map32_1_relu_after_sum
I0420 14:16:48.884238 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.884241 38983 net.cpp:137] Memory required for data: 379062272
I0420 14:16:48.884246 38983 layer_factory.hpp:77] Creating layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 14:16:48.884253 38983 net.cpp:84] Creating Layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 14:16:48.884255 38983 net.cpp:406] map32_1_eltsum_map32_1_relu_after_sum_0_split <- map32_1_eltsum
I0420 14:16:48.884260 38983 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0420 14:16:48.884266 38983 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0420 14:16:48.884299 38983 net.cpp:122] Setting up map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 14:16:48.884305 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.884308 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.884310 38983 net.cpp:137] Memory required for data: 387450880
I0420 14:16:48.884313 38983 layer_factory.hpp:77] Creating layer map32_2_conv_a
I0420 14:16:48.884320 38983 net.cpp:84] Creating Layer map32_2_conv_a
I0420 14:16:48.884325 38983 net.cpp:406] map32_2_conv_a <- map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0420 14:16:48.884341 38983 net.cpp:380] map32_2_conv_a -> map32_2_conv_a
I0420 14:16:48.891635 38983 net.cpp:122] Setting up map32_2_conv_a
I0420 14:16:48.891645 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.891647 38983 net.cpp:137] Memory required for data: 391645184
I0420 14:16:48.891654 38983 layer_factory.hpp:77] Creating layer map32_2_bn_a
I0420 14:16:48.891662 38983 net.cpp:84] Creating Layer map32_2_bn_a
I0420 14:16:48.891666 38983 net.cpp:406] map32_2_bn_a <- map32_2_conv_a
I0420 14:16:48.891670 38983 net.cpp:367] map32_2_bn_a -> map32_2_conv_a (in-place)
I0420 14:16:48.891829 38983 net.cpp:122] Setting up map32_2_bn_a
I0420 14:16:48.891834 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.891837 38983 net.cpp:137] Memory required for data: 395839488
I0420 14:16:48.891846 38983 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0420 14:16:48.891854 38983 net.cpp:84] Creating Layer map32_2_scale_a
I0420 14:16:48.891856 38983 net.cpp:406] map32_2_scale_a <- map32_2_conv_a
I0420 14:16:48.891860 38983 net.cpp:367] map32_2_scale_a -> map32_2_conv_a (in-place)
I0420 14:16:48.891888 38983 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0420 14:16:48.891976 38983 net.cpp:122] Setting up map32_2_scale_a
I0420 14:16:48.891981 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.891984 38983 net.cpp:137] Memory required for data: 400033792
I0420 14:16:48.891988 38983 layer_factory.hpp:77] Creating layer map32_2_relu_a
I0420 14:16:48.891993 38983 net.cpp:84] Creating Layer map32_2_relu_a
I0420 14:16:48.891996 38983 net.cpp:406] map32_2_relu_a <- map32_2_conv_a
I0420 14:16:48.892000 38983 net.cpp:367] map32_2_relu_a -> map32_2_conv_a (in-place)
I0420 14:16:48.893893 38983 net.cpp:122] Setting up map32_2_relu_a
I0420 14:16:48.893903 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.893905 38983 net.cpp:137] Memory required for data: 404228096
I0420 14:16:48.893908 38983 layer_factory.hpp:77] Creating layer map32_2_conv_b
I0420 14:16:48.893918 38983 net.cpp:84] Creating Layer map32_2_conv_b
I0420 14:16:48.893923 38983 net.cpp:406] map32_2_conv_b <- map32_2_conv_a
I0420 14:16:48.893929 38983 net.cpp:380] map32_2_conv_b -> map32_2_conv_b
I0420 14:16:48.901293 38983 net.cpp:122] Setting up map32_2_conv_b
I0420 14:16:48.901305 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.901309 38983 net.cpp:137] Memory required for data: 408422400
I0420 14:16:48.901314 38983 layer_factory.hpp:77] Creating layer map32_2_bn_b
I0420 14:16:48.901324 38983 net.cpp:84] Creating Layer map32_2_bn_b
I0420 14:16:48.901327 38983 net.cpp:406] map32_2_bn_b <- map32_2_conv_b
I0420 14:16:48.901331 38983 net.cpp:367] map32_2_bn_b -> map32_2_conv_b (in-place)
I0420 14:16:48.901492 38983 net.cpp:122] Setting up map32_2_bn_b
I0420 14:16:48.901497 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.901500 38983 net.cpp:137] Memory required for data: 412616704
I0420 14:16:48.901506 38983 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0420 14:16:48.901515 38983 net.cpp:84] Creating Layer map32_2_scale_b
I0420 14:16:48.901517 38983 net.cpp:406] map32_2_scale_b <- map32_2_conv_b
I0420 14:16:48.901521 38983 net.cpp:367] map32_2_scale_b -> map32_2_conv_b (in-place)
I0420 14:16:48.901551 38983 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0420 14:16:48.901643 38983 net.cpp:122] Setting up map32_2_scale_b
I0420 14:16:48.901648 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.901650 38983 net.cpp:137] Memory required for data: 416811008
I0420 14:16:48.901654 38983 layer_factory.hpp:77] Creating layer map32_2_eltsum
I0420 14:16:48.901659 38983 net.cpp:84] Creating Layer map32_2_eltsum
I0420 14:16:48.901662 38983 net.cpp:406] map32_2_eltsum <- map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0420 14:16:48.901666 38983 net.cpp:406] map32_2_eltsum <- map32_2_conv_b
I0420 14:16:48.901672 38983 net.cpp:380] map32_2_eltsum -> map32_2_eltsum
I0420 14:16:48.901691 38983 net.cpp:122] Setting up map32_2_eltsum
I0420 14:16:48.901696 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.901710 38983 net.cpp:137] Memory required for data: 421005312
I0420 14:16:48.901713 38983 layer_factory.hpp:77] Creating layer map32_2_relu_after_sum
I0420 14:16:48.901721 38983 net.cpp:84] Creating Layer map32_2_relu_after_sum
I0420 14:16:48.901723 38983 net.cpp:406] map32_2_relu_after_sum <- map32_2_eltsum
I0420 14:16:48.901726 38983 net.cpp:367] map32_2_relu_after_sum -> map32_2_eltsum (in-place)
I0420 14:16:48.903731 38983 net.cpp:122] Setting up map32_2_relu_after_sum
I0420 14:16:48.903741 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.903744 38983 net.cpp:137] Memory required for data: 425199616
I0420 14:16:48.903746 38983 layer_factory.hpp:77] Creating layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 14:16:48.903753 38983 net.cpp:84] Creating Layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 14:16:48.903756 38983 net.cpp:406] map32_2_eltsum_map32_2_relu_after_sum_0_split <- map32_2_eltsum
I0420 14:16:48.903760 38983 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0420 14:16:48.903769 38983 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0420 14:16:48.903805 38983 net.cpp:122] Setting up map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 14:16:48.903810 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.903813 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.903815 38983 net.cpp:137] Memory required for data: 433588224
I0420 14:16:48.903818 38983 layer_factory.hpp:77] Creating layer map32_3_conv_a
I0420 14:16:48.903830 38983 net.cpp:84] Creating Layer map32_3_conv_a
I0420 14:16:48.903832 38983 net.cpp:406] map32_3_conv_a <- map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0420 14:16:48.903837 38983 net.cpp:380] map32_3_conv_a -> map32_3_conv_a
I0420 14:16:48.910976 38983 net.cpp:122] Setting up map32_3_conv_a
I0420 14:16:48.910989 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.910991 38983 net.cpp:137] Memory required for data: 437782528
I0420 14:16:48.910997 38983 layer_factory.hpp:77] Creating layer map32_3_bn_a
I0420 14:16:48.911005 38983 net.cpp:84] Creating Layer map32_3_bn_a
I0420 14:16:48.911010 38983 net.cpp:406] map32_3_bn_a <- map32_3_conv_a
I0420 14:16:48.911015 38983 net.cpp:367] map32_3_bn_a -> map32_3_conv_a (in-place)
I0420 14:16:48.911171 38983 net.cpp:122] Setting up map32_3_bn_a
I0420 14:16:48.911176 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.911180 38983 net.cpp:137] Memory required for data: 441976832
I0420 14:16:48.911185 38983 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0420 14:16:48.911192 38983 net.cpp:84] Creating Layer map32_3_scale_a
I0420 14:16:48.911195 38983 net.cpp:406] map32_3_scale_a <- map32_3_conv_a
I0420 14:16:48.911200 38983 net.cpp:367] map32_3_scale_a -> map32_3_conv_a (in-place)
I0420 14:16:48.911226 38983 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0420 14:16:48.911316 38983 net.cpp:122] Setting up map32_3_scale_a
I0420 14:16:48.911321 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.911324 38983 net.cpp:137] Memory required for data: 446171136
I0420 14:16:48.911329 38983 layer_factory.hpp:77] Creating layer map32_3_relu_a
I0420 14:16:48.911334 38983 net.cpp:84] Creating Layer map32_3_relu_a
I0420 14:16:48.911339 38983 net.cpp:406] map32_3_relu_a <- map32_3_conv_a
I0420 14:16:48.911341 38983 net.cpp:367] map32_3_relu_a -> map32_3_conv_a (in-place)
I0420 14:16:48.913343 38983 net.cpp:122] Setting up map32_3_relu_a
I0420 14:16:48.913352 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.913353 38983 net.cpp:137] Memory required for data: 450365440
I0420 14:16:48.913357 38983 layer_factory.hpp:77] Creating layer map32_3_conv_b
I0420 14:16:48.913370 38983 net.cpp:84] Creating Layer map32_3_conv_b
I0420 14:16:48.913373 38983 net.cpp:406] map32_3_conv_b <- map32_3_conv_a
I0420 14:16:48.913378 38983 net.cpp:380] map32_3_conv_b -> map32_3_conv_b
I0420 14:16:48.920763 38983 net.cpp:122] Setting up map32_3_conv_b
I0420 14:16:48.920773 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.920776 38983 net.cpp:137] Memory required for data: 454559744
I0420 14:16:48.920781 38983 layer_factory.hpp:77] Creating layer map32_3_bn_b
I0420 14:16:48.920790 38983 net.cpp:84] Creating Layer map32_3_bn_b
I0420 14:16:48.920794 38983 net.cpp:406] map32_3_bn_b <- map32_3_conv_b
I0420 14:16:48.920800 38983 net.cpp:367] map32_3_bn_b -> map32_3_conv_b (in-place)
I0420 14:16:48.920958 38983 net.cpp:122] Setting up map32_3_bn_b
I0420 14:16:48.920964 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.920966 38983 net.cpp:137] Memory required for data: 458754048
I0420 14:16:48.920972 38983 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0420 14:16:48.920979 38983 net.cpp:84] Creating Layer map32_3_scale_b
I0420 14:16:48.920982 38983 net.cpp:406] map32_3_scale_b <- map32_3_conv_b
I0420 14:16:48.920987 38983 net.cpp:367] map32_3_scale_b -> map32_3_conv_b (in-place)
I0420 14:16:48.921015 38983 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0420 14:16:48.921104 38983 net.cpp:122] Setting up map32_3_scale_b
I0420 14:16:48.921111 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.921114 38983 net.cpp:137] Memory required for data: 462948352
I0420 14:16:48.921118 38983 layer_factory.hpp:77] Creating layer map32_3_eltsum
I0420 14:16:48.921123 38983 net.cpp:84] Creating Layer map32_3_eltsum
I0420 14:16:48.921128 38983 net.cpp:406] map32_3_eltsum <- map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0420 14:16:48.921130 38983 net.cpp:406] map32_3_eltsum <- map32_3_conv_b
I0420 14:16:48.921135 38983 net.cpp:380] map32_3_eltsum -> map32_3_eltsum
I0420 14:16:48.921150 38983 net.cpp:122] Setting up map32_3_eltsum
I0420 14:16:48.921154 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.921157 38983 net.cpp:137] Memory required for data: 467142656
I0420 14:16:48.921160 38983 layer_factory.hpp:77] Creating layer map32_3_relu_after_sum
I0420 14:16:48.921167 38983 net.cpp:84] Creating Layer map32_3_relu_after_sum
I0420 14:16:48.921170 38983 net.cpp:406] map32_3_relu_after_sum <- map32_3_eltsum
I0420 14:16:48.921175 38983 net.cpp:367] map32_3_relu_after_sum -> map32_3_eltsum (in-place)
I0420 14:16:48.923027 38983 net.cpp:122] Setting up map32_3_relu_after_sum
I0420 14:16:48.923034 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.923038 38983 net.cpp:137] Memory required for data: 471336960
I0420 14:16:48.923040 38983 layer_factory.hpp:77] Creating layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 14:16:48.923044 38983 net.cpp:84] Creating Layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 14:16:48.923048 38983 net.cpp:406] map32_3_eltsum_map32_3_relu_after_sum_0_split <- map32_3_eltsum
I0420 14:16:48.923055 38983 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0420 14:16:48.923060 38983 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0420 14:16:48.923095 38983 net.cpp:122] Setting up map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 14:16:48.923101 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.923105 38983 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0420 14:16:48.923106 38983 net.cpp:137] Memory required for data: 479725568
I0420 14:16:48.923110 38983 layer_factory.hpp:77] Creating layer map64_1_conv_proj
I0420 14:16:48.923118 38983 net.cpp:84] Creating Layer map64_1_conv_proj
I0420 14:16:48.923122 38983 net.cpp:406] map64_1_conv_proj <- map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0420 14:16:48.923128 38983 net.cpp:380] map64_1_conv_proj -> map64_1_conv_proj
I0420 14:16:48.930291 38983 net.cpp:122] Setting up map64_1_conv_proj
I0420 14:16:48.930302 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.930306 38983 net.cpp:137] Memory required for data: 481822720
I0420 14:16:48.930311 38983 layer_factory.hpp:77] Creating layer map64_1_bn_proj
I0420 14:16:48.930331 38983 net.cpp:84] Creating Layer map64_1_bn_proj
I0420 14:16:48.930335 38983 net.cpp:406] map64_1_bn_proj <- map64_1_conv_proj
I0420 14:16:48.930340 38983 net.cpp:367] map64_1_bn_proj -> map64_1_conv_proj (in-place)
I0420 14:16:48.930510 38983 net.cpp:122] Setting up map64_1_bn_proj
I0420 14:16:48.930515 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.930517 38983 net.cpp:137] Memory required for data: 483919872
I0420 14:16:48.930522 38983 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0420 14:16:48.930529 38983 net.cpp:84] Creating Layer map64_1_scale_proj
I0420 14:16:48.930532 38983 net.cpp:406] map64_1_scale_proj <- map64_1_conv_proj
I0420 14:16:48.930536 38983 net.cpp:367] map64_1_scale_proj -> map64_1_conv_proj (in-place)
I0420 14:16:48.930568 38983 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0420 14:16:48.930665 38983 net.cpp:122] Setting up map64_1_scale_proj
I0420 14:16:48.930670 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.930672 38983 net.cpp:137] Memory required for data: 486017024
I0420 14:16:48.930677 38983 layer_factory.hpp:77] Creating layer map64_1_conv_a
I0420 14:16:48.930690 38983 net.cpp:84] Creating Layer map64_1_conv_a
I0420 14:16:48.930711 38983 net.cpp:406] map64_1_conv_a <- map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0420 14:16:48.930717 38983 net.cpp:380] map64_1_conv_a -> map64_1_conv_a
I0420 14:16:48.937611 38983 net.cpp:122] Setting up map64_1_conv_a
I0420 14:16:48.937623 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.937626 38983 net.cpp:137] Memory required for data: 488114176
I0420 14:16:48.937631 38983 layer_factory.hpp:77] Creating layer map64_1_bn_a
I0420 14:16:48.937643 38983 net.cpp:84] Creating Layer map64_1_bn_a
I0420 14:16:48.937645 38983 net.cpp:406] map64_1_bn_a <- map64_1_conv_a
I0420 14:16:48.937651 38983 net.cpp:367] map64_1_bn_a -> map64_1_conv_a (in-place)
I0420 14:16:48.937822 38983 net.cpp:122] Setting up map64_1_bn_a
I0420 14:16:48.937829 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.937831 38983 net.cpp:137] Memory required for data: 490211328
I0420 14:16:48.937837 38983 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0420 14:16:48.937844 38983 net.cpp:84] Creating Layer map64_1_scale_a
I0420 14:16:48.937846 38983 net.cpp:406] map64_1_scale_a <- map64_1_conv_a
I0420 14:16:48.937850 38983 net.cpp:367] map64_1_scale_a -> map64_1_conv_a (in-place)
I0420 14:16:48.937880 38983 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0420 14:16:48.937973 38983 net.cpp:122] Setting up map64_1_scale_a
I0420 14:16:48.937978 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.937980 38983 net.cpp:137] Memory required for data: 492308480
I0420 14:16:48.937984 38983 layer_factory.hpp:77] Creating layer map64_1_relu_a
I0420 14:16:48.937991 38983 net.cpp:84] Creating Layer map64_1_relu_a
I0420 14:16:48.937994 38983 net.cpp:406] map64_1_relu_a <- map64_1_conv_a
I0420 14:16:48.937997 38983 net.cpp:367] map64_1_relu_a -> map64_1_conv_a (in-place)
I0420 14:16:48.939862 38983 net.cpp:122] Setting up map64_1_relu_a
I0420 14:16:48.939868 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.939872 38983 net.cpp:137] Memory required for data: 494405632
I0420 14:16:48.939874 38983 layer_factory.hpp:77] Creating layer map64_1_conv_b
I0420 14:16:48.939883 38983 net.cpp:84] Creating Layer map64_1_conv_b
I0420 14:16:48.939888 38983 net.cpp:406] map64_1_conv_b <- map64_1_conv_a
I0420 14:16:48.939893 38983 net.cpp:380] map64_1_conv_b -> map64_1_conv_b
I0420 14:16:48.947444 38983 net.cpp:122] Setting up map64_1_conv_b
I0420 14:16:48.947456 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.947459 38983 net.cpp:137] Memory required for data: 496502784
I0420 14:16:48.947466 38983 layer_factory.hpp:77] Creating layer map64_1_bn_b
I0420 14:16:48.947476 38983 net.cpp:84] Creating Layer map64_1_bn_b
I0420 14:16:48.947480 38983 net.cpp:406] map64_1_bn_b <- map64_1_conv_b
I0420 14:16:48.947485 38983 net.cpp:367] map64_1_bn_b -> map64_1_conv_b (in-place)
I0420 14:16:48.947664 38983 net.cpp:122] Setting up map64_1_bn_b
I0420 14:16:48.947669 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.947672 38983 net.cpp:137] Memory required for data: 498599936
I0420 14:16:48.947679 38983 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0420 14:16:48.947688 38983 net.cpp:84] Creating Layer map64_1_scale_b
I0420 14:16:48.947692 38983 net.cpp:406] map64_1_scale_b <- map64_1_conv_b
I0420 14:16:48.947696 38983 net.cpp:367] map64_1_scale_b -> map64_1_conv_b (in-place)
I0420 14:16:48.947727 38983 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0420 14:16:48.947824 38983 net.cpp:122] Setting up map64_1_scale_b
I0420 14:16:48.947829 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.947832 38983 net.cpp:137] Memory required for data: 500697088
I0420 14:16:48.947837 38983 layer_factory.hpp:77] Creating layer map64_1_eltsum
I0420 14:16:48.947844 38983 net.cpp:84] Creating Layer map64_1_eltsum
I0420 14:16:48.947846 38983 net.cpp:406] map64_1_eltsum <- map64_1_conv_proj
I0420 14:16:48.947850 38983 net.cpp:406] map64_1_eltsum <- map64_1_conv_b
I0420 14:16:48.947856 38983 net.cpp:380] map64_1_eltsum -> map64_1_eltsum
I0420 14:16:48.947872 38983 net.cpp:122] Setting up map64_1_eltsum
I0420 14:16:48.947876 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.947880 38983 net.cpp:137] Memory required for data: 502794240
I0420 14:16:48.947881 38983 layer_factory.hpp:77] Creating layer map64_1_relu_after_sum
I0420 14:16:48.947887 38983 net.cpp:84] Creating Layer map64_1_relu_after_sum
I0420 14:16:48.947890 38983 net.cpp:406] map64_1_relu_after_sum <- map64_1_eltsum
I0420 14:16:48.947895 38983 net.cpp:367] map64_1_relu_after_sum -> map64_1_eltsum (in-place)
I0420 14:16:48.949468 38983 net.cpp:122] Setting up map64_1_relu_after_sum
I0420 14:16:48.949476 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.949478 38983 net.cpp:137] Memory required for data: 504891392
I0420 14:16:48.949481 38983 layer_factory.hpp:77] Creating layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 14:16:48.949488 38983 net.cpp:84] Creating Layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 14:16:48.949492 38983 net.cpp:406] map64_1_eltsum_map64_1_relu_after_sum_0_split <- map64_1_eltsum
I0420 14:16:48.949496 38983 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0420 14:16:48.949501 38983 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0420 14:16:48.949538 38983 net.cpp:122] Setting up map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 14:16:48.949542 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.949546 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.949548 38983 net.cpp:137] Memory required for data: 509085696
I0420 14:16:48.949551 38983 layer_factory.hpp:77] Creating layer map64_2_conv_a
I0420 14:16:48.949561 38983 net.cpp:84] Creating Layer map64_2_conv_a
I0420 14:16:48.949564 38983 net.cpp:406] map64_2_conv_a <- map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0420 14:16:48.949569 38983 net.cpp:380] map64_2_conv_a -> map64_2_conv_a
I0420 14:16:48.956590 38983 net.cpp:122] Setting up map64_2_conv_a
I0420 14:16:48.956601 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.956605 38983 net.cpp:137] Memory required for data: 511182848
I0420 14:16:48.956610 38983 layer_factory.hpp:77] Creating layer map64_2_bn_a
I0420 14:16:48.956620 38983 net.cpp:84] Creating Layer map64_2_bn_a
I0420 14:16:48.956624 38983 net.cpp:406] map64_2_bn_a <- map64_2_conv_a
I0420 14:16:48.956629 38983 net.cpp:367] map64_2_bn_a -> map64_2_conv_a (in-place)
I0420 14:16:48.956805 38983 net.cpp:122] Setting up map64_2_bn_a
I0420 14:16:48.956811 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.956815 38983 net.cpp:137] Memory required for data: 513280000
I0420 14:16:48.956821 38983 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0420 14:16:48.956826 38983 net.cpp:84] Creating Layer map64_2_scale_a
I0420 14:16:48.956840 38983 net.cpp:406] map64_2_scale_a <- map64_2_conv_a
I0420 14:16:48.956845 38983 net.cpp:367] map64_2_scale_a -> map64_2_conv_a (in-place)
I0420 14:16:48.956878 38983 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0420 14:16:48.956975 38983 net.cpp:122] Setting up map64_2_scale_a
I0420 14:16:48.956980 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.956984 38983 net.cpp:137] Memory required for data: 515377152
I0420 14:16:48.956989 38983 layer_factory.hpp:77] Creating layer map64_2_relu_a
I0420 14:16:48.956995 38983 net.cpp:84] Creating Layer map64_2_relu_a
I0420 14:16:48.956998 38983 net.cpp:406] map64_2_relu_a <- map64_2_conv_a
I0420 14:16:48.957002 38983 net.cpp:367] map64_2_relu_a -> map64_2_conv_a (in-place)
I0420 14:16:48.958938 38983 net.cpp:122] Setting up map64_2_relu_a
I0420 14:16:48.958950 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.958952 38983 net.cpp:137] Memory required for data: 517474304
I0420 14:16:48.958956 38983 layer_factory.hpp:77] Creating layer map64_2_conv_b
I0420 14:16:48.958967 38983 net.cpp:84] Creating Layer map64_2_conv_b
I0420 14:16:48.958971 38983 net.cpp:406] map64_2_conv_b <- map64_2_conv_a
I0420 14:16:48.958976 38983 net.cpp:380] map64_2_conv_b -> map64_2_conv_b
I0420 14:16:48.966380 38983 net.cpp:122] Setting up map64_2_conv_b
I0420 14:16:48.966392 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.966397 38983 net.cpp:137] Memory required for data: 519571456
I0420 14:16:48.966403 38983 layer_factory.hpp:77] Creating layer map64_2_bn_b
I0420 14:16:48.966409 38983 net.cpp:84] Creating Layer map64_2_bn_b
I0420 14:16:48.966413 38983 net.cpp:406] map64_2_bn_b <- map64_2_conv_b
I0420 14:16:48.966419 38983 net.cpp:367] map64_2_bn_b -> map64_2_conv_b (in-place)
I0420 14:16:48.966593 38983 net.cpp:122] Setting up map64_2_bn_b
I0420 14:16:48.966598 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.966601 38983 net.cpp:137] Memory required for data: 521668608
I0420 14:16:48.966620 38983 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0420 14:16:48.966629 38983 net.cpp:84] Creating Layer map64_2_scale_b
I0420 14:16:48.966631 38983 net.cpp:406] map64_2_scale_b <- map64_2_conv_b
I0420 14:16:48.966635 38983 net.cpp:367] map64_2_scale_b -> map64_2_conv_b (in-place)
I0420 14:16:48.966665 38983 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0420 14:16:48.966790 38983 net.cpp:122] Setting up map64_2_scale_b
I0420 14:16:48.966796 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.966799 38983 net.cpp:137] Memory required for data: 523765760
I0420 14:16:48.966804 38983 layer_factory.hpp:77] Creating layer map64_2_eltsum
I0420 14:16:48.966809 38983 net.cpp:84] Creating Layer map64_2_eltsum
I0420 14:16:48.966814 38983 net.cpp:406] map64_2_eltsum <- map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0420 14:16:48.966817 38983 net.cpp:406] map64_2_eltsum <- map64_2_conv_b
I0420 14:16:48.966821 38983 net.cpp:380] map64_2_eltsum -> map64_2_eltsum
I0420 14:16:48.966838 38983 net.cpp:122] Setting up map64_2_eltsum
I0420 14:16:48.966843 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.966846 38983 net.cpp:137] Memory required for data: 525862912
I0420 14:16:48.966848 38983 layer_factory.hpp:77] Creating layer map64_2_relu_after_sum
I0420 14:16:48.966856 38983 net.cpp:84] Creating Layer map64_2_relu_after_sum
I0420 14:16:48.966859 38983 net.cpp:406] map64_2_relu_after_sum <- map64_2_eltsum
I0420 14:16:48.966862 38983 net.cpp:367] map64_2_relu_after_sum -> map64_2_eltsum (in-place)
I0420 14:16:48.968359 38983 net.cpp:122] Setting up map64_2_relu_after_sum
I0420 14:16:48.968366 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.968369 38983 net.cpp:137] Memory required for data: 527960064
I0420 14:16:48.968372 38983 layer_factory.hpp:77] Creating layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 14:16:48.968379 38983 net.cpp:84] Creating Layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 14:16:48.968384 38983 net.cpp:406] map64_2_eltsum_map64_2_relu_after_sum_0_split <- map64_2_eltsum
I0420 14:16:48.968399 38983 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0420 14:16:48.968405 38983 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0420 14:16:48.968442 38983 net.cpp:122] Setting up map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 14:16:48.968447 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.968451 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.968453 38983 net.cpp:137] Memory required for data: 532154368
I0420 14:16:48.968456 38983 layer_factory.hpp:77] Creating layer map64_3_conv_a
I0420 14:16:48.968466 38983 net.cpp:84] Creating Layer map64_3_conv_a
I0420 14:16:48.968469 38983 net.cpp:406] map64_3_conv_a <- map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0420 14:16:48.968474 38983 net.cpp:380] map64_3_conv_a -> map64_3_conv_a
I0420 14:16:48.975736 38983 net.cpp:122] Setting up map64_3_conv_a
I0420 14:16:48.975749 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.975751 38983 net.cpp:137] Memory required for data: 534251520
I0420 14:16:48.975757 38983 layer_factory.hpp:77] Creating layer map64_3_bn_a
I0420 14:16:48.975767 38983 net.cpp:84] Creating Layer map64_3_bn_a
I0420 14:16:48.975771 38983 net.cpp:406] map64_3_bn_a <- map64_3_conv_a
I0420 14:16:48.975775 38983 net.cpp:367] map64_3_bn_a -> map64_3_conv_a (in-place)
I0420 14:16:48.975951 38983 net.cpp:122] Setting up map64_3_bn_a
I0420 14:16:48.975957 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.975960 38983 net.cpp:137] Memory required for data: 536348672
I0420 14:16:48.975965 38983 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0420 14:16:48.975972 38983 net.cpp:84] Creating Layer map64_3_scale_a
I0420 14:16:48.975976 38983 net.cpp:406] map64_3_scale_a <- map64_3_conv_a
I0420 14:16:48.975980 38983 net.cpp:367] map64_3_scale_a -> map64_3_conv_a (in-place)
I0420 14:16:48.976027 38983 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0420 14:16:48.976126 38983 net.cpp:122] Setting up map64_3_scale_a
I0420 14:16:48.976131 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.976133 38983 net.cpp:137] Memory required for data: 538445824
I0420 14:16:48.976140 38983 layer_factory.hpp:77] Creating layer map64_3_relu_a
I0420 14:16:48.976145 38983 net.cpp:84] Creating Layer map64_3_relu_a
I0420 14:16:48.976147 38983 net.cpp:406] map64_3_relu_a <- map64_3_conv_a
I0420 14:16:48.976152 38983 net.cpp:367] map64_3_relu_a -> map64_3_conv_a (in-place)
I0420 14:16:48.978042 38983 net.cpp:122] Setting up map64_3_relu_a
I0420 14:16:48.978049 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.978052 38983 net.cpp:137] Memory required for data: 540542976
I0420 14:16:48.978055 38983 layer_factory.hpp:77] Creating layer map64_3_conv_b
I0420 14:16:48.978065 38983 net.cpp:84] Creating Layer map64_3_conv_b
I0420 14:16:48.978070 38983 net.cpp:406] map64_3_conv_b <- map64_3_conv_a
I0420 14:16:48.978075 38983 net.cpp:380] map64_3_conv_b -> map64_3_conv_b
I0420 14:16:48.985618 38983 net.cpp:122] Setting up map64_3_conv_b
I0420 14:16:48.985630 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.985632 38983 net.cpp:137] Memory required for data: 542640128
I0420 14:16:48.985640 38983 layer_factory.hpp:77] Creating layer map64_3_bn_b
I0420 14:16:48.985648 38983 net.cpp:84] Creating Layer map64_3_bn_b
I0420 14:16:48.985652 38983 net.cpp:406] map64_3_bn_b <- map64_3_conv_b
I0420 14:16:48.985656 38983 net.cpp:367] map64_3_bn_b -> map64_3_conv_b (in-place)
I0420 14:16:48.985841 38983 net.cpp:122] Setting up map64_3_bn_b
I0420 14:16:48.985846 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.985849 38983 net.cpp:137] Memory required for data: 544737280
I0420 14:16:48.985855 38983 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0420 14:16:48.985863 38983 net.cpp:84] Creating Layer map64_3_scale_b
I0420 14:16:48.985867 38983 net.cpp:406] map64_3_scale_b <- map64_3_conv_b
I0420 14:16:48.985882 38983 net.cpp:367] map64_3_scale_b -> map64_3_conv_b (in-place)
I0420 14:16:48.985913 38983 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0420 14:16:48.986016 38983 net.cpp:122] Setting up map64_3_scale_b
I0420 14:16:48.986021 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.986023 38983 net.cpp:137] Memory required for data: 546834432
I0420 14:16:48.986028 38983 layer_factory.hpp:77] Creating layer map64_3_eltsum
I0420 14:16:48.986033 38983 net.cpp:84] Creating Layer map64_3_eltsum
I0420 14:16:48.986037 38983 net.cpp:406] map64_3_eltsum <- map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0420 14:16:48.986040 38983 net.cpp:406] map64_3_eltsum <- map64_3_conv_b
I0420 14:16:48.986045 38983 net.cpp:380] map64_3_eltsum -> map64_3_eltsum
I0420 14:16:48.986063 38983 net.cpp:122] Setting up map64_3_eltsum
I0420 14:16:48.986068 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.986070 38983 net.cpp:137] Memory required for data: 548931584
I0420 14:16:48.986073 38983 layer_factory.hpp:77] Creating layer map64_3_relu_after_sum
I0420 14:16:48.986078 38983 net.cpp:84] Creating Layer map64_3_relu_after_sum
I0420 14:16:48.986080 38983 net.cpp:406] map64_3_relu_after_sum <- map64_3_eltsum
I0420 14:16:48.986083 38983 net.cpp:367] map64_3_relu_after_sum -> map64_3_eltsum (in-place)
I0420 14:16:48.987668 38983 net.cpp:122] Setting up map64_3_relu_after_sum
I0420 14:16:48.987680 38983 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0420 14:16:48.987686 38983 net.cpp:137] Memory required for data: 551028736
I0420 14:16:48.987689 38983 layer_factory.hpp:77] Creating layer pool_global
I0420 14:16:48.987716 38983 net.cpp:84] Creating Layer pool_global
I0420 14:16:48.987720 38983 net.cpp:406] pool_global <- map64_3_eltsum
I0420 14:16:48.987723 38983 net.cpp:380] pool_global -> pool_global
I0420 14:16:48.990140 38983 net.cpp:122] Setting up pool_global
I0420 14:16:48.990149 38983 net.cpp:129] Top shape: 128 64 1 1 (8192)
I0420 14:16:48.990151 38983 net.cpp:137] Memory required for data: 551061504
I0420 14:16:48.990154 38983 layer_factory.hpp:77] Creating layer score
I0420 14:16:48.990161 38983 net.cpp:84] Creating Layer score
I0420 14:16:48.990164 38983 net.cpp:406] score <- pool_global
I0420 14:16:48.990170 38983 net.cpp:380] score -> score
I0420 14:16:48.990281 38983 net.cpp:122] Setting up score
I0420 14:16:48.990286 38983 net.cpp:129] Top shape: 128 10 (1280)
I0420 14:16:48.990289 38983 net.cpp:137] Memory required for data: 551066624
I0420 14:16:48.990294 38983 layer_factory.hpp:77] Creating layer score_score_0_split
I0420 14:16:48.990299 38983 net.cpp:84] Creating Layer score_score_0_split
I0420 14:16:48.990303 38983 net.cpp:406] score_score_0_split <- score
I0420 14:16:48.990306 38983 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0420 14:16:48.990311 38983 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0420 14:16:48.990317 38983 net.cpp:380] score_score_0_split -> score_score_0_split_2
I0420 14:16:48.990357 38983 net.cpp:122] Setting up score_score_0_split
I0420 14:16:48.990362 38983 net.cpp:129] Top shape: 128 10 (1280)
I0420 14:16:48.990365 38983 net.cpp:129] Top shape: 128 10 (1280)
I0420 14:16:48.990368 38983 net.cpp:129] Top shape: 128 10 (1280)
I0420 14:16:48.990371 38983 net.cpp:137] Memory required for data: 551081984
I0420 14:16:48.990373 38983 layer_factory.hpp:77] Creating layer loss
I0420 14:16:48.990380 38983 net.cpp:84] Creating Layer loss
I0420 14:16:48.990382 38983 net.cpp:406] loss <- score_score_0_split_0
I0420 14:16:48.990386 38983 net.cpp:406] loss <- label_data_1_split_0
I0420 14:16:48.990391 38983 net.cpp:380] loss -> loss
I0420 14:16:48.990402 38983 layer_factory.hpp:77] Creating layer loss
I0420 14:16:48.992555 38983 net.cpp:122] Setting up loss
I0420 14:16:48.992568 38983 net.cpp:129] Top shape: (1)
I0420 14:16:48.992570 38983 net.cpp:132]     with loss weight 1
I0420 14:16:48.992596 38983 net.cpp:137] Memory required for data: 551081988
I0420 14:16:48.992599 38983 layer_factory.hpp:77] Creating layer acc/top1
I0420 14:16:48.992616 38983 net.cpp:84] Creating Layer acc/top1
I0420 14:16:48.992620 38983 net.cpp:406] acc/top1 <- score_score_0_split_1
I0420 14:16:48.992625 38983 net.cpp:406] acc/top1 <- label_data_1_split_1
I0420 14:16:48.992630 38983 net.cpp:380] acc/top1 -> acctop1
I0420 14:16:48.992642 38983 net.cpp:122] Setting up acc/top1
I0420 14:16:48.992646 38983 net.cpp:129] Top shape: (1)
I0420 14:16:48.992648 38983 net.cpp:137] Memory required for data: 551081992
I0420 14:16:48.992651 38983 layer_factory.hpp:77] Creating layer acc/top5
I0420 14:16:48.992658 38983 net.cpp:84] Creating Layer acc/top5
I0420 14:16:48.992661 38983 net.cpp:406] acc/top5 <- score_score_0_split_2
I0420 14:16:48.992664 38983 net.cpp:406] acc/top5 <- label_data_1_split_2
I0420 14:16:48.992668 38983 net.cpp:380] acc/top5 -> acctop5
I0420 14:16:48.992674 38983 net.cpp:122] Setting up acc/top5
I0420 14:16:48.992677 38983 net.cpp:129] Top shape: (1)
I0420 14:16:48.992679 38983 net.cpp:137] Memory required for data: 551081996
I0420 14:16:48.992687 38983 net.cpp:200] acc/top5 does not need backward computation.
I0420 14:16:48.992691 38983 net.cpp:200] acc/top1 does not need backward computation.
I0420 14:16:48.992693 38983 net.cpp:198] loss needs backward computation.
I0420 14:16:48.992697 38983 net.cpp:198] score_score_0_split needs backward computation.
I0420 14:16:48.992699 38983 net.cpp:198] score needs backward computation.
I0420 14:16:48.992702 38983 net.cpp:198] pool_global needs backward computation.
I0420 14:16:48.992704 38983 net.cpp:198] map64_3_relu_after_sum needs backward computation.
I0420 14:16:48.992707 38983 net.cpp:198] map64_3_eltsum needs backward computation.
I0420 14:16:48.992709 38983 net.cpp:198] map64_3_scale_b needs backward computation.
I0420 14:16:48.992712 38983 net.cpp:198] map64_3_bn_b needs backward computation.
I0420 14:16:48.992714 38983 net.cpp:198] map64_3_conv_b needs backward computation.
I0420 14:16:48.992717 38983 net.cpp:198] map64_3_relu_a needs backward computation.
I0420 14:16:48.992719 38983 net.cpp:198] map64_3_scale_a needs backward computation.
I0420 14:16:48.992722 38983 net.cpp:198] map64_3_bn_a needs backward computation.
I0420 14:16:48.992723 38983 net.cpp:198] map64_3_conv_a needs backward computation.
I0420 14:16:48.992727 38983 net.cpp:198] map64_2_eltsum_map64_2_relu_after_sum_0_split needs backward computation.
I0420 14:16:48.992728 38983 net.cpp:198] map64_2_relu_after_sum needs backward computation.
I0420 14:16:48.992732 38983 net.cpp:198] map64_2_eltsum needs backward computation.
I0420 14:16:48.992734 38983 net.cpp:198] map64_2_scale_b needs backward computation.
I0420 14:16:48.992736 38983 net.cpp:198] map64_2_bn_b needs backward computation.
I0420 14:16:48.992739 38983 net.cpp:198] map64_2_conv_b needs backward computation.
I0420 14:16:48.992741 38983 net.cpp:198] map64_2_relu_a needs backward computation.
I0420 14:16:48.992746 38983 net.cpp:198] map64_2_scale_a needs backward computation.
I0420 14:16:48.992748 38983 net.cpp:198] map64_2_bn_a needs backward computation.
I0420 14:16:48.992750 38983 net.cpp:198] map64_2_conv_a needs backward computation.
I0420 14:16:48.992753 38983 net.cpp:198] map64_1_eltsum_map64_1_relu_after_sum_0_split needs backward computation.
I0420 14:16:48.992756 38983 net.cpp:198] map64_1_relu_after_sum needs backward computation.
I0420 14:16:48.992758 38983 net.cpp:198] map64_1_eltsum needs backward computation.
I0420 14:16:48.992760 38983 net.cpp:198] map64_1_scale_b needs backward computation.
I0420 14:16:48.992763 38983 net.cpp:198] map64_1_bn_b needs backward computation.
I0420 14:16:48.992765 38983 net.cpp:198] map64_1_conv_b needs backward computation.
I0420 14:16:48.992768 38983 net.cpp:198] map64_1_relu_a needs backward computation.
I0420 14:16:48.992770 38983 net.cpp:198] map64_1_scale_a needs backward computation.
I0420 14:16:48.992774 38983 net.cpp:198] map64_1_bn_a needs backward computation.
I0420 14:16:48.992775 38983 net.cpp:198] map64_1_conv_a needs backward computation.
I0420 14:16:48.992777 38983 net.cpp:198] map64_1_scale_proj needs backward computation.
I0420 14:16:48.992789 38983 net.cpp:198] map64_1_bn_proj needs backward computation.
I0420 14:16:48.992791 38983 net.cpp:198] map64_1_conv_proj needs backward computation.
I0420 14:16:48.992794 38983 net.cpp:198] map32_3_eltsum_map32_3_relu_after_sum_0_split needs backward computation.
I0420 14:16:48.992796 38983 net.cpp:198] map32_3_relu_after_sum needs backward computation.
I0420 14:16:48.992799 38983 net.cpp:198] map32_3_eltsum needs backward computation.
I0420 14:16:48.992800 38983 net.cpp:198] map32_3_scale_b needs backward computation.
I0420 14:16:48.992804 38983 net.cpp:198] map32_3_bn_b needs backward computation.
I0420 14:16:48.992805 38983 net.cpp:198] map32_3_conv_b needs backward computation.
I0420 14:16:48.992808 38983 net.cpp:198] map32_3_relu_a needs backward computation.
I0420 14:16:48.992810 38983 net.cpp:198] map32_3_scale_a needs backward computation.
I0420 14:16:48.992813 38983 net.cpp:198] map32_3_bn_a needs backward computation.
I0420 14:16:48.992815 38983 net.cpp:198] map32_3_conv_a needs backward computation.
I0420 14:16:48.992817 38983 net.cpp:198] map32_2_eltsum_map32_2_relu_after_sum_0_split needs backward computation.
I0420 14:16:48.992820 38983 net.cpp:198] map32_2_relu_after_sum needs backward computation.
I0420 14:16:48.992822 38983 net.cpp:198] map32_2_eltsum needs backward computation.
I0420 14:16:48.992825 38983 net.cpp:198] map32_2_scale_b needs backward computation.
I0420 14:16:48.992827 38983 net.cpp:198] map32_2_bn_b needs backward computation.
I0420 14:16:48.992830 38983 net.cpp:198] map32_2_conv_b needs backward computation.
I0420 14:16:48.992832 38983 net.cpp:198] map32_2_relu_a needs backward computation.
I0420 14:16:48.992835 38983 net.cpp:198] map32_2_scale_a needs backward computation.
I0420 14:16:48.992836 38983 net.cpp:198] map32_2_bn_a needs backward computation.
I0420 14:16:48.992838 38983 net.cpp:198] map32_2_conv_a needs backward computation.
I0420 14:16:48.992841 38983 net.cpp:198] map32_1_eltsum_map32_1_relu_after_sum_0_split needs backward computation.
I0420 14:16:48.992843 38983 net.cpp:198] map32_1_relu_after_sum needs backward computation.
I0420 14:16:48.992846 38983 net.cpp:198] map32_1_eltsum needs backward computation.
I0420 14:16:48.992849 38983 net.cpp:198] map32_1_scale_b needs backward computation.
I0420 14:16:48.992851 38983 net.cpp:198] map32_1_bn_b needs backward computation.
I0420 14:16:48.992853 38983 net.cpp:198] map32_1_conv_b needs backward computation.
I0420 14:16:48.992856 38983 net.cpp:198] map32_1_relu_a needs backward computation.
I0420 14:16:48.992858 38983 net.cpp:198] map32_1_scale_a needs backward computation.
I0420 14:16:48.992861 38983 net.cpp:198] map32_1_bn_a needs backward computation.
I0420 14:16:48.992862 38983 net.cpp:198] map32_1_conv_a needs backward computation.
I0420 14:16:48.992866 38983 net.cpp:198] map32_1_scale_proj needs backward computation.
I0420 14:16:48.992868 38983 net.cpp:198] map32_1_bn_proj needs backward computation.
I0420 14:16:48.992871 38983 net.cpp:198] map32_1_conv_proj needs backward computation.
I0420 14:16:48.992872 38983 net.cpp:198] map16_3_eltsum_map16_3_relu_after_sum_0_split needs backward computation.
I0420 14:16:48.992874 38983 net.cpp:198] map16_3_relu_after_sum needs backward computation.
I0420 14:16:48.992877 38983 net.cpp:198] map16_3_eltsum needs backward computation.
I0420 14:16:48.992880 38983 net.cpp:198] map16_3_scale_b needs backward computation.
I0420 14:16:48.992882 38983 net.cpp:198] map16_3_bn_b needs backward computation.
I0420 14:16:48.992885 38983 net.cpp:198] map16_3_conv_b needs backward computation.
I0420 14:16:48.992887 38983 net.cpp:198] map16_3_relu_a needs backward computation.
I0420 14:16:48.992889 38983 net.cpp:198] map16_3_scale_a needs backward computation.
I0420 14:16:48.992892 38983 net.cpp:198] map16_3_bn_a needs backward computation.
I0420 14:16:48.992894 38983 net.cpp:198] map16_3_conv_a needs backward computation.
I0420 14:16:48.992897 38983 net.cpp:198] map16_2_eltsum_map16_2_relu_after_sum_0_split needs backward computation.
I0420 14:16:48.992899 38983 net.cpp:198] map16_2_relu_after_sum needs backward computation.
I0420 14:16:48.992908 38983 net.cpp:198] map16_2_eltsum needs backward computation.
I0420 14:16:48.992909 38983 net.cpp:198] map16_2_scale_b needs backward computation.
I0420 14:16:48.992913 38983 net.cpp:198] map16_2_bn_b needs backward computation.
I0420 14:16:48.992913 38983 net.cpp:198] map16_2_conv_b needs backward computation.
I0420 14:16:48.992916 38983 net.cpp:198] map16_2_relu_a needs backward computation.
I0420 14:16:48.992918 38983 net.cpp:198] map16_2_scale_a needs backward computation.
I0420 14:16:48.992920 38983 net.cpp:198] map16_2_bn_a needs backward computation.
I0420 14:16:48.992923 38983 net.cpp:198] map16_2_conv_a needs backward computation.
I0420 14:16:48.992924 38983 net.cpp:198] map16_1_eltsum_map16_1_relu_after_sum_0_split needs backward computation.
I0420 14:16:48.992928 38983 net.cpp:198] map16_1_relu_after_sum needs backward computation.
I0420 14:16:48.992929 38983 net.cpp:198] map16_1_eltsum needs backward computation.
I0420 14:16:48.992933 38983 net.cpp:198] map16_1_scale_b needs backward computation.
I0420 14:16:48.992934 38983 net.cpp:198] map16_1_bn_b needs backward computation.
I0420 14:16:48.992936 38983 net.cpp:198] map16_1_conv_b needs backward computation.
I0420 14:16:48.992939 38983 net.cpp:198] map16_1_relu_a needs backward computation.
I0420 14:16:48.992941 38983 net.cpp:198] map16_1_scale_a needs backward computation.
I0420 14:16:48.992944 38983 net.cpp:198] map16_1_bn_a needs backward computation.
I0420 14:16:48.992946 38983 net.cpp:198] map16_1_conv_a needs backward computation.
I0420 14:16:48.992949 38983 net.cpp:198] conv1_relu_conv1_0_split needs backward computation.
I0420 14:16:48.992951 38983 net.cpp:198] relu_conv1 needs backward computation.
I0420 14:16:48.992954 38983 net.cpp:198] scale_conv1 needs backward computation.
I0420 14:16:48.992956 38983 net.cpp:198] bn_conv1 needs backward computation.
I0420 14:16:48.992959 38983 net.cpp:198] conv1 needs backward computation.
I0420 14:16:48.992961 38983 net.cpp:200] label_data_1_split does not need backward computation.
I0420 14:16:48.992965 38983 net.cpp:200] data does not need backward computation.
I0420 14:16:48.992967 38983 net.cpp:242] This network produces output acctop1
I0420 14:16:48.992970 38983 net.cpp:242] This network produces output acctop5
I0420 14:16:48.992974 38983 net.cpp:242] This network produces output loss
I0420 14:16:48.993023 38983 net.cpp:255] Network initialization done.
I0420 14:16:48.995702 38983 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet20_relu_msra_cifar10_fix_pattern.prototxt
I0420 14:16:48.995715 38983 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0420 14:16:48.995723 38983 solver.cpp:173] Creating test net (#0) specified by net file: resnet20_relu_msra_cifar10_fix_pattern.prototxt
I0420 14:16:48.995836 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0420 14:16:48.995844 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv1
I0420 14:16:48.995851 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_1_bn_a
I0420 14:16:48.995856 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_1_bn_b
I0420 14:16:48.995862 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_2_bn_a
I0420 14:16:48.995867 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_2_bn_b
I0420 14:16:48.995872 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_3_bn_a
I0420 14:16:48.995877 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_3_bn_b
I0420 14:16:48.995882 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_proj
I0420 14:16:48.995896 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_a
I0420 14:16:48.995903 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_b
I0420 14:16:48.995908 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_2_bn_a
I0420 14:16:48.995911 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_2_bn_b
I0420 14:16:48.995918 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_3_bn_a
I0420 14:16:48.995923 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_3_bn_b
I0420 14:16:48.995928 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_proj
I0420 14:16:48.995932 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_a
I0420 14:16:48.995937 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_b
I0420 14:16:48.995942 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_2_bn_a
I0420 14:16:48.995947 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_2_bn_b
I0420 14:16:48.995952 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_3_bn_a
I0420 14:16:48.995957 38983 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_3_bn_b
I0420 14:16:48.996418 38983 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 32
    mean_file: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/mean.binaryproto"
  }
  data_param {
    source: "/Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_test_leveldb_copy/"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "map16_1_conv_a"
  type: "Convolution"
  bottom: "conv1"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_a"
  type: "BatchNorm"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_1_scale_a"
  type: "Scale"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_relu_a"
  type: "ReLU"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
}
layer {
  name: "map16_1_conv_b"
  type: "Convolution"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_b"
  type: "BatchNorm"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_1_scale_b"
  type: "Scale"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_eltsum"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "map16_1_conv_b"
  top: "map16_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_1_relu_after_sum"
  type: "ReLU"
  bottom: "map16_1_eltsum"
  top: "map16_1_eltsum"
}
layer {
  name: "map16_2_conv_a"
  type: "Convolution"
  bottom: "map16_1_eltsum"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_a"
  type: "BatchNorm"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_2_scale_a"
  type: "Scale"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_relu_a"
  type: "ReLU"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
}
layer {
  name: "map16_2_conv_b"
  type: "Convolution"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_b"
  type: "BatchNorm"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_2_scale_b"
  type: "Scale"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_eltsum"
  type: "Eltwise"
  bottom: "map16_1_eltsum"
  bottom: "map16_2_conv_b"
  top: "map16_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_2_relu_after_sum"
  type: "ReLU"
  bottom: "map16_2_eltsum"
  top: "map16_2_eltsum"
}
layer {
  name: "map16_3_conv_a"
  type: "Convolution"
  bottom: "map16_2_eltsum"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_a"
  type: "BatchNorm"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_3_scale_a"
  type: "Scale"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_relu_a"
  type: "ReLU"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
}
layer {
  name: "map16_3_conv_b"
  type: "Convolution"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_b"
  type: "BatchNorm"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_3_scale_b"
  type: "Scale"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_eltsum"
  type: "Eltwise"
  bottom: "map16_2_eltsum"
  bottom: "map16_3_conv_b"
  top: "map16_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_3_relu_after_sum"
  type: "ReLU"
  bottom: "map16_3_eltsum"
  top: "map16_3_eltsum"
}
layer {
  name: "map32_1_conv_proj"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_proj"
  type: "BatchNorm"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_proj"
  type: "Scale"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_conv_a"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_a"
  type: "BatchNorm"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_a"
  type: "Scale"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_relu_a"
  type: "ReLU"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
}
layer {
  name: "map32_1_conv_b"
  type: "Convolution"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_b"
  type: "BatchNorm"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_b"
  type: "Scale"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_eltsum"
  type: "Eltwise"
  bottom: "map32_1_conv_proj"
  bottom: "map32_1_conv_b"
  top: "map32_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_1_relu_after_sum"
  type: "ReLU"
  bottom: "map32_1_eltsum"
  top: "map32_1_eltsum"
}
layer {
  name: "map32_2_conv_a"
  type: "Convolution"
  bottom: "map32_1_eltsum"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_a"
  type: "BatchNorm"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_2_scale_a"
  type: "Scale"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_relu_a"
  type: "ReLU"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
}
layer {
  name: "map32_2_conv_b"
  type: "Convolution"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_b"
  type: "BatchNorm"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_2_scale_b"
  type: "Scale"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_eltsum"
  type: "Eltwise"
  bottom: "map32_1_eltsum"
  bottom: "map32_2_conv_b"
  top: "map32_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_2_relu_after_sum"
  type: "ReLU"
  bottom: "map32_2_eltsum"
  top: "map32_2_eltsum"
}
layer {
  name: "map32_3_conv_a"
  type: "Convolution"
  bottom: "map32_2_eltsum"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_a"
  type: "BatchNorm"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_3_scale_a"
  type: "Scale"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_relu_a"
  type: "ReLU"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
}
layer {
  name: "map32_3_conv_b"
  type: "Convolution"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_b"
  type: "BatchNorm"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_3_scale_b"
  type: "Scale"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_eltsum"
  type: "Eltwise"
  bottom: "map32_2_eltsum"
  bottom: "map32_3_conv_b"
  top: "map32_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_3_relu_after_sum"
  type: "ReLU"
  bottom: "map32_3_eltsum"
  top: "map32_3_eltsum"
}
layer {
  name: "map64_1_conv_proj"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_proj"
  type: "BatchNorm"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_proj"
  type: "Scale"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_conv_a"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_a"
  type: "BatchNorm"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_a"
  type: "Scale"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_relu_a"
  type: "ReLU"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
}
layer {
  name: "map64_1_conv_b"
  type: "Convolution"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_b"
  type: "BatchNorm"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_b"
  type: "Scale"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_eltsum"
  type: "Eltwise"
  bottom: "map64_1_conv_proj"
  bottom: "map64_1_conv_b"
  top: "map64_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_1_relu_after_sum"
  type: "ReLU"
  bottom: "map64_1_eltsum"
  top: "map64_1_eltsum"
}
layer {
  name: "map64_2_conv_a"
  type: "Convolution"
  bottom: "map64_1_eltsum"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_a"
  type: "BatchNorm"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_2_scale_a"
  type: "Scale"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_relu_a"
  type: "ReLU"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
}
layer {
  name: "map64_2_conv_b"
  type: "Convolution"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_b"
  type: "BatchNorm"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_2_scale_b"
  type: "Scale"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_eltsum"
  type: "Eltwise"
  bottom: "map64_1_eltsum"
  bottom: "map64_2_conv_b"
  top: "map64_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_2_relu_after_sum"
  type: "ReLU"
  bottom: "map64_2_eltsum"
  top: "map64_2_eltsum"
}
layer {
  name: "map64_3_conv_a"
  type: "Convolution"
  bottom: "map64_2_eltsum"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_a"
  type: "BatchNorm"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_3_scale_a"
  type: "Scale"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_relu_a"
  type: "ReLU"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
}
layer {
  name: "map64_3_conv_b"
  type: "Convolution"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_b"
  type: "BatchNorm"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_3_scale_b"
  type: "Scale"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_eltsum"
  type: "Eltwise"
  bottom: "map64_2_eltsum"
  bottom: "map64_3_conv_b"
  top: "map64_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_3_relu_after_sum"
  type: "ReLU"
  bottom: "map64_3_eltsum"
  top: "map64_3_eltsum"
}
layer {
  name: "pool_global"
  type: "Pooling"
  bottom: "map64_3_eltsum"
  top: "pool_global"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_global"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc/top1"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc/top5"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop5"
  accuracy_param {
    top_k: 5
  }
}
I0420 14:16:48.996772 38983 layer_factory.hpp:77] Creating layer data
I0420 14:16:49.010023 38983 db_leveldb.cpp:18] Opened leveldb /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/cifar10_test_leveldb_copy/
I0420 14:16:49.011521 38983 net.cpp:84] Creating Layer data
I0420 14:16:49.011533 38983 net.cpp:380] data -> data
I0420 14:16:49.011557 38983 net.cpp:380] data -> label
I0420 14:16:49.011564 38983 data_transformer.cpp:25] Loading mean file from: /Users/zli79/cifar10/cifar10-gcn-leveldb-splits/mean.binaryproto
I0420 14:16:49.012217 38983 data_layer.cpp:45] output data size: 100,3,32,32
I0420 14:16:49.024457 38983 net.cpp:122] Setting up data
I0420 14:16:49.024507 38983 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0420 14:16:49.024513 38983 net.cpp:129] Top shape: 100 (100)
I0420 14:16:49.024514 38983 net.cpp:137] Memory required for data: 1229200
I0420 14:16:49.024518 38983 layer_factory.hpp:77] Creating layer label_data_1_split
I0420 14:16:49.024523 38983 net.cpp:84] Creating Layer label_data_1_split
I0420 14:16:49.024528 38983 net.cpp:406] label_data_1_split <- label
I0420 14:16:49.024533 38983 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0420 14:16:49.024540 38983 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0420 14:16:49.024545 38983 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0420 14:16:49.024638 38983 net.cpp:122] Setting up label_data_1_split
I0420 14:16:49.024644 38983 net.cpp:129] Top shape: 100 (100)
I0420 14:16:49.024647 38983 net.cpp:129] Top shape: 100 (100)
I0420 14:16:49.024651 38983 net.cpp:129] Top shape: 100 (100)
I0420 14:16:49.024653 38983 net.cpp:137] Memory required for data: 1230400
I0420 14:16:49.024655 38983 layer_factory.hpp:77] Creating layer conv1
I0420 14:16:49.024667 38983 net.cpp:84] Creating Layer conv1
I0420 14:16:49.024670 38983 net.cpp:406] conv1 <- data
I0420 14:16:49.024675 38983 net.cpp:380] conv1 -> conv1
I0420 14:16:49.031708 38983 net.cpp:122] Setting up conv1
I0420 14:16:49.031719 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.031723 38983 net.cpp:137] Memory required for data: 7784000
I0420 14:16:49.031731 38983 layer_factory.hpp:77] Creating layer bn_conv1
I0420 14:16:49.031740 38983 net.cpp:84] Creating Layer bn_conv1
I0420 14:16:49.031744 38983 net.cpp:406] bn_conv1 <- conv1
I0420 14:16:49.031750 38983 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0420 14:16:49.034206 38983 net.cpp:122] Setting up bn_conv1
I0420 14:16:49.034214 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.034219 38983 net.cpp:137] Memory required for data: 14337600
I0420 14:16:49.034226 38983 layer_factory.hpp:77] Creating layer scale_conv1
I0420 14:16:49.034235 38983 net.cpp:84] Creating Layer scale_conv1
I0420 14:16:49.034238 38983 net.cpp:406] scale_conv1 <- conv1
I0420 14:16:49.034242 38983 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0420 14:16:49.034281 38983 layer_factory.hpp:77] Creating layer scale_conv1
I0420 14:16:49.034385 38983 net.cpp:122] Setting up scale_conv1
I0420 14:16:49.034390 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.034394 38983 net.cpp:137] Memory required for data: 20891200
I0420 14:16:49.034399 38983 layer_factory.hpp:77] Creating layer relu_conv1
I0420 14:16:49.034404 38983 net.cpp:84] Creating Layer relu_conv1
I0420 14:16:49.034406 38983 net.cpp:406] relu_conv1 <- conv1
I0420 14:16:49.034411 38983 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0420 14:16:49.034571 38983 net.cpp:122] Setting up relu_conv1
I0420 14:16:49.034579 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.034581 38983 net.cpp:137] Memory required for data: 27444800
I0420 14:16:49.034584 38983 layer_factory.hpp:77] Creating layer conv1_relu_conv1_0_split
I0420 14:16:49.034588 38983 net.cpp:84] Creating Layer conv1_relu_conv1_0_split
I0420 14:16:49.034603 38983 net.cpp:406] conv1_relu_conv1_0_split <- conv1
I0420 14:16:49.034610 38983 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_0
I0420 14:16:49.034615 38983 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_1
I0420 14:16:49.034657 38983 net.cpp:122] Setting up conv1_relu_conv1_0_split
I0420 14:16:49.034664 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.034668 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.034670 38983 net.cpp:137] Memory required for data: 40552000
I0420 14:16:49.034673 38983 layer_factory.hpp:77] Creating layer map16_1_conv_a
I0420 14:16:49.034685 38983 net.cpp:84] Creating Layer map16_1_conv_a
I0420 14:16:49.034689 38983 net.cpp:406] map16_1_conv_a <- conv1_relu_conv1_0_split_0
I0420 14:16:49.034709 38983 net.cpp:380] map16_1_conv_a -> map16_1_conv_a
I0420 14:16:49.041818 38983 net.cpp:122] Setting up map16_1_conv_a
I0420 14:16:49.041833 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.041837 38983 net.cpp:137] Memory required for data: 47105600
I0420 14:16:49.041846 38983 layer_factory.hpp:77] Creating layer map16_1_bn_a
I0420 14:16:49.041856 38983 net.cpp:84] Creating Layer map16_1_bn_a
I0420 14:16:49.041859 38983 net.cpp:406] map16_1_bn_a <- map16_1_conv_a
I0420 14:16:49.041863 38983 net.cpp:367] map16_1_bn_a -> map16_1_conv_a (in-place)
I0420 14:16:49.042047 38983 net.cpp:122] Setting up map16_1_bn_a
I0420 14:16:49.042054 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.042057 38983 net.cpp:137] Memory required for data: 53659200
I0420 14:16:49.042062 38983 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0420 14:16:49.042068 38983 net.cpp:84] Creating Layer map16_1_scale_a
I0420 14:16:49.042071 38983 net.cpp:406] map16_1_scale_a <- map16_1_conv_a
I0420 14:16:49.042075 38983 net.cpp:367] map16_1_scale_a -> map16_1_conv_a (in-place)
I0420 14:16:49.042110 38983 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0420 14:16:49.042215 38983 net.cpp:122] Setting up map16_1_scale_a
I0420 14:16:49.042220 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.042223 38983 net.cpp:137] Memory required for data: 60212800
I0420 14:16:49.042228 38983 layer_factory.hpp:77] Creating layer map16_1_relu_a
I0420 14:16:49.042234 38983 net.cpp:84] Creating Layer map16_1_relu_a
I0420 14:16:49.042238 38983 net.cpp:406] map16_1_relu_a <- map16_1_conv_a
I0420 14:16:49.042242 38983 net.cpp:367] map16_1_relu_a -> map16_1_conv_a (in-place)
I0420 14:16:49.043843 38983 net.cpp:122] Setting up map16_1_relu_a
I0420 14:16:49.043850 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.043853 38983 net.cpp:137] Memory required for data: 66766400
I0420 14:16:49.043856 38983 layer_factory.hpp:77] Creating layer map16_1_conv_b
I0420 14:16:49.043869 38983 net.cpp:84] Creating Layer map16_1_conv_b
I0420 14:16:49.043871 38983 net.cpp:406] map16_1_conv_b <- map16_1_conv_a
I0420 14:16:49.043876 38983 net.cpp:380] map16_1_conv_b -> map16_1_conv_b
I0420 14:16:49.051020 38983 net.cpp:122] Setting up map16_1_conv_b
I0420 14:16:49.051033 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.051053 38983 net.cpp:137] Memory required for data: 73320000
I0420 14:16:49.051059 38983 layer_factory.hpp:77] Creating layer map16_1_bn_b
I0420 14:16:49.051066 38983 net.cpp:84] Creating Layer map16_1_bn_b
I0420 14:16:49.051070 38983 net.cpp:406] map16_1_bn_b <- map16_1_conv_b
I0420 14:16:49.051076 38983 net.cpp:367] map16_1_bn_b -> map16_1_conv_b (in-place)
I0420 14:16:49.051257 38983 net.cpp:122] Setting up map16_1_bn_b
I0420 14:16:49.051264 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.051266 38983 net.cpp:137] Memory required for data: 79873600
I0420 14:16:49.051276 38983 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0420 14:16:49.051282 38983 net.cpp:84] Creating Layer map16_1_scale_b
I0420 14:16:49.051285 38983 net.cpp:406] map16_1_scale_b <- map16_1_conv_b
I0420 14:16:49.051290 38983 net.cpp:367] map16_1_scale_b -> map16_1_conv_b (in-place)
I0420 14:16:49.051338 38983 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0420 14:16:49.051442 38983 net.cpp:122] Setting up map16_1_scale_b
I0420 14:16:49.051447 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.051450 38983 net.cpp:137] Memory required for data: 86427200
I0420 14:16:49.051455 38983 layer_factory.hpp:77] Creating layer map16_1_eltsum
I0420 14:16:49.051461 38983 net.cpp:84] Creating Layer map16_1_eltsum
I0420 14:16:49.051465 38983 net.cpp:406] map16_1_eltsum <- conv1_relu_conv1_0_split_1
I0420 14:16:49.051468 38983 net.cpp:406] map16_1_eltsum <- map16_1_conv_b
I0420 14:16:49.051473 38983 net.cpp:380] map16_1_eltsum -> map16_1_eltsum
I0420 14:16:49.051496 38983 net.cpp:122] Setting up map16_1_eltsum
I0420 14:16:49.051501 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.051503 38983 net.cpp:137] Memory required for data: 92980800
I0420 14:16:49.051506 38983 layer_factory.hpp:77] Creating layer map16_1_relu_after_sum
I0420 14:16:49.051509 38983 net.cpp:84] Creating Layer map16_1_relu_after_sum
I0420 14:16:49.051512 38983 net.cpp:406] map16_1_relu_after_sum <- map16_1_eltsum
I0420 14:16:49.051517 38983 net.cpp:367] map16_1_relu_after_sum -> map16_1_eltsum (in-place)
I0420 14:16:49.053395 38983 net.cpp:122] Setting up map16_1_relu_after_sum
I0420 14:16:49.053402 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.053406 38983 net.cpp:137] Memory required for data: 99534400
I0420 14:16:49.053408 38983 layer_factory.hpp:77] Creating layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 14:16:49.053414 38983 net.cpp:84] Creating Layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 14:16:49.053417 38983 net.cpp:406] map16_1_eltsum_map16_1_relu_after_sum_0_split <- map16_1_eltsum
I0420 14:16:49.053423 38983 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0420 14:16:49.053429 38983 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0420 14:16:49.053467 38983 net.cpp:122] Setting up map16_1_eltsum_map16_1_relu_after_sum_0_split
I0420 14:16:49.053473 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.053478 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.053479 38983 net.cpp:137] Memory required for data: 112641600
I0420 14:16:49.053481 38983 layer_factory.hpp:77] Creating layer map16_2_conv_a
I0420 14:16:49.053490 38983 net.cpp:84] Creating Layer map16_2_conv_a
I0420 14:16:49.053493 38983 net.cpp:406] map16_2_conv_a <- map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0420 14:16:49.053498 38983 net.cpp:380] map16_2_conv_a -> map16_2_conv_a
I0420 14:16:49.060776 38983 net.cpp:122] Setting up map16_2_conv_a
I0420 14:16:49.060788 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.060791 38983 net.cpp:137] Memory required for data: 119195200
I0420 14:16:49.060797 38983 layer_factory.hpp:77] Creating layer map16_2_bn_a
I0420 14:16:49.060806 38983 net.cpp:84] Creating Layer map16_2_bn_a
I0420 14:16:49.060809 38983 net.cpp:406] map16_2_bn_a <- map16_2_conv_a
I0420 14:16:49.060817 38983 net.cpp:367] map16_2_bn_a -> map16_2_conv_a (in-place)
I0420 14:16:49.061018 38983 net.cpp:122] Setting up map16_2_bn_a
I0420 14:16:49.061024 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.061028 38983 net.cpp:137] Memory required for data: 125748800
I0420 14:16:49.061033 38983 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0420 14:16:49.061040 38983 net.cpp:84] Creating Layer map16_2_scale_a
I0420 14:16:49.061043 38983 net.cpp:406] map16_2_scale_a <- map16_2_conv_a
I0420 14:16:49.061048 38983 net.cpp:367] map16_2_scale_a -> map16_2_conv_a (in-place)
I0420 14:16:49.061082 38983 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0420 14:16:49.061184 38983 net.cpp:122] Setting up map16_2_scale_a
I0420 14:16:49.061189 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.061192 38983 net.cpp:137] Memory required for data: 132302400
I0420 14:16:49.061209 38983 layer_factory.hpp:77] Creating layer map16_2_relu_a
I0420 14:16:49.061214 38983 net.cpp:84] Creating Layer map16_2_relu_a
I0420 14:16:49.061218 38983 net.cpp:406] map16_2_relu_a <- map16_2_conv_a
I0420 14:16:49.061220 38983 net.cpp:367] map16_2_relu_a -> map16_2_conv_a (in-place)
I0420 14:16:49.063127 38983 net.cpp:122] Setting up map16_2_relu_a
I0420 14:16:49.063134 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.063138 38983 net.cpp:137] Memory required for data: 138856000
I0420 14:16:49.063139 38983 layer_factory.hpp:77] Creating layer map16_2_conv_b
I0420 14:16:49.063148 38983 net.cpp:84] Creating Layer map16_2_conv_b
I0420 14:16:49.063151 38983 net.cpp:406] map16_2_conv_b <- map16_2_conv_a
I0420 14:16:49.063158 38983 net.cpp:380] map16_2_conv_b -> map16_2_conv_b
I0420 14:16:49.070822 38983 net.cpp:122] Setting up map16_2_conv_b
I0420 14:16:49.070834 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.070837 38983 net.cpp:137] Memory required for data: 145409600
I0420 14:16:49.070843 38983 layer_factory.hpp:77] Creating layer map16_2_bn_b
I0420 14:16:49.070854 38983 net.cpp:84] Creating Layer map16_2_bn_b
I0420 14:16:49.070858 38983 net.cpp:406] map16_2_bn_b <- map16_2_conv_b
I0420 14:16:49.070863 38983 net.cpp:367] map16_2_bn_b -> map16_2_conv_b (in-place)
I0420 14:16:49.071051 38983 net.cpp:122] Setting up map16_2_bn_b
I0420 14:16:49.071058 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.071060 38983 net.cpp:137] Memory required for data: 151963200
I0420 14:16:49.071069 38983 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0420 14:16:49.071075 38983 net.cpp:84] Creating Layer map16_2_scale_b
I0420 14:16:49.071079 38983 net.cpp:406] map16_2_scale_b <- map16_2_conv_b
I0420 14:16:49.071084 38983 net.cpp:367] map16_2_scale_b -> map16_2_conv_b (in-place)
I0420 14:16:49.071121 38983 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0420 14:16:49.071223 38983 net.cpp:122] Setting up map16_2_scale_b
I0420 14:16:49.071228 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.071231 38983 net.cpp:137] Memory required for data: 158516800
I0420 14:16:49.071235 38983 layer_factory.hpp:77] Creating layer map16_2_eltsum
I0420 14:16:49.071243 38983 net.cpp:84] Creating Layer map16_2_eltsum
I0420 14:16:49.071245 38983 net.cpp:406] map16_2_eltsum <- map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0420 14:16:49.071249 38983 net.cpp:406] map16_2_eltsum <- map16_2_conv_b
I0420 14:16:49.071254 38983 net.cpp:380] map16_2_eltsum -> map16_2_eltsum
I0420 14:16:49.071275 38983 net.cpp:122] Setting up map16_2_eltsum
I0420 14:16:49.071280 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.071283 38983 net.cpp:137] Memory required for data: 165070400
I0420 14:16:49.071285 38983 layer_factory.hpp:77] Creating layer map16_2_relu_after_sum
I0420 14:16:49.071290 38983 net.cpp:84] Creating Layer map16_2_relu_after_sum
I0420 14:16:49.071292 38983 net.cpp:406] map16_2_relu_after_sum <- map16_2_eltsum
I0420 14:16:49.071296 38983 net.cpp:367] map16_2_relu_after_sum -> map16_2_eltsum (in-place)
I0420 14:16:49.072963 38983 net.cpp:122] Setting up map16_2_relu_after_sum
I0420 14:16:49.072988 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.072993 38983 net.cpp:137] Memory required for data: 171624000
I0420 14:16:49.072994 38983 layer_factory.hpp:77] Creating layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 14:16:49.073000 38983 net.cpp:84] Creating Layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 14:16:49.073004 38983 net.cpp:406] map16_2_eltsum_map16_2_relu_after_sum_0_split <- map16_2_eltsum
I0420 14:16:49.073010 38983 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0420 14:16:49.073019 38983 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0420 14:16:49.073058 38983 net.cpp:122] Setting up map16_2_eltsum_map16_2_relu_after_sum_0_split
I0420 14:16:49.073074 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.073078 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.073081 38983 net.cpp:137] Memory required for data: 184731200
I0420 14:16:49.073083 38983 layer_factory.hpp:77] Creating layer map16_3_conv_a
I0420 14:16:49.073092 38983 net.cpp:84] Creating Layer map16_3_conv_a
I0420 14:16:49.073096 38983 net.cpp:406] map16_3_conv_a <- map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0420 14:16:49.073102 38983 net.cpp:380] map16_3_conv_a -> map16_3_conv_a
I0420 14:16:49.080437 38983 net.cpp:122] Setting up map16_3_conv_a
I0420 14:16:49.080448 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.080451 38983 net.cpp:137] Memory required for data: 191284800
I0420 14:16:49.080457 38983 layer_factory.hpp:77] Creating layer map16_3_bn_a
I0420 14:16:49.080463 38983 net.cpp:84] Creating Layer map16_3_bn_a
I0420 14:16:49.080467 38983 net.cpp:406] map16_3_bn_a <- map16_3_conv_a
I0420 14:16:49.080476 38983 net.cpp:367] map16_3_bn_a -> map16_3_conv_a (in-place)
I0420 14:16:49.080659 38983 net.cpp:122] Setting up map16_3_bn_a
I0420 14:16:49.080665 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.080668 38983 net.cpp:137] Memory required for data: 197838400
I0420 14:16:49.080673 38983 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0420 14:16:49.080679 38983 net.cpp:84] Creating Layer map16_3_scale_a
I0420 14:16:49.080685 38983 net.cpp:406] map16_3_scale_a <- map16_3_conv_a
I0420 14:16:49.080690 38983 net.cpp:367] map16_3_scale_a -> map16_3_conv_a (in-place)
I0420 14:16:49.080744 38983 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0420 14:16:49.080852 38983 net.cpp:122] Setting up map16_3_scale_a
I0420 14:16:49.080857 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.080860 38983 net.cpp:137] Memory required for data: 204392000
I0420 14:16:49.080865 38983 layer_factory.hpp:77] Creating layer map16_3_relu_a
I0420 14:16:49.080870 38983 net.cpp:84] Creating Layer map16_3_relu_a
I0420 14:16:49.080873 38983 net.cpp:406] map16_3_relu_a <- map16_3_conv_a
I0420 14:16:49.080878 38983 net.cpp:367] map16_3_relu_a -> map16_3_conv_a (in-place)
I0420 14:16:49.082753 38983 net.cpp:122] Setting up map16_3_relu_a
I0420 14:16:49.082763 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.082767 38983 net.cpp:137] Memory required for data: 210945600
I0420 14:16:49.082769 38983 layer_factory.hpp:77] Creating layer map16_3_conv_b
I0420 14:16:49.082797 38983 net.cpp:84] Creating Layer map16_3_conv_b
I0420 14:16:49.082800 38983 net.cpp:406] map16_3_conv_b <- map16_3_conv_a
I0420 14:16:49.082808 38983 net.cpp:380] map16_3_conv_b -> map16_3_conv_b
I0420 14:16:49.090277 38983 net.cpp:122] Setting up map16_3_conv_b
I0420 14:16:49.090288 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.090291 38983 net.cpp:137] Memory required for data: 217499200
I0420 14:16:49.090297 38983 layer_factory.hpp:77] Creating layer map16_3_bn_b
I0420 14:16:49.090307 38983 net.cpp:84] Creating Layer map16_3_bn_b
I0420 14:16:49.090312 38983 net.cpp:406] map16_3_bn_b <- map16_3_conv_b
I0420 14:16:49.090317 38983 net.cpp:367] map16_3_bn_b -> map16_3_conv_b (in-place)
I0420 14:16:49.090505 38983 net.cpp:122] Setting up map16_3_bn_b
I0420 14:16:49.090512 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.090514 38983 net.cpp:137] Memory required for data: 224052800
I0420 14:16:49.090519 38983 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0420 14:16:49.090526 38983 net.cpp:84] Creating Layer map16_3_scale_b
I0420 14:16:49.090529 38983 net.cpp:406] map16_3_scale_b <- map16_3_conv_b
I0420 14:16:49.090533 38983 net.cpp:367] map16_3_scale_b -> map16_3_conv_b (in-place)
I0420 14:16:49.090569 38983 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0420 14:16:49.090673 38983 net.cpp:122] Setting up map16_3_scale_b
I0420 14:16:49.090678 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.090685 38983 net.cpp:137] Memory required for data: 230606400
I0420 14:16:49.090701 38983 layer_factory.hpp:77] Creating layer map16_3_eltsum
I0420 14:16:49.090708 38983 net.cpp:84] Creating Layer map16_3_eltsum
I0420 14:16:49.090710 38983 net.cpp:406] map16_3_eltsum <- map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0420 14:16:49.090714 38983 net.cpp:406] map16_3_eltsum <- map16_3_conv_b
I0420 14:16:49.090720 38983 net.cpp:380] map16_3_eltsum -> map16_3_eltsum
I0420 14:16:49.090744 38983 net.cpp:122] Setting up map16_3_eltsum
I0420 14:16:49.090750 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.090754 38983 net.cpp:137] Memory required for data: 237160000
I0420 14:16:49.090755 38983 layer_factory.hpp:77] Creating layer map16_3_relu_after_sum
I0420 14:16:49.090759 38983 net.cpp:84] Creating Layer map16_3_relu_after_sum
I0420 14:16:49.090762 38983 net.cpp:406] map16_3_relu_after_sum <- map16_3_eltsum
I0420 14:16:49.090765 38983 net.cpp:367] map16_3_relu_after_sum -> map16_3_eltsum (in-place)
I0420 14:16:49.092550 38983 net.cpp:122] Setting up map16_3_relu_after_sum
I0420 14:16:49.092559 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.092562 38983 net.cpp:137] Memory required for data: 243713600
I0420 14:16:49.092566 38983 layer_factory.hpp:77] Creating layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 14:16:49.092571 38983 net.cpp:84] Creating Layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 14:16:49.092573 38983 net.cpp:406] map16_3_eltsum_map16_3_relu_after_sum_0_split <- map16_3_eltsum
I0420 14:16:49.092577 38983 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0420 14:16:49.092583 38983 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0420 14:16:49.092622 38983 net.cpp:122] Setting up map16_3_eltsum_map16_3_relu_after_sum_0_split
I0420 14:16:49.092628 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.092631 38983 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0420 14:16:49.092633 38983 net.cpp:137] Memory required for data: 256820800
I0420 14:16:49.092635 38983 layer_factory.hpp:77] Creating layer map32_1_conv_proj
I0420 14:16:49.092644 38983 net.cpp:84] Creating Layer map32_1_conv_proj
I0420 14:16:49.092648 38983 net.cpp:406] map32_1_conv_proj <- map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0420 14:16:49.092653 38983 net.cpp:380] map32_1_conv_proj -> map32_1_conv_proj
I0420 14:16:49.099936 38983 net.cpp:122] Setting up map32_1_conv_proj
I0420 14:16:49.099947 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.099951 38983 net.cpp:137] Memory required for data: 260097600
I0420 14:16:49.099956 38983 layer_factory.hpp:77] Creating layer map32_1_bn_proj
I0420 14:16:49.099964 38983 net.cpp:84] Creating Layer map32_1_bn_proj
I0420 14:16:49.099968 38983 net.cpp:406] map32_1_bn_proj <- map32_1_conv_proj
I0420 14:16:49.099974 38983 net.cpp:367] map32_1_bn_proj -> map32_1_conv_proj (in-place)
I0420 14:16:49.100157 38983 net.cpp:122] Setting up map32_1_bn_proj
I0420 14:16:49.100162 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.100165 38983 net.cpp:137] Memory required for data: 263374400
I0420 14:16:49.100170 38983 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0420 14:16:49.100178 38983 net.cpp:84] Creating Layer map32_1_scale_proj
I0420 14:16:49.100180 38983 net.cpp:406] map32_1_scale_proj <- map32_1_conv_proj
I0420 14:16:49.100184 38983 net.cpp:367] map32_1_scale_proj -> map32_1_conv_proj (in-place)
I0420 14:16:49.100219 38983 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0420 14:16:49.100324 38983 net.cpp:122] Setting up map32_1_scale_proj
I0420 14:16:49.100329 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.100332 38983 net.cpp:137] Memory required for data: 266651200
I0420 14:16:49.100337 38983 layer_factory.hpp:77] Creating layer map32_1_conv_a
I0420 14:16:49.100347 38983 net.cpp:84] Creating Layer map32_1_conv_a
I0420 14:16:49.100349 38983 net.cpp:406] map32_1_conv_a <- map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0420 14:16:49.100368 38983 net.cpp:380] map32_1_conv_a -> map32_1_conv_a
I0420 14:16:49.107100 38983 net.cpp:122] Setting up map32_1_conv_a
I0420 14:16:49.107111 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.107115 38983 net.cpp:137] Memory required for data: 269928000
I0420 14:16:49.107120 38983 layer_factory.hpp:77] Creating layer map32_1_bn_a
I0420 14:16:49.107126 38983 net.cpp:84] Creating Layer map32_1_bn_a
I0420 14:16:49.107131 38983 net.cpp:406] map32_1_bn_a <- map32_1_conv_a
I0420 14:16:49.107136 38983 net.cpp:367] map32_1_bn_a -> map32_1_conv_a (in-place)
I0420 14:16:49.107314 38983 net.cpp:122] Setting up map32_1_bn_a
I0420 14:16:49.107321 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.107323 38983 net.cpp:137] Memory required for data: 273204800
I0420 14:16:49.107329 38983 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0420 14:16:49.107334 38983 net.cpp:84] Creating Layer map32_1_scale_a
I0420 14:16:49.107337 38983 net.cpp:406] map32_1_scale_a <- map32_1_conv_a
I0420 14:16:49.107342 38983 net.cpp:367] map32_1_scale_a -> map32_1_conv_a (in-place)
I0420 14:16:49.107380 38983 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0420 14:16:49.107482 38983 net.cpp:122] Setting up map32_1_scale_a
I0420 14:16:49.107487 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.107491 38983 net.cpp:137] Memory required for data: 276481600
I0420 14:16:49.107496 38983 layer_factory.hpp:77] Creating layer map32_1_relu_a
I0420 14:16:49.107501 38983 net.cpp:84] Creating Layer map32_1_relu_a
I0420 14:16:49.107504 38983 net.cpp:406] map32_1_relu_a <- map32_1_conv_a
I0420 14:16:49.107507 38983 net.cpp:367] map32_1_relu_a -> map32_1_conv_a (in-place)
I0420 14:16:49.109336 38983 net.cpp:122] Setting up map32_1_relu_a
I0420 14:16:49.109344 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.109347 38983 net.cpp:137] Memory required for data: 279758400
I0420 14:16:49.109349 38983 layer_factory.hpp:77] Creating layer map32_1_conv_b
I0420 14:16:49.109359 38983 net.cpp:84] Creating Layer map32_1_conv_b
I0420 14:16:49.109361 38983 net.cpp:406] map32_1_conv_b <- map32_1_conv_a
I0420 14:16:49.109367 38983 net.cpp:380] map32_1_conv_b -> map32_1_conv_b
I0420 14:16:49.112221 38983 net.cpp:122] Setting up map32_1_conv_b
I0420 14:16:49.112232 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.112236 38983 net.cpp:137] Memory required for data: 283035200
I0420 14:16:49.112249 38983 layer_factory.hpp:77] Creating layer map32_1_bn_b
I0420 14:16:49.112258 38983 net.cpp:84] Creating Layer map32_1_bn_b
I0420 14:16:49.112262 38983 net.cpp:406] map32_1_bn_b <- map32_1_conv_b
I0420 14:16:49.112267 38983 net.cpp:367] map32_1_bn_b -> map32_1_conv_b (in-place)
I0420 14:16:49.112442 38983 net.cpp:122] Setting up map32_1_bn_b
I0420 14:16:49.112447 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.112450 38983 net.cpp:137] Memory required for data: 286312000
I0420 14:16:49.112457 38983 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0420 14:16:49.112462 38983 net.cpp:84] Creating Layer map32_1_scale_b
I0420 14:16:49.112467 38983 net.cpp:406] map32_1_scale_b <- map32_1_conv_b
I0420 14:16:49.112469 38983 net.cpp:367] map32_1_scale_b -> map32_1_conv_b (in-place)
I0420 14:16:49.112506 38983 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0420 14:16:49.112612 38983 net.cpp:122] Setting up map32_1_scale_b
I0420 14:16:49.112617 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.112619 38983 net.cpp:137] Memory required for data: 289588800
I0420 14:16:49.112623 38983 layer_factory.hpp:77] Creating layer map32_1_eltsum
I0420 14:16:49.112629 38983 net.cpp:84] Creating Layer map32_1_eltsum
I0420 14:16:49.112633 38983 net.cpp:406] map32_1_eltsum <- map32_1_conv_proj
I0420 14:16:49.112637 38983 net.cpp:406] map32_1_eltsum <- map32_1_conv_b
I0420 14:16:49.112642 38983 net.cpp:380] map32_1_eltsum -> map32_1_eltsum
I0420 14:16:49.112660 38983 net.cpp:122] Setting up map32_1_eltsum
I0420 14:16:49.112664 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.112678 38983 net.cpp:137] Memory required for data: 292865600
I0420 14:16:49.112679 38983 layer_factory.hpp:77] Creating layer map32_1_relu_after_sum
I0420 14:16:49.112691 38983 net.cpp:84] Creating Layer map32_1_relu_after_sum
I0420 14:16:49.112694 38983 net.cpp:406] map32_1_relu_after_sum <- map32_1_eltsum
I0420 14:16:49.112713 38983 net.cpp:367] map32_1_relu_after_sum -> map32_1_eltsum (in-place)
I0420 14:16:49.112896 38983 net.cpp:122] Setting up map32_1_relu_after_sum
I0420 14:16:49.112905 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.112907 38983 net.cpp:137] Memory required for data: 296142400
I0420 14:16:49.112910 38983 layer_factory.hpp:77] Creating layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 14:16:49.112915 38983 net.cpp:84] Creating Layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 14:16:49.112917 38983 net.cpp:406] map32_1_eltsum_map32_1_relu_after_sum_0_split <- map32_1_eltsum
I0420 14:16:49.112921 38983 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0420 14:16:49.112931 38983 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0420 14:16:49.112970 38983 net.cpp:122] Setting up map32_1_eltsum_map32_1_relu_after_sum_0_split
I0420 14:16:49.112990 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.112993 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.112995 38983 net.cpp:137] Memory required for data: 302696000
I0420 14:16:49.112998 38983 layer_factory.hpp:77] Creating layer map32_2_conv_a
I0420 14:16:49.113008 38983 net.cpp:84] Creating Layer map32_2_conv_a
I0420 14:16:49.113013 38983 net.cpp:406] map32_2_conv_a <- map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0420 14:16:49.113016 38983 net.cpp:380] map32_2_conv_a -> map32_2_conv_a
I0420 14:16:49.119879 38983 net.cpp:122] Setting up map32_2_conv_a
I0420 14:16:49.119892 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.119895 38983 net.cpp:137] Memory required for data: 305972800
I0420 14:16:49.119901 38983 layer_factory.hpp:77] Creating layer map32_2_bn_a
I0420 14:16:49.119907 38983 net.cpp:84] Creating Layer map32_2_bn_a
I0420 14:16:49.119911 38983 net.cpp:406] map32_2_bn_a <- map32_2_conv_a
I0420 14:16:49.119917 38983 net.cpp:367] map32_2_bn_a -> map32_2_conv_a (in-place)
I0420 14:16:49.120095 38983 net.cpp:122] Setting up map32_2_bn_a
I0420 14:16:49.120101 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.120105 38983 net.cpp:137] Memory required for data: 309249600
I0420 14:16:49.120110 38983 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0420 14:16:49.120115 38983 net.cpp:84] Creating Layer map32_2_scale_a
I0420 14:16:49.120118 38983 net.cpp:406] map32_2_scale_a <- map32_2_conv_a
I0420 14:16:49.120121 38983 net.cpp:367] map32_2_scale_a -> map32_2_conv_a (in-place)
I0420 14:16:49.120158 38983 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0420 14:16:49.120262 38983 net.cpp:122] Setting up map32_2_scale_a
I0420 14:16:49.120267 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.120270 38983 net.cpp:137] Memory required for data: 312526400
I0420 14:16:49.120275 38983 layer_factory.hpp:77] Creating layer map32_2_relu_a
I0420 14:16:49.120280 38983 net.cpp:84] Creating Layer map32_2_relu_a
I0420 14:16:49.120282 38983 net.cpp:406] map32_2_relu_a <- map32_2_conv_a
I0420 14:16:49.120287 38983 net.cpp:367] map32_2_relu_a -> map32_2_conv_a (in-place)
I0420 14:16:49.122131 38983 net.cpp:122] Setting up map32_2_relu_a
I0420 14:16:49.122139 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.122143 38983 net.cpp:137] Memory required for data: 315803200
I0420 14:16:49.122144 38983 layer_factory.hpp:77] Creating layer map32_2_conv_b
I0420 14:16:49.122153 38983 net.cpp:84] Creating Layer map32_2_conv_b
I0420 14:16:49.122156 38983 net.cpp:406] map32_2_conv_b <- map32_2_conv_a
I0420 14:16:49.122164 38983 net.cpp:380] map32_2_conv_b -> map32_2_conv_b
I0420 14:16:49.129367 38983 net.cpp:122] Setting up map32_2_conv_b
I0420 14:16:49.129390 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.129395 38983 net.cpp:137] Memory required for data: 319080000
I0420 14:16:49.129400 38983 layer_factory.hpp:77] Creating layer map32_2_bn_b
I0420 14:16:49.129406 38983 net.cpp:84] Creating Layer map32_2_bn_b
I0420 14:16:49.129410 38983 net.cpp:406] map32_2_bn_b <- map32_2_conv_b
I0420 14:16:49.129415 38983 net.cpp:367] map32_2_bn_b -> map32_2_conv_b (in-place)
I0420 14:16:49.129595 38983 net.cpp:122] Setting up map32_2_bn_b
I0420 14:16:49.129601 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.129603 38983 net.cpp:137] Memory required for data: 322356800
I0420 14:16:49.129608 38983 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0420 14:16:49.129616 38983 net.cpp:84] Creating Layer map32_2_scale_b
I0420 14:16:49.129621 38983 net.cpp:406] map32_2_scale_b <- map32_2_conv_b
I0420 14:16:49.129624 38983 net.cpp:367] map32_2_scale_b -> map32_2_conv_b (in-place)
I0420 14:16:49.129662 38983 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0420 14:16:49.129771 38983 net.cpp:122] Setting up map32_2_scale_b
I0420 14:16:49.129777 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.129781 38983 net.cpp:137] Memory required for data: 325633600
I0420 14:16:49.129786 38983 layer_factory.hpp:77] Creating layer map32_2_eltsum
I0420 14:16:49.129791 38983 net.cpp:84] Creating Layer map32_2_eltsum
I0420 14:16:49.129793 38983 net.cpp:406] map32_2_eltsum <- map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0420 14:16:49.129796 38983 net.cpp:406] map32_2_eltsum <- map32_2_conv_b
I0420 14:16:49.129804 38983 net.cpp:380] map32_2_eltsum -> map32_2_eltsum
I0420 14:16:49.129822 38983 net.cpp:122] Setting up map32_2_eltsum
I0420 14:16:49.129828 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.129832 38983 net.cpp:137] Memory required for data: 328910400
I0420 14:16:49.129833 38983 layer_factory.hpp:77] Creating layer map32_2_relu_after_sum
I0420 14:16:49.129837 38983 net.cpp:84] Creating Layer map32_2_relu_after_sum
I0420 14:16:49.129840 38983 net.cpp:406] map32_2_relu_after_sum <- map32_2_eltsum
I0420 14:16:49.129843 38983 net.cpp:367] map32_2_relu_after_sum -> map32_2_eltsum (in-place)
I0420 14:16:49.131620 38983 net.cpp:122] Setting up map32_2_relu_after_sum
I0420 14:16:49.131629 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.131633 38983 net.cpp:137] Memory required for data: 332187200
I0420 14:16:49.131634 38983 layer_factory.hpp:77] Creating layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 14:16:49.131639 38983 net.cpp:84] Creating Layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 14:16:49.131642 38983 net.cpp:406] map32_2_eltsum_map32_2_relu_after_sum_0_split <- map32_2_eltsum
I0420 14:16:49.131645 38983 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0420 14:16:49.131654 38983 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0420 14:16:49.131696 38983 net.cpp:122] Setting up map32_2_eltsum_map32_2_relu_after_sum_0_split
I0420 14:16:49.131702 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.131705 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.131708 38983 net.cpp:137] Memory required for data: 338740800
I0420 14:16:49.131711 38983 layer_factory.hpp:77] Creating layer map32_3_conv_a
I0420 14:16:49.131721 38983 net.cpp:84] Creating Layer map32_3_conv_a
I0420 14:16:49.131724 38983 net.cpp:406] map32_3_conv_a <- map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0420 14:16:49.131728 38983 net.cpp:380] map32_3_conv_a -> map32_3_conv_a
I0420 14:16:49.138669 38983 net.cpp:122] Setting up map32_3_conv_a
I0420 14:16:49.138680 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.138687 38983 net.cpp:137] Memory required for data: 342017600
I0420 14:16:49.138707 38983 layer_factory.hpp:77] Creating layer map32_3_bn_a
I0420 14:16:49.138716 38983 net.cpp:84] Creating Layer map32_3_bn_a
I0420 14:16:49.138731 38983 net.cpp:406] map32_3_bn_a <- map32_3_conv_a
I0420 14:16:49.138736 38983 net.cpp:367] map32_3_bn_a -> map32_3_conv_a (in-place)
I0420 14:16:49.138922 38983 net.cpp:122] Setting up map32_3_bn_a
I0420 14:16:49.138927 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.138931 38983 net.cpp:137] Memory required for data: 345294400
I0420 14:16:49.138936 38983 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0420 14:16:49.138943 38983 net.cpp:84] Creating Layer map32_3_scale_a
I0420 14:16:49.138947 38983 net.cpp:406] map32_3_scale_a <- map32_3_conv_a
I0420 14:16:49.138950 38983 net.cpp:367] map32_3_scale_a -> map32_3_conv_a (in-place)
I0420 14:16:49.139003 38983 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0420 14:16:49.139108 38983 net.cpp:122] Setting up map32_3_scale_a
I0420 14:16:49.139113 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.139117 38983 net.cpp:137] Memory required for data: 348571200
I0420 14:16:49.139120 38983 layer_factory.hpp:77] Creating layer map32_3_relu_a
I0420 14:16:49.139125 38983 net.cpp:84] Creating Layer map32_3_relu_a
I0420 14:16:49.139128 38983 net.cpp:406] map32_3_relu_a <- map32_3_conv_a
I0420 14:16:49.139132 38983 net.cpp:367] map32_3_relu_a -> map32_3_conv_a (in-place)
I0420 14:16:49.140914 38983 net.cpp:122] Setting up map32_3_relu_a
I0420 14:16:49.140924 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.140928 38983 net.cpp:137] Memory required for data: 351848000
I0420 14:16:49.140930 38983 layer_factory.hpp:77] Creating layer map32_3_conv_b
I0420 14:16:49.140947 38983 net.cpp:84] Creating Layer map32_3_conv_b
I0420 14:16:49.140951 38983 net.cpp:406] map32_3_conv_b <- map32_3_conv_a
I0420 14:16:49.140956 38983 net.cpp:380] map32_3_conv_b -> map32_3_conv_b
I0420 14:16:49.148123 38983 net.cpp:122] Setting up map32_3_conv_b
I0420 14:16:49.148136 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.148140 38983 net.cpp:137] Memory required for data: 355124800
I0420 14:16:49.148146 38983 layer_factory.hpp:77] Creating layer map32_3_bn_b
I0420 14:16:49.148152 38983 net.cpp:84] Creating Layer map32_3_bn_b
I0420 14:16:49.148156 38983 net.cpp:406] map32_3_bn_b <- map32_3_conv_b
I0420 14:16:49.148162 38983 net.cpp:367] map32_3_bn_b -> map32_3_conv_b (in-place)
I0420 14:16:49.148344 38983 net.cpp:122] Setting up map32_3_bn_b
I0420 14:16:49.148350 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.148353 38983 net.cpp:137] Memory required for data: 358401600
I0420 14:16:49.148358 38983 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0420 14:16:49.148363 38983 net.cpp:84] Creating Layer map32_3_scale_b
I0420 14:16:49.148366 38983 net.cpp:406] map32_3_scale_b <- map32_3_conv_b
I0420 14:16:49.148370 38983 net.cpp:367] map32_3_scale_b -> map32_3_conv_b (in-place)
I0420 14:16:49.148406 38983 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0420 14:16:49.148509 38983 net.cpp:122] Setting up map32_3_scale_b
I0420 14:16:49.148514 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.148516 38983 net.cpp:137] Memory required for data: 361678400
I0420 14:16:49.148520 38983 layer_factory.hpp:77] Creating layer map32_3_eltsum
I0420 14:16:49.148526 38983 net.cpp:84] Creating Layer map32_3_eltsum
I0420 14:16:49.148530 38983 net.cpp:406] map32_3_eltsum <- map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0420 14:16:49.148533 38983 net.cpp:406] map32_3_eltsum <- map32_3_conv_b
I0420 14:16:49.148538 38983 net.cpp:380] map32_3_eltsum -> map32_3_eltsum
I0420 14:16:49.148556 38983 net.cpp:122] Setting up map32_3_eltsum
I0420 14:16:49.148561 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.148563 38983 net.cpp:137] Memory required for data: 364955200
I0420 14:16:49.148566 38983 layer_factory.hpp:77] Creating layer map32_3_relu_after_sum
I0420 14:16:49.148571 38983 net.cpp:84] Creating Layer map32_3_relu_after_sum
I0420 14:16:49.148574 38983 net.cpp:406] map32_3_relu_after_sum <- map32_3_eltsum
I0420 14:16:49.148577 38983 net.cpp:367] map32_3_relu_after_sum -> map32_3_eltsum (in-place)
I0420 14:16:49.150400 38983 net.cpp:122] Setting up map32_3_relu_after_sum
I0420 14:16:49.150409 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.150413 38983 net.cpp:137] Memory required for data: 368232000
I0420 14:16:49.150414 38983 layer_factory.hpp:77] Creating layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 14:16:49.150419 38983 net.cpp:84] Creating Layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 14:16:49.150423 38983 net.cpp:406] map32_3_eltsum_map32_3_relu_after_sum_0_split <- map32_3_eltsum
I0420 14:16:49.150426 38983 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0420 14:16:49.150432 38983 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0420 14:16:49.150472 38983 net.cpp:122] Setting up map32_3_eltsum_map32_3_relu_after_sum_0_split
I0420 14:16:49.150477 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.150481 38983 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0420 14:16:49.150483 38983 net.cpp:137] Memory required for data: 374785600
I0420 14:16:49.150486 38983 layer_factory.hpp:77] Creating layer map64_1_conv_proj
I0420 14:16:49.150494 38983 net.cpp:84] Creating Layer map64_1_conv_proj
I0420 14:16:49.150498 38983 net.cpp:406] map64_1_conv_proj <- map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0420 14:16:49.150504 38983 net.cpp:380] map64_1_conv_proj -> map64_1_conv_proj
I0420 14:16:49.157804 38983 net.cpp:122] Setting up map64_1_conv_proj
I0420 14:16:49.157816 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.157819 38983 net.cpp:137] Memory required for data: 376424000
I0420 14:16:49.157825 38983 layer_factory.hpp:77] Creating layer map64_1_bn_proj
I0420 14:16:49.157832 38983 net.cpp:84] Creating Layer map64_1_bn_proj
I0420 14:16:49.157836 38983 net.cpp:406] map64_1_bn_proj <- map64_1_conv_proj
I0420 14:16:49.157841 38983 net.cpp:367] map64_1_bn_proj -> map64_1_conv_proj (in-place)
I0420 14:16:49.158049 38983 net.cpp:122] Setting up map64_1_bn_proj
I0420 14:16:49.158054 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.158057 38983 net.cpp:137] Memory required for data: 378062400
I0420 14:16:49.158062 38983 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0420 14:16:49.158067 38983 net.cpp:84] Creating Layer map64_1_scale_proj
I0420 14:16:49.158071 38983 net.cpp:406] map64_1_scale_proj <- map64_1_conv_proj
I0420 14:16:49.158077 38983 net.cpp:367] map64_1_scale_proj -> map64_1_conv_proj (in-place)
I0420 14:16:49.158113 38983 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0420 14:16:49.158219 38983 net.cpp:122] Setting up map64_1_scale_proj
I0420 14:16:49.158224 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.158227 38983 net.cpp:137] Memory required for data: 379700800
I0420 14:16:49.158231 38983 layer_factory.hpp:77] Creating layer map64_1_conv_a
I0420 14:16:49.158241 38983 net.cpp:84] Creating Layer map64_1_conv_a
I0420 14:16:49.158243 38983 net.cpp:406] map64_1_conv_a <- map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0420 14:16:49.158251 38983 net.cpp:380] map64_1_conv_a -> map64_1_conv_a
I0420 14:16:49.165045 38983 net.cpp:122] Setting up map64_1_conv_a
I0420 14:16:49.165055 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.165058 38983 net.cpp:137] Memory required for data: 381339200
I0420 14:16:49.165063 38983 layer_factory.hpp:77] Creating layer map64_1_bn_a
I0420 14:16:49.165071 38983 net.cpp:84] Creating Layer map64_1_bn_a
I0420 14:16:49.165076 38983 net.cpp:406] map64_1_bn_a <- map64_1_conv_a
I0420 14:16:49.165083 38983 net.cpp:367] map64_1_bn_a -> map64_1_conv_a (in-place)
I0420 14:16:49.165272 38983 net.cpp:122] Setting up map64_1_bn_a
I0420 14:16:49.165278 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.165282 38983 net.cpp:137] Memory required for data: 382977600
I0420 14:16:49.165287 38983 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0420 14:16:49.165303 38983 net.cpp:84] Creating Layer map64_1_scale_a
I0420 14:16:49.165307 38983 net.cpp:406] map64_1_scale_a <- map64_1_conv_a
I0420 14:16:49.165311 38983 net.cpp:367] map64_1_scale_a -> map64_1_conv_a (in-place)
I0420 14:16:49.165351 38983 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0420 14:16:49.165459 38983 net.cpp:122] Setting up map64_1_scale_a
I0420 14:16:49.165464 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.165467 38983 net.cpp:137] Memory required for data: 384616000
I0420 14:16:49.165472 38983 layer_factory.hpp:77] Creating layer map64_1_relu_a
I0420 14:16:49.165477 38983 net.cpp:84] Creating Layer map64_1_relu_a
I0420 14:16:49.165480 38983 net.cpp:406] map64_1_relu_a <- map64_1_conv_a
I0420 14:16:49.165484 38983 net.cpp:367] map64_1_relu_a -> map64_1_conv_a (in-place)
I0420 14:16:49.167359 38983 net.cpp:122] Setting up map64_1_relu_a
I0420 14:16:49.167368 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.167371 38983 net.cpp:137] Memory required for data: 386254400
I0420 14:16:49.167374 38983 layer_factory.hpp:77] Creating layer map64_1_conv_b
I0420 14:16:49.167384 38983 net.cpp:84] Creating Layer map64_1_conv_b
I0420 14:16:49.167387 38983 net.cpp:406] map64_1_conv_b <- map64_1_conv_a
I0420 14:16:49.167392 38983 net.cpp:380] map64_1_conv_b -> map64_1_conv_b
I0420 14:16:49.174666 38983 net.cpp:122] Setting up map64_1_conv_b
I0420 14:16:49.174679 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.174685 38983 net.cpp:137] Memory required for data: 387892800
I0420 14:16:49.174691 38983 layer_factory.hpp:77] Creating layer map64_1_bn_b
I0420 14:16:49.174697 38983 net.cpp:84] Creating Layer map64_1_bn_b
I0420 14:16:49.174701 38983 net.cpp:406] map64_1_bn_b <- map64_1_conv_b
I0420 14:16:49.174707 38983 net.cpp:367] map64_1_bn_b -> map64_1_conv_b (in-place)
I0420 14:16:49.174898 38983 net.cpp:122] Setting up map64_1_bn_b
I0420 14:16:49.174904 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.174907 38983 net.cpp:137] Memory required for data: 389531200
I0420 14:16:49.174913 38983 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0420 14:16:49.174919 38983 net.cpp:84] Creating Layer map64_1_scale_b
I0420 14:16:49.174922 38983 net.cpp:406] map64_1_scale_b <- map64_1_conv_b
I0420 14:16:49.174926 38983 net.cpp:367] map64_1_scale_b -> map64_1_conv_b (in-place)
I0420 14:16:49.174964 38983 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0420 14:16:49.175073 38983 net.cpp:122] Setting up map64_1_scale_b
I0420 14:16:49.175078 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.175081 38983 net.cpp:137] Memory required for data: 391169600
I0420 14:16:49.175086 38983 layer_factory.hpp:77] Creating layer map64_1_eltsum
I0420 14:16:49.175091 38983 net.cpp:84] Creating Layer map64_1_eltsum
I0420 14:16:49.175094 38983 net.cpp:406] map64_1_eltsum <- map64_1_conv_proj
I0420 14:16:49.175097 38983 net.cpp:406] map64_1_eltsum <- map64_1_conv_b
I0420 14:16:49.175103 38983 net.cpp:380] map64_1_eltsum -> map64_1_eltsum
I0420 14:16:49.175124 38983 net.cpp:122] Setting up map64_1_eltsum
I0420 14:16:49.175129 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.175132 38983 net.cpp:137] Memory required for data: 392808000
I0420 14:16:49.175134 38983 layer_factory.hpp:77] Creating layer map64_1_relu_after_sum
I0420 14:16:49.175140 38983 net.cpp:84] Creating Layer map64_1_relu_after_sum
I0420 14:16:49.175143 38983 net.cpp:406] map64_1_relu_after_sum <- map64_1_eltsum
I0420 14:16:49.175146 38983 net.cpp:367] map64_1_relu_after_sum -> map64_1_eltsum (in-place)
I0420 14:16:49.176942 38983 net.cpp:122] Setting up map64_1_relu_after_sum
I0420 14:16:49.176951 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.176954 38983 net.cpp:137] Memory required for data: 394446400
I0420 14:16:49.176956 38983 layer_factory.hpp:77] Creating layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 14:16:49.176962 38983 net.cpp:84] Creating Layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 14:16:49.176965 38983 net.cpp:406] map64_1_eltsum_map64_1_relu_after_sum_0_split <- map64_1_eltsum
I0420 14:16:49.176980 38983 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0420 14:16:49.176986 38983 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0420 14:16:49.177027 38983 net.cpp:122] Setting up map64_1_eltsum_map64_1_relu_after_sum_0_split
I0420 14:16:49.177032 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.177037 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.177038 38983 net.cpp:137] Memory required for data: 397723200
I0420 14:16:49.177042 38983 layer_factory.hpp:77] Creating layer map64_2_conv_a
I0420 14:16:49.177049 38983 net.cpp:84] Creating Layer map64_2_conv_a
I0420 14:16:49.177052 38983 net.cpp:406] map64_2_conv_a <- map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0420 14:16:49.177058 38983 net.cpp:380] map64_2_conv_a -> map64_2_conv_a
I0420 14:16:49.184331 38983 net.cpp:122] Setting up map64_2_conv_a
I0420 14:16:49.184341 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.184345 38983 net.cpp:137] Memory required for data: 399361600
I0420 14:16:49.184350 38983 layer_factory.hpp:77] Creating layer map64_2_bn_a
I0420 14:16:49.184360 38983 net.cpp:84] Creating Layer map64_2_bn_a
I0420 14:16:49.184362 38983 net.cpp:406] map64_2_bn_a <- map64_2_conv_a
I0420 14:16:49.184368 38983 net.cpp:367] map64_2_bn_a -> map64_2_conv_a (in-place)
I0420 14:16:49.184563 38983 net.cpp:122] Setting up map64_2_bn_a
I0420 14:16:49.184569 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.184572 38983 net.cpp:137] Memory required for data: 401000000
I0420 14:16:49.184577 38983 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0420 14:16:49.184583 38983 net.cpp:84] Creating Layer map64_2_scale_a
I0420 14:16:49.184587 38983 net.cpp:406] map64_2_scale_a <- map64_2_conv_a
I0420 14:16:49.184590 38983 net.cpp:367] map64_2_scale_a -> map64_2_conv_a (in-place)
I0420 14:16:49.184628 38983 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0420 14:16:49.184741 38983 net.cpp:122] Setting up map64_2_scale_a
I0420 14:16:49.184747 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.184751 38983 net.cpp:137] Memory required for data: 402638400
I0420 14:16:49.184754 38983 layer_factory.hpp:77] Creating layer map64_2_relu_a
I0420 14:16:49.184759 38983 net.cpp:84] Creating Layer map64_2_relu_a
I0420 14:16:49.184762 38983 net.cpp:406] map64_2_relu_a <- map64_2_conv_a
I0420 14:16:49.184765 38983 net.cpp:367] map64_2_relu_a -> map64_2_conv_a (in-place)
I0420 14:16:49.186645 38983 net.cpp:122] Setting up map64_2_relu_a
I0420 14:16:49.186653 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.186656 38983 net.cpp:137] Memory required for data: 404276800
I0420 14:16:49.186660 38983 layer_factory.hpp:77] Creating layer map64_2_conv_b
I0420 14:16:49.186669 38983 net.cpp:84] Creating Layer map64_2_conv_b
I0420 14:16:49.186673 38983 net.cpp:406] map64_2_conv_b <- map64_2_conv_a
I0420 14:16:49.186677 38983 net.cpp:380] map64_2_conv_b -> map64_2_conv_b
I0420 14:16:49.193857 38983 net.cpp:122] Setting up map64_2_conv_b
I0420 14:16:49.193867 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.193871 38983 net.cpp:137] Memory required for data: 405915200
I0420 14:16:49.193876 38983 layer_factory.hpp:77] Creating layer map64_2_bn_b
I0420 14:16:49.193884 38983 net.cpp:84] Creating Layer map64_2_bn_b
I0420 14:16:49.193888 38983 net.cpp:406] map64_2_bn_b <- map64_2_conv_b
I0420 14:16:49.193893 38983 net.cpp:367] map64_2_bn_b -> map64_2_conv_b (in-place)
I0420 14:16:49.194084 38983 net.cpp:122] Setting up map64_2_bn_b
I0420 14:16:49.194090 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.194093 38983 net.cpp:137] Memory required for data: 407553600
I0420 14:16:49.194113 38983 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0420 14:16:49.194118 38983 net.cpp:84] Creating Layer map64_2_scale_b
I0420 14:16:49.194121 38983 net.cpp:406] map64_2_scale_b <- map64_2_conv_b
I0420 14:16:49.194136 38983 net.cpp:367] map64_2_scale_b -> map64_2_conv_b (in-place)
I0420 14:16:49.194180 38983 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0420 14:16:49.194286 38983 net.cpp:122] Setting up map64_2_scale_b
I0420 14:16:49.194291 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.194294 38983 net.cpp:137] Memory required for data: 409192000
I0420 14:16:49.194298 38983 layer_factory.hpp:77] Creating layer map64_2_eltsum
I0420 14:16:49.194303 38983 net.cpp:84] Creating Layer map64_2_eltsum
I0420 14:16:49.194308 38983 net.cpp:406] map64_2_eltsum <- map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0420 14:16:49.194310 38983 net.cpp:406] map64_2_eltsum <- map64_2_conv_b
I0420 14:16:49.194315 38983 net.cpp:380] map64_2_eltsum -> map64_2_eltsum
I0420 14:16:49.194341 38983 net.cpp:122] Setting up map64_2_eltsum
I0420 14:16:49.194345 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.194349 38983 net.cpp:137] Memory required for data: 410830400
I0420 14:16:49.194351 38983 layer_factory.hpp:77] Creating layer map64_2_relu_after_sum
I0420 14:16:49.194357 38983 net.cpp:84] Creating Layer map64_2_relu_after_sum
I0420 14:16:49.194360 38983 net.cpp:406] map64_2_relu_after_sum <- map64_2_eltsum
I0420 14:16:49.194363 38983 net.cpp:367] map64_2_relu_after_sum -> map64_2_eltsum (in-place)
I0420 14:16:49.196188 38983 net.cpp:122] Setting up map64_2_relu_after_sum
I0420 14:16:49.196197 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.196200 38983 net.cpp:137] Memory required for data: 412468800
I0420 14:16:49.196202 38983 layer_factory.hpp:77] Creating layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 14:16:49.196208 38983 net.cpp:84] Creating Layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 14:16:49.196210 38983 net.cpp:406] map64_2_eltsum_map64_2_relu_after_sum_0_split <- map64_2_eltsum
I0420 14:16:49.196214 38983 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0420 14:16:49.196220 38983 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0420 14:16:49.196259 38983 net.cpp:122] Setting up map64_2_eltsum_map64_2_relu_after_sum_0_split
I0420 14:16:49.196264 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.196269 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.196270 38983 net.cpp:137] Memory required for data: 415745600
I0420 14:16:49.196272 38983 layer_factory.hpp:77] Creating layer map64_3_conv_a
I0420 14:16:49.196282 38983 net.cpp:84] Creating Layer map64_3_conv_a
I0420 14:16:49.196285 38983 net.cpp:406] map64_3_conv_a <- map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0420 14:16:49.196291 38983 net.cpp:380] map64_3_conv_a -> map64_3_conv_a
I0420 14:16:49.203644 38983 net.cpp:122] Setting up map64_3_conv_a
I0420 14:16:49.203655 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.203658 38983 net.cpp:137] Memory required for data: 417384000
I0420 14:16:49.203665 38983 layer_factory.hpp:77] Creating layer map64_3_bn_a
I0420 14:16:49.203672 38983 net.cpp:84] Creating Layer map64_3_bn_a
I0420 14:16:49.203676 38983 net.cpp:406] map64_3_bn_a <- map64_3_conv_a
I0420 14:16:49.203685 38983 net.cpp:367] map64_3_bn_a -> map64_3_conv_a (in-place)
I0420 14:16:49.203898 38983 net.cpp:122] Setting up map64_3_bn_a
I0420 14:16:49.203904 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.203907 38983 net.cpp:137] Memory required for data: 419022400
I0420 14:16:49.203913 38983 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0420 14:16:49.203918 38983 net.cpp:84] Creating Layer map64_3_scale_a
I0420 14:16:49.203922 38983 net.cpp:406] map64_3_scale_a <- map64_3_conv_a
I0420 14:16:49.203927 38983 net.cpp:367] map64_3_scale_a -> map64_3_conv_a (in-place)
I0420 14:16:49.203966 38983 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0420 14:16:49.204089 38983 net.cpp:122] Setting up map64_3_scale_a
I0420 14:16:49.204094 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.204107 38983 net.cpp:137] Memory required for data: 420660800
I0420 14:16:49.204113 38983 layer_factory.hpp:77] Creating layer map64_3_relu_a
I0420 14:16:49.204119 38983 net.cpp:84] Creating Layer map64_3_relu_a
I0420 14:16:49.204123 38983 net.cpp:406] map64_3_relu_a <- map64_3_conv_a
I0420 14:16:49.204126 38983 net.cpp:367] map64_3_relu_a -> map64_3_conv_a (in-place)
I0420 14:16:49.205646 38983 net.cpp:122] Setting up map64_3_relu_a
I0420 14:16:49.205656 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.205658 38983 net.cpp:137] Memory required for data: 422299200
I0420 14:16:49.205660 38983 layer_factory.hpp:77] Creating layer map64_3_conv_b
I0420 14:16:49.205672 38983 net.cpp:84] Creating Layer map64_3_conv_b
I0420 14:16:49.205677 38983 net.cpp:406] map64_3_conv_b <- map64_3_conv_a
I0420 14:16:49.205684 38983 net.cpp:380] map64_3_conv_b -> map64_3_conv_b
I0420 14:16:49.212940 38983 net.cpp:122] Setting up map64_3_conv_b
I0420 14:16:49.212951 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.212955 38983 net.cpp:137] Memory required for data: 423937600
I0420 14:16:49.212960 38983 layer_factory.hpp:77] Creating layer map64_3_bn_b
I0420 14:16:49.212967 38983 net.cpp:84] Creating Layer map64_3_bn_b
I0420 14:16:49.212970 38983 net.cpp:406] map64_3_bn_b <- map64_3_conv_b
I0420 14:16:49.212977 38983 net.cpp:367] map64_3_bn_b -> map64_3_conv_b (in-place)
I0420 14:16:49.213167 38983 net.cpp:122] Setting up map64_3_bn_b
I0420 14:16:49.213173 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.213176 38983 net.cpp:137] Memory required for data: 425576000
I0420 14:16:49.213181 38983 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0420 14:16:49.213186 38983 net.cpp:84] Creating Layer map64_3_scale_b
I0420 14:16:49.213191 38983 net.cpp:406] map64_3_scale_b <- map64_3_conv_b
I0420 14:16:49.213196 38983 net.cpp:367] map64_3_scale_b -> map64_3_conv_b (in-place)
I0420 14:16:49.213232 38983 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0420 14:16:49.213340 38983 net.cpp:122] Setting up map64_3_scale_b
I0420 14:16:49.213346 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.213349 38983 net.cpp:137] Memory required for data: 427214400
I0420 14:16:49.213353 38983 layer_factory.hpp:77] Creating layer map64_3_eltsum
I0420 14:16:49.213358 38983 net.cpp:84] Creating Layer map64_3_eltsum
I0420 14:16:49.213361 38983 net.cpp:406] map64_3_eltsum <- map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0420 14:16:49.213366 38983 net.cpp:406] map64_3_eltsum <- map64_3_conv_b
I0420 14:16:49.213371 38983 net.cpp:380] map64_3_eltsum -> map64_3_eltsum
I0420 14:16:49.213394 38983 net.cpp:122] Setting up map64_3_eltsum
I0420 14:16:49.213400 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.213402 38983 net.cpp:137] Memory required for data: 428852800
I0420 14:16:49.213405 38983 layer_factory.hpp:77] Creating layer map64_3_relu_after_sum
I0420 14:16:49.213408 38983 net.cpp:84] Creating Layer map64_3_relu_after_sum
I0420 14:16:49.213412 38983 net.cpp:406] map64_3_relu_after_sum <- map64_3_eltsum
I0420 14:16:49.213415 38983 net.cpp:367] map64_3_relu_after_sum -> map64_3_eltsum (in-place)
I0420 14:16:49.215427 38983 net.cpp:122] Setting up map64_3_relu_after_sum
I0420 14:16:49.215438 38983 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0420 14:16:49.215441 38983 net.cpp:137] Memory required for data: 430491200
I0420 14:16:49.215445 38983 layer_factory.hpp:77] Creating layer pool_global
I0420 14:16:49.215451 38983 net.cpp:84] Creating Layer pool_global
I0420 14:16:49.215456 38983 net.cpp:406] pool_global <- map64_3_eltsum
I0420 14:16:49.215461 38983 net.cpp:380] pool_global -> pool_global
I0420 14:16:49.217792 38983 net.cpp:122] Setting up pool_global
I0420 14:16:49.217800 38983 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0420 14:16:49.217803 38983 net.cpp:137] Memory required for data: 430516800
I0420 14:16:49.217805 38983 layer_factory.hpp:77] Creating layer score
I0420 14:16:49.217811 38983 net.cpp:84] Creating Layer score
I0420 14:16:49.217815 38983 net.cpp:406] score <- pool_global
I0420 14:16:49.217835 38983 net.cpp:380] score -> score
I0420 14:16:49.217959 38983 net.cpp:122] Setting up score
I0420 14:16:49.217965 38983 net.cpp:129] Top shape: 100 10 (1000)
I0420 14:16:49.217968 38983 net.cpp:137] Memory required for data: 430520800
I0420 14:16:49.217973 38983 layer_factory.hpp:77] Creating layer score_score_0_split
I0420 14:16:49.217993 38983 net.cpp:84] Creating Layer score_score_0_split
I0420 14:16:49.217996 38983 net.cpp:406] score_score_0_split <- score
I0420 14:16:49.218000 38983 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0420 14:16:49.218008 38983 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0420 14:16:49.218013 38983 net.cpp:380] score_score_0_split -> score_score_0_split_2
I0420 14:16:49.218060 38983 net.cpp:122] Setting up score_score_0_split
I0420 14:16:49.218065 38983 net.cpp:129] Top shape: 100 10 (1000)
I0420 14:16:49.218068 38983 net.cpp:129] Top shape: 100 10 (1000)
I0420 14:16:49.218070 38983 net.cpp:129] Top shape: 100 10 (1000)
I0420 14:16:49.218073 38983 net.cpp:137] Memory required for data: 430532800
I0420 14:16:49.218075 38983 layer_factory.hpp:77] Creating layer loss
I0420 14:16:49.218080 38983 net.cpp:84] Creating Layer loss
I0420 14:16:49.218085 38983 net.cpp:406] loss <- score_score_0_split_0
I0420 14:16:49.218087 38983 net.cpp:406] loss <- label_data_1_split_0
I0420 14:16:49.218091 38983 net.cpp:380] loss -> loss
I0420 14:16:49.218097 38983 layer_factory.hpp:77] Creating layer loss
I0420 14:16:49.220212 38983 net.cpp:122] Setting up loss
I0420 14:16:49.220221 38983 net.cpp:129] Top shape: (1)
I0420 14:16:49.220223 38983 net.cpp:132]     with loss weight 1
I0420 14:16:49.220232 38983 net.cpp:137] Memory required for data: 430532804
I0420 14:16:49.220235 38983 layer_factory.hpp:77] Creating layer acc/top1
I0420 14:16:49.220239 38983 net.cpp:84] Creating Layer acc/top1
I0420 14:16:49.220243 38983 net.cpp:406] acc/top1 <- score_score_0_split_1
I0420 14:16:49.220247 38983 net.cpp:406] acc/top1 <- label_data_1_split_1
I0420 14:16:49.220252 38983 net.cpp:380] acc/top1 -> acctop1
I0420 14:16:49.220259 38983 net.cpp:122] Setting up acc/top1
I0420 14:16:49.220263 38983 net.cpp:129] Top shape: (1)
I0420 14:16:49.220265 38983 net.cpp:137] Memory required for data: 430532808
I0420 14:16:49.220268 38983 layer_factory.hpp:77] Creating layer acc/top5
I0420 14:16:49.220271 38983 net.cpp:84] Creating Layer acc/top5
I0420 14:16:49.220274 38983 net.cpp:406] acc/top5 <- score_score_0_split_2
I0420 14:16:49.220278 38983 net.cpp:406] acc/top5 <- label_data_1_split_2
I0420 14:16:49.220283 38983 net.cpp:380] acc/top5 -> acctop5
I0420 14:16:49.220288 38983 net.cpp:122] Setting up acc/top5
I0420 14:16:49.220293 38983 net.cpp:129] Top shape: (1)
I0420 14:16:49.220294 38983 net.cpp:137] Memory required for data: 430532812
I0420 14:16:49.220296 38983 net.cpp:200] acc/top5 does not need backward computation.
I0420 14:16:49.220299 38983 net.cpp:200] acc/top1 does not need backward computation.
I0420 14:16:49.220302 38983 net.cpp:198] loss needs backward computation.
I0420 14:16:49.220305 38983 net.cpp:198] score_score_0_split needs backward computation.
I0420 14:16:49.220309 38983 net.cpp:198] score needs backward computation.
I0420 14:16:49.220310 38983 net.cpp:198] pool_global needs backward computation.
I0420 14:16:49.220312 38983 net.cpp:198] map64_3_relu_after_sum needs backward computation.
I0420 14:16:49.220315 38983 net.cpp:198] map64_3_eltsum needs backward computation.
I0420 14:16:49.220319 38983 net.cpp:198] map64_3_scale_b needs backward computation.
I0420 14:16:49.220321 38983 net.cpp:198] map64_3_bn_b needs backward computation.
I0420 14:16:49.220324 38983 net.cpp:198] map64_3_conv_b needs backward computation.
I0420 14:16:49.220325 38983 net.cpp:198] map64_3_relu_a needs backward computation.
I0420 14:16:49.220327 38983 net.cpp:198] map64_3_scale_a needs backward computation.
I0420 14:16:49.220330 38983 net.cpp:198] map64_3_bn_a needs backward computation.
I0420 14:16:49.220332 38983 net.cpp:198] map64_3_conv_a needs backward computation.
I0420 14:16:49.220345 38983 net.cpp:198] map64_2_eltsum_map64_2_relu_after_sum_0_split needs backward computation.
I0420 14:16:49.220347 38983 net.cpp:198] map64_2_relu_after_sum needs backward computation.
I0420 14:16:49.220350 38983 net.cpp:198] map64_2_eltsum needs backward computation.
I0420 14:16:49.220352 38983 net.cpp:198] map64_2_scale_b needs backward computation.
I0420 14:16:49.220355 38983 net.cpp:198] map64_2_bn_b needs backward computation.
I0420 14:16:49.220357 38983 net.cpp:198] map64_2_conv_b needs backward computation.
I0420 14:16:49.220360 38983 net.cpp:198] map64_2_relu_a needs backward computation.
I0420 14:16:49.220361 38983 net.cpp:198] map64_2_scale_a needs backward computation.
I0420 14:16:49.220363 38983 net.cpp:198] map64_2_bn_a needs backward computation.
I0420 14:16:49.220366 38983 net.cpp:198] map64_2_conv_a needs backward computation.
I0420 14:16:49.220368 38983 net.cpp:198] map64_1_eltsum_map64_1_relu_after_sum_0_split needs backward computation.
I0420 14:16:49.220371 38983 net.cpp:198] map64_1_relu_after_sum needs backward computation.
I0420 14:16:49.220373 38983 net.cpp:198] map64_1_eltsum needs backward computation.
I0420 14:16:49.220376 38983 net.cpp:198] map64_1_scale_b needs backward computation.
I0420 14:16:49.220379 38983 net.cpp:198] map64_1_bn_b needs backward computation.
I0420 14:16:49.220381 38983 net.cpp:198] map64_1_conv_b needs backward computation.
I0420 14:16:49.220383 38983 net.cpp:198] map64_1_relu_a needs backward computation.
I0420 14:16:49.220386 38983 net.cpp:198] map64_1_scale_a needs backward computation.
I0420 14:16:49.220388 38983 net.cpp:198] map64_1_bn_a needs backward computation.
I0420 14:16:49.220391 38983 net.cpp:198] map64_1_conv_a needs backward computation.
I0420 14:16:49.220392 38983 net.cpp:198] map64_1_scale_proj needs backward computation.
I0420 14:16:49.220394 38983 net.cpp:198] map64_1_bn_proj needs backward computation.
I0420 14:16:49.220397 38983 net.cpp:198] map64_1_conv_proj needs backward computation.
I0420 14:16:49.220401 38983 net.cpp:198] map32_3_eltsum_map32_3_relu_after_sum_0_split needs backward computation.
I0420 14:16:49.220402 38983 net.cpp:198] map32_3_relu_after_sum needs backward computation.
I0420 14:16:49.220405 38983 net.cpp:198] map32_3_eltsum needs backward computation.
I0420 14:16:49.220407 38983 net.cpp:198] map32_3_scale_b needs backward computation.
I0420 14:16:49.220410 38983 net.cpp:198] map32_3_bn_b needs backward computation.
I0420 14:16:49.220413 38983 net.cpp:198] map32_3_conv_b needs backward computation.
I0420 14:16:49.220415 38983 net.cpp:198] map32_3_relu_a needs backward computation.
I0420 14:16:49.220417 38983 net.cpp:198] map32_3_scale_a needs backward computation.
I0420 14:16:49.220419 38983 net.cpp:198] map32_3_bn_a needs backward computation.
I0420 14:16:49.220422 38983 net.cpp:198] map32_3_conv_a needs backward computation.
I0420 14:16:49.220423 38983 net.cpp:198] map32_2_eltsum_map32_2_relu_after_sum_0_split needs backward computation.
I0420 14:16:49.220427 38983 net.cpp:198] map32_2_relu_after_sum needs backward computation.
I0420 14:16:49.220428 38983 net.cpp:198] map32_2_eltsum needs backward computation.
I0420 14:16:49.220432 38983 net.cpp:198] map32_2_scale_b needs backward computation.
I0420 14:16:49.220433 38983 net.cpp:198] map32_2_bn_b needs backward computation.
I0420 14:16:49.220435 38983 net.cpp:198] map32_2_conv_b needs backward computation.
I0420 14:16:49.220438 38983 net.cpp:198] map32_2_relu_a needs backward computation.
I0420 14:16:49.220439 38983 net.cpp:198] map32_2_scale_a needs backward computation.
I0420 14:16:49.220443 38983 net.cpp:198] map32_2_bn_a needs backward computation.
I0420 14:16:49.220445 38983 net.cpp:198] map32_2_conv_a needs backward computation.
I0420 14:16:49.220448 38983 net.cpp:198] map32_1_eltsum_map32_1_relu_after_sum_0_split needs backward computation.
I0420 14:16:49.220449 38983 net.cpp:198] map32_1_relu_after_sum needs backward computation.
I0420 14:16:49.220451 38983 net.cpp:198] map32_1_eltsum needs backward computation.
I0420 14:16:49.220455 38983 net.cpp:198] map32_1_scale_b needs backward computation.
I0420 14:16:49.220465 38983 net.cpp:198] map32_1_bn_b needs backward computation.
I0420 14:16:49.220468 38983 net.cpp:198] map32_1_conv_b needs backward computation.
I0420 14:16:49.220469 38983 net.cpp:198] map32_1_relu_a needs backward computation.
I0420 14:16:49.220471 38983 net.cpp:198] map32_1_scale_a needs backward computation.
I0420 14:16:49.220474 38983 net.cpp:198] map32_1_bn_a needs backward computation.
I0420 14:16:49.220475 38983 net.cpp:198] map32_1_conv_a needs backward computation.
I0420 14:16:49.220479 38983 net.cpp:198] map32_1_scale_proj needs backward computation.
I0420 14:16:49.220480 38983 net.cpp:198] map32_1_bn_proj needs backward computation.
I0420 14:16:49.220482 38983 net.cpp:198] map32_1_conv_proj needs backward computation.
I0420 14:16:49.220485 38983 net.cpp:198] map16_3_eltsum_map16_3_relu_after_sum_0_split needs backward computation.
I0420 14:16:49.220489 38983 net.cpp:198] map16_3_relu_after_sum needs backward computation.
I0420 14:16:49.220490 38983 net.cpp:198] map16_3_eltsum needs backward computation.
I0420 14:16:49.220494 38983 net.cpp:198] map16_3_scale_b needs backward computation.
I0420 14:16:49.220496 38983 net.cpp:198] map16_3_bn_b needs backward computation.
I0420 14:16:49.220499 38983 net.cpp:198] map16_3_conv_b needs backward computation.
I0420 14:16:49.220500 38983 net.cpp:198] map16_3_relu_a needs backward computation.
I0420 14:16:49.220504 38983 net.cpp:198] map16_3_scale_a needs backward computation.
I0420 14:16:49.220505 38983 net.cpp:198] map16_3_bn_a needs backward computation.
I0420 14:16:49.220507 38983 net.cpp:198] map16_3_conv_a needs backward computation.
I0420 14:16:49.220510 38983 net.cpp:198] map16_2_eltsum_map16_2_relu_after_sum_0_split needs backward computation.
I0420 14:16:49.220511 38983 net.cpp:198] map16_2_relu_after_sum needs backward computation.
I0420 14:16:49.220515 38983 net.cpp:198] map16_2_eltsum needs backward computation.
I0420 14:16:49.220518 38983 net.cpp:198] map16_2_scale_b needs backward computation.
I0420 14:16:49.220521 38983 net.cpp:198] map16_2_bn_b needs backward computation.
I0420 14:16:49.220523 38983 net.cpp:198] map16_2_conv_b needs backward computation.
I0420 14:16:49.220525 38983 net.cpp:198] map16_2_relu_a needs backward computation.
I0420 14:16:49.220527 38983 net.cpp:198] map16_2_scale_a needs backward computation.
I0420 14:16:49.220530 38983 net.cpp:198] map16_2_bn_a needs backward computation.
I0420 14:16:49.220531 38983 net.cpp:198] map16_2_conv_a needs backward computation.
I0420 14:16:49.220535 38983 net.cpp:198] map16_1_eltsum_map16_1_relu_after_sum_0_split needs backward computation.
I0420 14:16:49.220537 38983 net.cpp:198] map16_1_relu_after_sum needs backward computation.
I0420 14:16:49.220540 38983 net.cpp:198] map16_1_eltsum needs backward computation.
I0420 14:16:49.220541 38983 net.cpp:198] map16_1_scale_b needs backward computation.
I0420 14:16:49.220544 38983 net.cpp:198] map16_1_bn_b needs backward computation.
I0420 14:16:49.220546 38983 net.cpp:198] map16_1_conv_b needs backward computation.
I0420 14:16:49.220548 38983 net.cpp:198] map16_1_relu_a needs backward computation.
I0420 14:16:49.220551 38983 net.cpp:198] map16_1_scale_a needs backward computation.
I0420 14:16:49.220554 38983 net.cpp:198] map16_1_bn_a needs backward computation.
I0420 14:16:49.220556 38983 net.cpp:198] map16_1_conv_a needs backward computation.
I0420 14:16:49.220558 38983 net.cpp:198] conv1_relu_conv1_0_split needs backward computation.
I0420 14:16:49.220561 38983 net.cpp:198] relu_conv1 needs backward computation.
I0420 14:16:49.220564 38983 net.cpp:198] scale_conv1 needs backward computation.
I0420 14:16:49.220566 38983 net.cpp:198] bn_conv1 needs backward computation.
I0420 14:16:49.220568 38983 net.cpp:198] conv1 needs backward computation.
I0420 14:16:49.220571 38983 net.cpp:200] label_data_1_split does not need backward computation.
I0420 14:16:49.220576 38983 net.cpp:200] data does not need backward computation.
I0420 14:16:49.220577 38983 net.cpp:242] This network produces output acctop1
I0420 14:16:49.220585 38983 net.cpp:242] This network produces output acctop5
I0420 14:16:49.220588 38983 net.cpp:242] This network produces output loss
I0420 14:16:49.220638 38983 net.cpp:255] Network initialization done.
I0420 14:16:49.220927 38983 solver.cpp:56] Solver scaffolding done.
I0420 14:16:49.226120 38983 caffe.cpp:242] Resuming from model/ResNet20_finetune_quant_0.09_iter_10000.solverstate
I0420 14:16:49.278017 38983 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: model/ResNet20_finetune_quant_0.09_iter_10000.caffemodel
I0420 14:16:49.278030 38983 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0420 14:16:49.278424 38983 sgd_solver.cpp:318] SGDSolver: restoring history
I0420 14:16:49.281358 38983 caffe.cpp:248] Starting Optimization
I0420 14:16:49.281369 38983 solver.cpp:273] Solving 
I0420 14:16:49.281373 38983 solver.cpp:274] Learning Rate Policy: multistep
I0420 14:16:49.284438 38983 solver.cpp:331] Iteration 10000, Testing net (#0)
I0420 14:16:54.398860 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:16:54.529548 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8262
I0420 14:16:54.529573 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9891
I0420 14:16:54.529597 38983 solver.cpp:398]     Test net output #2: loss = 0.578185 (* 1 = 0.578185 loss)
I0420 14:16:54.856542 38983 solver.cpp:219] Iteration 10000 (1794.29 iter/s, 5.57325s/100 iters), loss = 0.265537
I0420 14:16:54.856585 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 14:16:54.856591 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:16:54.856597 38983 solver.cpp:238]     Train net output #2: loss = 0.265537 (* 1 = 0.265537 loss)
I0420 14:16:54.856618 38983 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0420 14:17:18.126063 38983 solver.cpp:219] Iteration 10100 (4.29792 iter/s, 23.2671s/100 iters), loss = 0.286762
I0420 14:17:18.126209 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:17:18.126217 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:17:18.126224 38983 solver.cpp:238]     Train net output #2: loss = 0.286762 (* 1 = 0.286762 loss)
I0420 14:17:18.126229 38983 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0420 14:17:41.251646 38983 solver.cpp:219] Iteration 10200 (4.32463 iter/s, 23.1234s/100 iters), loss = 0.365642
I0420 14:17:41.251710 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 14:17:41.251716 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:17:41.251724 38983 solver.cpp:238]     Train net output #2: loss = 0.365642 (* 1 = 0.365642 loss)
I0420 14:17:41.251727 38983 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0420 14:18:04.259445 38983 solver.cpp:219] Iteration 10300 (4.34637 iter/s, 23.0077s/100 iters), loss = 0.387728
I0420 14:18:04.259644 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 14:18:04.259651 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:18:04.259658 38983 solver.cpp:238]     Train net output #2: loss = 0.387728 (* 1 = 0.387728 loss)
I0420 14:18:04.259662 38983 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0420 14:18:24.157016 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:18:27.266258 38983 solver.cpp:219] Iteration 10400 (4.34695 iter/s, 23.0046s/100 iters), loss = 0.324432
I0420 14:18:27.266317 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 14:18:27.266322 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:18:27.266330 38983 solver.cpp:238]     Train net output #2: loss = 0.324432 (* 1 = 0.324432 loss)
I0420 14:18:27.266333 38983 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0420 14:18:50.396915 38983 solver.cpp:219] Iteration 10500 (4.3233 iter/s, 23.1305s/100 iters), loss = 0.32557
I0420 14:18:50.397210 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 14:18:50.397220 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:18:50.397228 38983 solver.cpp:238]     Train net output #2: loss = 0.32557 (* 1 = 0.32557 loss)
I0420 14:18:50.397233 38983 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0420 14:19:14.137573 38983 solver.cpp:219] Iteration 10600 (4.21257 iter/s, 23.7385s/100 iters), loss = 0.471028
I0420 14:19:14.137632 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.804688
I0420 14:19:14.137639 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:19:14.137645 38983 solver.cpp:238]     Train net output #2: loss = 0.471028 (* 1 = 0.471028 loss)
I0420 14:19:14.137650 38983 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0420 14:19:37.626989 38983 solver.cpp:219] Iteration 10700 (4.25746 iter/s, 23.4882s/100 iters), loss = 0.254537
I0420 14:19:37.627178 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 14:19:37.627187 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:19:37.627193 38983 solver.cpp:238]     Train net output #2: loss = 0.254537 (* 1 = 0.254537 loss)
I0420 14:19:37.627197 38983 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0420 14:19:55.414484 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:20:00.733742 38983 solver.cpp:219] Iteration 10800 (4.32817 iter/s, 23.1045s/100 iters), loss = 0.226121
I0420 14:20:00.733803 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 14:20:00.733808 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:20:00.733814 38983 solver.cpp:238]     Train net output #2: loss = 0.226121 (* 1 = 0.226121 loss)
I0420 14:20:00.733819 38983 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0420 14:20:23.807399 38983 solver.cpp:219] Iteration 10900 (4.33398 iter/s, 23.0735s/100 iters), loss = 0.378917
I0420 14:20:23.807489 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 14:20:23.807497 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:20:23.807503 38983 solver.cpp:238]     Train net output #2: loss = 0.378917 (* 1 = 0.378917 loss)
I0420 14:20:23.807507 38983 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0420 14:20:46.657783 38983 solver.cpp:331] Iteration 11000, Testing net (#0)
I0420 14:20:51.527463 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:20:51.760988 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8338
I0420 14:20:51.761014 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9926
I0420 14:20:51.761039 38983 solver.cpp:398]     Test net output #2: loss = 0.534923 (* 1 = 0.534923 loss)
I0420 14:20:51.945006 38983 solver.cpp:219] Iteration 11000 (3.55424 iter/s, 28.1354s/100 iters), loss = 0.23385
I0420 14:20:51.945029 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 14:20:51.945050 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:20:51.945055 38983 solver.cpp:238]     Train net output #2: loss = 0.23385 (* 1 = 0.23385 loss)
I0420 14:20:51.945062 38983 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0420 14:21:14.998878 38983 solver.cpp:219] Iteration 11100 (4.3377 iter/s, 23.0537s/100 iters), loss = 0.372258
I0420 14:21:14.999078 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 14:21:14.999086 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:21:14.999094 38983 solver.cpp:238]     Train net output #2: loss = 0.372258 (* 1 = 0.372258 loss)
I0420 14:21:14.999099 38983 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0420 14:21:30.451191 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:21:37.979096 38983 solver.cpp:219] Iteration 11200 (4.35198 iter/s, 22.978s/100 iters), loss = 0.266908
I0420 14:21:37.979151 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:21:37.979156 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:21:37.979162 38983 solver.cpp:238]     Train net output #2: loss = 0.266908 (* 1 = 0.266908 loss)
I0420 14:21:37.979166 38983 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0420 14:22:01.071491 38983 solver.cpp:219] Iteration 11300 (4.33085 iter/s, 23.0901s/100 iters), loss = 0.362784
I0420 14:22:01.071743 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 14:22:01.071750 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:22:01.071758 38983 solver.cpp:238]     Train net output #2: loss = 0.362784 (* 1 = 0.362784 loss)
I0420 14:22:01.071763 38983 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0420 14:22:24.072202 38983 solver.cpp:219] Iteration 11400 (4.3481 iter/s, 22.9985s/100 iters), loss = 0.392806
I0420 14:22:24.072263 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 14:22:24.072270 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:22:24.072278 38983 solver.cpp:238]     Train net output #2: loss = 0.392806 (* 1 = 0.392806 loss)
I0420 14:22:24.072283 38983 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0420 14:22:47.124882 38983 solver.cpp:219] Iteration 11500 (4.33831 iter/s, 23.0504s/100 iters), loss = 0.263782
I0420 14:22:47.125082 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 14:22:47.125088 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:22:47.125095 38983 solver.cpp:238]     Train net output #2: loss = 0.263782 (* 1 = 0.263782 loss)
I0420 14:22:47.125100 38983 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0420 14:23:00.591439 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:23:10.242846 38983 solver.cpp:219] Iteration 11600 (4.32606 iter/s, 23.1157s/100 iters), loss = 0.290554
I0420 14:23:10.242907 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:23:10.242913 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:23:10.242920 38983 solver.cpp:238]     Train net output #2: loss = 0.290554 (* 1 = 0.290554 loss)
I0420 14:23:10.242925 38983 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0420 14:23:33.258468 38983 solver.cpp:219] Iteration 11700 (4.34489 iter/s, 23.0155s/100 iters), loss = 0.352673
I0420 14:23:33.258599 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 14:23:33.258605 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:23:33.258612 38983 solver.cpp:238]     Train net output #2: loss = 0.352673 (* 1 = 0.352673 loss)
I0420 14:23:33.258617 38983 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0420 14:23:56.305469 38983 solver.cpp:219] Iteration 11800 (4.33938 iter/s, 23.0448s/100 iters), loss = 0.244785
I0420 14:23:56.305531 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 14:23:56.305538 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:23:56.305544 38983 solver.cpp:238]     Train net output #2: loss = 0.244785 (* 1 = 0.244785 loss)
I0420 14:23:56.305549 38983 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0420 14:24:19.367517 38983 solver.cpp:219] Iteration 11900 (4.33653 iter/s, 23.0599s/100 iters), loss = 0.365877
I0420 14:24:19.367602 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 14:24:19.367609 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:24:19.367615 38983 solver.cpp:238]     Train net output #2: loss = 0.365877 (* 1 = 0.365877 loss)
I0420 14:24:19.367620 38983 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0420 14:24:24.512784 38983 blocking_queue.cpp:49] Waiting for data
I0420 14:24:31.869539 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:24:43.426820 38983 solver.cpp:331] Iteration 12000, Testing net (#0)
I0420 14:24:48.210330 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:24:48.436795 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8424
I0420 14:24:48.436821 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9933
I0420 14:24:48.436846 38983 solver.cpp:398]     Test net output #2: loss = 0.496403 (* 1 = 0.496403 loss)
I0420 14:24:48.667089 38983 solver.cpp:219] Iteration 12000 (3.41303 iter/s, 29.2995s/100 iters), loss = 0.36098
I0420 14:24:48.667129 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 14:24:48.667135 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:24:48.667140 38983 solver.cpp:238]     Train net output #2: loss = 0.36098 (* 1 = 0.36098 loss)
I0420 14:24:48.667145 38983 sgd_solver.cpp:46] MultiStep Status: Iteration 12000, step = 1
I0420 14:24:48.667148 38983 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I0420 14:25:11.679100 38983 solver.cpp:219] Iteration 12100 (4.34598 iter/s, 23.0098s/100 iters), loss = 0.213398
I0420 14:25:11.679338 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 14:25:11.679347 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:25:11.679354 38983 solver.cpp:238]     Train net output #2: loss = 0.213398 (* 1 = 0.213398 loss)
I0420 14:25:11.679358 38983 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I0420 14:25:34.716697 38983 solver.cpp:219] Iteration 12200 (4.34116 iter/s, 23.0353s/100 iters), loss = 0.313105
I0420 14:25:34.716754 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 14:25:34.716760 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:25:34.716768 38983 solver.cpp:238]     Train net output #2: loss = 0.313105 (* 1 = 0.313105 loss)
I0420 14:25:34.716773 38983 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I0420 14:25:57.854128 38983 solver.cpp:219] Iteration 12300 (4.3223 iter/s, 23.1358s/100 iters), loss = 0.323252
I0420 14:25:57.854334 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 14:25:57.854342 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 14:25:57.854349 38983 solver.cpp:238]     Train net output #2: loss = 0.323252 (* 1 = 0.323252 loss)
I0420 14:25:57.854354 38983 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I0420 14:26:06.836531 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:26:20.883538 38983 solver.cpp:219] Iteration 12400 (4.34231 iter/s, 23.0292s/100 iters), loss = 0.304316
I0420 14:26:20.883596 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 14:26:20.883602 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:26:20.883610 38983 solver.cpp:238]     Train net output #2: loss = 0.304316 (* 1 = 0.304316 loss)
I0420 14:26:20.883613 38983 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I0420 14:26:43.933424 38983 solver.cpp:219] Iteration 12500 (4.33884 iter/s, 23.0476s/100 iters), loss = 0.351316
I0420 14:26:43.933609 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 14:26:43.933615 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:26:43.933622 38983 solver.cpp:238]     Train net output #2: loss = 0.351316 (* 1 = 0.351316 loss)
I0420 14:26:43.933627 38983 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I0420 14:27:07.012572 38983 solver.cpp:219] Iteration 12600 (4.33333 iter/s, 23.077s/100 iters), loss = 0.466523
I0420 14:27:07.012629 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 14:27:07.012634 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:27:07.012641 38983 solver.cpp:238]     Train net output #2: loss = 0.466523 (* 1 = 0.466523 loss)
I0420 14:27:07.012645 38983 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I0420 14:27:30.146240 38983 solver.cpp:219] Iteration 12700 (4.32273 iter/s, 23.1335s/100 iters), loss = 0.288121
I0420 14:27:30.146381 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 14:27:30.146389 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:27:30.146396 38983 solver.cpp:238]     Train net output #2: loss = 0.288121 (* 1 = 0.288121 loss)
I0420 14:27:30.146400 38983 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I0420 14:27:37.084302 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:27:53.186580 38983 solver.cpp:219] Iteration 12800 (4.34067 iter/s, 23.0379s/100 iters), loss = 0.39887
I0420 14:27:53.186637 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 14:27:53.186642 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 14:27:53.186650 38983 solver.cpp:238]     Train net output #2: loss = 0.39887 (* 1 = 0.39887 loss)
I0420 14:27:53.186655 38983 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I0420 14:28:16.245322 38983 solver.cpp:219] Iteration 12900 (4.33716 iter/s, 23.0566s/100 iters), loss = 0.321789
I0420 14:28:16.245451 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 14:28:16.245458 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:28:16.245465 38983 solver.cpp:238]     Train net output #2: loss = 0.321789 (* 1 = 0.321789 loss)
I0420 14:28:16.245470 38983 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I0420 14:28:39.209735 38983 solver.cpp:331] Iteration 13000, Testing net (#0)
I0420 14:28:44.014839 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:28:44.227538 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8544
I0420 14:28:44.227567 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9935
I0420 14:28:44.227591 38983 solver.cpp:398]     Test net output #2: loss = 0.454411 (* 1 = 0.454411 loss)
I0420 14:28:44.459623 38983 solver.cpp:219] Iteration 13000 (3.54458 iter/s, 28.2121s/100 iters), loss = 0.227557
I0420 14:28:44.459645 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 14:28:44.459667 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:28:44.459673 38983 solver.cpp:238]     Train net output #2: loss = 0.227557 (* 1 = 0.227557 loss)
I0420 14:28:44.459684 38983 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I0420 14:29:07.483608 38983 solver.cpp:219] Iteration 13100 (4.34371 iter/s, 23.0218s/100 iters), loss = 0.30461
I0420 14:29:07.483814 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 14:29:07.483821 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:29:07.483829 38983 solver.cpp:238]     Train net output #2: loss = 0.30461 (* 1 = 0.30461 loss)
I0420 14:29:07.483834 38983 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I0420 14:29:12.133919 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:29:31.819550 38983 solver.cpp:219] Iteration 13200 (4.1095 iter/s, 24.3338s/100 iters), loss = 0.300669
I0420 14:29:31.819612 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 14:29:31.819618 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:29:31.819625 38983 solver.cpp:238]     Train net output #2: loss = 0.300669 (* 1 = 0.300669 loss)
I0420 14:29:31.819629 38983 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I0420 14:29:54.847939 38983 solver.cpp:219] Iteration 13300 (4.34288 iter/s, 23.0262s/100 iters), loss = 0.27655
I0420 14:29:54.848165 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:29:54.848172 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:29:54.848179 38983 solver.cpp:238]     Train net output #2: loss = 0.27655 (* 1 = 0.27655 loss)
I0420 14:29:54.848184 38983 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I0420 14:30:17.985833 38983 solver.cpp:219] Iteration 13400 (4.32235 iter/s, 23.1355s/100 iters), loss = 0.350938
I0420 14:30:17.985895 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 14:30:17.985901 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:30:17.985908 38983 solver.cpp:238]     Train net output #2: loss = 0.350938 (* 1 = 0.350938 loss)
I0420 14:30:17.985913 38983 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I0420 14:30:40.992418 38983 solver.cpp:219] Iteration 13500 (4.3466 iter/s, 23.0065s/100 iters), loss = 0.30485
I0420 14:30:40.992600 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:30:40.992607 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:30:40.992614 38983 solver.cpp:238]     Train net output #2: loss = 0.30485 (* 1 = 0.30485 loss)
I0420 14:30:40.992619 38983 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I0420 14:30:43.608352 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:31:04.018390 38983 solver.cpp:219] Iteration 13600 (4.34335 iter/s, 23.0237s/100 iters), loss = 0.341772
I0420 14:31:04.018450 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 14:31:04.018456 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:31:04.018463 38983 solver.cpp:238]     Train net output #2: loss = 0.341772 (* 1 = 0.341772 loss)
I0420 14:31:04.018467 38983 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I0420 14:31:27.137780 38983 solver.cpp:219] Iteration 13700 (4.3258 iter/s, 23.1171s/100 iters), loss = 0.278202
I0420 14:31:27.137904 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:31:27.137912 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:31:27.137918 38983 solver.cpp:238]     Train net output #2: loss = 0.278202 (* 1 = 0.278202 loss)
I0420 14:31:27.137923 38983 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I0420 14:31:50.156936 38983 solver.cpp:219] Iteration 13800 (4.34425 iter/s, 23.0189s/100 iters), loss = 0.462387
I0420 14:31:50.156996 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 14:31:50.157002 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 14:31:50.157009 38983 solver.cpp:238]     Train net output #2: loss = 0.462387 (* 1 = 0.462387 loss)
I0420 14:31:50.157013 38983 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I0420 14:32:13.155624 38983 solver.cpp:219] Iteration 13900 (4.34851 iter/s, 22.9964s/100 iters), loss = 0.27512
I0420 14:32:13.155777 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 14:32:13.155784 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:32:13.155791 38983 solver.cpp:238]     Train net output #2: loss = 0.27512 (* 1 = 0.27512 loss)
I0420 14:32:13.155797 38983 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I0420 14:32:13.663251 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:32:36.091619 38983 solver.cpp:331] Iteration 14000, Testing net (#0)
I0420 14:32:40.947850 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:32:41.090549 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8586
I0420 14:32:41.090576 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 14:32:41.090600 38983 solver.cpp:398]     Test net output #2: loss = 0.451048 (* 1 = 0.451048 loss)
I0420 14:32:41.310662 38983 solver.cpp:219] Iteration 14000 (3.55204 iter/s, 28.1528s/100 iters), loss = 0.272541
I0420 14:32:41.310699 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 14:32:41.310708 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:32:41.310714 38983 solver.cpp:238]     Train net output #2: loss = 0.272541 (* 1 = 0.272541 loss)
I0420 14:32:41.310719 38983 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I0420 14:33:04.375654 38983 solver.cpp:219] Iteration 14100 (4.336 iter/s, 23.0627s/100 iters), loss = 0.289483
I0420 14:33:04.375828 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 14:33:04.375836 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:33:04.375844 38983 solver.cpp:238]     Train net output #2: loss = 0.289483 (* 1 = 0.289483 loss)
I0420 14:33:04.375849 38983 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I0420 14:33:27.451105 38983 solver.cpp:219] Iteration 14200 (4.33403 iter/s, 23.0732s/100 iters), loss = 0.360307
I0420 14:33:27.451164 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 14:33:27.451169 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:33:27.451177 38983 solver.cpp:238]     Train net output #2: loss = 0.360307 (* 1 = 0.360307 loss)
I0420 14:33:27.451181 38983 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I0420 14:33:48.724153 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:33:50.523313 38983 solver.cpp:219] Iteration 14300 (4.33424 iter/s, 23.0721s/100 iters), loss = 0.230432
I0420 14:33:50.523373 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 14:33:50.523380 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:33:50.523386 38983 solver.cpp:238]     Train net output #2: loss = 0.230432 (* 1 = 0.230432 loss)
I0420 14:33:50.523391 38983 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I0420 14:34:13.534621 38983 solver.cpp:219] Iteration 14400 (4.34611 iter/s, 23.0091s/100 iters), loss = 0.282817
I0420 14:34:13.534685 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 14:34:13.534692 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:34:13.534698 38983 solver.cpp:238]     Train net output #2: loss = 0.282817 (* 1 = 0.282817 loss)
I0420 14:34:13.534703 38983 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I0420 14:34:36.617101 38983 solver.cpp:219] Iteration 14500 (4.33274 iter/s, 23.0801s/100 iters), loss = 0.192181
I0420 14:34:36.617295 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 14:34:36.617301 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:34:36.617310 38983 solver.cpp:238]     Train net output #2: loss = 0.192181 (* 1 = 0.192181 loss)
I0420 14:34:36.617313 38983 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I0420 14:34:59.724913 38983 solver.cpp:219] Iteration 14600 (4.32756 iter/s, 23.1077s/100 iters), loss = 0.266893
I0420 14:34:59.724972 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:34:59.724977 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:34:59.724984 38983 solver.cpp:238]     Train net output #2: loss = 0.266893 (* 1 = 0.266893 loss)
I0420 14:34:59.724988 38983 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I0420 14:35:18.898629 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:35:22.766108 38983 solver.cpp:219] Iteration 14700 (4.34048 iter/s, 23.0389s/100 iters), loss = 0.27352
I0420 14:35:22.766165 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 14:35:22.766171 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:35:22.766178 38983 solver.cpp:238]     Train net output #2: loss = 0.27352 (* 1 = 0.27352 loss)
I0420 14:35:22.766182 38983 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I0420 14:35:45.789428 38983 solver.cpp:219] Iteration 14800 (4.34383 iter/s, 23.0211s/100 iters), loss = 0.32976
I0420 14:35:45.789487 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 14:35:45.789494 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:35:45.789500 38983 solver.cpp:238]     Train net output #2: loss = 0.32976 (* 1 = 0.32976 loss)
I0420 14:35:45.789505 38983 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I0420 14:36:08.936959 38983 solver.cpp:219] Iteration 14900 (4.32052 iter/s, 23.1453s/100 iters), loss = 0.337442
I0420 14:36:08.937165 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 14:36:08.937173 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:36:08.937180 38983 solver.cpp:238]     Train net output #2: loss = 0.337442 (* 1 = 0.337442 loss)
I0420 14:36:08.937185 38983 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I0420 14:36:31.734235 38983 solver.cpp:331] Iteration 15000, Testing net (#0)
I0420 14:36:36.630316 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:36:36.856355 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8569
I0420 14:36:36.856382 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.994
I0420 14:36:36.856406 38983 solver.cpp:398]     Test net output #2: loss = 0.449224 (* 1 = 0.449224 loss)
I0420 14:36:36.985335 38983 solver.cpp:219] Iteration 15000 (3.56528 iter/s, 28.0483s/100 iters), loss = 0.203732
I0420 14:36:36.985357 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 14:36:36.985379 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:36:36.985385 38983 solver.cpp:238]     Train net output #2: loss = 0.203732 (* 1 = 0.203732 loss)
I0420 14:36:36.985391 38983 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I0420 14:36:54.137158 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:37:00.100795 38983 solver.cpp:219] Iteration 15100 (4.32653 iter/s, 23.1132s/100 iters), loss = 0.209757
I0420 14:37:00.100853 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 14:37:00.100859 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:37:00.100867 38983 solver.cpp:238]     Train net output #2: loss = 0.209757 (* 1 = 0.209757 loss)
I0420 14:37:00.100872 38983 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I0420 14:37:23.124475 38983 solver.cpp:219] Iteration 15200 (4.34338 iter/s, 23.0235s/100 iters), loss = 0.343075
I0420 14:37:23.124536 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:37:23.124542 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 14:37:23.124548 38983 solver.cpp:238]     Train net output #2: loss = 0.343075 (* 1 = 0.343075 loss)
I0420 14:37:23.124552 38983 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I0420 14:37:46.140478 38983 solver.cpp:219] Iteration 15300 (4.34524 iter/s, 23.0137s/100 iters), loss = 0.351807
I0420 14:37:46.140645 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 14:37:46.140652 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:37:46.140660 38983 solver.cpp:238]     Train net output #2: loss = 0.351807 (* 1 = 0.351807 loss)
I0420 14:37:46.140664 38983 sgd_solver.cpp:105] Iteration 15300, lr = 0.001
I0420 14:38:09.261760 38983 solver.cpp:219] Iteration 15400 (4.32545 iter/s, 23.119s/100 iters), loss = 0.280377
I0420 14:38:09.261821 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 14:38:09.261826 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:38:09.261832 38983 solver.cpp:238]     Train net output #2: loss = 0.280377 (* 1 = 0.280377 loss)
I0420 14:38:09.261837 38983 sgd_solver.cpp:105] Iteration 15400, lr = 0.001
I0420 14:38:24.100940 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:38:32.347908 38983 solver.cpp:219] Iteration 15500 (4.33165 iter/s, 23.0859s/100 iters), loss = 0.395897
I0420 14:38:32.347966 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 14:38:32.347972 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 14:38:32.347978 38983 solver.cpp:238]     Train net output #2: loss = 0.395897 (* 1 = 0.395897 loss)
I0420 14:38:32.347983 38983 sgd_solver.cpp:105] Iteration 15500, lr = 0.001
I0420 14:38:55.377990 38983 solver.cpp:219] Iteration 15600 (4.34257 iter/s, 23.0278s/100 iters), loss = 0.386671
I0420 14:38:55.378177 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 14:38:55.378185 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:38:55.378192 38983 solver.cpp:238]     Train net output #2: loss = 0.386672 (* 1 = 0.386672 loss)
I0420 14:38:55.378197 38983 sgd_solver.cpp:105] Iteration 15600, lr = 0.001
I0420 14:39:18.432016 38983 solver.cpp:219] Iteration 15700 (4.33766 iter/s, 23.0539s/100 iters), loss = 0.256841
I0420 14:39:18.432078 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 14:39:18.432085 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:39:18.432090 38983 solver.cpp:238]     Train net output #2: loss = 0.256841 (* 1 = 0.256841 loss)
I0420 14:39:18.432096 38983 sgd_solver.cpp:105] Iteration 15700, lr = 0.001
I0420 14:39:42.725575 38983 solver.cpp:219] Iteration 15800 (4.11633 iter/s, 24.2935s/100 iters), loss = 0.232499
I0420 14:39:42.725771 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 14:39:42.725780 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:39:42.725786 38983 solver.cpp:238]     Train net output #2: loss = 0.232499 (* 1 = 0.232499 loss)
I0420 14:39:42.725790 38983 sgd_solver.cpp:105] Iteration 15800, lr = 0.001
I0420 14:39:55.425736 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:40:05.772495 38983 solver.cpp:219] Iteration 15900 (4.339 iter/s, 23.0468s/100 iters), loss = 0.374145
I0420 14:40:05.772553 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 14:40:05.772558 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:40:05.772565 38983 solver.cpp:238]     Train net output #2: loss = 0.374145 (* 1 = 0.374145 loss)
I0420 14:40:05.772569 38983 sgd_solver.cpp:105] Iteration 15900, lr = 0.001
I0420 14:40:28.633846 38983 solver.cpp:331] Iteration 16000, Testing net (#0)
I0420 14:40:33.487303 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:40:33.715405 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8597
I0420 14:40:33.715431 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 14:40:33.715456 38983 solver.cpp:398]     Test net output #2: loss = 0.450848 (* 1 = 0.450848 loss)
I0420 14:40:33.922570 38983 solver.cpp:219] Iteration 16000 (3.55265 iter/s, 28.148s/100 iters), loss = 0.339035
I0420 14:40:33.922592 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 14:40:33.922615 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:40:33.922621 38983 solver.cpp:238]     Train net output #2: loss = 0.339035 (* 1 = 0.339035 loss)
I0420 14:40:33.922626 38983 sgd_solver.cpp:105] Iteration 16000, lr = 0.001
I0420 14:40:57.006944 38983 solver.cpp:219] Iteration 16100 (4.33196 iter/s, 23.0843s/100 iters), loss = 0.338597
I0420 14:40:57.007014 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 14:40:57.007020 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:40:57.007028 38983 solver.cpp:238]     Train net output #2: loss = 0.338597 (* 1 = 0.338597 loss)
I0420 14:40:57.007035 38983 sgd_solver.cpp:105] Iteration 16100, lr = 0.001
I0420 14:41:20.046299 38983 solver.cpp:219] Iteration 16200 (4.34082 iter/s, 23.0371s/100 iters), loss = 0.321955
I0420 14:41:20.046499 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 14:41:20.046505 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:41:20.046512 38983 solver.cpp:238]     Train net output #2: loss = 0.321955 (* 1 = 0.321955 loss)
I0420 14:41:20.046519 38983 sgd_solver.cpp:105] Iteration 16200, lr = 0.001
I0420 14:41:30.505282 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:41:43.092694 38983 solver.cpp:219] Iteration 16300 (4.33948 iter/s, 23.0442s/100 iters), loss = 0.391548
I0420 14:41:43.092757 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 14:41:43.092763 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:41:43.092770 38983 solver.cpp:238]     Train net output #2: loss = 0.391548 (* 1 = 0.391548 loss)
I0420 14:41:43.092774 38983 sgd_solver.cpp:105] Iteration 16300, lr = 0.001
I0420 14:42:06.248764 38983 solver.cpp:219] Iteration 16400 (4.31855 iter/s, 23.1559s/100 iters), loss = 0.240432
I0420 14:42:06.248945 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 14:42:06.248952 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:42:06.248960 38983 solver.cpp:238]     Train net output #2: loss = 0.240432 (* 1 = 0.240432 loss)
I0420 14:42:06.248965 38983 sgd_solver.cpp:105] Iteration 16400, lr = 0.001
I0420 14:42:29.284700 38983 solver.cpp:219] Iteration 16500 (4.34146 iter/s, 23.0337s/100 iters), loss = 0.337572
I0420 14:42:29.284761 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 14:42:29.284766 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:42:29.284773 38983 solver.cpp:238]     Train net output #2: loss = 0.337572 (* 1 = 0.337572 loss)
I0420 14:42:29.284778 38983 sgd_solver.cpp:105] Iteration 16500, lr = 0.001
I0420 14:42:52.307549 38983 solver.cpp:219] Iteration 16600 (4.34393 iter/s, 23.0206s/100 iters), loss = 0.298081
I0420 14:42:52.307806 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 14:42:52.307813 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:42:52.307822 38983 solver.cpp:238]     Train net output #2: loss = 0.298081 (* 1 = 0.298081 loss)
I0420 14:42:52.307827 38983 sgd_solver.cpp:105] Iteration 16600, lr = 0.001
I0420 14:43:00.665014 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:43:15.429955 38983 solver.cpp:219] Iteration 16700 (4.32522 iter/s, 23.1202s/100 iters), loss = 0.240932
I0420 14:43:15.430016 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 14:43:15.430022 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:43:15.430028 38983 solver.cpp:238]     Train net output #2: loss = 0.240932 (* 1 = 0.240932 loss)
I0420 14:43:15.430032 38983 sgd_solver.cpp:105] Iteration 16700, lr = 0.001
I0420 14:43:38.468773 38983 solver.cpp:219] Iteration 16800 (4.34052 iter/s, 23.0387s/100 iters), loss = 0.390562
I0420 14:43:38.468979 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 14:43:38.468987 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:43:38.468994 38983 solver.cpp:238]     Train net output #2: loss = 0.390562 (* 1 = 0.390562 loss)
I0420 14:43:38.468999 38983 sgd_solver.cpp:105] Iteration 16800, lr = 0.001
I0420 14:44:01.518887 38983 solver.cpp:219] Iteration 16900 (4.33879 iter/s, 23.0479s/100 iters), loss = 0.425594
I0420 14:44:01.518946 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 14:44:01.518952 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:44:01.518959 38983 solver.cpp:238]     Train net output #2: loss = 0.425594 (* 1 = 0.425594 loss)
I0420 14:44:01.518962 38983 sgd_solver.cpp:105] Iteration 16900, lr = 0.001
I0420 14:44:24.401104 38983 solver.cpp:331] Iteration 17000, Testing net (#0)
I0420 14:44:29.268815 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:44:29.433217 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8631
I0420 14:44:29.433244 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9936
I0420 14:44:29.433253 38983 solver.cpp:398]     Test net output #2: loss = 0.446608 (* 1 = 0.446608 loss)
I0420 14:44:29.652992 38983 solver.cpp:219] Iteration 17000 (3.55468 iter/s, 28.1319s/100 iters), loss = 0.405776
I0420 14:44:29.653014 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 14:44:29.653036 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:44:29.653043 38983 solver.cpp:238]     Train net output #2: loss = 0.405776 (* 1 = 0.405776 loss)
I0420 14:44:29.653048 38983 sgd_solver.cpp:105] Iteration 17000, lr = 0.001
I0420 14:44:35.892500 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:44:52.703110 38983 solver.cpp:219] Iteration 17100 (4.33879 iter/s, 23.0479s/100 iters), loss = 0.244635
I0420 14:44:52.703172 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 14:44:52.703178 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:44:52.703186 38983 solver.cpp:238]     Train net output #2: loss = 0.244635 (* 1 = 0.244635 loss)
I0420 14:44:52.703189 38983 sgd_solver.cpp:105] Iteration 17100, lr = 0.001
I0420 14:45:15.785022 38983 solver.cpp:219] Iteration 17200 (4.33284 iter/s, 23.0796s/100 iters), loss = 0.232444
I0420 14:45:15.785219 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 14:45:15.785226 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:45:15.785234 38983 solver.cpp:238]     Train net output #2: loss = 0.232444 (* 1 = 0.232444 loss)
I0420 14:45:15.785238 38983 sgd_solver.cpp:105] Iteration 17200, lr = 0.001
I0420 14:45:38.844534 38983 solver.cpp:219] Iteration 17300 (4.33667 iter/s, 23.0591s/100 iters), loss = 0.366186
I0420 14:45:38.844590 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 14:45:38.844595 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0420 14:45:38.844602 38983 solver.cpp:238]     Train net output #2: loss = 0.366186 (* 1 = 0.366186 loss)
I0420 14:45:38.844606 38983 sgd_solver.cpp:105] Iteration 17300, lr = 0.001
I0420 14:46:01.887902 38983 solver.cpp:219] Iteration 17400 (4.34006 iter/s, 23.0412s/100 iters), loss = 0.198259
I0420 14:46:01.888137 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 14:46:01.888146 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:46:01.888154 38983 solver.cpp:238]     Train net output #2: loss = 0.198259 (* 1 = 0.198259 loss)
I0420 14:46:01.888157 38983 sgd_solver.cpp:105] Iteration 17400, lr = 0.001
I0420 14:46:05.843896 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:46:24.950462 38983 solver.cpp:219] Iteration 17500 (4.33644 iter/s, 23.0604s/100 iters), loss = 0.268425
I0420 14:46:24.950520 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 14:46:24.950525 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:46:24.950531 38983 solver.cpp:238]     Train net output #2: loss = 0.268425 (* 1 = 0.268425 loss)
I0420 14:46:24.950537 38983 sgd_solver.cpp:105] Iteration 17500, lr = 0.001
I0420 14:46:48.079478 38983 solver.cpp:219] Iteration 17600 (4.32358 iter/s, 23.129s/100 iters), loss = 0.275226
I0420 14:46:48.079687 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 14:46:48.079695 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:46:48.079702 38983 solver.cpp:238]     Train net output #2: loss = 0.275226 (* 1 = 0.275226 loss)
I0420 14:46:48.079706 38983 sgd_solver.cpp:105] Iteration 17600, lr = 0.001
I0420 14:47:11.105751 38983 solver.cpp:219] Iteration 17700 (4.34328 iter/s, 23.0241s/100 iters), loss = 0.282055
I0420 14:47:11.105813 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 14:47:11.105818 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:47:11.105824 38983 solver.cpp:238]     Train net output #2: loss = 0.282055 (* 1 = 0.282055 loss)
I0420 14:47:11.105829 38983 sgd_solver.cpp:105] Iteration 17700, lr = 0.001
I0420 14:47:34.130343 38983 solver.cpp:219] Iteration 17800 (4.3436 iter/s, 23.0224s/100 iters), loss = 0.194264
I0420 14:47:34.130534 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 14:47:34.130542 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:47:34.130549 38983 solver.cpp:238]     Train net output #2: loss = 0.194264 (* 1 = 0.194264 loss)
I0420 14:47:34.130553 38983 sgd_solver.cpp:105] Iteration 17800, lr = 0.001
I0420 14:47:36.034032 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:47:57.243633 38983 solver.cpp:219] Iteration 17900 (4.32696 iter/s, 23.1109s/100 iters), loss = 0.266495
I0420 14:47:57.243698 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 14:47:57.243703 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:47:57.243710 38983 solver.cpp:238]     Train net output #2: loss = 0.266495 (* 1 = 0.266495 loss)
I0420 14:47:57.243716 38983 sgd_solver.cpp:105] Iteration 17900, lr = 0.001
I0420 14:48:20.061202 38983 solver.cpp:331] Iteration 18000, Testing net (#0)
I0420 14:48:24.950187 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:48:25.168628 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8607
I0420 14:48:25.168658 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9937
I0420 14:48:25.168684 38983 solver.cpp:398]     Test net output #2: loss = 0.447928 (* 1 = 0.447928 loss)
I0420 14:48:25.297130 38983 solver.cpp:219] Iteration 18000 (3.56463 iter/s, 28.0534s/100 iters), loss = 0.25001
I0420 14:48:25.297152 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 14:48:25.297173 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:48:25.297179 38983 solver.cpp:238]     Train net output #2: loss = 0.25001 (* 1 = 0.25001 loss)
I0420 14:48:25.297185 38983 sgd_solver.cpp:105] Iteration 18000, lr = 0.001
I0420 14:48:48.447515 38983 solver.cpp:219] Iteration 18100 (4.32 iter/s, 23.1482s/100 iters), loss = 0.271998
I0420 14:48:48.447573 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 14:48:48.447578 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:48:48.447585 38983 solver.cpp:238]     Train net output #2: loss = 0.271998 (* 1 = 0.271998 loss)
I0420 14:48:48.447589 38983 sgd_solver.cpp:105] Iteration 18100, lr = 0.001
I0420 14:49:11.282812 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:49:11.500315 38983 solver.cpp:219] Iteration 18200 (4.3379 iter/s, 23.0526s/100 iters), loss = 0.292028
I0420 14:49:11.500375 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:49:11.500381 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:49:11.500387 38983 solver.cpp:238]     Train net output #2: loss = 0.292028 (* 1 = 0.292028 loss)
I0420 14:49:11.500391 38983 sgd_solver.cpp:105] Iteration 18200, lr = 0.001
I0420 14:49:35.024019 38983 solver.cpp:219] Iteration 18300 (4.25143 iter/s, 23.5215s/100 iters), loss = 0.256502
I0420 14:49:35.024073 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 14:49:35.024080 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:49:35.024085 38983 solver.cpp:238]     Train net output #2: loss = 0.256502 (* 1 = 0.256502 loss)
I0420 14:49:35.024091 38983 sgd_solver.cpp:105] Iteration 18300, lr = 0.001
I0420 14:49:58.832731 38983 solver.cpp:219] Iteration 18400 (4.20055 iter/s, 23.8064s/100 iters), loss = 0.40356
I0420 14:49:58.832936 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 14:49:58.832942 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:49:58.832949 38983 solver.cpp:238]     Train net output #2: loss = 0.40356 (* 1 = 0.40356 loss)
I0420 14:49:58.832954 38983 sgd_solver.cpp:105] Iteration 18400, lr = 0.001
I0420 14:50:21.908426 38983 solver.cpp:219] Iteration 18500 (4.33397 iter/s, 23.0735s/100 iters), loss = 0.335844
I0420 14:50:21.908483 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:50:21.908489 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:50:21.908495 38983 solver.cpp:238]     Train net output #2: loss = 0.335844 (* 1 = 0.335844 loss)
I0420 14:50:21.908500 38983 sgd_solver.cpp:105] Iteration 18500, lr = 0.001
I0420 14:50:42.475878 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:50:44.978153 38983 solver.cpp:219] Iteration 18600 (4.33471 iter/s, 23.0696s/100 iters), loss = 0.389695
I0420 14:50:44.978214 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 14:50:44.978221 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 14:50:44.978229 38983 solver.cpp:238]     Train net output #2: loss = 0.389695 (* 1 = 0.389695 loss)
I0420 14:50:44.978232 38983 sgd_solver.cpp:105] Iteration 18600, lr = 0.001
I0420 14:51:07.979861 38983 solver.cpp:219] Iteration 18700 (4.34793 iter/s, 22.9995s/100 iters), loss = 0.327678
I0420 14:51:07.979921 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:51:07.979926 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:51:07.979934 38983 solver.cpp:238]     Train net output #2: loss = 0.327678 (* 1 = 0.327678 loss)
I0420 14:51:07.979938 38983 sgd_solver.cpp:105] Iteration 18700, lr = 0.001
I0420 14:51:31.030716 38983 solver.cpp:219] Iteration 18800 (4.33868 iter/s, 23.0485s/100 iters), loss = 0.223008
I0420 14:51:31.030903 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 14:51:31.030910 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:51:31.030918 38983 solver.cpp:238]     Train net output #2: loss = 0.223008 (* 1 = 0.223008 loss)
I0420 14:51:31.030922 38983 sgd_solver.cpp:105] Iteration 18800, lr = 0.001
I0420 14:51:54.180534 38983 solver.cpp:219] Iteration 18900 (4.31974 iter/s, 23.1495s/100 iters), loss = 0.238499
I0420 14:51:54.180591 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 14:51:54.180596 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:51:54.180603 38983 solver.cpp:238]     Train net output #2: loss = 0.238499 (* 1 = 0.238499 loss)
I0420 14:51:54.180608 38983 sgd_solver.cpp:105] Iteration 18900, lr = 0.001
I0420 14:52:12.668234 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:52:16.973707 38983 solver.cpp:331] Iteration 19000, Testing net (#0)
I0420 14:52:21.885481 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:52:22.112490 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8622
I0420 14:52:22.112516 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9936
I0420 14:52:22.112540 38983 solver.cpp:398]     Test net output #2: loss = 0.446065 (* 1 = 0.446065 loss)
I0420 14:52:22.230725 38983 solver.cpp:219] Iteration 19000 (3.56533 iter/s, 28.0479s/100 iters), loss = 0.270227
I0420 14:52:22.230744 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 14:52:22.230765 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:52:22.230772 38983 solver.cpp:238]     Train net output #2: loss = 0.270227 (* 1 = 0.270227 loss)
I0420 14:52:22.230777 38983 sgd_solver.cpp:105] Iteration 19000, lr = 0.001
I0420 14:52:45.362200 38983 solver.cpp:219] Iteration 19100 (4.32354 iter/s, 23.1292s/100 iters), loss = 0.280907
I0420 14:52:45.362332 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 14:52:45.362339 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:52:45.362345 38983 solver.cpp:238]     Train net output #2: loss = 0.280907 (* 1 = 0.280907 loss)
I0420 14:52:45.362350 38983 sgd_solver.cpp:105] Iteration 19100, lr = 0.001
I0420 14:53:08.382695 38983 solver.cpp:219] Iteration 19200 (4.34437 iter/s, 23.0183s/100 iters), loss = 0.243057
I0420 14:53:08.382756 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 14:53:08.382761 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:53:08.382768 38983 solver.cpp:238]     Train net output #2: loss = 0.243057 (* 1 = 0.243057 loss)
I0420 14:53:08.382772 38983 sgd_solver.cpp:105] Iteration 19200, lr = 0.001
I0420 14:53:31.392130 38983 solver.cpp:219] Iteration 19300 (4.34647 iter/s, 23.0072s/100 iters), loss = 0.33591
I0420 14:53:31.392330 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 14:53:31.392338 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:53:31.392344 38983 solver.cpp:238]     Train net output #2: loss = 0.33591 (* 1 = 0.33591 loss)
I0420 14:53:31.392349 38983 sgd_solver.cpp:105] Iteration 19300, lr = 0.001
I0420 14:53:47.599220 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:53:54.518992 38983 solver.cpp:219] Iteration 19400 (4.3244 iter/s, 23.1246s/100 iters), loss = 0.349036
I0420 14:53:54.519050 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 14:53:54.519055 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:53:54.519062 38983 solver.cpp:238]     Train net output #2: loss = 0.349036 (* 1 = 0.349036 loss)
I0420 14:53:54.519067 38983 sgd_solver.cpp:105] Iteration 19400, lr = 0.001
I0420 14:54:17.607517 38983 solver.cpp:219] Iteration 19500 (4.33117 iter/s, 23.0884s/100 iters), loss = 0.365528
I0420 14:54:17.607702 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 14:54:17.607709 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:54:17.607717 38983 solver.cpp:238]     Train net output #2: loss = 0.365528 (* 1 = 0.365528 loss)
I0420 14:54:17.607722 38983 sgd_solver.cpp:105] Iteration 19500, lr = 0.001
I0420 14:54:40.620170 38983 solver.cpp:219] Iteration 19600 (4.34585 iter/s, 23.0105s/100 iters), loss = 0.183322
I0420 14:54:40.620229 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 14:54:40.620234 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:54:40.620240 38983 solver.cpp:238]     Train net output #2: loss = 0.183322 (* 1 = 0.183322 loss)
I0420 14:54:40.620244 38983 sgd_solver.cpp:105] Iteration 19600, lr = 0.001
I0420 14:55:03.692983 38983 solver.cpp:219] Iteration 19700 (4.33452 iter/s, 23.0706s/100 iters), loss = 0.402438
I0420 14:55:03.693197 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 14:55:03.693204 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:55:03.693212 38983 solver.cpp:238]     Train net output #2: loss = 0.402437 (* 1 = 0.402437 loss)
I0420 14:55:03.693217 38983 sgd_solver.cpp:105] Iteration 19700, lr = 0.001
I0420 14:55:17.824753 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:55:26.791405 38983 solver.cpp:219] Iteration 19800 (4.32933 iter/s, 23.0983s/100 iters), loss = 0.221748
I0420 14:55:26.791460 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 14:55:26.791467 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:55:26.791473 38983 solver.cpp:238]     Train net output #2: loss = 0.221748 (* 1 = 0.221748 loss)
I0420 14:55:26.791478 38983 sgd_solver.cpp:105] Iteration 19800, lr = 0.001
I0420 14:55:49.815726 38983 solver.cpp:219] Iteration 19900 (4.34368 iter/s, 23.0219s/100 iters), loss = 0.271919
I0420 14:55:49.815907 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 14:55:49.815915 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:55:49.815922 38983 solver.cpp:238]     Train net output #2: loss = 0.271919 (* 1 = 0.271919 loss)
I0420 14:55:49.815927 38983 sgd_solver.cpp:105] Iteration 19900, lr = 0.001
I0420 14:56:12.733173 38983 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_finetune_quant_0.09_iter_20000.caffemodel
I0420 14:56:12.758898 38983 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_finetune_quant_0.09_iter_20000.solverstate
I0420 14:56:12.776095 38983 solver.cpp:331] Iteration 20000, Testing net (#0)
I0420 14:56:17.667063 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:56:17.904602 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8615
I0420 14:56:17.904629 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9938
I0420 14:56:17.904654 38983 solver.cpp:398]     Test net output #2: loss = 0.44222 (* 1 = 0.44222 loss)
I0420 14:56:18.048444 38983 solver.cpp:219] Iteration 20000 (3.54227 iter/s, 28.2305s/100 iters), loss = 0.28926
I0420 14:56:18.048463 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:56:18.048485 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:56:18.048491 38983 solver.cpp:238]     Train net output #2: loss = 0.28926 (* 1 = 0.28926 loss)
I0420 14:56:18.048496 38983 sgd_solver.cpp:105] Iteration 20000, lr = 0.001
I0420 14:56:41.200229 38983 solver.cpp:219] Iteration 20100 (4.31935 iter/s, 23.1516s/100 iters), loss = 0.436908
I0420 14:56:41.200354 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 14:56:41.200361 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:56:41.200367 38983 solver.cpp:238]     Train net output #2: loss = 0.436908 (* 1 = 0.436908 loss)
I0420 14:56:41.200372 38983 sgd_solver.cpp:105] Iteration 20100, lr = 0.001
I0420 14:56:53.177922 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:57:04.206457 38983 solver.cpp:219] Iteration 20200 (4.34707 iter/s, 23.004s/100 iters), loss = 0.335886
I0420 14:57:04.206502 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 14:57:04.206524 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:57:04.206532 38983 solver.cpp:238]     Train net output #2: loss = 0.335886 (* 1 = 0.335886 loss)
I0420 14:57:04.206537 38983 sgd_solver.cpp:105] Iteration 20200, lr = 0.001
I0420 14:57:27.241128 38983 solver.cpp:219] Iteration 20300 (4.34169 iter/s, 23.0325s/100 iters), loss = 0.275828
I0420 14:57:27.241293 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:57:27.241300 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:57:27.241307 38983 solver.cpp:238]     Train net output #2: loss = 0.275828 (* 1 = 0.275828 loss)
I0420 14:57:27.241312 38983 sgd_solver.cpp:105] Iteration 20300, lr = 0.001
I0420 14:57:50.329499 38983 solver.cpp:219] Iteration 20400 (4.33148 iter/s, 23.0868s/100 iters), loss = 0.170814
I0420 14:57:50.329556 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 14:57:50.329561 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:57:50.329567 38983 solver.cpp:238]     Train net output #2: loss = 0.170814 (* 1 = 0.170814 loss)
I0420 14:57:50.329572 38983 sgd_solver.cpp:105] Iteration 20400, lr = 0.001
I0420 14:58:13.201750 38983 solver.cpp:219] Iteration 20500 (4.37253 iter/s, 22.8701s/100 iters), loss = 0.273016
I0420 14:58:13.201975 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 14:58:13.201982 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:58:13.201989 38983 solver.cpp:238]     Train net output #2: loss = 0.273016 (* 1 = 0.273016 loss)
I0420 14:58:13.201993 38983 sgd_solver.cpp:105] Iteration 20500, lr = 0.001
I0420 14:58:22.918128 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 14:58:36.221021 38983 solver.cpp:219] Iteration 20600 (4.34462 iter/s, 23.0169s/100 iters), loss = 0.38378
I0420 14:58:36.221077 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 14:58:36.221082 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 14:58:36.221089 38983 solver.cpp:238]     Train net output #2: loss = 0.38378 (* 1 = 0.38378 loss)
I0420 14:58:36.221093 38983 sgd_solver.cpp:105] Iteration 20600, lr = 0.001
I0420 14:58:59.114737 38983 solver.cpp:219] Iteration 20700 (4.36843 iter/s, 22.8915s/100 iters), loss = 0.266381
I0420 14:58:59.114879 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 14:58:59.114886 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:58:59.114892 38983 solver.cpp:238]     Train net output #2: loss = 0.266381 (* 1 = 0.266381 loss)
I0420 14:58:59.114897 38983 sgd_solver.cpp:105] Iteration 20700, lr = 0.001
I0420 14:59:22.111187 38983 solver.cpp:219] Iteration 20800 (4.34892 iter/s, 22.9942s/100 iters), loss = 0.33753
I0420 14:59:22.111243 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 14:59:22.111248 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:59:22.111254 38983 solver.cpp:238]     Train net output #2: loss = 0.33753 (* 1 = 0.33753 loss)
I0420 14:59:22.111258 38983 sgd_solver.cpp:105] Iteration 20800, lr = 0.001
I0420 14:59:45.756742 38983 solver.cpp:219] Iteration 20900 (4.22952 iter/s, 23.6433s/100 iters), loss = 0.435704
I0420 14:59:45.756932 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 14:59:45.756937 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 14:59:45.756944 38983 solver.cpp:238]     Train net output #2: loss = 0.435704 (* 1 = 0.435704 loss)
I0420 14:59:45.756948 38983 sgd_solver.cpp:105] Iteration 20900, lr = 0.001
I0420 14:59:53.889675 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:00:09.068794 38983 solver.cpp:331] Iteration 21000, Testing net (#0)
I0420 15:00:13.940294 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:00:14.110622 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8606
I0420 15:00:14.110648 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9937
I0420 15:00:14.110672 38983 solver.cpp:398]     Test net output #2: loss = 0.445882 (* 1 = 0.445882 loss)
I0420 15:00:14.330039 38983 solver.cpp:219] Iteration 21000 (3.50004 iter/s, 28.5711s/100 iters), loss = 0.310782
I0420 15:00:14.330059 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 15:00:14.330080 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:00:14.330085 38983 solver.cpp:238]     Train net output #2: loss = 0.310782 (* 1 = 0.310782 loss)
I0420 15:00:14.330090 38983 sgd_solver.cpp:105] Iteration 21000, lr = 0.001
I0420 15:00:37.251751 38983 solver.cpp:219] Iteration 21100 (4.3631 iter/s, 22.9195s/100 iters), loss = 0.29178
I0420 15:00:37.251937 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 15:00:37.251945 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:00:37.251951 38983 solver.cpp:238]     Train net output #2: loss = 0.29178 (* 1 = 0.29178 loss)
I0420 15:00:37.251955 38983 sgd_solver.cpp:105] Iteration 21100, lr = 0.001
I0420 15:01:00.226676 38983 solver.cpp:219] Iteration 21200 (4.35261 iter/s, 22.9747s/100 iters), loss = 0.307806
I0420 15:01:00.226729 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:01:00.226734 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:01:00.226742 38983 solver.cpp:238]     Train net output #2: loss = 0.307806 (* 1 = 0.307806 loss)
I0420 15:01:00.226745 38983 sgd_solver.cpp:105] Iteration 21200, lr = 0.001
I0420 15:01:23.181849 38983 solver.cpp:219] Iteration 21300 (4.35673 iter/s, 22.953s/100 iters), loss = 0.408928
I0420 15:01:23.182075 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 15:01:23.182081 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:01:23.182088 38983 solver.cpp:238]     Train net output #2: loss = 0.408928 (* 1 = 0.408928 loss)
I0420 15:01:23.182092 38983 sgd_solver.cpp:105] Iteration 21300, lr = 0.001
I0420 15:01:28.711961 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:01:46.132320 38983 solver.cpp:219] Iteration 21400 (4.35726 iter/s, 22.9502s/100 iters), loss = 0.312828
I0420 15:01:46.132388 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 15:01:46.132395 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:01:46.132403 38983 solver.cpp:238]     Train net output #2: loss = 0.312827 (* 1 = 0.312827 loss)
I0420 15:01:46.132410 38983 sgd_solver.cpp:105] Iteration 21400, lr = 0.001
I0420 15:02:09.101609 38983 solver.cpp:219] Iteration 21500 (4.35406 iter/s, 22.9671s/100 iters), loss = 0.303816
I0420 15:02:09.101788 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:02:09.101796 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:02:09.101804 38983 solver.cpp:238]     Train net output #2: loss = 0.303816 (* 1 = 0.303816 loss)
I0420 15:02:09.101809 38983 sgd_solver.cpp:105] Iteration 21500, lr = 0.001
I0420 15:02:32.184985 38983 solver.cpp:219] Iteration 21600 (4.33214 iter/s, 23.0833s/100 iters), loss = 0.208432
I0420 15:02:32.185048 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 15:02:32.185055 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:02:32.185061 38983 solver.cpp:238]     Train net output #2: loss = 0.208432 (* 1 = 0.208432 loss)
I0420 15:02:32.185065 38983 sgd_solver.cpp:105] Iteration 21600, lr = 0.001
I0420 15:02:55.213667 38983 solver.cpp:219] Iteration 21700 (4.34285 iter/s, 23.0264s/100 iters), loss = 0.296981
I0420 15:02:55.213760 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 15:02:55.213766 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:02:55.213773 38983 solver.cpp:238]     Train net output #2: loss = 0.29698 (* 1 = 0.29698 loss)
I0420 15:02:55.213778 38983 sgd_solver.cpp:105] Iteration 21700, lr = 0.001
I0420 15:02:58.510666 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:03:18.254148 38983 solver.cpp:219] Iteration 21800 (4.34061 iter/s, 23.0382s/100 iters), loss = 0.419446
I0420 15:03:18.254212 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 15:03:18.254218 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:03:18.254225 38983 solver.cpp:238]     Train net output #2: loss = 0.419446 (* 1 = 0.419446 loss)
I0420 15:03:18.254230 38983 sgd_solver.cpp:105] Iteration 21800, lr = 0.001
I0420 15:03:41.345278 38983 solver.cpp:219] Iteration 21900 (4.33069 iter/s, 23.091s/100 iters), loss = 0.225878
I0420 15:03:41.345463 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 15:03:41.345469 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:03:41.345475 38983 solver.cpp:238]     Train net output #2: loss = 0.225878 (* 1 = 0.225878 loss)
I0420 15:03:41.345482 38983 sgd_solver.cpp:105] Iteration 21900, lr = 0.001
I0420 15:04:04.118679 38983 solver.cpp:331] Iteration 22000, Testing net (#0)
I0420 15:04:08.901011 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:04:09.103000 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.862
I0420 15:04:09.103027 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 15:04:09.103051 38983 solver.cpp:398]     Test net output #2: loss = 0.448449 (* 1 = 0.448449 loss)
I0420 15:04:09.333441 38983 solver.cpp:219] Iteration 22000 (3.57322 iter/s, 27.986s/100 iters), loss = 0.259354
I0420 15:04:09.333463 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 15:04:09.333484 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:04:09.333492 38983 solver.cpp:238]     Train net output #2: loss = 0.259354 (* 1 = 0.259354 loss)
I0420 15:04:09.333497 38983 sgd_solver.cpp:105] Iteration 22000, lr = 0.001
I0420 15:04:32.220818 38983 solver.cpp:219] Iteration 22100 (4.36965 iter/s, 22.8851s/100 iters), loss = 0.262423
I0420 15:04:32.221052 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:04:32.221061 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:04:32.221068 38983 solver.cpp:238]     Train net output #2: loss = 0.262423 (* 1 = 0.262423 loss)
I0420 15:04:32.221072 38983 sgd_solver.cpp:105] Iteration 22100, lr = 0.001
I0420 15:04:33.417572 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:04:55.206120 38983 solver.cpp:219] Iteration 22200 (4.35105 iter/s, 22.983s/100 iters), loss = 0.333076
I0420 15:04:55.206176 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:04:55.206182 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:04:55.206187 38983 solver.cpp:238]     Train net output #2: loss = 0.333076 (* 1 = 0.333076 loss)
I0420 15:04:55.206192 38983 sgd_solver.cpp:105] Iteration 22200, lr = 0.001
I0420 15:05:18.113770 38983 solver.cpp:219] Iteration 22300 (4.36578 iter/s, 22.9054s/100 iters), loss = 0.338177
I0420 15:05:18.113930 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 15:05:18.113937 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:05:18.113943 38983 solver.cpp:238]     Train net output #2: loss = 0.338177 (* 1 = 0.338177 loss)
I0420 15:05:18.113950 38983 sgd_solver.cpp:105] Iteration 22300, lr = 0.001
I0420 15:05:41.092635 38983 solver.cpp:219] Iteration 22400 (4.35184 iter/s, 22.9788s/100 iters), loss = 0.217006
I0420 15:05:41.092694 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 15:05:41.092700 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:05:41.092706 38983 solver.cpp:238]     Train net output #2: loss = 0.217005 (* 1 = 0.217005 loss)
I0420 15:05:41.092710 38983 sgd_solver.cpp:105] Iteration 22400, lr = 0.001
I0420 15:06:02.913926 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:06:04.021306 38983 solver.cpp:219] Iteration 22500 (4.36176 iter/s, 22.9265s/100 iters), loss = 0.237456
I0420 15:06:04.021356 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:06:04.021361 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:06:04.021368 38983 solver.cpp:238]     Train net output #2: loss = 0.237456 (* 1 = 0.237456 loss)
I0420 15:06:04.021371 38983 sgd_solver.cpp:105] Iteration 22500, lr = 0.001
I0420 15:06:26.968577 38983 solver.cpp:219] Iteration 22600 (4.35785 iter/s, 22.9471s/100 iters), loss = 0.249573
I0420 15:06:26.968636 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 15:06:26.968642 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:06:26.968648 38983 solver.cpp:238]     Train net output #2: loss = 0.249573 (* 1 = 0.249573 loss)
I0420 15:06:26.968652 38983 sgd_solver.cpp:105] Iteration 22600, lr = 0.001
I0420 15:06:49.919447 38983 solver.cpp:219] Iteration 22700 (4.35755 iter/s, 22.9487s/100 iters), loss = 0.361005
I0420 15:06:49.919533 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 15:06:49.919540 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:06:49.919546 38983 solver.cpp:238]     Train net output #2: loss = 0.361004 (* 1 = 0.361004 loss)
I0420 15:06:49.919551 38983 sgd_solver.cpp:105] Iteration 22700, lr = 0.001
I0420 15:07:12.859580 38983 solver.cpp:219] Iteration 22800 (4.35919 iter/s, 22.94s/100 iters), loss = 0.407525
I0420 15:07:12.859637 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 15:07:12.859642 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:07:12.859648 38983 solver.cpp:238]     Train net output #2: loss = 0.407525 (* 1 = 0.407525 loss)
I0420 15:07:12.859652 38983 sgd_solver.cpp:105] Iteration 22800, lr = 0.001
I0420 15:07:32.656666 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:07:35.842861 38983 solver.cpp:219] Iteration 22900 (4.3514 iter/s, 22.9811s/100 iters), loss = 0.254061
I0420 15:07:35.842914 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:07:35.842919 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:07:35.842926 38983 solver.cpp:238]     Train net output #2: loss = 0.254061 (* 1 = 0.254061 loss)
I0420 15:07:35.842931 38983 sgd_solver.cpp:105] Iteration 22900, lr = 0.001
I0420 15:07:58.538522 38983 solver.cpp:331] Iteration 23000, Testing net (#0)
I0420 15:08:03.419440 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:08:03.661584 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8617
I0420 15:08:03.661607 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 15:08:03.661633 38983 solver.cpp:398]     Test net output #2: loss = 0.447419 (* 1 = 0.447419 loss)
I0420 15:08:03.828994 38983 solver.cpp:219] Iteration 23000 (3.57322 iter/s, 27.986s/100 iters), loss = 0.317371
I0420 15:08:03.829015 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:08:03.829036 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:08:03.829042 38983 solver.cpp:238]     Train net output #2: loss = 0.317371 (* 1 = 0.317371 loss)
I0420 15:08:03.829048 38983 sgd_solver.cpp:105] Iteration 23000, lr = 0.001
I0420 15:08:26.807519 38983 solver.cpp:219] Iteration 23100 (4.35189 iter/s, 22.9785s/100 iters), loss = 0.381379
I0420 15:08:26.807557 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 15:08:26.807579 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:08:26.807586 38983 solver.cpp:238]     Train net output #2: loss = 0.381379 (* 1 = 0.381379 loss)
I0420 15:08:26.807590 38983 sgd_solver.cpp:105] Iteration 23100, lr = 0.001
I0420 15:08:49.729187 38983 solver.cpp:219] Iteration 23200 (4.3631 iter/s, 22.9195s/100 iters), loss = 0.236877
I0420 15:08:49.729310 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:08:49.729317 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:08:49.729323 38983 solver.cpp:238]     Train net output #2: loss = 0.236877 (* 1 = 0.236877 loss)
I0420 15:08:49.729327 38983 sgd_solver.cpp:105] Iteration 23200, lr = 0.001
I0420 15:09:07.483762 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:09:12.681957 38983 solver.cpp:219] Iteration 23300 (4.35678 iter/s, 22.9527s/100 iters), loss = 0.27231
I0420 15:09:12.682013 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:09:12.682019 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:09:12.682025 38983 solver.cpp:238]     Train net output #2: loss = 0.27231 (* 1 = 0.27231 loss)
I0420 15:09:12.682029 38983 sgd_solver.cpp:105] Iteration 23300, lr = 0.001
I0420 15:09:35.641150 38983 solver.cpp:219] Iteration 23400 (4.35599 iter/s, 22.9569s/100 iters), loss = 0.320499
I0420 15:09:35.641329 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:09:35.641335 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:09:35.641341 38983 solver.cpp:238]     Train net output #2: loss = 0.320499 (* 1 = 0.320499 loss)
I0420 15:09:35.641346 38983 sgd_solver.cpp:105] Iteration 23400, lr = 0.001
I0420 15:09:59.832348 38983 solver.cpp:219] Iteration 23500 (4.13377 iter/s, 24.191s/100 iters), loss = 0.258772
I0420 15:09:59.832404 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:09:59.832409 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:09:59.832415 38983 solver.cpp:238]     Train net output #2: loss = 0.258772 (* 1 = 0.258772 loss)
I0420 15:09:59.832419 38983 sgd_solver.cpp:105] Iteration 23500, lr = 0.001
I0420 15:10:22.725265 38983 solver.cpp:219] Iteration 23600 (4.3686 iter/s, 22.8906s/100 iters), loss = 0.311422
I0420 15:10:22.725458 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:10:22.725467 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:10:22.725473 38983 solver.cpp:238]     Train net output #2: loss = 0.311422 (* 1 = 0.311422 loss)
I0420 15:10:22.725478 38983 sgd_solver.cpp:105] Iteration 23600, lr = 0.001
I0420 15:10:38.155299 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:10:45.735288 38983 solver.cpp:219] Iteration 23700 (4.34637 iter/s, 23.0077s/100 iters), loss = 0.395963
I0420 15:10:45.735344 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:10:45.735349 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 15:10:45.735355 38983 solver.cpp:238]     Train net output #2: loss = 0.395963 (* 1 = 0.395963 loss)
I0420 15:10:45.735359 38983 sgd_solver.cpp:105] Iteration 23700, lr = 0.001
I0420 15:11:08.625349 38983 solver.cpp:219] Iteration 23800 (4.36912 iter/s, 22.8879s/100 iters), loss = 0.300862
I0420 15:11:08.625557 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:11:08.625564 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:11:08.625571 38983 solver.cpp:238]     Train net output #2: loss = 0.300862 (* 1 = 0.300862 loss)
I0420 15:11:08.625576 38983 sgd_solver.cpp:105] Iteration 23800, lr = 0.001
I0420 15:11:31.629915 38983 solver.cpp:219] Iteration 23900 (4.34728 iter/s, 23.0029s/100 iters), loss = 0.236255
I0420 15:11:31.629967 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:11:31.629972 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:11:31.629978 38983 solver.cpp:238]     Train net output #2: loss = 0.236255 (* 1 = 0.236255 loss)
I0420 15:11:31.629982 38983 sgd_solver.cpp:105] Iteration 23900, lr = 0.001
I0420 15:11:54.425521 38983 solver.cpp:331] Iteration 24000, Testing net (#0)
I0420 15:11:59.220191 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:11:59.426112 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8617
I0420 15:11:59.426138 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 15:11:59.426163 38983 solver.cpp:398]     Test net output #2: loss = 0.445818 (* 1 = 0.445818 loss)
I0420 15:11:59.656198 38983 solver.cpp:219] Iteration 24000 (3.56836 iter/s, 28.0241s/100 iters), loss = 0.321825
I0420 15:11:59.656219 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:11:59.656240 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:11:59.656245 38983 solver.cpp:238]     Train net output #2: loss = 0.321825 (* 1 = 0.321825 loss)
I0420 15:11:59.656250 38983 sgd_solver.cpp:46] MultiStep Status: Iteration 24000, step = 2
I0420 15:11:59.656255 38983 sgd_solver.cpp:105] Iteration 24000, lr = 0.0001
I0420 15:12:12.951154 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:12:22.554076 38983 solver.cpp:219] Iteration 24100 (4.36767 iter/s, 22.8955s/100 iters), loss = 0.250286
I0420 15:12:22.554132 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 15:12:22.554138 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:12:22.554144 38983 solver.cpp:238]     Train net output #2: loss = 0.250286 (* 1 = 0.250286 loss)
I0420 15:12:22.554148 38983 sgd_solver.cpp:105] Iteration 24100, lr = 0.0001
I0420 15:12:45.555827 38983 solver.cpp:219] Iteration 24200 (4.34791 iter/s, 22.9996s/100 iters), loss = 0.340834
I0420 15:12:45.556046 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:12:45.556053 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:12:45.556061 38983 solver.cpp:238]     Train net output #2: loss = 0.340834 (* 1 = 0.340834 loss)
I0420 15:12:45.556064 38983 sgd_solver.cpp:105] Iteration 24200, lr = 0.0001
I0420 15:13:08.450140 38983 solver.cpp:219] Iteration 24300 (4.36833 iter/s, 22.8921s/100 iters), loss = 0.282897
I0420 15:13:08.450194 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:13:08.450199 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:13:08.450206 38983 solver.cpp:238]     Train net output #2: loss = 0.282897 (* 1 = 0.282897 loss)
I0420 15:13:08.450209 38983 sgd_solver.cpp:105] Iteration 24300, lr = 0.0001
I0420 15:13:31.458293 38983 solver.cpp:219] Iteration 24400 (4.34673 iter/s, 23.0058s/100 iters), loss = 0.320879
I0420 15:13:31.458473 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:13:31.458480 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:13:31.458487 38983 solver.cpp:238]     Train net output #2: loss = 0.320879 (* 1 = 0.320879 loss)
I0420 15:13:31.458492 38983 sgd_solver.cpp:105] Iteration 24400, lr = 0.0001
I0420 15:13:42.737640 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:13:54.352692 38983 solver.cpp:219] Iteration 24500 (4.36831 iter/s, 22.8922s/100 iters), loss = 0.444895
I0420 15:13:54.352749 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 15:13:54.352754 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:13:54.352761 38983 solver.cpp:238]     Train net output #2: loss = 0.444894 (* 1 = 0.444894 loss)
I0420 15:13:54.352766 38983 sgd_solver.cpp:105] Iteration 24500, lr = 0.0001
I0420 15:14:17.442679 38983 solver.cpp:219] Iteration 24600 (4.33131 iter/s, 23.0877s/100 iters), loss = 0.244013
I0420 15:14:17.442808 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:14:17.442817 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:14:17.442823 38983 solver.cpp:238]     Train net output #2: loss = 0.244013 (* 1 = 0.244013 loss)
I0420 15:14:17.442828 38983 sgd_solver.cpp:105] Iteration 24600, lr = 0.0001
I0420 15:14:40.446277 38983 solver.cpp:219] Iteration 24700 (4.34747 iter/s, 23.0019s/100 iters), loss = 0.210925
I0420 15:14:40.446328 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 15:14:40.446333 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:14:40.446341 38983 solver.cpp:238]     Train net output #2: loss = 0.210925 (* 1 = 0.210925 loss)
I0420 15:14:40.446344 38983 sgd_solver.cpp:105] Iteration 24700, lr = 0.0001
I0420 15:15:03.362351 38983 solver.cpp:219] Iteration 24800 (4.36416 iter/s, 22.9139s/100 iters), loss = 0.342556
I0420 15:15:03.362519 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:15:03.362525 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:15:03.362531 38983 solver.cpp:238]     Train net output #2: loss = 0.342556 (* 1 = 0.342556 loss)
I0420 15:15:03.362536 38983 sgd_solver.cpp:105] Iteration 24800, lr = 0.0001
I0420 15:15:12.343152 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:15:26.325206 38983 solver.cpp:219] Iteration 24900 (4.3549 iter/s, 22.9626s/100 iters), loss = 0.19547
I0420 15:15:26.325263 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 15:15:26.325268 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:15:26.325274 38983 solver.cpp:238]     Train net output #2: loss = 0.19547 (* 1 = 0.19547 loss)
I0420 15:15:26.325278 38983 sgd_solver.cpp:105] Iteration 24900, lr = 0.0001
I0420 15:15:49.105763 38983 solver.cpp:331] Iteration 25000, Testing net (#0)
I0420 15:15:53.949698 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:15:54.126179 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8642
I0420 15:15:54.126206 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 15:15:54.126230 38983 solver.cpp:398]     Test net output #2: loss = 0.443143 (* 1 = 0.443143 loss)
I0420 15:15:54.344949 38983 solver.cpp:219] Iteration 25000 (3.56919 iter/s, 28.0175s/100 iters), loss = 0.416575
I0420 15:15:54.344970 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 15:15:54.344991 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:15:54.344997 38983 solver.cpp:238]     Train net output #2: loss = 0.416575 (* 1 = 0.416575 loss)
I0420 15:15:54.345003 38983 sgd_solver.cpp:105] Iteration 25000, lr = 0.0001
I0420 15:16:17.250229 38983 solver.cpp:219] Iteration 25100 (4.36622 iter/s, 22.9031s/100 iters), loss = 0.287447
I0420 15:16:17.250285 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 15:16:17.250291 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:16:17.250298 38983 solver.cpp:238]     Train net output #2: loss = 0.287447 (* 1 = 0.287447 loss)
I0420 15:16:17.250301 38983 sgd_solver.cpp:105] Iteration 25100, lr = 0.0001
I0420 15:16:40.247500 38983 solver.cpp:219] Iteration 25200 (4.34836 iter/s, 22.9972s/100 iters), loss = 0.288763
I0420 15:16:40.247769 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:16:40.247776 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:16:40.247783 38983 solver.cpp:238]     Train net output #2: loss = 0.288763 (* 1 = 0.288763 loss)
I0420 15:16:40.247788 38983 sgd_solver.cpp:105] Iteration 25200, lr = 0.0001
I0420 15:16:47.136451 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:17:03.154047 38983 solver.cpp:219] Iteration 25300 (4.366 iter/s, 22.9043s/100 iters), loss = 0.260831
I0420 15:17:03.154100 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 15:17:03.154105 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:17:03.154111 38983 solver.cpp:238]     Train net output #2: loss = 0.260831 (* 1 = 0.260831 loss)
I0420 15:17:03.154115 38983 sgd_solver.cpp:105] Iteration 25300, lr = 0.0001
I0420 15:17:26.181077 38983 solver.cpp:219] Iteration 25400 (4.34316 iter/s, 23.0247s/100 iters), loss = 0.325124
I0420 15:17:26.181262 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:17:26.181269 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:17:26.181275 38983 solver.cpp:238]     Train net output #2: loss = 0.325124 (* 1 = 0.325124 loss)
I0420 15:17:26.181280 38983 sgd_solver.cpp:105] Iteration 25400, lr = 0.0001
I0420 15:17:49.084939 38983 solver.cpp:219] Iteration 25500 (4.36651 iter/s, 22.9016s/100 iters), loss = 0.263014
I0420 15:17:49.084995 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:17:49.085000 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:17:49.085006 38983 solver.cpp:238]     Train net output #2: loss = 0.263013 (* 1 = 0.263013 loss)
I0420 15:17:49.085011 38983 sgd_solver.cpp:105] Iteration 25500, lr = 0.0001
I0420 15:18:12.095536 38983 solver.cpp:219] Iteration 25600 (4.34625 iter/s, 23.0084s/100 iters), loss = 0.314154
I0420 15:18:12.095811 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:18:12.095818 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:18:12.095825 38983 solver.cpp:238]     Train net output #2: loss = 0.314154 (* 1 = 0.314154 loss)
I0420 15:18:12.095829 38983 sgd_solver.cpp:105] Iteration 25600, lr = 0.0001
I0420 15:18:16.706637 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:18:34.998775 38983 solver.cpp:219] Iteration 25700 (4.36627 iter/s, 22.9028s/100 iters), loss = 0.258826
I0420 15:18:34.998827 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:18:34.998832 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:18:34.998838 38983 solver.cpp:238]     Train net output #2: loss = 0.258826 (* 1 = 0.258826 loss)
I0420 15:18:34.998843 38983 sgd_solver.cpp:105] Iteration 25700, lr = 0.0001
I0420 15:18:57.976788 38983 solver.cpp:219] Iteration 25800 (4.352 iter/s, 22.9779s/100 iters), loss = 0.364865
I0420 15:18:57.976912 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 15:18:57.976918 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:18:57.976925 38983 solver.cpp:238]     Train net output #2: loss = 0.364865 (* 1 = 0.364865 loss)
I0420 15:18:57.976929 38983 sgd_solver.cpp:105] Iteration 25800, lr = 0.0001
I0420 15:19:20.880064 38983 solver.cpp:219] Iteration 25900 (4.36621 iter/s, 22.9032s/100 iters), loss = 0.310095
I0420 15:19:20.880120 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:19:20.880127 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:19:20.880134 38983 solver.cpp:238]     Train net output #2: loss = 0.310095 (* 1 = 0.310095 loss)
I0420 15:19:20.880138 38983 sgd_solver.cpp:105] Iteration 25900, lr = 0.0001
I0420 15:19:43.672734 38983 solver.cpp:331] Iteration 26000, Testing net (#0)
I0420 15:19:48.517154 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:19:48.666020 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8645
I0420 15:19:48.666045 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9941
I0420 15:19:48.666069 38983 solver.cpp:398]     Test net output #2: loss = 0.44175 (* 1 = 0.44175 loss)
I0420 15:19:48.884451 38983 solver.cpp:219] Iteration 26000 (3.57115 iter/s, 28.0022s/100 iters), loss = 0.22651
I0420 15:19:48.884471 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 15:19:48.884492 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:19:48.884498 38983 solver.cpp:238]     Train net output #2: loss = 0.22651 (* 1 = 0.22651 loss)
I0420 15:19:48.884505 38983 sgd_solver.cpp:105] Iteration 26000, lr = 0.0001
I0420 15:19:51.485198 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:20:13.008666 38983 solver.cpp:219] Iteration 26100 (4.1456 iter/s, 24.122s/100 iters), loss = 0.292983
I0420 15:20:13.008721 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:20:13.008726 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:20:13.008733 38983 solver.cpp:238]     Train net output #2: loss = 0.292983 (* 1 = 0.292983 loss)
I0420 15:20:13.008738 38983 sgd_solver.cpp:105] Iteration 26100, lr = 0.0001
I0420 15:20:36.028158 38983 solver.cpp:219] Iteration 26200 (4.34456 iter/s, 23.0173s/100 iters), loss = 0.211915
I0420 15:20:36.028362 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 15:20:36.028368 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:20:36.028374 38983 solver.cpp:238]     Train net output #2: loss = 0.211915 (* 1 = 0.211915 loss)
I0420 15:20:36.028379 38983 sgd_solver.cpp:105] Iteration 26200, lr = 0.0001
I0420 15:20:58.940140 38983 solver.cpp:219] Iteration 26300 (4.36494 iter/s, 22.9098s/100 iters), loss = 0.320805
I0420 15:20:58.940197 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:20:58.940204 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:20:58.940210 38983 solver.cpp:238]     Train net output #2: loss = 0.320805 (* 1 = 0.320805 loss)
I0420 15:20:58.940215 38983 sgd_solver.cpp:105] Iteration 26300, lr = 0.0001
I0420 15:21:21.928400 38983 solver.cpp:219] Iteration 26400 (4.35046 iter/s, 22.9861s/100 iters), loss = 0.19386
I0420 15:21:21.928540 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 15:21:21.928547 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:21:21.928555 38983 solver.cpp:238]     Train net output #2: loss = 0.19386 (* 1 = 0.19386 loss)
I0420 15:21:21.928558 38983 sgd_solver.cpp:105] Iteration 26400, lr = 0.0001
I0420 15:21:22.447362 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:21:44.852915 38983 solver.cpp:219] Iteration 26500 (4.36218 iter/s, 22.9243s/100 iters), loss = 0.29583
I0420 15:21:44.852946 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:21:44.852968 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:21:44.852975 38983 solver.cpp:238]     Train net output #2: loss = 0.295829 (* 1 = 0.295829 loss)
I0420 15:21:44.852979 38983 sgd_solver.cpp:105] Iteration 26500, lr = 0.0001
I0420 15:22:07.826241 38983 solver.cpp:219] Iteration 26600 (4.35329 iter/s, 22.9711s/100 iters), loss = 0.295061
I0420 15:22:07.826432 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 15:22:07.826441 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:22:07.826447 38983 solver.cpp:238]     Train net output #2: loss = 0.295061 (* 1 = 0.295061 loss)
I0420 15:22:07.826452 38983 sgd_solver.cpp:105] Iteration 26600, lr = 0.0001
I0420 15:22:30.753356 38983 solver.cpp:219] Iteration 26700 (4.36171 iter/s, 22.9268s/100 iters), loss = 0.317143
I0420 15:22:30.753412 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:22:30.753417 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:22:30.753423 38983 solver.cpp:238]     Train net output #2: loss = 0.317143 (* 1 = 0.317143 loss)
I0420 15:22:30.753427 38983 sgd_solver.cpp:105] Iteration 26700, lr = 0.0001
I0420 15:22:51.926956 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:22:53.736064 38983 solver.cpp:219] Iteration 26800 (4.35153 iter/s, 22.9804s/100 iters), loss = 0.267723
I0420 15:22:53.736116 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:22:53.736121 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:22:53.736127 38983 solver.cpp:238]     Train net output #2: loss = 0.267723 (* 1 = 0.267723 loss)
I0420 15:22:53.736131 38983 sgd_solver.cpp:105] Iteration 26800, lr = 0.0001
I0420 15:23:16.630933 38983 solver.cpp:219] Iteration 26900 (4.36781 iter/s, 22.8948s/100 iters), loss = 0.28895
I0420 15:23:16.630985 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 15:23:16.630990 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:23:16.630996 38983 solver.cpp:238]     Train net output #2: loss = 0.28895 (* 1 = 0.28895 loss)
I0420 15:23:16.631000 38983 sgd_solver.cpp:105] Iteration 26900, lr = 0.0001
I0420 15:23:39.417177 38983 solver.cpp:331] Iteration 27000, Testing net (#0)
I0420 15:23:44.303479 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:23:44.424952 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8648
I0420 15:23:44.424978 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 15:23:44.425001 38983 solver.cpp:398]     Test net output #2: loss = 0.441497 (* 1 = 0.441497 loss)
I0420 15:23:44.650480 38983 solver.cpp:219] Iteration 27000 (3.56895 iter/s, 28.0194s/100 iters), loss = 0.20017
I0420 15:23:44.650532 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 15:23:44.650537 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:23:44.650545 38983 solver.cpp:238]     Train net output #2: loss = 0.20017 (* 1 = 0.20017 loss)
I0420 15:23:44.650552 38983 sgd_solver.cpp:105] Iteration 27000, lr = 0.0001
I0420 15:24:07.618610 38983 solver.cpp:219] Iteration 27100 (4.35427 iter/s, 22.9659s/100 iters), loss = 0.262547
I0420 15:24:07.618666 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:24:07.618672 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:24:07.618679 38983 solver.cpp:238]     Train net output #2: loss = 0.262547 (* 1 = 0.262547 loss)
I0420 15:24:07.618685 38983 sgd_solver.cpp:105] Iteration 27100, lr = 0.0001
I0420 15:24:26.683034 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:24:30.515766 38983 solver.cpp:219] Iteration 27200 (4.36739 iter/s, 22.897s/100 iters), loss = 0.327243
I0420 15:24:30.515820 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 15:24:30.515825 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:24:30.515831 38983 solver.cpp:238]     Train net output #2: loss = 0.327243 (* 1 = 0.327243 loss)
I0420 15:24:30.515836 38983 sgd_solver.cpp:105] Iteration 27200, lr = 0.0001
I0420 15:24:53.524636 38983 solver.cpp:219] Iteration 27300 (4.34657 iter/s, 23.0066s/100 iters), loss = 0.330115
I0420 15:24:53.524694 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 15:24:53.524700 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:24:53.524724 38983 solver.cpp:238]     Train net output #2: loss = 0.330114 (* 1 = 0.330114 loss)
I0420 15:24:53.524727 38983 sgd_solver.cpp:105] Iteration 27300, lr = 0.0001
I0420 15:25:16.415880 38983 solver.cpp:219] Iteration 27400 (4.3685 iter/s, 22.8911s/100 iters), loss = 0.316548
I0420 15:25:16.416040 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:25:16.416048 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:25:16.416071 38983 solver.cpp:238]     Train net output #2: loss = 0.316548 (* 1 = 0.316548 loss)
I0420 15:25:16.416075 38983 sgd_solver.cpp:105] Iteration 27400, lr = 0.0001
I0420 15:25:39.419344 38983 solver.cpp:219] Iteration 27500 (4.34723 iter/s, 23.0032s/100 iters), loss = 0.233854
I0420 15:25:39.419400 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 15:25:39.419405 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:25:39.419411 38983 solver.cpp:238]     Train net output #2: loss = 0.233854 (* 1 = 0.233854 loss)
I0420 15:25:39.419415 38983 sgd_solver.cpp:105] Iteration 27500, lr = 0.0001
I0420 15:25:56.376443 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:26:02.298390 38983 solver.cpp:219] Iteration 27600 (4.37124 iter/s, 22.8768s/100 iters), loss = 0.250325
I0420 15:26:02.298444 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 15:26:02.298449 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:26:02.298455 38983 solver.cpp:238]     Train net output #2: loss = 0.250325 (* 1 = 0.250325 loss)
I0420 15:26:02.298460 38983 sgd_solver.cpp:105] Iteration 27600, lr = 0.0001
I0420 15:26:25.304666 38983 solver.cpp:219] Iteration 27700 (4.34706 iter/s, 23.004s/100 iters), loss = 0.297361
I0420 15:26:25.304719 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 15:26:25.304724 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:26:25.304731 38983 solver.cpp:238]     Train net output #2: loss = 0.29736 (* 1 = 0.29736 loss)
I0420 15:26:25.304736 38983 sgd_solver.cpp:105] Iteration 27700, lr = 0.0001
I0420 15:26:48.195443 38983 solver.cpp:219] Iteration 27800 (4.36899 iter/s, 22.8886s/100 iters), loss = 0.31049
I0420 15:26:48.195646 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 15:26:48.195652 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:26:48.195658 38983 solver.cpp:238]     Train net output #2: loss = 0.31049 (* 1 = 0.31049 loss)
I0420 15:26:48.195662 38983 sgd_solver.cpp:105] Iteration 27800, lr = 0.0001
I0420 15:27:11.188168 38983 solver.cpp:219] Iteration 27900 (4.34962 iter/s, 22.9905s/100 iters), loss = 0.267297
I0420 15:27:11.188223 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 15:27:11.188228 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:27:11.188235 38983 solver.cpp:238]     Train net output #2: loss = 0.267296 (* 1 = 0.267296 loss)
I0420 15:27:11.188240 38983 sgd_solver.cpp:105] Iteration 27900, lr = 0.0001
I0420 15:27:25.894865 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:27:33.930263 38983 solver.cpp:331] Iteration 28000, Testing net (#0)
I0420 15:27:38.759956 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:27:38.984884 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.864
I0420 15:27:38.984911 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 15:27:38.984935 38983 solver.cpp:398]     Test net output #2: loss = 0.44242 (* 1 = 0.44242 loss)
I0420 15:27:39.215858 38983 solver.cpp:219] Iteration 28000 (3.56817 iter/s, 28.0256s/100 iters), loss = 0.295244
I0420 15:27:39.215878 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:27:39.215899 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 15:27:39.215904 38983 solver.cpp:238]     Train net output #2: loss = 0.295244 (* 1 = 0.295244 loss)
I0420 15:27:39.215910 38983 sgd_solver.cpp:105] Iteration 28000, lr = 0.0001
I0420 15:28:02.107887 38983 solver.cpp:219] Iteration 28100 (4.36876 iter/s, 22.8898s/100 iters), loss = 0.343485
I0420 15:28:02.108134 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:28:02.108142 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:28:02.108150 38983 solver.cpp:238]     Train net output #2: loss = 0.343485 (* 1 = 0.343485 loss)
I0420 15:28:02.108153 38983 sgd_solver.cpp:105] Iteration 28100, lr = 0.0001
I0420 15:28:25.100695 38983 solver.cpp:219] Iteration 28200 (4.34965 iter/s, 22.9903s/100 iters), loss = 0.250537
I0420 15:28:25.100746 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:28:25.100751 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:28:25.100757 38983 solver.cpp:238]     Train net output #2: loss = 0.250537 (* 1 = 0.250537 loss)
I0420 15:28:25.100761 38983 sgd_solver.cpp:105] Iteration 28200, lr = 0.0001
I0420 15:28:47.964212 38983 solver.cpp:219] Iteration 28300 (4.37419 iter/s, 22.8614s/100 iters), loss = 0.278848
I0420 15:28:47.964426 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:28:47.964432 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:28:47.964438 38983 solver.cpp:238]     Train net output #2: loss = 0.278848 (* 1 = 0.278848 loss)
I0420 15:28:47.964442 38983 sgd_solver.cpp:105] Iteration 28300, lr = 0.0001
I0420 15:29:00.641137 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:29:10.958796 38983 solver.cpp:219] Iteration 28400 (4.34929 iter/s, 22.9923s/100 iters), loss = 0.337468
I0420 15:29:10.958849 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 15:29:10.958854 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 15:29:10.958861 38983 solver.cpp:238]     Train net output #2: loss = 0.337467 (* 1 = 0.337467 loss)
I0420 15:29:10.958865 38983 sgd_solver.cpp:105] Iteration 28400, lr = 0.0001
I0420 15:29:33.843266 38983 solver.cpp:219] Iteration 28500 (4.3702 iter/s, 22.8823s/100 iters), loss = 0.241988
I0420 15:29:33.843415 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 15:29:33.843421 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:29:33.843427 38983 solver.cpp:238]     Train net output #2: loss = 0.241988 (* 1 = 0.241988 loss)
I0420 15:29:33.843432 38983 sgd_solver.cpp:105] Iteration 28500, lr = 0.0001
I0420 15:29:56.870370 38983 solver.cpp:219] Iteration 28600 (4.34274 iter/s, 23.0269s/100 iters), loss = 0.336789
I0420 15:29:56.870427 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 15:29:56.870434 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:29:56.870440 38983 solver.cpp:238]     Train net output #2: loss = 0.336789 (* 1 = 0.336789 loss)
I0420 15:29:56.870445 38983 sgd_solver.cpp:105] Iteration 28600, lr = 0.0001
I0420 15:30:20.997370 38983 solver.cpp:219] Iteration 28700 (4.14511 iter/s, 24.1248s/100 iters), loss = 0.267361
I0420 15:30:20.997447 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 15:30:20.997453 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:30:20.997460 38983 solver.cpp:238]     Train net output #2: loss = 0.267361 (* 1 = 0.267361 loss)
I0420 15:30:20.997464 38983 sgd_solver.cpp:105] Iteration 28700, lr = 0.0001
I0420 15:30:31.418215 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:30:44.006315 38983 solver.cpp:219] Iteration 28800 (4.34658 iter/s, 23.0066s/100 iters), loss = 0.284222
I0420 15:30:44.006371 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:30:44.006376 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:30:44.006381 38983 solver.cpp:238]     Train net output #2: loss = 0.284222 (* 1 = 0.284222 loss)
I0420 15:30:44.006386 38983 sgd_solver.cpp:105] Iteration 28800, lr = 0.0001
I0420 15:31:06.888085 38983 solver.cpp:219] Iteration 28900 (4.37032 iter/s, 22.8816s/100 iters), loss = 0.225852
I0420 15:31:06.888319 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:31:06.888327 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:31:06.888334 38983 solver.cpp:238]     Train net output #2: loss = 0.225852 (* 1 = 0.225852 loss)
I0420 15:31:06.888339 38983 sgd_solver.cpp:105] Iteration 28900, lr = 0.0001
I0420 15:31:29.664814 38983 solver.cpp:331] Iteration 29000, Testing net (#0)
I0420 15:31:34.523026 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:31:34.708287 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8653
I0420 15:31:34.708313 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 15:31:34.708338 38983 solver.cpp:398]     Test net output #2: loss = 0.442194 (* 1 = 0.442194 loss)
I0420 15:31:34.867306 38983 solver.cpp:219] Iteration 29000 (3.57437 iter/s, 27.977s/100 iters), loss = 0.384084
I0420 15:31:34.867329 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0420 15:31:34.867352 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:31:34.867357 38983 solver.cpp:238]     Train net output #2: loss = 0.384084 (* 1 = 0.384084 loss)
I0420 15:31:34.867363 38983 sgd_solver.cpp:105] Iteration 29000, lr = 0.0001
I0420 15:31:57.866189 38983 solver.cpp:219] Iteration 29100 (4.34849 iter/s, 22.9965s/100 iters), loss = 0.420153
I0420 15:31:57.866381 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 15:31:57.866389 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:31:57.866394 38983 solver.cpp:238]     Train net output #2: loss = 0.420153 (* 1 = 0.420153 loss)
I0420 15:31:57.866405 38983 sgd_solver.cpp:105] Iteration 29100, lr = 0.0001
I0420 15:32:06.170267 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:32:20.763648 38983 solver.cpp:219] Iteration 29200 (4.36772 iter/s, 22.8952s/100 iters), loss = 0.191601
I0420 15:32:20.763708 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 15:32:20.763713 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:32:20.763720 38983 solver.cpp:238]     Train net output #2: loss = 0.191601 (* 1 = 0.191601 loss)
I0420 15:32:20.763725 38983 sgd_solver.cpp:105] Iteration 29200, lr = 0.0001
I0420 15:32:43.760776 38983 solver.cpp:219] Iteration 29300 (4.34884 iter/s, 22.9946s/100 iters), loss = 0.405406
I0420 15:32:43.760967 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 15:32:43.760973 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 15:32:43.760979 38983 solver.cpp:238]     Train net output #2: loss = 0.405406 (* 1 = 0.405406 loss)
I0420 15:32:43.760984 38983 sgd_solver.cpp:105] Iteration 29300, lr = 0.0001
I0420 15:33:06.679579 38983 solver.cpp:219] Iteration 29400 (4.36366 iter/s, 22.9165s/100 iters), loss = 0.396012
I0420 15:33:06.679636 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 15:33:06.679641 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:33:06.679647 38983 solver.cpp:238]     Train net output #2: loss = 0.396011 (* 1 = 0.396011 loss)
I0420 15:33:06.679651 38983 sgd_solver.cpp:105] Iteration 29400, lr = 0.0001
I0420 15:33:29.641850 38983 solver.cpp:219] Iteration 29500 (4.35499 iter/s, 22.9622s/100 iters), loss = 0.314494
I0420 15:33:29.641983 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 15:33:29.641989 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:33:29.641995 38983 solver.cpp:238]     Train net output #2: loss = 0.314494 (* 1 = 0.314494 loss)
I0420 15:33:29.641999 38983 sgd_solver.cpp:105] Iteration 29500, lr = 0.0001
I0420 15:33:35.871536 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:33:52.588907 38983 solver.cpp:219] Iteration 29600 (4.35827 iter/s, 22.9449s/100 iters), loss = 0.245752
I0420 15:33:52.588943 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:33:52.588964 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:33:52.588971 38983 solver.cpp:238]     Train net output #2: loss = 0.245752 (* 1 = 0.245752 loss)
I0420 15:33:52.588975 38983 sgd_solver.cpp:105] Iteration 29600, lr = 0.0001
I0420 15:34:15.520076 38983 solver.cpp:219] Iteration 29700 (4.36091 iter/s, 22.931s/100 iters), loss = 0.349094
I0420 15:34:15.520200 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:34:15.520206 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:34:15.520213 38983 solver.cpp:238]     Train net output #2: loss = 0.349094 (* 1 = 0.349094 loss)
I0420 15:34:15.520217 38983 sgd_solver.cpp:105] Iteration 29700, lr = 0.0001
I0420 15:34:38.515566 38983 solver.cpp:219] Iteration 29800 (4.34913 iter/s, 22.9931s/100 iters), loss = 0.277605
I0420 15:34:38.515621 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:34:38.515626 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:34:38.515632 38983 solver.cpp:238]     Train net output #2: loss = 0.277604 (* 1 = 0.277604 loss)
I0420 15:34:38.515636 38983 sgd_solver.cpp:105] Iteration 29800, lr = 0.0001
I0420 15:35:01.435564 38983 solver.cpp:219] Iteration 29900 (4.36302 iter/s, 22.9199s/100 iters), loss = 0.192522
I0420 15:35:01.435811 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 15:35:01.435817 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:35:01.435824 38983 solver.cpp:238]     Train net output #2: loss = 0.192522 (* 1 = 0.192522 loss)
I0420 15:35:01.435828 38983 sgd_solver.cpp:105] Iteration 29900, lr = 0.0001
I0420 15:35:05.374581 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:35:24.201210 38983 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_finetune_quant_0.09_iter_30000.caffemodel
I0420 15:35:24.224679 38983 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_finetune_quant_0.09_iter_30000.solverstate
I0420 15:35:24.240231 38983 solver.cpp:331] Iteration 30000, Testing net (#0)
I0420 15:35:29.089520 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:35:29.283056 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8646
I0420 15:35:29.283080 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 15:35:29.283105 38983 solver.cpp:398]     Test net output #2: loss = 0.442612 (* 1 = 0.442612 loss)
I0420 15:35:29.508693 38983 solver.cpp:219] Iteration 30000 (3.5624 iter/s, 28.071s/100 iters), loss = 0.30091
I0420 15:35:29.508713 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:35:29.508735 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:35:29.508740 38983 solver.cpp:238]     Train net output #2: loss = 0.30091 (* 1 = 0.30091 loss)
I0420 15:35:29.508746 38983 sgd_solver.cpp:105] Iteration 30000, lr = 0.0001
I0420 15:35:52.402532 38983 solver.cpp:219] Iteration 30100 (4.36843 iter/s, 22.8915s/100 iters), loss = 0.358868
I0420 15:35:52.402737 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 15:35:52.402745 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:35:52.402751 38983 solver.cpp:238]     Train net output #2: loss = 0.358868 (* 1 = 0.358868 loss)
I0420 15:35:52.402755 38983 sgd_solver.cpp:105] Iteration 30100, lr = 0.0001
I0420 15:36:15.390000 38983 solver.cpp:219] Iteration 30200 (4.35027 iter/s, 22.9871s/100 iters), loss = 0.217339
I0420 15:36:15.390056 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 15:36:15.390061 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:36:15.390067 38983 solver.cpp:238]     Train net output #2: loss = 0.217339 (* 1 = 0.217339 loss)
I0420 15:36:15.390072 38983 sgd_solver.cpp:105] Iteration 30200, lr = 0.0001
I0420 15:36:38.312847 38983 solver.cpp:219] Iteration 30300 (4.3629 iter/s, 22.9205s/100 iters), loss = 0.277649
I0420 15:36:38.313745 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:36:38.313751 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:36:38.313758 38983 solver.cpp:238]     Train net output #2: loss = 0.277649 (* 1 = 0.277649 loss)
I0420 15:36:38.313762 38983 sgd_solver.cpp:105] Iteration 30300, lr = 0.0001
I0420 15:36:40.199350 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:37:01.324383 38983 solver.cpp:219] Iteration 30400 (4.34581 iter/s, 23.0106s/100 iters), loss = 0.307052
I0420 15:37:01.324435 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:37:01.324440 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:37:01.324447 38983 solver.cpp:238]     Train net output #2: loss = 0.307052 (* 1 = 0.307052 loss)
I0420 15:37:01.324451 38983 sgd_solver.cpp:105] Iteration 30400, lr = 0.0001
I0420 15:37:24.238560 38983 solver.cpp:219] Iteration 30500 (4.36452 iter/s, 22.912s/100 iters), loss = 0.206693
I0420 15:37:24.238729 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 15:37:24.238736 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:37:24.238742 38983 solver.cpp:238]     Train net output #2: loss = 0.206693 (* 1 = 0.206693 loss)
I0420 15:37:24.238747 38983 sgd_solver.cpp:105] Iteration 30500, lr = 0.0001
I0420 15:37:47.210871 38983 solver.cpp:219] Iteration 30600 (4.3531 iter/s, 22.9721s/100 iters), loss = 0.274507
I0420 15:37:47.210927 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:37:47.210932 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:37:47.210938 38983 solver.cpp:238]     Train net output #2: loss = 0.274507 (* 1 = 0.274507 loss)
I0420 15:37:47.210942 38983 sgd_solver.cpp:105] Iteration 30600, lr = 0.0001
I0420 15:38:09.981910 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:38:10.151906 38983 solver.cpp:219] Iteration 30700 (4.35941 iter/s, 22.9389s/100 iters), loss = 0.486302
I0420 15:38:10.151934 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.804688
I0420 15:38:10.151955 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:38:10.151962 38983 solver.cpp:238]     Train net output #2: loss = 0.486302 (* 1 = 0.486302 loss)
I0420 15:38:10.151965 38983 sgd_solver.cpp:105] Iteration 30700, lr = 0.0001
I0420 15:38:33.095388 38983 solver.cpp:219] Iteration 30800 (4.35856 iter/s, 22.9434s/100 iters), loss = 0.411952
I0420 15:38:33.095443 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 15:38:33.095448 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:38:33.095454 38983 solver.cpp:238]     Train net output #2: loss = 0.411952 (* 1 = 0.411952 loss)
I0420 15:38:33.095458 38983 sgd_solver.cpp:105] Iteration 30800, lr = 0.0001
I0420 15:38:56.075531 38983 solver.cpp:219] Iteration 30900 (4.352 iter/s, 22.9779s/100 iters), loss = 0.394709
I0420 15:38:56.075788 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:38:56.075794 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 15:38:56.075800 38983 solver.cpp:238]     Train net output #2: loss = 0.394709 (* 1 = 0.394709 loss)
I0420 15:38:56.075805 38983 sgd_solver.cpp:105] Iteration 30900, lr = 0.0001
I0420 15:39:18.770689 38983 solver.cpp:331] Iteration 31000, Testing net (#0)
I0420 15:39:23.645982 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:39:23.877034 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8645
I0420 15:39:23.877060 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 15:39:23.877084 38983 solver.cpp:398]     Test net output #2: loss = 0.443315 (* 1 = 0.443315 loss)
I0420 15:39:24.059918 38983 solver.cpp:219] Iteration 31000 (3.57346 iter/s, 27.9841s/100 iters), loss = 0.420929
I0420 15:39:24.059938 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 15:39:24.059959 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:39:24.059965 38983 solver.cpp:238]     Train net output #2: loss = 0.420929 (* 1 = 0.420929 loss)
I0420 15:39:24.059972 38983 sgd_solver.cpp:105] Iteration 31000, lr = 0.0001
I0420 15:39:44.525959 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:39:47.021814 38983 solver.cpp:219] Iteration 31100 (4.35507 iter/s, 22.9618s/100 iters), loss = 0.310094
I0420 15:39:47.021869 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:39:47.021874 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:39:47.021880 38983 solver.cpp:238]     Train net output #2: loss = 0.310094 (* 1 = 0.310094 loss)
I0420 15:39:47.021884 38983 sgd_solver.cpp:105] Iteration 31100, lr = 0.0001
I0420 15:40:09.961598 38983 solver.cpp:219] Iteration 31200 (4.35965 iter/s, 22.9376s/100 iters), loss = 0.339835
I0420 15:40:09.961652 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 15:40:09.961657 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:40:09.961663 38983 solver.cpp:238]     Train net output #2: loss = 0.339835 (* 1 = 0.339835 loss)
I0420 15:40:09.961668 38983 sgd_solver.cpp:105] Iteration 31200, lr = 0.0001
I0420 15:40:34.159624 38983 solver.cpp:219] Iteration 31300 (4.13259 iter/s, 24.1979s/100 iters), loss = 0.264331
I0420 15:40:34.159837 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:40:34.159844 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:40:34.159852 38983 solver.cpp:238]     Train net output #2: loss = 0.26433 (* 1 = 0.26433 loss)
I0420 15:40:34.159855 38983 sgd_solver.cpp:105] Iteration 31300, lr = 0.0001
I0420 15:40:57.056740 38983 solver.cpp:219] Iteration 31400 (4.36777 iter/s, 22.895s/100 iters), loss = 0.245959
I0420 15:40:57.056792 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:40:57.056797 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:40:57.056803 38983 solver.cpp:238]     Train net output #2: loss = 0.245959 (* 1 = 0.245959 loss)
I0420 15:40:57.056807 38983 sgd_solver.cpp:105] Iteration 31400, lr = 0.0001
I0420 15:41:15.482434 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:41:20.072799 38983 solver.cpp:219] Iteration 31500 (4.34523 iter/s, 23.0137s/100 iters), loss = 0.272239
I0420 15:41:20.072851 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 15:41:20.072856 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0420 15:41:20.072862 38983 solver.cpp:238]     Train net output #2: loss = 0.272239 (* 1 = 0.272239 loss)
I0420 15:41:20.072866 38983 sgd_solver.cpp:105] Iteration 31500, lr = 0.0001
I0420 15:41:42.964102 38983 solver.cpp:219] Iteration 31600 (4.3689 iter/s, 22.889s/100 iters), loss = 0.371977
I0420 15:41:42.964155 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:41:42.964160 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:41:42.964167 38983 solver.cpp:238]     Train net output #2: loss = 0.371977 (* 1 = 0.371977 loss)
I0420 15:41:42.964171 38983 sgd_solver.cpp:105] Iteration 31600, lr = 0.0001
I0420 15:42:05.967113 38983 solver.cpp:219] Iteration 31700 (4.34761 iter/s, 23.0011s/100 iters), loss = 0.280478
I0420 15:42:05.967303 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 15:42:05.967308 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:42:05.967315 38983 solver.cpp:238]     Train net output #2: loss = 0.280478 (* 1 = 0.280478 loss)
I0420 15:42:05.967320 38983 sgd_solver.cpp:105] Iteration 31700, lr = 0.0001
I0420 15:42:28.878334 38983 solver.cpp:219] Iteration 31800 (4.36509 iter/s, 22.909s/100 iters), loss = 0.360406
I0420 15:42:28.878386 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 15:42:28.878391 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:42:28.878396 38983 solver.cpp:238]     Train net output #2: loss = 0.360405 (* 1 = 0.360405 loss)
I0420 15:42:28.878401 38983 sgd_solver.cpp:105] Iteration 31800, lr = 0.0001
I0420 15:42:44.985261 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:42:51.853265 38983 solver.cpp:219] Iteration 31900 (4.3526 iter/s, 22.9748s/100 iters), loss = 0.259583
I0420 15:42:51.853320 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 15:42:51.853325 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:42:51.853332 38983 solver.cpp:238]     Train net output #2: loss = 0.259582 (* 1 = 0.259582 loss)
I0420 15:42:51.853335 38983 sgd_solver.cpp:105] Iteration 31900, lr = 0.0001
I0420 15:43:14.639123 38983 solver.cpp:331] Iteration 32000, Testing net (#0)
I0420 15:43:19.478248 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:43:19.671543 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8648
I0420 15:43:19.671569 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 15:43:19.671593 38983 solver.cpp:398]     Test net output #2: loss = 0.443338 (* 1 = 0.443338 loss)
I0420 15:43:19.904223 38983 solver.cpp:219] Iteration 32000 (3.56524 iter/s, 28.0486s/100 iters), loss = 0.211889
I0420 15:43:19.904249 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 15:43:19.904270 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:43:19.904276 38983 solver.cpp:238]     Train net output #2: loss = 0.211888 (* 1 = 0.211888 loss)
I0420 15:43:19.904284 38983 sgd_solver.cpp:105] Iteration 32000, lr = 0.0001
I0420 15:43:42.812854 38983 solver.cpp:219] Iteration 32100 (4.3656 iter/s, 22.9063s/100 iters), loss = 0.174375
I0420 15:43:42.812893 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 15:43:42.812916 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:43:42.812922 38983 solver.cpp:238]     Train net output #2: loss = 0.174375 (* 1 = 0.174375 loss)
I0420 15:43:42.812927 38983 sgd_solver.cpp:105] Iteration 32100, lr = 0.0001
I0420 15:44:05.813758 38983 solver.cpp:219] Iteration 32200 (4.34807 iter/s, 22.9987s/100 iters), loss = 0.330197
I0420 15:44:05.813930 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 15:44:05.813936 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:44:05.813943 38983 solver.cpp:238]     Train net output #2: loss = 0.330197 (* 1 = 0.330197 loss)
I0420 15:44:05.813947 38983 sgd_solver.cpp:105] Iteration 32200, lr = 0.0001
I0420 15:44:19.792414 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:44:28.727082 38983 solver.cpp:219] Iteration 32300 (4.36469 iter/s, 22.9111s/100 iters), loss = 0.278919
I0420 15:44:28.727133 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:44:28.727138 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:44:28.727144 38983 solver.cpp:238]     Train net output #2: loss = 0.278919 (* 1 = 0.278919 loss)
I0420 15:44:28.727149 38983 sgd_solver.cpp:105] Iteration 32300, lr = 0.0001
I0420 15:44:51.704186 38983 solver.cpp:219] Iteration 32400 (4.35218 iter/s, 22.977s/100 iters), loss = 0.30065
I0420 15:44:51.704375 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:44:51.704381 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:44:51.704388 38983 solver.cpp:238]     Train net output #2: loss = 0.30065 (* 1 = 0.30065 loss)
I0420 15:44:51.704392 38983 sgd_solver.cpp:105] Iteration 32400, lr = 0.0001
I0420 15:45:14.662598 38983 solver.cpp:219] Iteration 32500 (4.35613 iter/s, 22.9562s/100 iters), loss = 0.244166
I0420 15:45:14.662653 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 15:45:14.662658 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:45:14.662665 38983 solver.cpp:238]     Train net output #2: loss = 0.244165 (* 1 = 0.244165 loss)
I0420 15:45:14.662669 38983 sgd_solver.cpp:105] Iteration 32500, lr = 0.0001
I0420 15:45:37.608387 38983 solver.cpp:219] Iteration 32600 (4.35812 iter/s, 22.9457s/100 iters), loss = 0.304223
I0420 15:45:37.608562 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 15:45:37.608568 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:45:37.608575 38983 solver.cpp:238]     Train net output #2: loss = 0.304223 (* 1 = 0.304223 loss)
I0420 15:45:37.608580 38983 sgd_solver.cpp:105] Iteration 32600, lr = 0.0001
I0420 15:45:49.586014 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:46:00.582635 38983 solver.cpp:219] Iteration 32700 (4.35311 iter/s, 22.9721s/100 iters), loss = 0.321166
I0420 15:46:00.582689 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:46:00.582711 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:46:00.582718 38983 solver.cpp:238]     Train net output #2: loss = 0.321166 (* 1 = 0.321166 loss)
I0420 15:46:00.582722 38983 sgd_solver.cpp:105] Iteration 32700, lr = 0.0001
I0420 15:46:23.485184 38983 solver.cpp:219] Iteration 32800 (4.36636 iter/s, 22.9024s/100 iters), loss = 0.350602
I0420 15:46:23.485308 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:46:23.485316 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:46:23.485322 38983 solver.cpp:238]     Train net output #2: loss = 0.350602 (* 1 = 0.350602 loss)
I0420 15:46:23.485327 38983 sgd_solver.cpp:105] Iteration 32800, lr = 0.0001
I0420 15:46:46.502578 38983 solver.cpp:219] Iteration 32900 (4.34497 iter/s, 23.0151s/100 iters), loss = 0.231796
I0420 15:46:46.502615 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:46:46.502637 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:46:46.502645 38983 solver.cpp:238]     Train net output #2: loss = 0.231796 (* 1 = 0.231796 loss)
I0420 15:46:46.502648 38983 sgd_solver.cpp:105] Iteration 32900, lr = 0.0001
I0420 15:47:09.217607 38983 solver.cpp:331] Iteration 33000, Testing net (#0)
I0420 15:47:14.061064 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:47:14.287508 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8645
I0420 15:47:14.287533 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 15:47:14.287557 38983 solver.cpp:398]     Test net output #2: loss = 0.442137 (* 1 = 0.442137 loss)
I0420 15:47:14.496879 38983 solver.cpp:219] Iteration 33000 (3.57243 iter/s, 27.9921s/100 iters), loss = 0.276487
I0420 15:47:14.496901 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:47:14.496922 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:47:14.496927 38983 solver.cpp:238]     Train net output #2: loss = 0.276487 (* 1 = 0.276487 loss)
I0420 15:47:14.496933 38983 sgd_solver.cpp:105] Iteration 33000, lr = 0.0001
I0420 15:47:24.113301 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:47:37.408051 38983 solver.cpp:219] Iteration 33100 (4.36471 iter/s, 22.9111s/100 iters), loss = 0.380421
I0420 15:47:37.408102 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:47:37.408107 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:47:37.408115 38983 solver.cpp:238]     Train net output #2: loss = 0.380421 (* 1 = 0.380421 loss)
I0420 15:47:37.408119 38983 sgd_solver.cpp:105] Iteration 33100, lr = 0.0001
I0420 15:48:00.413064 38983 solver.cpp:219] Iteration 33200 (4.3473 iter/s, 23.0028s/100 iters), loss = 0.206469
I0420 15:48:00.413256 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 15:48:00.413264 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:48:00.413270 38983 solver.cpp:238]     Train net output #2: loss = 0.206469 (* 1 = 0.206469 loss)
I0420 15:48:00.413275 38983 sgd_solver.cpp:105] Iteration 33200, lr = 0.0001
I0420 15:48:23.326122 38983 solver.cpp:219] Iteration 33300 (4.36438 iter/s, 22.9128s/100 iters), loss = 0.243572
I0420 15:48:23.326176 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 15:48:23.326181 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:48:23.326187 38983 solver.cpp:238]     Train net output #2: loss = 0.243572 (* 1 = 0.243572 loss)
I0420 15:48:23.326192 38983 sgd_solver.cpp:105] Iteration 33300, lr = 0.0001
I0420 15:48:46.327776 38983 solver.cpp:219] Iteration 33400 (4.34792 iter/s, 22.9995s/100 iters), loss = 0.314897
I0420 15:48:46.328025 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:48:46.328032 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:48:46.328039 38983 solver.cpp:238]     Train net output #2: loss = 0.314896 (* 1 = 0.314896 loss)
I0420 15:48:46.328043 38983 sgd_solver.cpp:105] Iteration 33400, lr = 0.0001
I0420 15:48:53.913025 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:49:09.219627 38983 solver.cpp:219] Iteration 33500 (4.36877 iter/s, 22.8897s/100 iters), loss = 0.29085
I0420 15:49:09.219678 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 15:49:09.219687 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:49:09.219693 38983 solver.cpp:238]     Train net output #2: loss = 0.290849 (* 1 = 0.290849 loss)
I0420 15:49:09.219697 38983 sgd_solver.cpp:105] Iteration 33500, lr = 0.0001
I0420 15:49:32.208480 38983 solver.cpp:219] Iteration 33600 (4.35036 iter/s, 22.9866s/100 iters), loss = 0.251036
I0420 15:49:32.208570 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 15:49:32.208575 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:49:32.208581 38983 solver.cpp:238]     Train net output #2: loss = 0.251036 (* 1 = 0.251036 loss)
I0420 15:49:32.208585 38983 sgd_solver.cpp:105] Iteration 33600, lr = 0.0001
I0420 15:49:55.109937 38983 solver.cpp:219] Iteration 33700 (4.36694 iter/s, 22.8993s/100 iters), loss = 0.403993
I0420 15:49:55.109994 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 15:49:55.109999 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:49:55.110007 38983 solver.cpp:238]     Train net output #2: loss = 0.403993 (* 1 = 0.403993 loss)
I0420 15:49:55.110011 38983 sgd_solver.cpp:105] Iteration 33700, lr = 0.0001
I0420 15:50:18.112012 38983 solver.cpp:219] Iteration 33800 (4.34787 iter/s, 22.9998s/100 iters), loss = 0.459938
I0420 15:50:18.112169 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 15:50:18.112176 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:50:18.112182 38983 solver.cpp:238]     Train net output #2: loss = 0.459938 (* 1 = 0.459938 loss)
I0420 15:50:18.112187 38983 sgd_solver.cpp:105] Iteration 33800, lr = 0.0001
I0420 15:50:23.871034 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:50:42.276772 38983 solver.cpp:219] Iteration 33900 (4.13863 iter/s, 24.1626s/100 iters), loss = 0.261055
I0420 15:50:42.276828 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:50:42.276834 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:50:42.276839 38983 solver.cpp:238]     Train net output #2: loss = 0.261055 (* 1 = 0.261055 loss)
I0420 15:50:42.276844 38983 sgd_solver.cpp:105] Iteration 33900, lr = 0.0001
I0420 15:51:05.045833 38983 solver.cpp:331] Iteration 34000, Testing net (#0)
I0420 15:51:09.938648 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:51:10.076730 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8644
I0420 15:51:10.076752 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9944
I0420 15:51:10.076776 38983 solver.cpp:398]     Test net output #2: loss = 0.442859 (* 1 = 0.442859 loss)
I0420 15:51:10.295223 38983 solver.cpp:219] Iteration 34000 (3.56935 iter/s, 28.0163s/100 iters), loss = 0.303966
I0420 15:51:10.295243 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:51:10.295264 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:51:10.295269 38983 solver.cpp:238]     Train net output #2: loss = 0.303965 (* 1 = 0.303965 loss)
I0420 15:51:10.295275 38983 sgd_solver.cpp:105] Iteration 34000, lr = 0.0001
I0420 15:51:33.236472 38983 solver.cpp:219] Iteration 34100 (4.35939 iter/s, 22.939s/100 iters), loss = 0.256598
I0420 15:51:33.236531 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:51:33.236537 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:51:33.236543 38983 solver.cpp:238]     Train net output #2: loss = 0.256598 (* 1 = 0.256598 loss)
I0420 15:51:33.236548 38983 sgd_solver.cpp:105] Iteration 34100, lr = 0.0001
I0420 15:51:56.184540 38983 solver.cpp:219] Iteration 34200 (4.35769 iter/s, 22.948s/100 iters), loss = 0.296071
I0420 15:51:56.184798 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:51:56.184806 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:51:56.184813 38983 solver.cpp:238]     Train net output #2: loss = 0.296071 (* 1 = 0.296071 loss)
I0420 15:51:56.184818 38983 sgd_solver.cpp:105] Iteration 34200, lr = 0.0001
I0420 15:51:59.462158 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:52:19.160390 38983 solver.cpp:219] Iteration 34300 (4.35282 iter/s, 22.9736s/100 iters), loss = 0.404773
I0420 15:52:19.160444 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 15:52:19.160449 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 15:52:19.160456 38983 solver.cpp:238]     Train net output #2: loss = 0.404773 (* 1 = 0.404773 loss)
I0420 15:52:19.160460 38983 sgd_solver.cpp:105] Iteration 34300, lr = 0.0001
I0420 15:52:42.082659 38983 solver.cpp:219] Iteration 34400 (4.36259 iter/s, 22.9222s/100 iters), loss = 0.143791
I0420 15:52:42.082825 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 15:52:42.082831 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:52:42.082839 38983 solver.cpp:238]     Train net output #2: loss = 0.143791 (* 1 = 0.143791 loss)
I0420 15:52:42.082842 38983 sgd_solver.cpp:105] Iteration 34400, lr = 0.0001
I0420 15:53:05.085439 38983 solver.cpp:219] Iteration 34500 (4.34772 iter/s, 23.0006s/100 iters), loss = 0.251784
I0420 15:53:05.085492 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:53:05.085497 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:53:05.085505 38983 solver.cpp:238]     Train net output #2: loss = 0.251784 (* 1 = 0.251784 loss)
I0420 15:53:05.085511 38983 sgd_solver.cpp:105] Iteration 34500, lr = 0.0001
I0420 15:53:27.972625 38983 solver.cpp:219] Iteration 34600 (4.36967 iter/s, 22.885s/100 iters), loss = 0.33717
I0420 15:53:27.972839 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 15:53:27.972846 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:53:27.972852 38983 solver.cpp:238]     Train net output #2: loss = 0.33717 (* 1 = 0.33717 loss)
I0420 15:53:27.972856 38983 sgd_solver.cpp:105] Iteration 34600, lr = 0.0001
I0420 15:53:29.164808 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:53:50.993302 38983 solver.cpp:219] Iteration 34700 (4.34435 iter/s, 23.0184s/100 iters), loss = 0.232041
I0420 15:53:50.993356 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 15:53:50.993361 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:53:50.993368 38983 solver.cpp:238]     Train net output #2: loss = 0.23204 (* 1 = 0.23204 loss)
I0420 15:53:50.993372 38983 sgd_solver.cpp:105] Iteration 34700, lr = 0.0001
I0420 15:54:13.870491 38983 solver.cpp:219] Iteration 34800 (4.37157 iter/s, 22.8751s/100 iters), loss = 0.349916
I0420 15:54:13.870638 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 15:54:13.870645 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:54:13.870652 38983 solver.cpp:238]     Train net output #2: loss = 0.349916 (* 1 = 0.349916 loss)
I0420 15:54:13.870656 38983 sgd_solver.cpp:105] Iteration 34800, lr = 0.0001
I0420 15:54:36.873258 38983 solver.cpp:219] Iteration 34900 (4.34775 iter/s, 23.0004s/100 iters), loss = 0.296763
I0420 15:54:36.873307 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 15:54:36.873312 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:54:36.873319 38983 solver.cpp:238]     Train net output #2: loss = 0.296763 (* 1 = 0.296763 loss)
I0420 15:54:36.873323 38983 sgd_solver.cpp:105] Iteration 34900, lr = 0.0001
I0420 15:54:58.683758 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:54:59.646374 38983 solver.cpp:331] Iteration 35000, Testing net (#0)
I0420 15:55:04.438436 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:55:04.671197 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8635
I0420 15:55:04.671223 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 15:55:04.671247 38983 solver.cpp:398]     Test net output #2: loss = 0.442161 (* 1 = 0.442161 loss)
I0420 15:55:04.901195 38983 solver.cpp:219] Iteration 35000 (3.56815 iter/s, 28.0257s/100 iters), loss = 0.20036
I0420 15:55:04.901214 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 15:55:04.901235 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:55:04.901242 38983 solver.cpp:238]     Train net output #2: loss = 0.20036 (* 1 = 0.20036 loss)
I0420 15:55:04.901247 38983 sgd_solver.cpp:105] Iteration 35000, lr = 0.0001
I0420 15:55:27.809876 38983 solver.cpp:219] Iteration 35100 (4.36559 iter/s, 22.9064s/100 iters), loss = 0.230117
I0420 15:55:27.809931 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 15:55:27.809937 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:55:27.809943 38983 solver.cpp:238]     Train net output #2: loss = 0.230117 (* 1 = 0.230117 loss)
I0420 15:55:27.809947 38983 sgd_solver.cpp:105] Iteration 35100, lr = 0.0001
I0420 15:55:50.819833 38983 solver.cpp:219] Iteration 35200 (4.34639 iter/s, 23.0076s/100 iters), loss = 0.372455
I0420 15:55:50.820001 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 15:55:50.820008 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:55:50.820014 38983 solver.cpp:238]     Train net output #2: loss = 0.372455 (* 1 = 0.372455 loss)
I0420 15:55:50.820019 38983 sgd_solver.cpp:105] Iteration 35200, lr = 0.0001
I0420 15:56:13.724781 38983 solver.cpp:219] Iteration 35300 (4.36627 iter/s, 22.9028s/100 iters), loss = 0.3074
I0420 15:56:13.724831 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:56:13.724836 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:56:13.724844 38983 solver.cpp:238]     Train net output #2: loss = 0.3074 (* 1 = 0.3074 loss)
I0420 15:56:13.724848 38983 sgd_solver.cpp:105] Iteration 35300, lr = 0.0001
I0420 15:56:33.528753 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:56:36.734514 38983 solver.cpp:219] Iteration 35400 (4.34641 iter/s, 23.0075s/100 iters), loss = 0.279022
I0420 15:56:36.734567 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:56:36.734572 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:56:36.734580 38983 solver.cpp:238]     Train net output #2: loss = 0.279022 (* 1 = 0.279022 loss)
I0420 15:56:36.734583 38983 sgd_solver.cpp:105] Iteration 35400, lr = 0.0001
I0420 15:56:59.598083 38983 solver.cpp:219] Iteration 35500 (4.3742 iter/s, 22.8613s/100 iters), loss = 0.273848
I0420 15:56:59.598120 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:56:59.598141 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:56:59.598148 38983 solver.cpp:238]     Train net output #2: loss = 0.273847 (* 1 = 0.273847 loss)
I0420 15:56:59.598152 38983 sgd_solver.cpp:105] Iteration 35500, lr = 0.0001
I0420 15:57:22.588407 38983 solver.cpp:219] Iteration 35600 (4.35009 iter/s, 22.988s/100 iters), loss = 0.518016
I0420 15:57:22.588490 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 15:57:22.588496 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:57:22.588503 38983 solver.cpp:238]     Train net output #2: loss = 0.518016 (* 1 = 0.518016 loss)
I0420 15:57:22.588507 38983 sgd_solver.cpp:105] Iteration 35600, lr = 0.0001
I0420 15:57:45.497071 38983 solver.cpp:219] Iteration 35700 (4.3656 iter/s, 22.9064s/100 iters), loss = 0.296186
I0420 15:57:45.497119 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:57:45.497124 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:57:45.497130 38983 solver.cpp:238]     Train net output #2: loss = 0.296186 (* 1 = 0.296186 loss)
I0420 15:57:45.497135 38983 sgd_solver.cpp:105] Iteration 35700, lr = 0.0001
I0420 15:58:03.249281 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:58:08.488329 38983 solver.cpp:219] Iteration 35800 (4.34992 iter/s, 22.9889s/100 iters), loss = 0.241255
I0420 15:58:08.488382 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 15:58:08.488389 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:58:08.488394 38983 solver.cpp:238]     Train net output #2: loss = 0.241255 (* 1 = 0.241255 loss)
I0420 15:58:08.488399 38983 sgd_solver.cpp:105] Iteration 35800, lr = 0.0001
I0420 15:58:31.379950 38983 solver.cpp:219] Iteration 35900 (4.36883 iter/s, 22.8894s/100 iters), loss = 0.365087
I0420 15:58:31.380004 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 15:58:31.380010 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:58:31.380017 38983 solver.cpp:238]     Train net output #2: loss = 0.365087 (* 1 = 0.365087 loss)
I0420 15:58:31.380020 38983 sgd_solver.cpp:105] Iteration 35900, lr = 0.0001
I0420 15:58:54.163306 38983 solver.cpp:331] Iteration 36000, Testing net (#0)
I0420 15:58:59.058061 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:58:59.254739 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8638
I0420 15:58:59.254765 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9944
I0420 15:58:59.254789 38983 solver.cpp:398]     Test net output #2: loss = 0.441583 (* 1 = 0.441583 loss)
I0420 15:58:59.403230 38983 solver.cpp:219] Iteration 36000 (3.56848 iter/s, 28.0232s/100 iters), loss = 0.196244
I0420 15:58:59.403250 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 15:58:59.403271 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:58:59.403276 38983 solver.cpp:238]     Train net output #2: loss = 0.196244 (* 1 = 0.196244 loss)
I0420 15:58:59.403282 38983 sgd_solver.cpp:105] Iteration 36000, lr = 0.0001
I0420 15:59:22.425977 38983 solver.cpp:219] Iteration 36100 (4.34396 iter/s, 23.0204s/100 iters), loss = 0.359951
I0420 15:59:22.426031 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 15:59:22.426036 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 15:59:22.426043 38983 solver.cpp:238]     Train net output #2: loss = 0.359951 (* 1 = 0.359951 loss)
I0420 15:59:22.426048 38983 sgd_solver.cpp:105] Iteration 36100, lr = 0.0001
I0420 15:59:37.808817 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 15:59:45.343247 38983 solver.cpp:219] Iteration 36200 (4.36395 iter/s, 22.915s/100 iters), loss = 0.353206
I0420 15:59:45.343297 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 15:59:45.343302 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 15:59:45.343308 38983 solver.cpp:238]     Train net output #2: loss = 0.353206 (* 1 = 0.353206 loss)
I0420 15:59:45.343312 38983 sgd_solver.cpp:105] Iteration 36200, lr = 0.0001
I0420 16:00:08.254945 38983 solver.cpp:219] Iteration 36300 (4.36461 iter/s, 22.9115s/100 iters), loss = 0.372577
I0420 16:00:08.255128 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 16:00:08.255136 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:00:08.255141 38983 solver.cpp:238]     Train net output #2: loss = 0.372577 (* 1 = 0.372577 loss)
I0420 16:00:08.255146 38983 sgd_solver.cpp:105] Iteration 36300, lr = 0.0001
I0420 16:00:31.137924 38983 solver.cpp:219] Iteration 36400 (4.37047 iter/s, 22.8808s/100 iters), loss = 0.333113
I0420 16:00:31.137980 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 16:00:31.137986 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:00:31.137995 38983 solver.cpp:238]     Train net output #2: loss = 0.333113 (* 1 = 0.333113 loss)
I0420 16:00:31.137998 38983 sgd_solver.cpp:105] Iteration 36400, lr = 0.0001
I0420 16:00:55.195322 38983 solver.cpp:219] Iteration 36500 (4.1571 iter/s, 24.0552s/100 iters), loss = 0.291687
I0420 16:00:55.195523 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:00:55.195530 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:00:55.195538 38983 solver.cpp:238]     Train net output #2: loss = 0.291687 (* 1 = 0.291687 loss)
I0420 16:00:55.195541 38983 sgd_solver.cpp:105] Iteration 36500, lr = 0.0001
I0420 16:01:08.560612 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:01:18.168076 38983 solver.cpp:219] Iteration 36600 (4.35343 iter/s, 22.9704s/100 iters), loss = 0.297042
I0420 16:01:18.168112 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:01:18.168133 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:01:18.168140 38983 solver.cpp:238]     Train net output #2: loss = 0.297042 (* 1 = 0.297042 loss)
I0420 16:01:18.168144 38983 sgd_solver.cpp:105] Iteration 36600, lr = 0.0001
I0420 16:01:41.027716 38983 solver.cpp:219] Iteration 36700 (4.37494 iter/s, 22.8574s/100 iters), loss = 0.329975
I0420 16:01:41.027894 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 16:01:41.027900 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:01:41.027907 38983 solver.cpp:238]     Train net output #2: loss = 0.329975 (* 1 = 0.329975 loss)
I0420 16:01:41.027912 38983 sgd_solver.cpp:105] Iteration 36700, lr = 0.0001
I0420 16:02:04.045210 38983 solver.cpp:219] Iteration 36800 (4.34496 iter/s, 23.0152s/100 iters), loss = 0.324253
I0420 16:02:04.045266 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:02:04.045272 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:02:04.045279 38983 solver.cpp:238]     Train net output #2: loss = 0.324253 (* 1 = 0.324253 loss)
I0420 16:02:04.045282 38983 sgd_solver.cpp:105] Iteration 36800, lr = 0.0001
I0420 16:02:26.937608 38983 solver.cpp:219] Iteration 36900 (4.36868 iter/s, 22.8902s/100 iters), loss = 0.311359
I0420 16:02:26.937803 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:02:26.937809 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:02:26.937816 38983 solver.cpp:238]     Train net output #2: loss = 0.311359 (* 1 = 0.311359 loss)
I0420 16:02:26.937820 38983 sgd_solver.cpp:105] Iteration 36900, lr = 0.0001
I0420 16:02:38.202983 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:02:49.692745 38983 solver.cpp:331] Iteration 37000, Testing net (#0)
I0420 16:02:54.587211 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:02:54.767930 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8633
I0420 16:02:54.767956 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 16:02:54.767980 38983 solver.cpp:398]     Test net output #2: loss = 0.44229 (* 1 = 0.44229 loss)
I0420 16:02:54.936753 38983 solver.cpp:219] Iteration 37000 (3.57184 iter/s, 27.9968s/100 iters), loss = 0.390212
I0420 16:02:54.936772 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 16:02:54.936794 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:02:54.936799 38983 solver.cpp:238]     Train net output #2: loss = 0.390212 (* 1 = 0.390212 loss)
I0420 16:02:54.936805 38983 sgd_solver.cpp:105] Iteration 37000, lr = 0.0001
I0420 16:03:17.943658 38983 solver.cpp:219] Iteration 37100 (4.34695 iter/s, 23.0046s/100 iters), loss = 0.242938
I0420 16:03:17.943867 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:03:17.943874 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:03:17.943881 38983 solver.cpp:238]     Train net output #2: loss = 0.242938 (* 1 = 0.242938 loss)
I0420 16:03:17.943884 38983 sgd_solver.cpp:105] Iteration 37100, lr = 0.0001
I0420 16:03:40.815582 38983 solver.cpp:219] Iteration 37200 (4.37261 iter/s, 22.8697s/100 iters), loss = 0.239226
I0420 16:03:40.815635 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 16:03:40.815640 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:03:40.815647 38983 solver.cpp:238]     Train net output #2: loss = 0.239226 (* 1 = 0.239226 loss)
I0420 16:03:40.815651 38983 sgd_solver.cpp:105] Iteration 37200, lr = 0.0001
I0420 16:04:03.791105 38983 solver.cpp:219] Iteration 37300 (4.35289 iter/s, 22.9733s/100 iters), loss = 0.338047
I0420 16:04:03.791316 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 16:04:03.791324 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 16:04:03.791330 38983 solver.cpp:238]     Train net output #2: loss = 0.338047 (* 1 = 0.338047 loss)
I0420 16:04:03.791335 38983 sgd_solver.cpp:105] Iteration 37300, lr = 0.0001
I0420 16:04:12.788067 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:04:26.700660 38983 solver.cpp:219] Iteration 37400 (4.3654 iter/s, 22.9074s/100 iters), loss = 0.318215
I0420 16:04:26.700700 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:04:26.700721 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:04:26.700729 38983 solver.cpp:238]     Train net output #2: loss = 0.318215 (* 1 = 0.318215 loss)
I0420 16:04:26.700733 38983 sgd_solver.cpp:105] Iteration 37400, lr = 0.0001
I0420 16:04:49.653571 38983 solver.cpp:219] Iteration 37500 (4.35677 iter/s, 22.9528s/100 iters), loss = 0.263859
I0420 16:04:49.653652 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:04:49.653658 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:04:49.653664 38983 solver.cpp:238]     Train net output #2: loss = 0.263858 (* 1 = 0.263858 loss)
I0420 16:04:49.653668 38983 sgd_solver.cpp:105] Iteration 37500, lr = 0.0001
I0420 16:05:12.628749 38983 solver.cpp:219] Iteration 37600 (4.35294 iter/s, 22.973s/100 iters), loss = 0.379248
I0420 16:05:12.628787 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 16:05:12.628808 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:05:12.628815 38983 solver.cpp:238]     Train net output #2: loss = 0.379248 (* 1 = 0.379248 loss)
I0420 16:05:12.628819 38983 sgd_solver.cpp:105] Iteration 37600, lr = 0.0001
I0420 16:05:35.547297 38983 solver.cpp:219] Iteration 37700 (4.3633 iter/s, 22.9184s/100 iters), loss = 0.382648
I0420 16:05:35.547441 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:05:35.547448 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:05:35.547454 38983 solver.cpp:238]     Train net output #2: loss = 0.382648 (* 1 = 0.382648 loss)
I0420 16:05:35.547459 38983 sgd_solver.cpp:105] Iteration 37700, lr = 0.0001
I0420 16:05:42.478977 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:05:58.546866 38983 solver.cpp:219] Iteration 37800 (4.34833 iter/s, 22.9973s/100 iters), loss = 0.268189
I0420 16:05:58.546919 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 16:05:58.546924 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:05:58.546931 38983 solver.cpp:238]     Train net output #2: loss = 0.268189 (* 1 = 0.268189 loss)
I0420 16:05:58.546936 38983 sgd_solver.cpp:105] Iteration 37800, lr = 0.0001
I0420 16:06:21.427904 38983 solver.cpp:219] Iteration 37900 (4.37085 iter/s, 22.8789s/100 iters), loss = 0.281123
I0420 16:06:21.428059 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:06:21.428066 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:06:21.428072 38983 solver.cpp:238]     Train net output #2: loss = 0.281123 (* 1 = 0.281123 loss)
I0420 16:06:21.428077 38983 sgd_solver.cpp:105] Iteration 37900, lr = 0.0001
I0420 16:06:44.198328 38983 solver.cpp:331] Iteration 38000, Testing net (#0)
I0420 16:06:49.103976 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:06:49.236578 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8633
I0420 16:06:49.236604 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 16:06:49.236629 38983 solver.cpp:398]     Test net output #2: loss = 0.442529 (* 1 = 0.442529 loss)
I0420 16:06:49.447440 38983 solver.cpp:219] Iteration 38000 (3.56923 iter/s, 28.0172s/100 iters), loss = 0.249111
I0420 16:06:49.447461 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:06:49.447482 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 16:06:49.447489 38983 solver.cpp:238]     Train net output #2: loss = 0.24911 (* 1 = 0.24911 loss)
I0420 16:06:49.447494 38983 sgd_solver.cpp:105] Iteration 38000, lr = 0.0001
I0420 16:07:12.440671 38983 solver.cpp:219] Iteration 38100 (4.34952 iter/s, 22.991s/100 iters), loss = 0.214533
I0420 16:07:12.440886 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 16:07:12.440893 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:07:12.440901 38983 solver.cpp:238]     Train net output #2: loss = 0.214533 (* 1 = 0.214533 loss)
I0420 16:07:12.440904 38983 sgd_solver.cpp:105] Iteration 38100, lr = 0.0001
I0420 16:07:17.046867 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:07:35.319595 38983 solver.cpp:219] Iteration 38200 (4.37125 iter/s, 22.8768s/100 iters), loss = 0.244447
I0420 16:07:35.319630 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:07:35.319653 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:07:35.319660 38983 solver.cpp:238]     Train net output #2: loss = 0.244447 (* 1 = 0.244447 loss)
I0420 16:07:35.319664 38983 sgd_solver.cpp:105] Iteration 38200, lr = 0.0001
I0420 16:07:58.321305 38983 solver.cpp:219] Iteration 38300 (4.34792 iter/s, 22.9995s/100 iters), loss = 0.34616
I0420 16:07:58.321498 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 16:07:58.321504 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:07:58.321511 38983 solver.cpp:238]     Train net output #2: loss = 0.34616 (* 1 = 0.34616 loss)
I0420 16:07:58.321516 38983 sgd_solver.cpp:105] Iteration 38300, lr = 0.0001
I0420 16:08:21.205420 38983 solver.cpp:219] Iteration 38400 (4.37026 iter/s, 22.8819s/100 iters), loss = 0.257576
I0420 16:08:21.205471 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:08:21.205476 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:08:21.205482 38983 solver.cpp:238]     Train net output #2: loss = 0.257576 (* 1 = 0.257576 loss)
I0420 16:08:21.205487 38983 sgd_solver.cpp:105] Iteration 38400, lr = 0.0001
I0420 16:08:44.219362 38983 solver.cpp:219] Iteration 38500 (4.34566 iter/s, 23.0115s/100 iters), loss = 0.211503
I0420 16:08:44.219442 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:08:44.219450 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:08:44.219456 38983 solver.cpp:238]     Train net output #2: loss = 0.211503 (* 1 = 0.211503 loss)
I0420 16:08:44.219460 38983 sgd_solver.cpp:105] Iteration 38500, lr = 0.0001
I0420 16:08:46.757426 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:09:07.104766 38983 solver.cpp:219] Iteration 38600 (4.37003 iter/s, 22.8831s/100 iters), loss = 0.268464
I0420 16:09:07.104822 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:09:07.104827 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:09:07.104833 38983 solver.cpp:238]     Train net output #2: loss = 0.268464 (* 1 = 0.268464 loss)
I0420 16:09:07.104837 38983 sgd_solver.cpp:105] Iteration 38600, lr = 0.0001
I0420 16:09:30.103368 38983 solver.cpp:219] Iteration 38700 (4.34851 iter/s, 22.9964s/100 iters), loss = 0.299786
I0420 16:09:30.103504 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 16:09:30.103512 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:09:30.103518 38983 solver.cpp:238]     Train net output #2: loss = 0.299786 (* 1 = 0.299786 loss)
I0420 16:09:30.103523 38983 sgd_solver.cpp:105] Iteration 38700, lr = 0.0001
I0420 16:09:53.025197 38983 solver.cpp:219] Iteration 38800 (4.36307 iter/s, 22.9196s/100 iters), loss = 0.385964
I0420 16:09:53.025248 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 16:09:53.025252 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:09:53.025259 38983 solver.cpp:238]     Train net output #2: loss = 0.385964 (* 1 = 0.385964 loss)
I0420 16:09:53.025264 38983 sgd_solver.cpp:105] Iteration 38800, lr = 0.0001
I0420 16:10:16.003280 38983 solver.cpp:219] Iteration 38900 (4.35199 iter/s, 22.978s/100 iters), loss = 0.178185
I0420 16:10:16.003474 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 16:10:16.003482 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:10:16.003489 38983 solver.cpp:238]     Train net output #2: loss = 0.178184 (* 1 = 0.178184 loss)
I0420 16:10:16.003494 38983 sgd_solver.cpp:105] Iteration 38900, lr = 0.0001
I0420 16:10:16.486073 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:10:38.771327 38983 solver.cpp:331] Iteration 39000, Testing net (#0)
I0420 16:10:44.100093 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:10:44.318163 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8647
I0420 16:10:44.318192 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 16:10:44.318215 38983 solver.cpp:398]     Test net output #2: loss = 0.442532 (* 1 = 0.442532 loss)
I0420 16:10:44.525462 38983 solver.cpp:219] Iteration 39000 (3.50631 iter/s, 28.52s/100 iters), loss = 0.259972
I0420 16:10:44.525482 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:10:44.525503 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:10:44.525508 38983 solver.cpp:238]     Train net output #2: loss = 0.259972 (* 1 = 0.259972 loss)
I0420 16:10:44.525516 38983 sgd_solver.cpp:105] Iteration 39000, lr = 0.0001
I0420 16:11:08.186110 38983 solver.cpp:219] Iteration 39100 (4.22684 iter/s, 23.6584s/100 iters), loss = 0.362873
I0420 16:11:08.186281 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 16:11:08.186288 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:11:08.186295 38983 solver.cpp:238]     Train net output #2: loss = 0.362873 (* 1 = 0.362873 loss)
I0420 16:11:08.186300 38983 sgd_solver.cpp:105] Iteration 39100, lr = 0.0001
I0420 16:11:31.192926 38983 solver.cpp:219] Iteration 39200 (4.34659 iter/s, 23.0065s/100 iters), loss = 0.365296
I0420 16:11:31.192981 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 16:11:31.192986 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:11:31.192992 38983 solver.cpp:238]     Train net output #2: loss = 0.365296 (* 1 = 0.365296 loss)
I0420 16:11:31.192996 38983 sgd_solver.cpp:105] Iteration 39200, lr = 0.0001
I0420 16:11:52.301931 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:11:54.097570 38983 solver.cpp:219] Iteration 39300 (4.36634 iter/s, 22.9025s/100 iters), loss = 0.326587
I0420 16:11:54.097622 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:11:54.097627 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:11:54.097635 38983 solver.cpp:238]     Train net output #2: loss = 0.326587 (* 1 = 0.326587 loss)
I0420 16:11:54.097638 38983 sgd_solver.cpp:105] Iteration 39300, lr = 0.0001
I0420 16:12:18.786243 38983 solver.cpp:219] Iteration 39400 (4.05082 iter/s, 24.6864s/100 iters), loss = 0.347625
I0420 16:12:18.786299 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:12:18.786305 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:12:18.786311 38983 solver.cpp:238]     Train net output #2: loss = 0.347625 (* 1 = 0.347625 loss)
I0420 16:12:18.786315 38983 sgd_solver.cpp:105] Iteration 39400, lr = 0.0001
I0420 16:12:41.713943 38983 solver.cpp:219] Iteration 39500 (4.36197 iter/s, 22.9254s/100 iters), loss = 0.18973
I0420 16:12:41.714195 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 16:12:41.714203 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:12:41.714210 38983 solver.cpp:238]     Train net output #2: loss = 0.18973 (* 1 = 0.18973 loss)
I0420 16:12:41.714215 38983 sgd_solver.cpp:105] Iteration 39500, lr = 0.0001
I0420 16:13:04.683359 38983 solver.cpp:219] Iteration 39600 (4.35369 iter/s, 22.969s/100 iters), loss = 0.240876
I0420 16:13:04.683411 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:13:04.683418 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:13:04.683423 38983 solver.cpp:238]     Train net output #2: loss = 0.240876 (* 1 = 0.240876 loss)
I0420 16:13:04.683429 38983 sgd_solver.cpp:105] Iteration 39600, lr = 0.0001
I0420 16:13:23.760145 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:13:27.619809 38983 solver.cpp:219] Iteration 39700 (4.36029 iter/s, 22.9343s/100 iters), loss = 0.288711
I0420 16:13:27.619843 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:13:27.619864 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:13:27.619870 38983 solver.cpp:238]     Train net output #2: loss = 0.288711 (* 1 = 0.288711 loss)
I0420 16:13:27.619875 38983 sgd_solver.cpp:105] Iteration 39700, lr = 0.0001
I0420 16:13:50.558255 38983 solver.cpp:219] Iteration 39800 (4.35951 iter/s, 22.9383s/100 iters), loss = 0.280924
I0420 16:13:50.558310 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:13:50.558316 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:13:50.558322 38983 solver.cpp:238]     Train net output #2: loss = 0.280924 (* 1 = 0.280924 loss)
I0420 16:13:50.558326 38983 sgd_solver.cpp:105] Iteration 39800, lr = 0.0001
I0420 16:14:13.541481 38983 solver.cpp:219] Iteration 39900 (4.35142 iter/s, 22.981s/100 iters), loss = 0.30674
I0420 16:14:13.541630 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:14:13.541636 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:14:13.541642 38983 solver.cpp:238]     Train net output #2: loss = 0.30674 (* 1 = 0.30674 loss)
I0420 16:14:13.541648 38983 sgd_solver.cpp:105] Iteration 39900, lr = 0.0001
I0420 16:14:36.254334 38983 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_finetune_quant_0.09_iter_40000.caffemodel
I0420 16:14:36.283535 38983 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_finetune_quant_0.09_iter_40000.solverstate
I0420 16:14:36.318289 38983 solver.cpp:331] Iteration 40000, Testing net (#0)
I0420 16:14:41.191354 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:14:41.427080 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8638
I0420 16:14:41.427106 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9945
I0420 16:14:41.427130 38983 solver.cpp:398]     Test net output #2: loss = 0.441921 (* 1 = 0.441921 loss)
I0420 16:14:41.540776 38983 solver.cpp:219] Iteration 40000 (3.57156 iter/s, 27.999s/100 iters), loss = 0.258805
I0420 16:14:41.540796 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:14:41.540817 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:14:41.540823 38983 solver.cpp:238]     Train net output #2: loss = 0.258805 (* 1 = 0.258805 loss)
I0420 16:14:41.540829 38983 sgd_solver.cpp:105] Iteration 40000, lr = 0.0001
I0420 16:14:58.614140 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:15:04.532075 38983 solver.cpp:219] Iteration 40100 (4.34951 iter/s, 22.9911s/100 iters), loss = 0.265774
I0420 16:15:04.532127 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:15:04.532132 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:15:04.532140 38983 solver.cpp:238]     Train net output #2: loss = 0.265774 (* 1 = 0.265774 loss)
I0420 16:15:04.532145 38983 sgd_solver.cpp:105] Iteration 40100, lr = 0.0001
I0420 16:15:27.454848 38983 solver.cpp:219] Iteration 40200 (4.36289 iter/s, 22.9206s/100 iters), loss = 0.467075
I0420 16:15:27.454897 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 16:15:27.454902 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0420 16:15:27.454910 38983 solver.cpp:238]     Train net output #2: loss = 0.467075 (* 1 = 0.467075 loss)
I0420 16:15:27.454913 38983 sgd_solver.cpp:105] Iteration 40200, lr = 0.0001
I0420 16:15:50.480782 38983 solver.cpp:219] Iteration 40300 (4.34296 iter/s, 23.0258s/100 iters), loss = 0.33039
I0420 16:15:50.481014 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 16:15:50.481021 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:15:50.481027 38983 solver.cpp:238]     Train net output #2: loss = 0.330389 (* 1 = 0.330389 loss)
I0420 16:15:50.481032 38983 sgd_solver.cpp:105] Iteration 40300, lr = 0.0001
I0420 16:16:13.372426 38983 solver.cpp:219] Iteration 40400 (4.36884 iter/s, 22.8894s/100 iters), loss = 0.274653
I0420 16:16:13.372483 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 16:16:13.372488 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:16:13.372494 38983 solver.cpp:238]     Train net output #2: loss = 0.274653 (* 1 = 0.274653 loss)
I0420 16:16:13.372499 38983 sgd_solver.cpp:105] Iteration 40400, lr = 0.0001
I0420 16:16:28.169307 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:16:36.369205 38983 solver.cpp:219] Iteration 40500 (4.34878 iter/s, 22.995s/100 iters), loss = 0.37332
I0420 16:16:36.369261 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 16:16:36.369266 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:16:36.369273 38983 solver.cpp:238]     Train net output #2: loss = 0.37332 (* 1 = 0.37332 loss)
I0420 16:16:36.369277 38983 sgd_solver.cpp:105] Iteration 40500, lr = 0.0001
I0420 16:16:59.272150 38983 solver.cpp:219] Iteration 40600 (4.36668 iter/s, 22.9007s/100 iters), loss = 0.264344
I0420 16:16:59.272225 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:16:59.272231 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:16:59.272238 38983 solver.cpp:238]     Train net output #2: loss = 0.264343 (* 1 = 0.264343 loss)
I0420 16:16:59.272241 38983 sgd_solver.cpp:105] Iteration 40600, lr = 0.0001
I0420 16:17:22.284831 38983 solver.cpp:219] Iteration 40700 (4.3455 iter/s, 23.0123s/100 iters), loss = 0.285973
I0420 16:17:22.284885 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:17:22.284890 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:17:22.284898 38983 solver.cpp:238]     Train net output #2: loss = 0.285973 (* 1 = 0.285973 loss)
I0420 16:17:22.284901 38983 sgd_solver.cpp:105] Iteration 40700, lr = 0.0001
I0420 16:17:45.206450 38983 solver.cpp:219] Iteration 40800 (4.36311 iter/s, 22.9194s/100 iters), loss = 0.253538
I0420 16:17:45.206640 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:17:45.206646 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:17:45.206652 38983 solver.cpp:238]     Train net output #2: loss = 0.253537 (* 1 = 0.253537 loss)
I0420 16:17:45.206657 38983 sgd_solver.cpp:105] Iteration 40800, lr = 0.0001
I0420 16:17:57.880806 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:18:08.178825 38983 solver.cpp:219] Iteration 40900 (4.35308 iter/s, 22.9722s/100 iters), loss = 0.417597
I0420 16:18:08.178880 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 16:18:08.178885 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0420 16:18:08.178891 38983 solver.cpp:238]     Train net output #2: loss = 0.417597 (* 1 = 0.417597 loss)
I0420 16:18:08.178896 38983 sgd_solver.cpp:105] Iteration 40900, lr = 0.0001
I0420 16:18:30.941213 38983 solver.cpp:331] Iteration 41000, Testing net (#0)
I0420 16:18:35.785686 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:18:35.955550 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8639
I0420 16:18:35.955574 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9944
I0420 16:18:35.955596 38983 solver.cpp:398]     Test net output #2: loss = 0.442728 (* 1 = 0.442728 loss)
I0420 16:18:36.174139 38983 solver.cpp:219] Iteration 41000 (3.57232 iter/s, 27.993s/100 iters), loss = 0.26705
I0420 16:18:36.174160 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:18:36.174181 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:18:36.174186 38983 solver.cpp:238]     Train net output #2: loss = 0.26705 (* 1 = 0.26705 loss)
I0420 16:18:36.174192 38983 sgd_solver.cpp:105] Iteration 41000, lr = 0.0001
I0420 16:18:59.087944 38983 solver.cpp:219] Iteration 41100 (4.3646 iter/s, 22.9116s/100 iters), loss = 0.315918
I0420 16:18:59.088009 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:18:59.088014 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:18:59.088021 38983 solver.cpp:238]     Train net output #2: loss = 0.315918 (* 1 = 0.315918 loss)
I0420 16:18:59.088026 38983 sgd_solver.cpp:105] Iteration 41100, lr = 0.0001
I0420 16:19:22.060803 38983 solver.cpp:219] Iteration 41200 (4.35298 iter/s, 22.9728s/100 iters), loss = 0.233289
I0420 16:19:22.061033 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 16:19:22.061040 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:19:22.061046 38983 solver.cpp:238]     Train net output #2: loss = 0.233289 (* 1 = 0.233289 loss)
I0420 16:19:22.061053 38983 sgd_solver.cpp:105] Iteration 41200, lr = 0.0001
I0420 16:19:32.444187 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:19:45.032896 38983 solver.cpp:219] Iteration 41300 (4.35354 iter/s, 22.9698s/100 iters), loss = 0.294632
I0420 16:19:45.032950 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:19:45.032956 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:19:45.032963 38983 solver.cpp:238]     Train net output #2: loss = 0.294631 (* 1 = 0.294631 loss)
I0420 16:19:45.032968 38983 sgd_solver.cpp:105] Iteration 41300, lr = 0.0001
I0420 16:20:07.956039 38983 solver.cpp:219] Iteration 41400 (4.36242 iter/s, 22.923s/100 iters), loss = 0.184788
I0420 16:20:07.956183 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 16:20:07.956190 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:20:07.956197 38983 solver.cpp:238]     Train net output #2: loss = 0.184788 (* 1 = 0.184788 loss)
I0420 16:20:07.956202 38983 sgd_solver.cpp:105] Iteration 41400, lr = 0.0001
I0420 16:20:30.932898 38983 solver.cpp:219] Iteration 41500 (4.35262 iter/s, 22.9747s/100 iters), loss = 0.350674
I0420 16:20:30.932950 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 16:20:30.932955 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:20:30.932962 38983 solver.cpp:238]     Train net output #2: loss = 0.350674 (* 1 = 0.350674 loss)
I0420 16:20:30.932967 38983 sgd_solver.cpp:105] Iteration 41500, lr = 0.0001
I0420 16:20:54.420027 38983 solver.cpp:219] Iteration 41600 (4.25767 iter/s, 23.487s/100 iters), loss = 0.312078
I0420 16:20:54.420107 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 16:20:54.420115 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:20:54.420121 38983 solver.cpp:238]     Train net output #2: loss = 0.312078 (* 1 = 0.312078 loss)
I0420 16:20:54.420125 38983 sgd_solver.cpp:105] Iteration 41600, lr = 0.0001
I0420 16:21:03.397338 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:21:18.003152 38983 solver.cpp:219] Iteration 41700 (4.24072 iter/s, 23.5809s/100 iters), loss = 0.204462
I0420 16:21:18.003208 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 16:21:18.003214 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:21:18.003221 38983 solver.cpp:238]     Train net output #2: loss = 0.204462 (* 1 = 0.204462 loss)
I0420 16:21:18.003226 38983 sgd_solver.cpp:105] Iteration 41700, lr = 0.0001
I0420 16:21:40.990950 38983 solver.cpp:219] Iteration 41800 (4.35015 iter/s, 22.9877s/100 iters), loss = 0.358835
I0420 16:21:40.991138 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 16:21:40.991147 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:21:40.991153 38983 solver.cpp:238]     Train net output #2: loss = 0.358835 (* 1 = 0.358835 loss)
I0420 16:21:40.991158 38983 sgd_solver.cpp:105] Iteration 41800, lr = 0.0001
I0420 16:22:03.931290 38983 solver.cpp:219] Iteration 41900 (4.35955 iter/s, 22.9381s/100 iters), loss = 0.359923
I0420 16:22:03.931341 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 16:22:03.931346 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:22:03.931354 38983 solver.cpp:238]     Train net output #2: loss = 0.359922 (* 1 = 0.359922 loss)
I0420 16:22:03.931358 38983 sgd_solver.cpp:105] Iteration 41900, lr = 0.0001
I0420 16:22:26.696118 38983 solver.cpp:331] Iteration 42000, Testing net (#0)
I0420 16:22:31.589184 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:22:31.813959 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8635
I0420 16:22:31.813987 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9941
I0420 16:22:31.814010 38983 solver.cpp:398]     Test net output #2: loss = 0.442822 (* 1 = 0.442822 loss)
I0420 16:22:31.938237 38983 solver.cpp:219] Iteration 42000 (3.57055 iter/s, 28.0069s/100 iters), loss = 0.322268
I0420 16:22:31.938258 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:22:31.938279 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:22:31.938285 38983 solver.cpp:238]     Train net output #2: loss = 0.322268 (* 1 = 0.322268 loss)
I0420 16:22:31.938292 38983 sgd_solver.cpp:105] Iteration 42000, lr = 0.0001
I0420 16:22:38.239653 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:22:54.961603 38983 solver.cpp:219] Iteration 42100 (4.34386 iter/s, 23.021s/100 iters), loss = 0.272507
I0420 16:22:54.961660 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:22:54.961665 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:22:54.961673 38983 solver.cpp:238]     Train net output #2: loss = 0.272507 (* 1 = 0.272507 loss)
I0420 16:22:54.961678 38983 sgd_solver.cpp:105] Iteration 42100, lr = 0.0001
I0420 16:23:17.849752 38983 solver.cpp:219] Iteration 42200 (4.3695 iter/s, 22.8859s/100 iters), loss = 0.299814
I0420 16:23:17.849952 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:23:17.849958 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:23:17.849966 38983 solver.cpp:238]     Train net output #2: loss = 0.299814 (* 1 = 0.299814 loss)
I0420 16:23:17.849969 38983 sgd_solver.cpp:105] Iteration 42200, lr = 0.0001
I0420 16:23:40.850073 38983 solver.cpp:219] Iteration 42300 (4.34806 iter/s, 22.9988s/100 iters), loss = 0.349942
I0420 16:23:40.850107 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:23:40.850129 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 16:23:40.850136 38983 solver.cpp:238]     Train net output #2: loss = 0.349941 (* 1 = 0.349941 loss)
I0420 16:23:40.850141 38983 sgd_solver.cpp:105] Iteration 42300, lr = 0.0001
I0420 16:24:03.768645 38983 solver.cpp:219] Iteration 42400 (4.36369 iter/s, 22.9164s/100 iters), loss = 0.232309
I0420 16:24:03.768724 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:24:03.768731 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:24:03.768738 38983 solver.cpp:238]     Train net output #2: loss = 0.232309 (* 1 = 0.232309 loss)
I0420 16:24:03.768741 38983 sgd_solver.cpp:105] Iteration 42400, lr = 0.0001
I0420 16:24:07.758939 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:24:26.742597 38983 solver.cpp:219] Iteration 42500 (4.3528 iter/s, 22.9737s/100 iters), loss = 0.189458
I0420 16:24:26.742651 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:24:26.742656 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:24:26.742663 38983 solver.cpp:238]     Train net output #2: loss = 0.189458 (* 1 = 0.189458 loss)
I0420 16:24:26.742667 38983 sgd_solver.cpp:105] Iteration 42500, lr = 0.0001
I0420 16:24:49.688326 38983 solver.cpp:219] Iteration 42600 (4.35854 iter/s, 22.9435s/100 iters), loss = 0.346324
I0420 16:24:49.688570 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:24:49.688577 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:24:49.688585 38983 solver.cpp:238]     Train net output #2: loss = 0.346324 (* 1 = 0.346324 loss)
I0420 16:24:49.688588 38983 sgd_solver.cpp:105] Iteration 42600, lr = 0.0001
I0420 16:25:12.628142 38983 solver.cpp:219] Iteration 42700 (4.3593 iter/s, 22.9395s/100 iters), loss = 0.306657
I0420 16:25:12.628199 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:25:12.628204 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:25:12.628211 38983 solver.cpp:238]     Train net output #2: loss = 0.306657 (* 1 = 0.306657 loss)
I0420 16:25:12.628216 38983 sgd_solver.cpp:105] Iteration 42700, lr = 0.0001
I0420 16:25:35.608057 38983 solver.cpp:219] Iteration 42800 (4.35205 iter/s, 22.9777s/100 iters), loss = 0.293822
I0420 16:25:35.608247 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:25:35.608253 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:25:35.608259 38983 solver.cpp:238]     Train net output #2: loss = 0.293821 (* 1 = 0.293821 loss)
I0420 16:25:35.608263 38983 sgd_solver.cpp:105] Iteration 42800, lr = 0.0001
I0420 16:25:37.432665 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:25:58.512436 38983 solver.cpp:219] Iteration 42900 (4.366 iter/s, 22.9042s/100 iters), loss = 0.284606
I0420 16:25:58.512492 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:25:58.512500 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:25:58.512506 38983 solver.cpp:238]     Train net output #2: loss = 0.284606 (* 1 = 0.284606 loss)
I0420 16:25:58.512511 38983 sgd_solver.cpp:105] Iteration 42900, lr = 0.0001
I0420 16:26:21.289852 38983 solver.cpp:331] Iteration 43000, Testing net (#0)
I0420 16:26:26.171902 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:26:26.297245 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8642
I0420 16:26:26.297271 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 16:26:26.297296 38983 solver.cpp:398]     Test net output #2: loss = 0.443169 (* 1 = 0.443169 loss)
I0420 16:26:26.519336 38983 solver.cpp:219] Iteration 43000 (3.57082 iter/s, 28.0048s/100 iters), loss = 0.213389
I0420 16:26:26.519356 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 16:26:26.519377 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:26:26.519383 38983 solver.cpp:238]     Train net output #2: loss = 0.213389 (* 1 = 0.213389 loss)
I0420 16:26:26.519389 38983 sgd_solver.cpp:105] Iteration 43000, lr = 0.0001
I0420 16:26:49.515532 38983 solver.cpp:219] Iteration 43100 (4.34897 iter/s, 22.994s/100 iters), loss = 0.265429
I0420 16:26:49.515570 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 16:26:49.515592 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:26:49.515599 38983 solver.cpp:238]     Train net output #2: loss = 0.265429 (* 1 = 0.265429 loss)
I0420 16:26:49.515604 38983 sgd_solver.cpp:105] Iteration 43100, lr = 0.0001
I0420 16:27:12.233635 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:27:12.435940 38983 solver.cpp:219] Iteration 43200 (4.36294 iter/s, 22.9203s/100 iters), loss = 0.333959
I0420 16:27:12.435966 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:27:12.435987 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:27:12.435993 38983 solver.cpp:238]     Train net output #2: loss = 0.333959 (* 1 = 0.333959 loss)
I0420 16:27:12.435997 38983 sgd_solver.cpp:105] Iteration 43200, lr = 0.0001
I0420 16:27:35.419231 38983 solver.cpp:219] Iteration 43300 (4.35141 iter/s, 22.9811s/100 iters), loss = 0.30417
I0420 16:27:35.419286 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 16:27:35.419291 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:27:35.419298 38983 solver.cpp:238]     Train net output #2: loss = 0.30417 (* 1 = 0.30417 loss)
I0420 16:27:35.419302 38983 sgd_solver.cpp:105] Iteration 43300, lr = 0.0001
I0420 16:27:58.321013 38983 solver.cpp:219] Iteration 43400 (4.36694 iter/s, 22.8993s/100 iters), loss = 0.386948
I0420 16:27:58.321223 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 16:27:58.321230 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:27:58.321238 38983 solver.cpp:238]     Train net output #2: loss = 0.386948 (* 1 = 0.386948 loss)
I0420 16:27:58.321241 38983 sgd_solver.cpp:105] Iteration 43400, lr = 0.0001
I0420 16:28:21.309628 38983 solver.cpp:219] Iteration 43500 (4.3504 iter/s, 22.9864s/100 iters), loss = 0.315923
I0420 16:28:21.309686 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:28:21.309692 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 16:28:21.309698 38983 solver.cpp:238]     Train net output #2: loss = 0.315923 (* 1 = 0.315923 loss)
I0420 16:28:21.309702 38983 sgd_solver.cpp:105] Iteration 43500, lr = 0.0001
I0420 16:28:41.723546 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:28:44.192271 38983 solver.cpp:219] Iteration 43600 (4.37056 iter/s, 22.8803s/100 iters), loss = 0.313747
I0420 16:28:44.192306 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 16:28:44.192327 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:28:44.192334 38983 solver.cpp:238]     Train net output #2: loss = 0.313746 (* 1 = 0.313746 loss)
I0420 16:28:44.192338 38983 sgd_solver.cpp:105] Iteration 43600, lr = 0.0001
I0420 16:29:07.196151 38983 solver.cpp:219] Iteration 43700 (4.34752 iter/s, 23.0016s/100 iters), loss = 0.362242
I0420 16:29:07.196207 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:29:07.196211 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:29:07.196218 38983 solver.cpp:238]     Train net output #2: loss = 0.362242 (* 1 = 0.362242 loss)
I0420 16:29:07.196223 38983 sgd_solver.cpp:105] Iteration 43700, lr = 0.0001
I0420 16:29:30.088733 38983 solver.cpp:219] Iteration 43800 (4.36866 iter/s, 22.8903s/100 iters), loss = 0.247303
I0420 16:29:30.088914 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:29:30.088922 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:29:30.088928 38983 solver.cpp:238]     Train net output #2: loss = 0.247303 (* 1 = 0.247303 loss)
I0420 16:29:30.088935 38983 sgd_solver.cpp:105] Iteration 43800, lr = 0.0001
I0420 16:29:53.095362 38983 solver.cpp:219] Iteration 43900 (4.34689 iter/s, 23.0049s/100 iters), loss = 0.308451
I0420 16:29:53.095417 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 16:29:53.095423 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:29:53.095429 38983 solver.cpp:238]     Train net output #2: loss = 0.308451 (* 1 = 0.308451 loss)
I0420 16:29:53.095433 38983 sgd_solver.cpp:105] Iteration 43900, lr = 0.0001
I0420 16:30:11.478284 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:30:15.866060 38983 solver.cpp:331] Iteration 44000, Testing net (#0)
I0420 16:30:20.681438 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:30:20.913638 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8635
I0420 16:30:20.913664 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 16:30:20.913691 38983 solver.cpp:398]     Test net output #2: loss = 0.443356 (* 1 = 0.443356 loss)
I0420 16:30:21.141119 38983 solver.cpp:219] Iteration 44000 (3.56587 iter/s, 28.0436s/100 iters), loss = 0.222229
I0420 16:30:21.141139 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 16:30:21.141160 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:30:21.141166 38983 solver.cpp:238]     Train net output #2: loss = 0.222229 (* 1 = 0.222229 loss)
I0420 16:30:21.141171 38983 sgd_solver.cpp:105] Iteration 44000, lr = 0.0001
I0420 16:30:44.015512 38983 solver.cpp:219] Iteration 44100 (4.37212 iter/s, 22.8722s/100 iters), loss = 0.37138
I0420 16:30:44.015739 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 16:30:44.015748 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:30:44.015754 38983 solver.cpp:238]     Train net output #2: loss = 0.37138 (* 1 = 0.37138 loss)
I0420 16:30:44.015759 38983 sgd_solver.cpp:105] Iteration 44100, lr = 0.0001
I0420 16:31:08.039153 38983 solver.cpp:219] Iteration 44200 (4.16296 iter/s, 24.0214s/100 iters), loss = 0.294332
I0420 16:31:08.039209 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:31:08.039214 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:31:08.039221 38983 solver.cpp:238]     Train net output #2: loss = 0.294332 (* 1 = 0.294332 loss)
I0420 16:31:08.039225 38983 sgd_solver.cpp:105] Iteration 44200, lr = 0.0001
I0420 16:31:31.164350 38983 solver.cpp:219] Iteration 44300 (4.32471 iter/s, 23.123s/100 iters), loss = 0.27102
I0420 16:31:31.164533 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:31:31.164539 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:31:31.164546 38983 solver.cpp:238]     Train net output #2: loss = 0.27102 (* 1 = 0.27102 loss)
I0420 16:31:31.164552 38983 sgd_solver.cpp:105] Iteration 44300, lr = 0.0001
I0420 16:31:47.292378 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:31:54.167652 38983 solver.cpp:219] Iteration 44400 (4.34762 iter/s, 23.0011s/100 iters), loss = 0.330452
I0420 16:31:54.167712 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 16:31:54.167718 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:31:54.167726 38983 solver.cpp:238]     Train net output #2: loss = 0.330451 (* 1 = 0.330451 loss)
I0420 16:31:54.167731 38983 sgd_solver.cpp:105] Iteration 44400, lr = 0.0001
I0420 16:32:17.084081 38983 solver.cpp:219] Iteration 44500 (4.3637 iter/s, 22.9163s/100 iters), loss = 0.254067
I0420 16:32:17.084161 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 16:32:17.084169 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:32:17.084175 38983 solver.cpp:238]     Train net output #2: loss = 0.254067 (* 1 = 0.254067 loss)
I0420 16:32:17.084179 38983 sgd_solver.cpp:105] Iteration 44500, lr = 0.0001
I0420 16:32:40.092087 38983 solver.cpp:219] Iteration 44600 (4.34673 iter/s, 23.0058s/100 iters), loss = 0.199344
I0420 16:32:40.092141 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 16:32:40.092146 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:32:40.092154 38983 solver.cpp:238]     Train net output #2: loss = 0.199344 (* 1 = 0.199344 loss)
I0420 16:32:40.092157 38983 sgd_solver.cpp:105] Iteration 44600, lr = 0.0001
I0420 16:33:02.982587 38983 solver.cpp:219] Iteration 44700 (4.36909 iter/s, 22.888s/100 iters), loss = 0.278983
I0420 16:33:02.982784 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:33:02.982791 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:33:02.982798 38983 solver.cpp:238]     Train net output #2: loss = 0.278983 (* 1 = 0.278983 loss)
I0420 16:33:02.982802 38983 sgd_solver.cpp:105] Iteration 44700, lr = 0.0001
I0420 16:33:17.086092 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:33:25.988839 38983 solver.cpp:219] Iteration 44800 (4.34706 iter/s, 23.004s/100 iters), loss = 0.32257
I0420 16:33:25.988895 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 16:33:25.988900 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:33:25.988907 38983 solver.cpp:238]     Train net output #2: loss = 0.32257 (* 1 = 0.32257 loss)
I0420 16:33:25.988911 38983 sgd_solver.cpp:105] Iteration 44800, lr = 0.0001
I0420 16:33:48.873212 38983 solver.cpp:219] Iteration 44900 (4.37022 iter/s, 22.8822s/100 iters), loss = 0.411034
I0420 16:33:48.873440 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0420 16:33:48.873448 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:33:48.873456 38983 solver.cpp:238]     Train net output #2: loss = 0.411033 (* 1 = 0.411033 loss)
I0420 16:33:48.873459 38983 sgd_solver.cpp:105] Iteration 44900, lr = 0.0001
I0420 16:34:11.646436 38983 solver.cpp:331] Iteration 45000, Testing net (#0)
I0420 16:34:16.563846 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:34:16.718274 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8649
I0420 16:34:16.718297 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9941
I0420 16:34:16.718322 38983 solver.cpp:398]     Test net output #2: loss = 0.44303 (* 1 = 0.44303 loss)
I0420 16:34:16.921643 38983 solver.cpp:219] Iteration 45000 (3.56554 iter/s, 28.0462s/100 iters), loss = 0.249096
I0420 16:34:16.921664 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 16:34:16.921689 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:34:16.921695 38983 solver.cpp:238]     Train net output #2: loss = 0.249095 (* 1 = 0.249095 loss)
I0420 16:34:16.921701 38983 sgd_solver.cpp:105] Iteration 45000, lr = 0.0001
I0420 16:34:39.925041 38983 solver.cpp:219] Iteration 45100 (4.34722 iter/s, 23.0032s/100 iters), loss = 0.278041
I0420 16:34:39.925237 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:34:39.925245 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:34:39.925251 38983 solver.cpp:238]     Train net output #2: loss = 0.278041 (* 1 = 0.278041 loss)
I0420 16:34:39.925256 38983 sgd_solver.cpp:105] Iteration 45100, lr = 0.0001
I0420 16:34:51.874348 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:35:02.819785 38983 solver.cpp:219] Iteration 45200 (4.36784 iter/s, 22.8946s/100 iters), loss = 0.289878
I0420 16:35:02.819839 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:35:02.819845 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:35:02.819851 38983 solver.cpp:238]     Train net output #2: loss = 0.289877 (* 1 = 0.289877 loss)
I0420 16:35:02.819855 38983 sgd_solver.cpp:105] Iteration 45200, lr = 0.0001
I0420 16:35:25.848536 38983 solver.cpp:219] Iteration 45300 (4.34283 iter/s, 23.0265s/100 iters), loss = 0.306295
I0420 16:35:25.848660 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:35:25.848667 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:35:25.848675 38983 solver.cpp:238]     Train net output #2: loss = 0.306294 (* 1 = 0.306294 loss)
I0420 16:35:25.848678 38983 sgd_solver.cpp:105] Iteration 45300, lr = 0.0001
I0420 16:35:48.736562 38983 solver.cpp:219] Iteration 45400 (4.36952 iter/s, 22.8858s/100 iters), loss = 0.223604
I0420 16:35:48.736613 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:35:48.736618 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:35:48.736624 38983 solver.cpp:238]     Train net output #2: loss = 0.223604 (* 1 = 0.223604 loss)
I0420 16:35:48.736629 38983 sgd_solver.cpp:105] Iteration 45400, lr = 0.0001
I0420 16:36:11.740316 38983 solver.cpp:219] Iteration 45500 (4.34755 iter/s, 23.0015s/100 iters), loss = 0.304301
I0420 16:36:11.740398 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:36:11.740406 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:36:11.740411 38983 solver.cpp:238]     Train net output #2: loss = 0.304301 (* 1 = 0.304301 loss)
I0420 16:36:11.740417 38983 sgd_solver.cpp:105] Iteration 45500, lr = 0.0001
I0420 16:36:21.372841 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:36:34.620405 38983 solver.cpp:219] Iteration 45600 (4.37103 iter/s, 22.8779s/100 iters), loss = 0.482481
I0420 16:36:34.620460 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 16:36:34.620465 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:36:34.620471 38983 solver.cpp:238]     Train net output #2: loss = 0.482481 (* 1 = 0.482481 loss)
I0420 16:36:34.620476 38983 sgd_solver.cpp:105] Iteration 45600, lr = 0.0001
I0420 16:36:57.654081 38983 solver.cpp:219] Iteration 45700 (4.34191 iter/s, 23.0313s/100 iters), loss = 0.351867
I0420 16:36:57.654307 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 16:36:57.654315 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:36:57.654322 38983 solver.cpp:238]     Train net output #2: loss = 0.351867 (* 1 = 0.351867 loss)
I0420 16:36:57.654326 38983 sgd_solver.cpp:105] Iteration 45700, lr = 0.0001
I0420 16:37:20.546289 38983 solver.cpp:219] Iteration 45800 (4.36873 iter/s, 22.89s/100 iters), loss = 0.248762
I0420 16:37:20.546340 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:37:20.546345 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:37:20.546351 38983 solver.cpp:238]     Train net output #2: loss = 0.248762 (* 1 = 0.248762 loss)
I0420 16:37:20.546355 38983 sgd_solver.cpp:105] Iteration 45800, lr = 0.0001
I0420 16:37:43.550525 38983 solver.cpp:219] Iteration 45900 (4.34747 iter/s, 23.0019s/100 iters), loss = 0.361928
I0420 16:37:43.550844 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 16:37:43.550851 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:37:43.550858 38983 solver.cpp:238]     Train net output #2: loss = 0.361928 (* 1 = 0.361928 loss)
I0420 16:37:43.550863 38983 sgd_solver.cpp:105] Iteration 45900, lr = 0.0001
I0420 16:37:51.149812 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:38:06.327625 38983 solver.cpp:331] Iteration 46000, Testing net (#0)
I0420 16:38:11.114344 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:38:11.346515 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8641
I0420 16:38:11.346545 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 16:38:11.346570 38983 solver.cpp:398]     Test net output #2: loss = 0.442023 (* 1 = 0.442023 loss)
I0420 16:38:11.574000 38983 solver.cpp:219] Iteration 46000 (3.56872 iter/s, 28.0213s/100 iters), loss = 0.334678
I0420 16:38:11.574020 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:38:11.574043 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:38:11.574048 38983 solver.cpp:238]     Train net output #2: loss = 0.334677 (* 1 = 0.334677 loss)
I0420 16:38:11.574054 38983 sgd_solver.cpp:105] Iteration 46000, lr = 0.0001
I0420 16:38:34.457198 38983 solver.cpp:219] Iteration 46100 (4.37046 iter/s, 22.8809s/100 iters), loss = 0.232582
I0420 16:38:34.457377 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 16:38:34.457384 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:38:34.457391 38983 solver.cpp:238]     Train net output #2: loss = 0.232582 (* 1 = 0.232582 loss)
I0420 16:38:34.457396 38983 sgd_solver.cpp:105] Iteration 46100, lr = 0.0001
I0420 16:38:57.462548 38983 solver.cpp:219] Iteration 46200 (4.34724 iter/s, 23.0031s/100 iters), loss = 0.429473
I0420 16:38:57.462602 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0420 16:38:57.462607 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:38:57.462613 38983 solver.cpp:238]     Train net output #2: loss = 0.429473 (* 1 = 0.429473 loss)
I0420 16:38:57.462617 38983 sgd_solver.cpp:105] Iteration 46200, lr = 0.0001
I0420 16:39:20.342553 38983 solver.cpp:219] Iteration 46300 (4.37106 iter/s, 22.8777s/100 iters), loss = 0.486887
I0420 16:39:20.342701 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 16:39:20.342708 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 16:39:20.342715 38983 solver.cpp:238]     Train net output #2: loss = 0.486887 (* 1 = 0.486887 loss)
I0420 16:39:20.342720 38983 sgd_solver.cpp:105] Iteration 46300, lr = 0.0001
I0420 16:39:25.921520 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:39:43.339339 38983 solver.cpp:219] Iteration 46400 (4.34885 iter/s, 22.9946s/100 iters), loss = 0.309174
I0420 16:39:43.339391 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 16:39:43.339396 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:39:43.339403 38983 solver.cpp:238]     Train net output #2: loss = 0.309174 (* 1 = 0.309174 loss)
I0420 16:39:43.339407 38983 sgd_solver.cpp:105] Iteration 46400, lr = 0.0001
I0420 16:40:06.268934 38983 solver.cpp:219] Iteration 46500 (4.36161 iter/s, 22.9273s/100 iters), loss = 0.315543
I0420 16:40:06.269212 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:40:06.269222 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:40:06.269227 38983 solver.cpp:238]     Train net output #2: loss = 0.315543 (* 1 = 0.315543 loss)
I0420 16:40:06.269232 38983 sgd_solver.cpp:105] Iteration 46500, lr = 0.0001
I0420 16:40:29.251180 38983 solver.cpp:219] Iteration 46600 (4.35125 iter/s, 22.9819s/100 iters), loss = 0.178933
I0420 16:40:29.251237 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:40:29.251242 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:40:29.251250 38983 solver.cpp:238]     Train net output #2: loss = 0.178933 (* 1 = 0.178933 loss)
I0420 16:40:29.251253 38983 sgd_solver.cpp:105] Iteration 46600, lr = 0.0001
I0420 16:40:52.205945 38983 solver.cpp:219] Iteration 46700 (4.35681 iter/s, 22.9526s/100 iters), loss = 0.366433
I0420 16:40:52.206137 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 16:40:52.206145 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 16:40:52.206151 38983 solver.cpp:238]     Train net output #2: loss = 0.366433 (* 1 = 0.366433 loss)
I0420 16:40:52.206156 38983 sgd_solver.cpp:105] Iteration 46700, lr = 0.0001
I0420 16:40:55.467588 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:41:16.128629 38983 solver.cpp:219] Iteration 46800 (4.1802 iter/s, 23.9223s/100 iters), loss = 0.503692
I0420 16:41:16.128685 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0420 16:41:16.128692 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:41:16.128698 38983 solver.cpp:238]     Train net output #2: loss = 0.503692 (* 1 = 0.503692 loss)
I0420 16:41:16.128702 38983 sgd_solver.cpp:105] Iteration 46800, lr = 0.0001
I0420 16:41:39.285264 38983 solver.cpp:219] Iteration 46900 (4.31865 iter/s, 23.1554s/100 iters), loss = 0.181139
I0420 16:41:39.285456 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0420 16:41:39.285464 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:41:39.285470 38983 solver.cpp:238]     Train net output #2: loss = 0.181139 (* 1 = 0.181139 loss)
I0420 16:41:39.285475 38983 sgd_solver.cpp:105] Iteration 46900, lr = 0.0001
I0420 16:42:02.080530 38983 solver.cpp:331] Iteration 47000, Testing net (#0)
I0420 16:42:06.976795 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:42:07.142851 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8638
I0420 16:42:07.142879 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 16:42:07.142902 38983 solver.cpp:398]     Test net output #2: loss = 0.443342 (* 1 = 0.443342 loss)
I0420 16:42:07.328486 38983 solver.cpp:219] Iteration 47000 (3.56621 iter/s, 28.041s/100 iters), loss = 0.180855
I0420 16:42:07.328506 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 16:42:07.328528 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:42:07.328533 38983 solver.cpp:238]     Train net output #2: loss = 0.180855 (* 1 = 0.180855 loss)
I0420 16:42:07.328541 38983 sgd_solver.cpp:105] Iteration 47000, lr = 0.0001
I0420 16:42:30.328930 38983 solver.cpp:219] Iteration 47100 (4.34818 iter/s, 22.9981s/100 iters), loss = 0.312069
I0420 16:42:30.329145 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 16:42:30.329154 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:42:30.329161 38983 solver.cpp:238]     Train net output #2: loss = 0.312069 (* 1 = 0.312069 loss)
I0420 16:42:30.329165 38983 sgd_solver.cpp:105] Iteration 47100, lr = 0.0001
I0420 16:42:31.522845 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:42:53.230159 38983 solver.cpp:219] Iteration 47200 (4.367 iter/s, 22.899s/100 iters), loss = 0.25827
I0420 16:42:53.230211 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:42:53.230217 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:42:53.230223 38983 solver.cpp:238]     Train net output #2: loss = 0.25827 (* 1 = 0.25827 loss)
I0420 16:42:53.230227 38983 sgd_solver.cpp:105] Iteration 47200, lr = 0.0001
I0420 16:43:16.226620 38983 solver.cpp:219] Iteration 47300 (4.34893 iter/s, 22.9942s/100 iters), loss = 0.359753
I0420 16:43:16.226805 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 16:43:16.226812 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:43:16.226819 38983 solver.cpp:238]     Train net output #2: loss = 0.359753 (* 1 = 0.359753 loss)
I0420 16:43:16.226824 38983 sgd_solver.cpp:105] Iteration 47300, lr = 0.0001
I0420 16:43:39.121228 38983 solver.cpp:219] Iteration 47400 (4.36826 iter/s, 22.8924s/100 iters), loss = 0.281261
I0420 16:43:39.121268 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:43:39.121289 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:43:39.121295 38983 solver.cpp:238]     Train net output #2: loss = 0.281261 (* 1 = 0.281261 loss)
I0420 16:43:39.121299 38983 sgd_solver.cpp:105] Iteration 47400, lr = 0.0001
I0420 16:44:01.005806 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:44:02.134186 38983 solver.cpp:219] Iteration 47500 (4.34581 iter/s, 23.0107s/100 iters), loss = 0.266503
I0420 16:44:02.134237 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:44:02.134241 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:44:02.134248 38983 solver.cpp:238]     Train net output #2: loss = 0.266503 (* 1 = 0.266503 loss)
I0420 16:44:02.134253 38983 sgd_solver.cpp:105] Iteration 47500, lr = 0.0001
I0420 16:44:25.018260 38983 solver.cpp:219] Iteration 47600 (4.37027 iter/s, 22.8819s/100 iters), loss = 0.266089
I0420 16:44:25.018306 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:44:25.018311 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:44:25.018316 38983 solver.cpp:238]     Train net output #2: loss = 0.266089 (* 1 = 0.266089 loss)
I0420 16:44:25.018321 38983 sgd_solver.cpp:105] Iteration 47600, lr = 0.0001
I0420 16:44:48.027642 38983 solver.cpp:219] Iteration 47700 (4.34648 iter/s, 23.0071s/100 iters), loss = 0.29883
I0420 16:44:48.027845 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:44:48.027851 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 16:44:48.027858 38983 solver.cpp:238]     Train net output #2: loss = 0.29883 (* 1 = 0.29883 loss)
I0420 16:44:48.027863 38983 sgd_solver.cpp:105] Iteration 47700, lr = 0.0001
I0420 16:45:10.919493 38983 solver.cpp:219] Iteration 47800 (4.3688 iter/s, 22.8896s/100 iters), loss = 0.316076
I0420 16:45:10.919551 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:45:10.919558 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:45:10.919564 38983 solver.cpp:238]     Train net output #2: loss = 0.316076 (* 1 = 0.316076 loss)
I0420 16:45:10.919567 38983 sgd_solver.cpp:105] Iteration 47800, lr = 0.0001
I0420 16:45:30.716104 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:45:33.915222 38983 solver.cpp:219] Iteration 47900 (4.34871 iter/s, 22.9953s/100 iters), loss = 0.207997
I0420 16:45:33.915278 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 16:45:33.915283 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:45:33.915290 38983 solver.cpp:238]     Train net output #2: loss = 0.207997 (* 1 = 0.207997 loss)
I0420 16:45:33.915294 38983 sgd_solver.cpp:105] Iteration 47900, lr = 0.0001
I0420 16:45:56.720252 38983 solver.cpp:331] Iteration 48000, Testing net (#0)
I0420 16:46:01.529759 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:46:01.753759 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8642
I0420 16:46:01.753785 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9944
I0420 16:46:01.753810 38983 solver.cpp:398]     Test net output #2: loss = 0.443471 (* 1 = 0.443471 loss)
I0420 16:46:01.984134 38983 solver.cpp:219] Iteration 48000 (3.56293 iter/s, 28.0668s/100 iters), loss = 0.402043
I0420 16:46:01.984154 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 16:46:01.984176 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:46:01.984182 38983 solver.cpp:238]     Train net output #2: loss = 0.402043 (* 1 = 0.402043 loss)
I0420 16:46:01.984189 38983 sgd_solver.cpp:105] Iteration 48000, lr = 0.0001
I0420 16:46:24.886833 38983 solver.cpp:219] Iteration 48100 (4.36673 iter/s, 22.9004s/100 iters), loss = 0.418662
I0420 16:46:24.886886 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:46:24.886891 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:46:24.886898 38983 solver.cpp:238]     Train net output #2: loss = 0.418662 (* 1 = 0.418662 loss)
I0420 16:46:24.886904 38983 sgd_solver.cpp:105] Iteration 48100, lr = 0.0001
I0420 16:46:47.876315 38983 solver.cpp:219] Iteration 48200 (4.35025 iter/s, 22.9872s/100 iters), loss = 0.19078
I0420 16:46:47.876507 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 16:46:47.876513 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:46:47.876520 38983 solver.cpp:238]     Train net output #2: loss = 0.19078 (* 1 = 0.19078 loss)
I0420 16:46:47.876524 38983 sgd_solver.cpp:105] Iteration 48200, lr = 0.0001
I0420 16:47:05.555994 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:47:10.772902 38983 solver.cpp:219] Iteration 48300 (4.36788 iter/s, 22.8944s/100 iters), loss = 0.164599
I0420 16:47:10.772956 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 16:47:10.772961 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:47:10.772969 38983 solver.cpp:238]     Train net output #2: loss = 0.164599 (* 1 = 0.164599 loss)
I0420 16:47:10.772972 38983 sgd_solver.cpp:105] Iteration 48300, lr = 0.0001
I0420 16:47:33.757606 38983 solver.cpp:219] Iteration 48400 (4.35104 iter/s, 22.983s/100 iters), loss = 0.284638
I0420 16:47:33.757786 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:47:33.757793 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:47:33.757800 38983 solver.cpp:238]     Train net output #2: loss = 0.284638 (* 1 = 0.284638 loss)
I0420 16:47:33.757805 38983 sgd_solver.cpp:105] Iteration 48400, lr = 0.0001
I0420 16:47:56.686740 38983 solver.cpp:219] Iteration 48500 (4.36168 iter/s, 22.927s/100 iters), loss = 0.265164
I0420 16:47:56.686792 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:47:56.686797 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:47:56.686805 38983 solver.cpp:238]     Train net output #2: loss = 0.265164 (* 1 = 0.265164 loss)
I0420 16:47:56.686808 38983 sgd_solver.cpp:105] Iteration 48500, lr = 0.0001
I0420 16:48:19.640687 38983 solver.cpp:219] Iteration 48600 (4.35658 iter/s, 22.9538s/100 iters), loss = 0.326711
I0420 16:48:19.640772 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 16:48:19.640780 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:48:19.640786 38983 solver.cpp:238]     Train net output #2: loss = 0.326711 (* 1 = 0.326711 loss)
I0420 16:48:19.640790 38983 sgd_solver.cpp:105] Iteration 48600, lr = 0.0001
I0420 16:48:35.045580 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:48:42.612923 38983 solver.cpp:219] Iteration 48700 (4.35349 iter/s, 22.9701s/100 iters), loss = 0.259636
I0420 16:48:42.612977 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:48:42.612982 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:48:42.612988 38983 solver.cpp:238]     Train net output #2: loss = 0.259636 (* 1 = 0.259636 loss)
I0420 16:48:42.612993 38983 sgd_solver.cpp:105] Iteration 48700, lr = 0.0001
I0420 16:49:05.542963 38983 solver.cpp:219] Iteration 48800 (4.36113 iter/s, 22.9298s/100 iters), loss = 0.316964
I0420 16:49:05.543195 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 16:49:05.543202 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:49:05.543210 38983 solver.cpp:238]     Train net output #2: loss = 0.316964 (* 1 = 0.316964 loss)
I0420 16:49:05.543215 38983 sgd_solver.cpp:105] Iteration 48800, lr = 0.0001
I0420 16:49:28.520633 38983 solver.cpp:219] Iteration 48900 (4.35245 iter/s, 22.9756s/100 iters), loss = 0.325785
I0420 16:49:28.520686 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:49:28.520692 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 16:49:28.520715 38983 solver.cpp:238]     Train net output #2: loss = 0.325785 (* 1 = 0.325785 loss)
I0420 16:49:28.520720 38983 sgd_solver.cpp:105] Iteration 48900, lr = 0.0001
I0420 16:49:51.209806 38983 solver.cpp:331] Iteration 49000, Testing net (#0)
I0420 16:49:56.087038 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:49:56.329488 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8632
I0420 16:49:56.329516 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9941
I0420 16:49:56.329540 38983 solver.cpp:398]     Test net output #2: loss = 0.443612 (* 1 = 0.443612 loss)
I0420 16:49:56.486518 38983 solver.cpp:219] Iteration 49000 (3.5758 iter/s, 27.9658s/100 iters), loss = 0.266074
I0420 16:49:56.486539 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:49:56.486562 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:49:56.486567 38983 solver.cpp:238]     Train net output #2: loss = 0.266074 (* 1 = 0.266074 loss)
I0420 16:49:56.486572 38983 sgd_solver.cpp:105] Iteration 49000, lr = 0.0001
I0420 16:50:09.834096 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:50:19.441373 38983 solver.cpp:219] Iteration 49100 (4.3564 iter/s, 22.9547s/100 iters), loss = 0.219575
I0420 16:50:19.441428 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:50:19.441433 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:50:19.441439 38983 solver.cpp:238]     Train net output #2: loss = 0.219575 (* 1 = 0.219575 loss)
I0420 16:50:19.441443 38983 sgd_solver.cpp:105] Iteration 49100, lr = 0.0001
I0420 16:50:42.400037 38983 solver.cpp:219] Iteration 49200 (4.35609 iter/s, 22.9564s/100 iters), loss = 0.325121
I0420 16:50:42.400236 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 16:50:42.400243 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:50:42.400249 38983 solver.cpp:238]     Train net output #2: loss = 0.325121 (* 1 = 0.325121 loss)
I0420 16:50:42.400254 38983 sgd_solver.cpp:105] Iteration 49200, lr = 0.0001
I0420 16:51:05.352427 38983 solver.cpp:219] Iteration 49300 (4.35687 iter/s, 22.9523s/100 iters), loss = 0.261262
I0420 16:51:05.352483 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 16:51:05.352488 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:51:05.352494 38983 solver.cpp:238]     Train net output #2: loss = 0.261262 (* 1 = 0.261262 loss)
I0420 16:51:05.352499 38983 sgd_solver.cpp:105] Iteration 49300, lr = 0.0001
I0420 16:51:29.534202 38983 solver.cpp:219] Iteration 49400 (4.13572 iter/s, 24.1796s/100 iters), loss = 0.344771
I0420 16:51:29.534380 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 16:51:29.534387 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:51:29.534394 38983 solver.cpp:238]     Train net output #2: loss = 0.344771 (* 1 = 0.344771 loss)
I0420 16:51:29.534399 38983 sgd_solver.cpp:105] Iteration 49400, lr = 0.0001
I0420 16:51:40.823837 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:51:52.550528 38983 solver.cpp:219] Iteration 49500 (4.3452 iter/s, 23.0139s/100 iters), loss = 0.409974
I0420 16:51:52.550582 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 16:51:52.550588 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:51:52.550595 38983 solver.cpp:238]     Train net output #2: loss = 0.409974 (* 1 = 0.409974 loss)
I0420 16:51:52.550598 38983 sgd_solver.cpp:105] Iteration 49500, lr = 0.0001
I0420 16:52:15.430763 38983 solver.cpp:219] Iteration 49600 (4.37101 iter/s, 22.878s/100 iters), loss = 0.161132
I0420 16:52:15.430996 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:52:15.431005 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:52:15.431011 38983 solver.cpp:238]     Train net output #2: loss = 0.161132 (* 1 = 0.161132 loss)
I0420 16:52:15.431015 38983 sgd_solver.cpp:105] Iteration 49600, lr = 0.0001
I0420 16:52:38.448072 38983 solver.cpp:219] Iteration 49700 (4.34502 iter/s, 23.0148s/100 iters), loss = 0.199586
I0420 16:52:38.448127 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 16:52:38.448132 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:52:38.448139 38983 solver.cpp:238]     Train net output #2: loss = 0.199586 (* 1 = 0.199586 loss)
I0420 16:52:38.448143 38983 sgd_solver.cpp:105] Iteration 49700, lr = 0.0001
I0420 16:53:01.322911 38983 solver.cpp:219] Iteration 49800 (4.37203 iter/s, 22.8726s/100 iters), loss = 0.286529
I0420 16:53:01.322988 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:53:01.322993 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:53:01.323000 38983 solver.cpp:238]     Train net output #2: loss = 0.286529 (* 1 = 0.286529 loss)
I0420 16:53:01.323004 38983 sgd_solver.cpp:105] Iteration 49800, lr = 0.0001
I0420 16:53:10.346946 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:53:24.333190 38983 solver.cpp:219] Iteration 49900 (4.3463 iter/s, 23.0081s/100 iters), loss = 0.239832
I0420 16:53:24.333246 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:53:24.333252 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:53:24.333258 38983 solver.cpp:238]     Train net output #2: loss = 0.239832 (* 1 = 0.239832 loss)
I0420 16:53:24.333262 38983 sgd_solver.cpp:105] Iteration 49900, lr = 0.0001
I0420 16:53:47.113077 38983 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_finetune_quant_0.09_iter_50000.caffemodel
I0420 16:53:47.137060 38983 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_finetune_quant_0.09_iter_50000.solverstate
I0420 16:53:47.152117 38983 solver.cpp:331] Iteration 50000, Testing net (#0)
I0420 16:53:52.025112 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:53:52.262429 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8631
I0420 16:53:52.262459 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.994
I0420 16:53:52.262485 38983 solver.cpp:398]     Test net output #2: loss = 0.443854 (* 1 = 0.443854 loss)
I0420 16:53:52.437270 38983 solver.cpp:219] Iteration 50000 (3.55847 iter/s, 28.1019s/100 iters), loss = 0.388886
I0420 16:53:52.437289 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 16:53:52.437311 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:53:52.437317 38983 solver.cpp:238]     Train net output #2: loss = 0.388886 (* 1 = 0.388886 loss)
I0420 16:53:52.437324 38983 sgd_solver.cpp:105] Iteration 50000, lr = 0.0001
I0420 16:54:15.359750 38983 solver.cpp:219] Iteration 50100 (4.36257 iter/s, 22.9223s/100 iters), loss = 0.456094
I0420 16:54:15.359807 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 16:54:15.359812 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 16:54:15.359818 38983 solver.cpp:238]     Train net output #2: loss = 0.456094 (* 1 = 0.456094 loss)
I0420 16:54:15.359822 38983 sgd_solver.cpp:105] Iteration 50100, lr = 0.0001
I0420 16:54:38.341743 38983 solver.cpp:219] Iteration 50200 (4.35165 iter/s, 22.9798s/100 iters), loss = 0.284691
I0420 16:54:38.341868 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:54:38.341876 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:54:38.341882 38983 solver.cpp:238]     Train net output #2: loss = 0.28469 (* 1 = 0.28469 loss)
I0420 16:54:38.341886 38983 sgd_solver.cpp:105] Iteration 50200, lr = 0.0001
I0420 16:54:45.274502 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:55:01.273751 38983 solver.cpp:219] Iteration 50300 (4.36074 iter/s, 22.9319s/100 iters), loss = 0.398205
I0420 16:55:01.273803 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 16:55:01.273808 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:55:01.273815 38983 solver.cpp:238]     Train net output #2: loss = 0.398205 (* 1 = 0.398205 loss)
I0420 16:55:01.273819 38983 sgd_solver.cpp:105] Iteration 50300, lr = 0.0001
I0420 16:55:24.284478 38983 solver.cpp:219] Iteration 50400 (4.34621 iter/s, 23.0085s/100 iters), loss = 0.279034
I0420 16:55:24.284679 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 16:55:24.284692 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:55:24.284698 38983 solver.cpp:238]     Train net output #2: loss = 0.279034 (* 1 = 0.279034 loss)
I0420 16:55:24.284703 38983 sgd_solver.cpp:105] Iteration 50400, lr = 0.0001
I0420 16:55:47.165030 38983 solver.cpp:219] Iteration 50500 (4.37056 iter/s, 22.8803s/100 iters), loss = 0.216106
I0420 16:55:47.165086 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 16:55:47.165091 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:55:47.165097 38983 solver.cpp:238]     Train net output #2: loss = 0.216106 (* 1 = 0.216106 loss)
I0420 16:55:47.165102 38983 sgd_solver.cpp:105] Iteration 50500, lr = 0.0001
I0420 16:56:10.173333 38983 solver.cpp:219] Iteration 50600 (4.34668 iter/s, 23.0061s/100 iters), loss = 0.272705
I0420 16:56:10.173526 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:56:10.173532 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:56:10.173540 38983 solver.cpp:238]     Train net output #2: loss = 0.272705 (* 1 = 0.272705 loss)
I0420 16:56:10.173544 38983 sgd_solver.cpp:105] Iteration 50600, lr = 0.0001
I0420 16:56:14.771401 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:56:33.050529 38983 solver.cpp:219] Iteration 50700 (4.3716 iter/s, 22.8749s/100 iters), loss = 0.278945
I0420 16:56:33.050581 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 16:56:33.050586 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:56:33.050593 38983 solver.cpp:238]     Train net output #2: loss = 0.278945 (* 1 = 0.278945 loss)
I0420 16:56:33.050597 38983 sgd_solver.cpp:105] Iteration 50700, lr = 0.0001
I0420 16:56:56.051632 38983 solver.cpp:219] Iteration 50800 (4.34803 iter/s, 22.9989s/100 iters), loss = 0.347943
I0420 16:56:56.051785 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 16:56:56.051792 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:56:56.051800 38983 solver.cpp:238]     Train net output #2: loss = 0.347943 (* 1 = 0.347943 loss)
I0420 16:56:56.051805 38983 sgd_solver.cpp:105] Iteration 50800, lr = 0.0001
I0420 16:57:18.936025 38983 solver.cpp:219] Iteration 50900 (4.37023 iter/s, 22.8821s/100 iters), loss = 0.292536
I0420 16:57:18.936081 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 16:57:18.936086 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:57:18.936092 38983 solver.cpp:238]     Train net output #2: loss = 0.292536 (* 1 = 0.292536 loss)
I0420 16:57:18.936096 38983 sgd_solver.cpp:105] Iteration 50900, lr = 0.0001
I0420 16:57:41.705219 38983 solver.cpp:331] Iteration 51000, Testing net (#0)
I0420 16:57:46.611670 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:57:46.815347 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8638
I0420 16:57:46.815373 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 16:57:46.815398 38983 solver.cpp:398]     Test net output #2: loss = 0.443338 (* 1 = 0.443338 loss)
I0420 16:57:46.954702 38983 solver.cpp:219] Iteration 51000 (3.56933 iter/s, 28.0165s/100 iters), loss = 0.28349
I0420 16:57:46.954722 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:57:46.954744 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:57:46.954751 38983 solver.cpp:238]     Train net output #2: loss = 0.28349 (* 1 = 0.28349 loss)
I0420 16:57:46.954756 38983 sgd_solver.cpp:105] Iteration 51000, lr = 0.0001
I0420 16:57:49.556313 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:58:09.961447 38983 solver.cpp:219] Iteration 51100 (4.34698 iter/s, 23.0045s/100 iters), loss = 0.380945
I0420 16:58:09.961500 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 16:58:09.961505 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 16:58:09.961513 38983 solver.cpp:238]     Train net output #2: loss = 0.380945 (* 1 = 0.380945 loss)
I0420 16:58:09.961516 38983 sgd_solver.cpp:105] Iteration 51100, lr = 0.0001
I0420 16:58:32.846441 38983 solver.cpp:219] Iteration 51200 (4.37012 iter/s, 22.8827s/100 iters), loss = 0.323733
I0420 16:58:32.846603 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 16:58:32.846611 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:58:32.846616 38983 solver.cpp:238]     Train net output #2: loss = 0.323733 (* 1 = 0.323733 loss)
I0420 16:58:32.846621 38983 sgd_solver.cpp:105] Iteration 51200, lr = 0.0001
I0420 16:58:55.822043 38983 solver.cpp:219] Iteration 51300 (4.35246 iter/s, 22.9755s/100 iters), loss = 0.35242
I0420 16:58:55.822099 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 16:58:55.822104 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:58:55.822110 38983 solver.cpp:238]     Train net output #2: loss = 0.35242 (* 1 = 0.35242 loss)
I0420 16:58:55.822114 38983 sgd_solver.cpp:105] Iteration 51300, lr = 0.0001
I0420 16:59:18.780045 38983 solver.cpp:219] Iteration 51400 (4.3562 iter/s, 22.9558s/100 iters), loss = 0.20658
I0420 16:59:18.780234 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 16:59:18.780241 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:59:18.780248 38983 solver.cpp:238]     Train net output #2: loss = 0.20658 (* 1 = 0.20658 loss)
I0420 16:59:18.780253 38983 sgd_solver.cpp:105] Iteration 51400, lr = 0.0001
I0420 16:59:19.317214 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 16:59:41.721017 38983 solver.cpp:219] Iteration 51500 (4.35908 iter/s, 22.9406s/100 iters), loss = 0.271041
I0420 16:59:41.721073 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 16:59:41.721078 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 16:59:41.721084 38983 solver.cpp:238]     Train net output #2: loss = 0.271041 (* 1 = 0.271041 loss)
I0420 16:59:41.721089 38983 sgd_solver.cpp:105] Iteration 51500, lr = 0.0001
I0420 17:00:04.716516 38983 solver.cpp:219] Iteration 51600 (4.34909 iter/s, 22.9933s/100 iters), loss = 0.26869
I0420 17:00:04.716732 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:00:04.716739 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:00:04.716745 38983 solver.cpp:238]     Train net output #2: loss = 0.26869 (* 1 = 0.26869 loss)
I0420 17:00:04.716750 38983 sgd_solver.cpp:105] Iteration 51600, lr = 0.0001
I0420 17:00:27.635011 38983 solver.cpp:219] Iteration 51700 (4.36336 iter/s, 22.9181s/100 iters), loss = 0.315802
I0420 17:00:27.635066 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:00:27.635071 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:00:27.635077 38983 solver.cpp:238]     Train net output #2: loss = 0.315802 (* 1 = 0.315802 loss)
I0420 17:00:27.635082 38983 sgd_solver.cpp:105] Iteration 51700, lr = 0.0001
I0420 17:00:48.828193 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:00:50.638506 38983 solver.cpp:219] Iteration 51800 (4.34759 iter/s, 23.0013s/100 iters), loss = 0.269203
I0420 17:00:50.638561 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:00:50.638566 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:00:50.638572 38983 solver.cpp:238]     Train net output #2: loss = 0.269203 (* 1 = 0.269203 loss)
I0420 17:00:50.638576 38983 sgd_solver.cpp:105] Iteration 51800, lr = 0.0001
I0420 17:01:13.553073 38983 solver.cpp:219] Iteration 51900 (4.36407 iter/s, 22.9144s/100 iters), loss = 0.30856
I0420 17:01:13.553129 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:01:13.553135 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:01:13.553143 38983 solver.cpp:238]     Train net output #2: loss = 0.30856 (* 1 = 0.30856 loss)
I0420 17:01:13.553146 38983 sgd_solver.cpp:105] Iteration 51900, lr = 0.0001
I0420 17:01:37.617444 38983 solver.cpp:331] Iteration 52000, Testing net (#0)
I0420 17:01:42.425988 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:01:42.652354 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8649
I0420 17:01:42.652395 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 17:01:42.652402 38983 solver.cpp:398]     Test net output #2: loss = 0.442462 (* 1 = 0.442462 loss)
I0420 17:01:42.885699 38983 solver.cpp:219] Iteration 52000 (3.40943 iter/s, 29.3304s/100 iters), loss = 0.198268
I0420 17:01:42.885748 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 17:01:42.885754 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:01:42.885762 38983 solver.cpp:238]     Train net output #2: loss = 0.198268 (* 1 = 0.198268 loss)
I0420 17:01:42.885769 38983 sgd_solver.cpp:105] Iteration 52000, lr = 0.0001
I0420 17:02:05.860858 38983 solver.cpp:219] Iteration 52100 (4.35295 iter/s, 22.9729s/100 iters), loss = 0.219627
I0420 17:02:05.860921 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 17:02:05.860927 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:02:05.860934 38983 solver.cpp:238]     Train net output #2: loss = 0.219627 (* 1 = 0.219627 loss)
I0420 17:02:05.860939 38983 sgd_solver.cpp:105] Iteration 52100, lr = 0.0001
I0420 17:02:24.928912 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:02:28.741678 38983 solver.cpp:219] Iteration 52200 (4.37089 iter/s, 22.8786s/100 iters), loss = 0.271105
I0420 17:02:28.741752 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:02:28.741758 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:02:28.741767 38983 solver.cpp:238]     Train net output #2: loss = 0.271105 (* 1 = 0.271105 loss)
I0420 17:02:28.741771 38983 sgd_solver.cpp:105] Iteration 52200, lr = 0.0001
I0420 17:02:51.679898 38983 solver.cpp:219] Iteration 52300 (4.35957 iter/s, 22.9381s/100 iters), loss = 0.268881
I0420 17:02:51.679960 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:02:51.679965 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:02:51.679971 38983 solver.cpp:238]     Train net output #2: loss = 0.268881 (* 1 = 0.268881 loss)
I0420 17:02:51.679977 38983 sgd_solver.cpp:105] Iteration 52300, lr = 0.0001
I0420 17:03:14.556612 38983 solver.cpp:219] Iteration 52400 (4.3717 iter/s, 22.8744s/100 iters), loss = 0.264887
I0420 17:03:14.556818 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:03:14.556826 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:03:14.556833 38983 solver.cpp:238]     Train net output #2: loss = 0.264887 (* 1 = 0.264887 loss)
I0420 17:03:14.556838 38983 sgd_solver.cpp:105] Iteration 52400, lr = 0.0001
I0420 17:03:37.512480 38983 solver.cpp:219] Iteration 52500 (4.35623 iter/s, 22.9556s/100 iters), loss = 0.280153
I0420 17:03:37.512540 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:03:37.512547 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:03:37.512553 38983 solver.cpp:238]     Train net output #2: loss = 0.280153 (* 1 = 0.280153 loss)
I0420 17:03:37.512558 38983 sgd_solver.cpp:105] Iteration 52500, lr = 0.0001
I0420 17:03:54.473173 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:04:00.408396 38983 solver.cpp:219] Iteration 52600 (4.36802 iter/s, 22.8937s/100 iters), loss = 0.270667
I0420 17:04:00.408452 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 17:04:00.408458 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:04:00.408466 38983 solver.cpp:238]     Train net output #2: loss = 0.270667 (* 1 = 0.270667 loss)
I0420 17:04:00.408471 38983 sgd_solver.cpp:105] Iteration 52600, lr = 0.0001
I0420 17:04:23.342641 38983 solver.cpp:219] Iteration 52700 (4.36034 iter/s, 22.934s/100 iters), loss = 0.500442
I0420 17:04:23.342705 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 17:04:23.342711 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:04:23.342718 38983 solver.cpp:238]     Train net output #2: loss = 0.500442 (* 1 = 0.500442 loss)
I0420 17:04:23.342723 38983 sgd_solver.cpp:105] Iteration 52700, lr = 0.0001
I0420 17:04:46.221163 38983 solver.cpp:219] Iteration 52800 (4.37134 iter/s, 22.8763s/100 iters), loss = 0.300213
I0420 17:04:46.221354 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:04:46.221364 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:04:46.221369 38983 solver.cpp:238]     Train net output #2: loss = 0.300213 (* 1 = 0.300213 loss)
I0420 17:04:46.221375 38983 sgd_solver.cpp:105] Iteration 52800, lr = 0.0001
I0420 17:05:09.188586 38983 solver.cpp:219] Iteration 52900 (4.35405 iter/s, 22.9671s/100 iters), loss = 0.296291
I0420 17:05:09.188647 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:05:09.188653 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:05:09.188659 38983 solver.cpp:238]     Train net output #2: loss = 0.296291 (* 1 = 0.296291 loss)
I0420 17:05:09.188664 38983 sgd_solver.cpp:105] Iteration 52900, lr = 0.0001
I0420 17:05:23.868185 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:05:31.926407 38983 solver.cpp:331] Iteration 53000, Testing net (#0)
I0420 17:05:36.719794 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:05:36.922924 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8627
I0420 17:05:36.922960 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 17:05:36.922984 38983 solver.cpp:398]     Test net output #2: loss = 0.443385 (* 1 = 0.443385 loss)
I0420 17:05:37.152570 38983 solver.cpp:219] Iteration 53000 (3.5763 iter/s, 27.9618s/100 iters), loss = 0.300231
I0420 17:05:37.152593 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:05:37.152616 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:05:37.152621 38983 solver.cpp:238]     Train net output #2: loss = 0.300231 (* 1 = 0.300231 loss)
I0420 17:05:37.152627 38983 sgd_solver.cpp:105] Iteration 53000, lr = 0.0001
I0420 17:06:00.022872 38983 solver.cpp:219] Iteration 53100 (4.37292 iter/s, 22.868s/100 iters), loss = 0.321512
I0420 17:06:00.023063 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:06:00.023071 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:06:00.023077 38983 solver.cpp:238]     Train net output #2: loss = 0.321512 (* 1 = 0.321512 loss)
I0420 17:06:00.023082 38983 sgd_solver.cpp:105] Iteration 53100, lr = 0.0001
I0420 17:06:23.018623 38983 solver.cpp:219] Iteration 53200 (4.34907 iter/s, 22.9934s/100 iters), loss = 0.263491
I0420 17:06:23.018684 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:06:23.018690 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:06:23.018697 38983 solver.cpp:238]     Train net output #2: loss = 0.263491 (* 1 = 0.263491 loss)
I0420 17:06:23.018702 38983 sgd_solver.cpp:105] Iteration 53200, lr = 0.0001
I0420 17:06:45.882869 38983 solver.cpp:219] Iteration 53300 (4.37406 iter/s, 22.862s/100 iters), loss = 0.311387
I0420 17:06:45.883088 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:06:45.883096 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:06:45.883105 38983 solver.cpp:238]     Train net output #2: loss = 0.311387 (* 1 = 0.311387 loss)
I0420 17:06:45.883110 38983 sgd_solver.cpp:105] Iteration 53300, lr = 0.0001
I0420 17:06:58.585026 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:07:08.960659 38983 solver.cpp:219] Iteration 53400 (4.33361 iter/s, 23.0754s/100 iters), loss = 0.390708
I0420 17:07:08.960734 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 17:07:08.960741 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0420 17:07:08.960747 38983 solver.cpp:238]     Train net output #2: loss = 0.390708 (* 1 = 0.390708 loss)
I0420 17:07:08.960752 38983 sgd_solver.cpp:105] Iteration 53400, lr = 0.0001
I0420 17:07:31.871887 38983 solver.cpp:219] Iteration 53500 (4.36499 iter/s, 22.9096s/100 iters), loss = 0.270816
I0420 17:07:31.872083 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:07:31.872090 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:07:31.872097 38983 solver.cpp:238]     Train net output #2: loss = 0.270816 (* 1 = 0.270816 loss)
I0420 17:07:31.872102 38983 sgd_solver.cpp:105] Iteration 53500, lr = 0.0001
I0420 17:07:54.877738 38983 solver.cpp:219] Iteration 53600 (4.34678 iter/s, 23.0055s/100 iters), loss = 0.405452
I0420 17:07:54.877795 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 17:07:54.877800 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:07:54.877807 38983 solver.cpp:238]     Train net output #2: loss = 0.405452 (* 1 = 0.405452 loss)
I0420 17:07:54.877811 38983 sgd_solver.cpp:105] Iteration 53600, lr = 0.0001
I0420 17:08:17.735898 38983 solver.cpp:219] Iteration 53700 (4.37525 iter/s, 22.8558s/100 iters), loss = 0.235376
I0420 17:08:17.736111 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:08:17.736119 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:08:17.736124 38983 solver.cpp:238]     Train net output #2: loss = 0.235376 (* 1 = 0.235376 loss)
I0420 17:08:17.736129 38983 sgd_solver.cpp:105] Iteration 53700, lr = 0.0001
I0420 17:08:28.155663 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:08:40.729172 38983 solver.cpp:219] Iteration 53800 (4.34953 iter/s, 22.991s/100 iters), loss = 0.29882
I0420 17:08:40.729224 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:08:40.729229 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:08:40.729236 38983 solver.cpp:238]     Train net output #2: loss = 0.29882 (* 1 = 0.29882 loss)
I0420 17:08:40.729240 38983 sgd_solver.cpp:105] Iteration 53800, lr = 0.0001
I0420 17:09:03.621734 38983 solver.cpp:219] Iteration 53900 (4.36865 iter/s, 22.8903s/100 iters), loss = 0.24152
I0420 17:09:03.621922 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:09:03.621928 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:09:03.621935 38983 solver.cpp:238]     Train net output #2: loss = 0.24152 (* 1 = 0.24152 loss)
I0420 17:09:03.621940 38983 sgd_solver.cpp:105] Iteration 53900, lr = 0.0001
I0420 17:09:26.399298 38983 solver.cpp:331] Iteration 54000, Testing net (#0)
I0420 17:09:31.254199 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:09:31.491073 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8643
I0420 17:09:31.491099 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9941
I0420 17:09:31.491124 38983 solver.cpp:398]     Test net output #2: loss = 0.443213 (* 1 = 0.443213 loss)
I0420 17:09:31.605635 38983 solver.cpp:219] Iteration 54000 (3.57368 iter/s, 27.9824s/100 iters), loss = 0.314932
I0420 17:09:31.605657 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:09:31.605679 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:09:31.605710 38983 solver.cpp:238]     Train net output #2: loss = 0.314932 (* 1 = 0.314932 loss)
I0420 17:09:31.605716 38983 sgd_solver.cpp:105] Iteration 54000, lr = 0.0001
I0420 17:09:54.616567 38983 solver.cpp:219] Iteration 54100 (4.3458 iter/s, 23.0107s/100 iters), loss = 0.271771
I0420 17:09:54.616818 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:09:54.616827 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:09:54.616833 38983 solver.cpp:238]     Train net output #2: loss = 0.271771 (* 1 = 0.271771 loss)
I0420 17:09:54.616837 38983 sgd_solver.cpp:105] Iteration 54100, lr = 0.0001
I0420 17:10:02.913311 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:10:17.538328 38983 solver.cpp:219] Iteration 54200 (4.36308 iter/s, 22.9196s/100 iters), loss = 0.215762
I0420 17:10:17.538384 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:10:17.538390 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:10:17.538396 38983 solver.cpp:238]     Train net output #2: loss = 0.215762 (* 1 = 0.215762 loss)
I0420 17:10:17.538400 38983 sgd_solver.cpp:105] Iteration 54200, lr = 0.0001
I0420 17:10:40.521284 38983 solver.cpp:219] Iteration 54300 (4.35108 iter/s, 22.9828s/100 iters), loss = 0.397736
I0420 17:10:40.521416 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 17:10:40.521423 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:10:40.521430 38983 solver.cpp:238]     Train net output #2: loss = 0.397736 (* 1 = 0.397736 loss)
I0420 17:10:40.521435 38983 sgd_solver.cpp:105] Iteration 54300, lr = 0.0001
I0420 17:11:03.472043 38983 solver.cpp:219] Iteration 54400 (4.35757 iter/s, 22.9486s/100 iters), loss = 0.360017
I0420 17:11:03.472097 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:11:03.472103 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:11:03.472110 38983 solver.cpp:238]     Train net output #2: loss = 0.360017 (* 1 = 0.360017 loss)
I0420 17:11:03.472113 38983 sgd_solver.cpp:105] Iteration 54400, lr = 0.0001
I0420 17:11:26.413215 38983 solver.cpp:219] Iteration 54500 (4.359 iter/s, 22.941s/100 iters), loss = 0.31337
I0420 17:11:26.413388 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:11:26.413394 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:11:26.413400 38983 solver.cpp:238]     Train net output #2: loss = 0.31337 (* 1 = 0.31337 loss)
I0420 17:11:26.413405 38983 sgd_solver.cpp:105] Iteration 54500, lr = 0.0001
I0420 17:11:32.746548 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:11:50.577940 38983 solver.cpp:219] Iteration 54600 (4.13867 iter/s, 24.1623s/100 iters), loss = 0.241172
I0420 17:11:50.577996 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 17:11:50.578001 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:11:50.578006 38983 solver.cpp:238]     Train net output #2: loss = 0.241172 (* 1 = 0.241172 loss)
I0420 17:11:50.578011 38983 sgd_solver.cpp:105] Iteration 54600, lr = 0.0001
I0420 17:12:13.586438 38983 solver.cpp:219] Iteration 54700 (4.34665 iter/s, 23.0062s/100 iters), loss = 0.311085
I0420 17:12:13.586637 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:12:13.586643 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:12:13.586650 38983 solver.cpp:238]     Train net output #2: loss = 0.311085 (* 1 = 0.311085 loss)
I0420 17:12:13.586654 38983 sgd_solver.cpp:105] Iteration 54700, lr = 0.0001
I0420 17:12:36.470367 38983 solver.cpp:219] Iteration 54800 (4.37033 iter/s, 22.8815s/100 iters), loss = 0.383313
I0420 17:12:36.470422 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 17:12:36.470428 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:12:36.470434 38983 solver.cpp:238]     Train net output #2: loss = 0.383313 (* 1 = 0.383313 loss)
I0420 17:12:36.470438 38983 sgd_solver.cpp:105] Iteration 54800, lr = 0.0001
I0420 17:12:59.468914 38983 solver.cpp:219] Iteration 54900 (4.34841 iter/s, 22.9969s/100 iters), loss = 0.239001
I0420 17:12:59.469112 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 17:12:59.469137 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:12:59.469144 38983 solver.cpp:238]     Train net output #2: loss = 0.239001 (* 1 = 0.239001 loss)
I0420 17:12:59.469148 38983 sgd_solver.cpp:105] Iteration 54900, lr = 0.0001
I0420 17:13:03.384405 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:13:22.244841 38983 solver.cpp:331] Iteration 55000, Testing net (#0)
I0420 17:13:27.048203 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:13:27.249505 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8639
I0420 17:13:27.249527 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 17:13:27.249552 38983 solver.cpp:398]     Test net output #2: loss = 0.443011 (* 1 = 0.443011 loss)
I0420 17:13:27.478824 38983 solver.cpp:219] Iteration 55000 (3.57044 iter/s, 28.0078s/100 iters), loss = 0.215067
I0420 17:13:27.478845 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 17:13:27.478866 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:13:27.478873 38983 solver.cpp:238]     Train net output #2: loss = 0.215067 (* 1 = 0.215067 loss)
I0420 17:13:27.478879 38983 sgd_solver.cpp:105] Iteration 55000, lr = 0.0001
I0420 17:13:50.386965 38983 solver.cpp:219] Iteration 55100 (4.36571 iter/s, 22.9058s/100 iters), loss = 0.353843
I0420 17:13:50.387146 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:13:50.387153 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:13:50.387161 38983 solver.cpp:238]     Train net output #2: loss = 0.353843 (* 1 = 0.353843 loss)
I0420 17:13:50.387166 38983 sgd_solver.cpp:105] Iteration 55100, lr = 0.0001
I0420 17:14:13.387250 38983 solver.cpp:219] Iteration 55200 (4.3482 iter/s, 22.998s/100 iters), loss = 0.251824
I0420 17:14:13.387306 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:14:13.387312 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:14:13.387320 38983 solver.cpp:238]     Train net output #2: loss = 0.251824 (* 1 = 0.251824 loss)
I0420 17:14:13.387323 38983 sgd_solver.cpp:105] Iteration 55200, lr = 0.0001
I0420 17:14:36.307744 38983 solver.cpp:219] Iteration 55300 (4.36332 iter/s, 22.9183s/100 iters), loss = 0.235778
I0420 17:14:36.307914 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 17:14:36.307921 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:14:36.307927 38983 solver.cpp:238]     Train net output #2: loss = 0.235778 (* 1 = 0.235778 loss)
I0420 17:14:36.307932 38983 sgd_solver.cpp:105] Iteration 55300, lr = 0.0001
I0420 17:14:38.185266 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:14:59.279863 38983 solver.cpp:219] Iteration 55400 (4.35312 iter/s, 22.972s/100 iters), loss = 0.244785
I0420 17:14:59.279916 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:14:59.279920 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:14:59.279927 38983 solver.cpp:238]     Train net output #2: loss = 0.244785 (* 1 = 0.244785 loss)
I0420 17:14:59.279932 38983 sgd_solver.cpp:105] Iteration 55400, lr = 0.0001
I0420 17:15:22.221101 38983 solver.cpp:219] Iteration 55500 (4.35939 iter/s, 22.939s/100 iters), loss = 0.242519
I0420 17:15:22.221339 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:15:22.221348 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:15:22.221354 38983 solver.cpp:238]     Train net output #2: loss = 0.242519 (* 1 = 0.242519 loss)
I0420 17:15:22.221359 38983 sgd_solver.cpp:105] Iteration 55500, lr = 0.0001
I0420 17:15:45.164366 38983 solver.cpp:219] Iteration 55600 (4.35864 iter/s, 22.9429s/100 iters), loss = 0.345794
I0420 17:15:45.164402 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:15:45.164422 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:15:45.164430 38983 solver.cpp:238]     Train net output #2: loss = 0.345794 (* 1 = 0.345794 loss)
I0420 17:15:45.164436 38983 sgd_solver.cpp:105] Iteration 55600, lr = 0.0001
I0420 17:16:07.944998 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:16:08.130812 38983 solver.cpp:219] Iteration 55700 (4.35459 iter/s, 22.9643s/100 iters), loss = 0.317873
I0420 17:16:08.130857 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:16:08.130861 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:16:08.130868 38983 solver.cpp:238]     Train net output #2: loss = 0.317873 (* 1 = 0.317873 loss)
I0420 17:16:08.130872 38983 sgd_solver.cpp:105] Iteration 55700, lr = 0.0001
I0420 17:16:31.057296 38983 solver.cpp:219] Iteration 55800 (4.36183 iter/s, 22.9262s/100 iters), loss = 0.281201
I0420 17:16:31.057348 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:16:31.057353 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:16:31.057359 38983 solver.cpp:238]     Train net output #2: loss = 0.281201 (* 1 = 0.281201 loss)
I0420 17:16:31.057363 38983 sgd_solver.cpp:105] Iteration 55800, lr = 0.0001
I0420 17:16:54.049113 38983 solver.cpp:219] Iteration 55900 (4.34984 iter/s, 22.9894s/100 iters), loss = 0.425349
I0420 17:16:54.049295 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 17:16:54.049301 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:16:54.049309 38983 solver.cpp:238]     Train net output #2: loss = 0.425349 (* 1 = 0.425349 loss)
I0420 17:16:54.049314 38983 sgd_solver.cpp:105] Iteration 55900, lr = 0.0001
I0420 17:17:16.763715 38983 solver.cpp:331] Iteration 56000, Testing net (#0)
I0420 17:17:21.650239 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:17:21.887336 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8643
I0420 17:17:21.887367 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9941
I0420 17:17:21.887392 38983 solver.cpp:398]     Test net output #2: loss = 0.442815 (* 1 = 0.442815 loss)
I0420 17:17:22.022023 38983 solver.cpp:219] Iteration 56000 (3.5749 iter/s, 27.9728s/100 iters), loss = 0.377577
I0420 17:17:22.022044 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 17:17:22.022066 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:17:22.022073 38983 solver.cpp:238]     Train net output #2: loss = 0.377577 (* 1 = 0.377577 loss)
I0420 17:17:22.022078 38983 sgd_solver.cpp:105] Iteration 56000, lr = 0.0001
I0420 17:17:42.512670 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:17:44.994268 38983 solver.cpp:219] Iteration 56100 (4.35311 iter/s, 22.9721s/100 iters), loss = 0.30717
I0420 17:17:44.994305 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:17:44.994312 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0420 17:17:44.994318 38983 solver.cpp:238]     Train net output #2: loss = 0.30717 (* 1 = 0.30717 loss)
I0420 17:17:44.994324 38983 sgd_solver.cpp:105] Iteration 56100, lr = 0.0001
I0420 17:18:07.910358 38983 solver.cpp:219] Iteration 56200 (4.36416 iter/s, 22.9139s/100 iters), loss = 0.375555
I0420 17:18:07.910414 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 17:18:07.910419 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:18:07.910426 38983 solver.cpp:238]     Train net output #2: loss = 0.375555 (* 1 = 0.375555 loss)
I0420 17:18:07.910430 38983 sgd_solver.cpp:105] Iteration 56200, lr = 0.0001
I0420 17:18:30.871206 38983 solver.cpp:219] Iteration 56300 (4.35526 iter/s, 22.9608s/100 iters), loss = 0.271862
I0420 17:18:30.871445 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:18:30.871454 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:18:30.871460 38983 solver.cpp:238]     Train net output #2: loss = 0.271862 (* 1 = 0.271862 loss)
I0420 17:18:30.871465 38983 sgd_solver.cpp:105] Iteration 56300, lr = 0.0001
I0420 17:18:53.823684 38983 solver.cpp:219] Iteration 56400 (4.35724 iter/s, 22.9503s/100 iters), loss = 0.299927
I0420 17:18:53.823741 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:18:53.823746 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:18:53.823752 38983 solver.cpp:238]     Train net output #2: loss = 0.299927 (* 1 = 0.299927 loss)
I0420 17:18:53.823756 38983 sgd_solver.cpp:105] Iteration 56400, lr = 0.0001
I0420 17:19:12.242039 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:19:16.746058 38983 solver.cpp:219] Iteration 56500 (4.36258 iter/s, 22.9222s/100 iters), loss = 0.251853
I0420 17:19:16.746111 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:19:16.746116 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:19:16.746124 38983 solver.cpp:238]     Train net output #2: loss = 0.251853 (* 1 = 0.251853 loss)
I0420 17:19:16.746127 38983 sgd_solver.cpp:105] Iteration 56500, lr = 0.0001
I0420 17:19:39.725610 38983 solver.cpp:219] Iteration 56600 (4.35211 iter/s, 22.9773s/100 iters), loss = 0.314971
I0420 17:19:39.725666 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 17:19:39.725672 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:19:39.725677 38983 solver.cpp:238]     Train net output #2: loss = 0.314971 (* 1 = 0.314971 loss)
I0420 17:19:39.725684 38983 sgd_solver.cpp:105] Iteration 56600, lr = 0.0001
I0420 17:20:02.620239 38983 solver.cpp:219] Iteration 56700 (4.36785 iter/s, 22.8945s/100 iters), loss = 0.230661
I0420 17:20:02.620395 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:20:02.620401 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:20:02.620409 38983 solver.cpp:238]     Train net output #2: loss = 0.230661 (* 1 = 0.230661 loss)
I0420 17:20:02.620414 38983 sgd_solver.cpp:105] Iteration 56700, lr = 0.0001
I0420 17:20:25.628775 38983 solver.cpp:219] Iteration 56800 (4.34623 iter/s, 23.0084s/100 iters), loss = 0.33645
I0420 17:20:25.628830 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:20:25.628835 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:20:25.628842 38983 solver.cpp:238]     Train net output #2: loss = 0.33645 (* 1 = 0.33645 loss)
I0420 17:20:25.628846 38983 sgd_solver.cpp:105] Iteration 56800, lr = 0.0001
I0420 17:20:41.733103 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:20:48.524176 38983 solver.cpp:219] Iteration 56900 (4.36812 iter/s, 22.8932s/100 iters), loss = 0.273958
I0420 17:20:48.524230 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:20:48.524235 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:20:48.524242 38983 solver.cpp:238]     Train net output #2: loss = 0.273958 (* 1 = 0.273958 loss)
I0420 17:20:48.524246 38983 sgd_solver.cpp:105] Iteration 56900, lr = 0.0001
I0420 17:21:11.279706 38983 solver.cpp:331] Iteration 57000, Testing net (#0)
I0420 17:21:16.191732 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:21:16.319319 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8639
I0420 17:21:16.319346 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 17:21:16.319371 38983 solver.cpp:398]     Test net output #2: loss = 0.442629 (* 1 = 0.442629 loss)
I0420 17:21:16.538300 38983 solver.cpp:219] Iteration 57000 (3.56991 iter/s, 28.0119s/100 iters), loss = 0.258545
I0420 17:21:16.538321 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:21:16.538342 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:21:16.538347 38983 solver.cpp:238]     Train net output #2: loss = 0.258545 (* 1 = 0.258545 loss)
I0420 17:21:16.538353 38983 sgd_solver.cpp:105] Iteration 57000, lr = 0.0001
I0420 17:21:39.506615 38983 solver.cpp:219] Iteration 57100 (4.35426 iter/s, 22.966s/100 iters), loss = 0.218073
I0420 17:21:39.506669 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 17:21:39.506675 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:21:39.506683 38983 solver.cpp:238]     Train net output #2: loss = 0.218073 (* 1 = 0.218073 loss)
I0420 17:21:39.506688 38983 sgd_solver.cpp:105] Iteration 57100, lr = 0.0001
I0420 17:22:03.685778 38983 solver.cpp:219] Iteration 57200 (4.13581 iter/s, 24.1791s/100 iters), loss = 0.333989
I0420 17:22:03.686014 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:22:03.686022 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:22:03.686029 38983 solver.cpp:238]     Train net output #2: loss = 0.333989 (* 1 = 0.333989 loss)
I0420 17:22:03.686033 38983 sgd_solver.cpp:105] Iteration 57200, lr = 0.0001
I0420 17:22:17.676342 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:22:26.578521 38983 solver.cpp:219] Iteration 57300 (4.36861 iter/s, 22.8906s/100 iters), loss = 0.288127
I0420 17:22:26.578575 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:22:26.578580 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:22:26.578586 38983 solver.cpp:238]     Train net output #2: loss = 0.288127 (* 1 = 0.288127 loss)
I0420 17:22:26.578591 38983 sgd_solver.cpp:105] Iteration 57300, lr = 0.0001
I0420 17:22:49.580188 38983 solver.cpp:219] Iteration 57400 (4.34758 iter/s, 23.0013s/100 iters), loss = 0.309019
I0420 17:22:49.580391 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:22:49.580399 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:22:49.580405 38983 solver.cpp:238]     Train net output #2: loss = 0.309019 (* 1 = 0.309019 loss)
I0420 17:22:49.580410 38983 sgd_solver.cpp:105] Iteration 57400, lr = 0.0001
I0420 17:23:12.484098 38983 solver.cpp:219] Iteration 57500 (4.36648 iter/s, 22.9017s/100 iters), loss = 0.297221
I0420 17:23:12.484153 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:23:12.484158 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:23:12.484165 38983 solver.cpp:238]     Train net output #2: loss = 0.297221 (* 1 = 0.297221 loss)
I0420 17:23:12.484169 38983 sgd_solver.cpp:105] Iteration 57500, lr = 0.0001
I0420 17:23:35.444380 38983 solver.cpp:219] Iteration 57600 (4.35537 iter/s, 22.9602s/100 iters), loss = 0.321915
I0420 17:23:35.444581 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:23:35.444587 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:23:35.444594 38983 solver.cpp:238]     Train net output #2: loss = 0.321915 (* 1 = 0.321915 loss)
I0420 17:23:35.444598 38983 sgd_solver.cpp:105] Iteration 57600, lr = 0.0001
I0420 17:23:47.444619 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:23:58.411111 38983 solver.cpp:219] Iteration 57700 (4.35454 iter/s, 22.9646s/100 iters), loss = 0.266974
I0420 17:23:58.411165 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:23:58.411170 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:23:58.411176 38983 solver.cpp:238]     Train net output #2: loss = 0.266974 (* 1 = 0.266974 loss)
I0420 17:23:58.411180 38983 sgd_solver.cpp:105] Iteration 57700, lr = 0.0001
I0420 17:24:21.349203 38983 solver.cpp:219] Iteration 57800 (4.3596 iter/s, 22.9379s/100 iters), loss = 0.336149
I0420 17:24:21.349351 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 17:24:21.349357 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:24:21.349364 38983 solver.cpp:238]     Train net output #2: loss = 0.336149 (* 1 = 0.336149 loss)
I0420 17:24:21.349370 38983 sgd_solver.cpp:105] Iteration 57800, lr = 0.0001
I0420 17:24:44.338675 38983 solver.cpp:219] Iteration 57900 (4.35023 iter/s, 22.9873s/100 iters), loss = 0.169008
I0420 17:24:44.338738 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 17:24:44.338744 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:24:44.338750 38983 solver.cpp:238]     Train net output #2: loss = 0.169008 (* 1 = 0.169008 loss)
I0420 17:24:44.338754 38983 sgd_solver.cpp:105] Iteration 57900, lr = 0.0001
I0420 17:25:07.049214 38983 solver.cpp:331] Iteration 58000, Testing net (#0)
I0420 17:25:11.923895 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:25:12.164110 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8634
I0420 17:25:12.164137 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9941
I0420 17:25:12.164160 38983 solver.cpp:398]     Test net output #2: loss = 0.442828 (* 1 = 0.442828 loss)
I0420 17:25:12.338131 38983 solver.cpp:219] Iteration 58000 (3.57151 iter/s, 27.9994s/100 iters), loss = 0.336795
I0420 17:25:12.338150 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:25:12.338172 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:25:12.338177 38983 solver.cpp:238]     Train net output #2: loss = 0.336795 (* 1 = 0.336795 loss)
I0420 17:25:12.338183 38983 sgd_solver.cpp:105] Iteration 58000, lr = 0.0001
I0420 17:25:21.993105 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:25:35.261606 38983 solver.cpp:219] Iteration 58100 (4.36236 iter/s, 22.9234s/100 iters), loss = 0.325319
I0420 17:25:35.261659 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 17:25:35.261664 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:25:35.261670 38983 solver.cpp:238]     Train net output #2: loss = 0.325319 (* 1 = 0.325319 loss)
I0420 17:25:35.261674 38983 sgd_solver.cpp:105] Iteration 58100, lr = 0.0001
I0420 17:25:58.258819 38983 solver.cpp:219] Iteration 58200 (4.34876 iter/s, 22.9951s/100 iters), loss = 0.28793
I0420 17:25:58.258905 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 17:25:58.258913 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:25:58.258919 38983 solver.cpp:238]     Train net output #2: loss = 0.28793 (* 1 = 0.28793 loss)
I0420 17:25:58.258924 38983 sgd_solver.cpp:105] Iteration 58200, lr = 0.0001
I0420 17:26:21.187993 38983 solver.cpp:219] Iteration 58300 (4.36128 iter/s, 22.9291s/100 iters), loss = 0.223158
I0420 17:26:21.188048 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 17:26:21.188053 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:26:21.188060 38983 solver.cpp:238]     Train net output #2: loss = 0.223158 (* 1 = 0.223158 loss)
I0420 17:26:21.188064 38983 sgd_solver.cpp:105] Iteration 58300, lr = 0.0001
I0420 17:26:44.169123 38983 solver.cpp:219] Iteration 58400 (4.35182 iter/s, 22.9789s/100 iters), loss = 0.37787
I0420 17:26:44.169307 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 17:26:44.169314 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:26:44.169320 38983 solver.cpp:238]     Train net output #2: loss = 0.37787 (* 1 = 0.37787 loss)
I0420 17:26:44.169325 38983 sgd_solver.cpp:105] Iteration 58400, lr = 0.0001
I0420 17:26:51.803215 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:27:07.091564 38983 solver.cpp:219] Iteration 58500 (4.36259 iter/s, 22.9221s/100 iters), loss = 0.350626
I0420 17:27:07.091615 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:27:07.091620 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:27:07.091626 38983 solver.cpp:238]     Train net output #2: loss = 0.350626 (* 1 = 0.350626 loss)
I0420 17:27:07.091630 38983 sgd_solver.cpp:105] Iteration 58500, lr = 0.0001
I0420 17:27:30.076010 38983 solver.cpp:219] Iteration 58600 (4.35118 iter/s, 22.9823s/100 iters), loss = 0.315591
I0420 17:27:30.076259 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:27:30.076267 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:27:30.076274 38983 solver.cpp:238]     Train net output #2: loss = 0.315591 (* 1 = 0.315591 loss)
I0420 17:27:30.076279 38983 sgd_solver.cpp:105] Iteration 58600, lr = 0.0001
I0420 17:27:52.995846 38983 solver.cpp:219] Iteration 58700 (4.36307 iter/s, 22.9196s/100 iters), loss = 0.449773
I0420 17:27:52.995899 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 17:27:52.995905 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:27:52.995911 38983 solver.cpp:238]     Train net output #2: loss = 0.449773 (* 1 = 0.449773 loss)
I0420 17:27:52.995915 38983 sgd_solver.cpp:105] Iteration 58700, lr = 0.0001
I0420 17:28:16.003829 38983 solver.cpp:219] Iteration 58800 (4.34635 iter/s, 23.0078s/100 iters), loss = 0.421088
I0420 17:28:16.003959 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:28:16.003967 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:28:16.003973 38983 solver.cpp:238]     Train net output #2: loss = 0.421088 (* 1 = 0.421088 loss)
I0420 17:28:16.003978 38983 sgd_solver.cpp:105] Iteration 58800, lr = 0.0001
I0420 17:28:21.470438 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:28:38.855327 38983 solver.cpp:219] Iteration 58900 (4.3765 iter/s, 22.8493s/100 iters), loss = 0.256288
I0420 17:28:38.855361 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:28:38.855383 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:28:38.855389 38983 solver.cpp:238]     Train net output #2: loss = 0.256288 (* 1 = 0.256288 loss)
I0420 17:28:38.855393 38983 sgd_solver.cpp:105] Iteration 58900, lr = 0.0001
I0420 17:29:01.632354 38983 solver.cpp:331] Iteration 59000, Testing net (#0)
I0420 17:29:06.507359 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:29:06.670457 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8632
I0420 17:29:06.670485 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9944
I0420 17:29:06.670509 38983 solver.cpp:398]     Test net output #2: loss = 0.44265 (* 1 = 0.44265 loss)
I0420 17:29:06.855489 38983 solver.cpp:219] Iteration 59000 (3.57172 iter/s, 27.9977s/100 iters), loss = 0.26468
I0420 17:29:06.855509 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 17:29:06.855530 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:29:06.855537 38983 solver.cpp:238]     Train net output #2: loss = 0.26468 (* 1 = 0.26468 loss)
I0420 17:29:06.855543 38983 sgd_solver.cpp:105] Iteration 59000, lr = 0.0001
I0420 17:29:29.852708 38983 solver.cpp:219] Iteration 59100 (4.34876 iter/s, 22.9951s/100 iters), loss = 0.217516
I0420 17:29:29.852766 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 17:29:29.852771 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:29:29.852777 38983 solver.cpp:238]     Train net output #2: loss = 0.217516 (* 1 = 0.217516 loss)
I0420 17:29:29.852782 38983 sgd_solver.cpp:105] Iteration 59100, lr = 0.0001
I0420 17:29:52.736986 38983 solver.cpp:219] Iteration 59200 (4.37023 iter/s, 22.8821s/100 iters), loss = 0.284039
I0420 17:29:52.737108 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:29:52.737114 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:29:52.737120 38983 solver.cpp:238]     Train net output #2: loss = 0.284039 (* 1 = 0.284039 loss)
I0420 17:29:52.737125 38983 sgd_solver.cpp:105] Iteration 59200, lr = 0.0001
I0420 17:29:56.052759 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:30:15.752184 38983 solver.cpp:219] Iteration 59300 (4.34539 iter/s, 23.0129s/100 iters), loss = 0.373793
I0420 17:30:15.752223 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 17:30:15.752228 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:30:15.752235 38983 solver.cpp:238]     Train net output #2: loss = 0.373793 (* 1 = 0.373793 loss)
I0420 17:30:15.752239 38983 sgd_solver.cpp:105] Iteration 59300, lr = 0.0001
I0420 17:30:38.623775 38983 solver.cpp:219] Iteration 59400 (4.37265 iter/s, 22.8694s/100 iters), loss = 0.162865
I0420 17:30:38.624024 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 17:30:38.624032 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:30:38.624039 38983 solver.cpp:238]     Train net output #2: loss = 0.162865 (* 1 = 0.162865 loss)
I0420 17:30:38.624044 38983 sgd_solver.cpp:105] Iteration 59400, lr = 0.0001
I0420 17:31:01.633913 38983 solver.cpp:219] Iteration 59500 (4.34636 iter/s, 23.0078s/100 iters), loss = 0.267052
I0420 17:31:01.633967 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 17:31:01.633972 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:31:01.633978 38983 solver.cpp:238]     Train net output #2: loss = 0.267052 (* 1 = 0.267052 loss)
I0420 17:31:01.633982 38983 sgd_solver.cpp:105] Iteration 59500, lr = 0.0001
I0420 17:31:24.519111 38983 solver.cpp:219] Iteration 59600 (4.37006 iter/s, 22.883s/100 iters), loss = 0.320047
I0420 17:31:24.519305 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:31:24.519312 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:31:24.519318 38983 solver.cpp:238]     Train net output #2: loss = 0.320047 (* 1 = 0.320047 loss)
I0420 17:31:24.519323 38983 sgd_solver.cpp:105] Iteration 59600, lr = 0.0001
I0420 17:31:25.707967 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:31:47.522333 38983 solver.cpp:219] Iteration 59700 (4.34765 iter/s, 23.001s/100 iters), loss = 0.255113
I0420 17:31:47.522405 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 17:31:47.522410 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:31:47.522418 38983 solver.cpp:238]     Train net output #2: loss = 0.255113 (* 1 = 0.255113 loss)
I0420 17:31:47.522423 38983 sgd_solver.cpp:105] Iteration 59700, lr = 0.0001
I0420 17:32:11.649961 38983 solver.cpp:219] Iteration 59800 (4.14501 iter/s, 24.1254s/100 iters), loss = 0.303551
I0420 17:32:11.650116 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 17:32:11.650123 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:32:11.650130 38983 solver.cpp:238]     Train net output #2: loss = 0.303551 (* 1 = 0.303551 loss)
I0420 17:32:11.650135 38983 sgd_solver.cpp:105] Iteration 59800, lr = 0.0001
I0420 17:32:34.647632 38983 solver.cpp:219] Iteration 59900 (4.3487 iter/s, 22.9954s/100 iters), loss = 0.270326
I0420 17:32:34.647689 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:32:34.647694 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:32:34.647701 38983 solver.cpp:238]     Train net output #2: loss = 0.270326 (* 1 = 0.270326 loss)
I0420 17:32:34.647706 38983 sgd_solver.cpp:105] Iteration 59900, lr = 0.0001
I0420 17:32:56.445794 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:32:57.365727 38983 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_finetune_quant_0.09_iter_60000.caffemodel
I0420 17:32:57.395916 38983 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_finetune_quant_0.09_iter_60000.solverstate
I0420 17:32:57.417286 38983 solver.cpp:331] Iteration 60000, Testing net (#0)
I0420 17:33:02.298127 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:33:02.537711 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8628
I0420 17:33:02.537740 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 17:33:02.537765 38983 solver.cpp:398]     Test net output #2: loss = 0.443025 (* 1 = 0.443025 loss)
I0420 17:33:02.656754 38983 solver.cpp:219] Iteration 60000 (3.57054 iter/s, 28.007s/100 iters), loss = 0.21852
I0420 17:33:02.656777 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 17:33:02.656798 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:33:02.656805 38983 solver.cpp:238]     Train net output #2: loss = 0.21852 (* 1 = 0.21852 loss)
I0420 17:33:02.656810 38983 sgd_solver.cpp:105] Iteration 60000, lr = 0.0001
I0420 17:33:25.645095 38983 solver.cpp:219] Iteration 60100 (4.35005 iter/s, 22.9882s/100 iters), loss = 0.201996
I0420 17:33:25.645151 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 17:33:25.645156 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:33:25.645162 38983 solver.cpp:238]     Train net output #2: loss = 0.201996 (* 1 = 0.201996 loss)
I0420 17:33:25.645167 38983 sgd_solver.cpp:105] Iteration 60100, lr = 0.0001
I0420 17:33:48.542464 38983 solver.cpp:219] Iteration 60200 (4.36773 iter/s, 22.8952s/100 iters), loss = 0.301164
I0420 17:33:48.542680 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:33:48.542691 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:33:48.542698 38983 solver.cpp:238]     Train net output #2: loss = 0.301164 (* 1 = 0.301164 loss)
I0420 17:33:48.542702 38983 sgd_solver.cpp:105] Iteration 60200, lr = 0.0001
I0420 17:34:11.567162 38983 solver.cpp:219] Iteration 60300 (4.34357 iter/s, 23.0225s/100 iters), loss = 0.271434
I0420 17:34:11.567214 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:34:11.567219 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:34:11.567224 38983 solver.cpp:238]     Train net output #2: loss = 0.271434 (* 1 = 0.271434 loss)
I0420 17:34:11.567229 38983 sgd_solver.cpp:105] Iteration 60300, lr = 0.0001
I0420 17:34:31.360098 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:34:34.468578 38983 solver.cpp:219] Iteration 60400 (4.36697 iter/s, 22.8992s/100 iters), loss = 0.263991
I0420 17:34:34.468632 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:34:34.468637 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:34:34.468644 38983 solver.cpp:238]     Train net output #2: loss = 0.263991 (* 1 = 0.263991 loss)
I0420 17:34:34.468648 38983 sgd_solver.cpp:105] Iteration 60400, lr = 0.0001
I0420 17:34:57.463029 38983 solver.cpp:219] Iteration 60500 (4.34932 iter/s, 22.9921s/100 iters), loss = 0.370223
I0420 17:34:57.463084 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:34:57.463089 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:34:57.463095 38983 solver.cpp:238]     Train net output #2: loss = 0.370223 (* 1 = 0.370223 loss)
I0420 17:34:57.463099 38983 sgd_solver.cpp:105] Iteration 60500, lr = 0.0001
I0420 17:35:20.337148 38983 solver.cpp:219] Iteration 60600 (4.3722 iter/s, 22.8718s/100 iters), loss = 0.470725
I0420 17:35:20.337334 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 17:35:20.337342 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:35:20.337348 38983 solver.cpp:238]     Train net output #2: loss = 0.470725 (* 1 = 0.470725 loss)
I0420 17:35:20.337352 38983 sgd_solver.cpp:105] Iteration 60600, lr = 0.0001
I0420 17:35:43.360368 38983 solver.cpp:219] Iteration 60700 (4.34352 iter/s, 23.0228s/100 iters), loss = 0.200213
I0420 17:35:43.360421 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:35:43.360426 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:35:43.360432 38983 solver.cpp:238]     Train net output #2: loss = 0.200213 (* 1 = 0.200213 loss)
I0420 17:35:43.360436 38983 sgd_solver.cpp:105] Iteration 60700, lr = 0.0001
I0420 17:36:01.040627 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:36:06.250948 38983 solver.cpp:219] Iteration 60800 (4.36904 iter/s, 22.8883s/100 iters), loss = 0.22072
I0420 17:36:06.250986 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:36:06.251008 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:36:06.251015 38983 solver.cpp:238]     Train net output #2: loss = 0.22072 (* 1 = 0.22072 loss)
I0420 17:36:06.251019 38983 sgd_solver.cpp:105] Iteration 60800, lr = 0.0001
I0420 17:36:29.235297 38983 solver.cpp:219] Iteration 60900 (4.35108 iter/s, 22.9828s/100 iters), loss = 0.366523
I0420 17:36:29.235354 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 17:36:29.235359 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:36:29.235365 38983 solver.cpp:238]     Train net output #2: loss = 0.366523 (* 1 = 0.366523 loss)
I0420 17:36:29.235370 38983 sgd_solver.cpp:105] Iteration 60900, lr = 0.0001
I0420 17:36:52.019151 38983 solver.cpp:331] Iteration 61000, Testing net (#0)
I0420 17:36:56.830219 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:36:57.028167 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.863
I0420 17:36:57.028195 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 17:36:57.028231 38983 solver.cpp:398]     Test net output #2: loss = 0.442853 (* 1 = 0.442853 loss)
I0420 17:36:57.257424 38983 solver.cpp:219] Iteration 61000 (3.56888 iter/s, 28.02s/100 iters), loss = 0.20437
I0420 17:36:57.257448 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 17:36:57.257470 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:36:57.257477 38983 solver.cpp:238]     Train net output #2: loss = 0.20437 (* 1 = 0.20437 loss)
I0420 17:36:57.257483 38983 sgd_solver.cpp:105] Iteration 61000, lr = 0.0001
I0420 17:37:20.143867 38983 solver.cpp:219] Iteration 61100 (4.36984 iter/s, 22.8841s/100 iters), loss = 0.353215
I0420 17:37:20.143923 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:37:20.143928 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:37:20.143934 38983 solver.cpp:238]     Train net output #2: loss = 0.353215 (* 1 = 0.353215 loss)
I0420 17:37:20.143937 38983 sgd_solver.cpp:105] Iteration 61100, lr = 0.0001
I0420 17:37:35.581454 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:37:43.128749 38983 solver.cpp:219] Iteration 61200 (4.35071 iter/s, 22.9848s/100 iters), loss = 0.238256
I0420 17:37:43.128800 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:37:43.128805 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:37:43.128813 38983 solver.cpp:238]     Train net output #2: loss = 0.238256 (* 1 = 0.238256 loss)
I0420 17:37:43.128816 38983 sgd_solver.cpp:105] Iteration 61200, lr = 0.0001
I0420 17:38:06.046489 38983 solver.cpp:219] Iteration 61300 (4.36385 iter/s, 22.9156s/100 iters), loss = 0.467818
I0420 17:38:06.046566 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 17:38:06.046571 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:38:06.046577 38983 solver.cpp:238]     Train net output #2: loss = 0.467818 (* 1 = 0.467818 loss)
I0420 17:38:06.046582 38983 sgd_solver.cpp:105] Iteration 61300, lr = 0.0001
I0420 17:38:29.012183 38983 solver.cpp:219] Iteration 61400 (4.35435 iter/s, 22.9655s/100 iters), loss = 0.308773
I0420 17:38:29.012238 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:38:29.012244 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:38:29.012250 38983 solver.cpp:238]     Train net output #2: loss = 0.308773 (* 1 = 0.308773 loss)
I0420 17:38:29.012255 38983 sgd_solver.cpp:105] Iteration 61400, lr = 0.0001
I0420 17:38:51.967816 38983 solver.cpp:219] Iteration 61500 (4.35664 iter/s, 22.9535s/100 iters), loss = 0.26931
I0420 17:38:51.968000 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:38:51.968006 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:38:51.968014 38983 solver.cpp:238]     Train net output #2: loss = 0.26931 (* 1 = 0.26931 loss)
I0420 17:38:51.968019 38983 sgd_solver.cpp:105] Iteration 61500, lr = 0.0001
I0420 17:39:05.338912 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:39:14.932288 38983 solver.cpp:219] Iteration 61600 (4.35459 iter/s, 22.9643s/100 iters), loss = 0.25952
I0420 17:39:14.932340 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:39:14.932345 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:39:14.932351 38983 solver.cpp:238]     Train net output #2: loss = 0.25952 (* 1 = 0.25952 loss)
I0420 17:39:14.932355 38983 sgd_solver.cpp:105] Iteration 61600, lr = 0.0001
I0420 17:39:37.887557 38983 solver.cpp:219] Iteration 61700 (4.35675 iter/s, 22.9529s/100 iters), loss = 0.282047
I0420 17:39:37.887801 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:39:37.887809 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:39:37.887816 38983 solver.cpp:238]     Train net output #2: loss = 0.282047 (* 1 = 0.282047 loss)
I0420 17:39:37.887820 38983 sgd_solver.cpp:105] Iteration 61700, lr = 0.0001
I0420 17:40:00.830912 38983 solver.cpp:219] Iteration 61800 (4.35862 iter/s, 22.943s/100 iters), loss = 0.303301
I0420 17:40:00.830966 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:40:00.830971 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:40:00.830978 38983 solver.cpp:238]     Train net output #2: loss = 0.303301 (* 1 = 0.303301 loss)
I0420 17:40:00.830983 38983 sgd_solver.cpp:105] Iteration 61800, lr = 0.0001
I0420 17:40:23.803789 38983 solver.cpp:219] Iteration 61900 (4.35337 iter/s, 22.9707s/100 iters), loss = 0.289812
I0420 17:40:23.803922 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:40:23.803930 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:40:23.803936 38983 solver.cpp:238]     Train net output #2: loss = 0.289812 (* 1 = 0.289812 loss)
I0420 17:40:23.803941 38983 sgd_solver.cpp:105] Iteration 61900, lr = 0.0001
I0420 17:40:35.093621 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:40:46.521711 38983 solver.cpp:331] Iteration 62000, Testing net (#0)
I0420 17:40:51.398085 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:40:51.639868 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.863
I0420 17:40:51.639891 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9944
I0420 17:40:51.639915 38983 solver.cpp:398]     Test net output #2: loss = 0.442822 (* 1 = 0.442822 loss)
I0420 17:40:51.781659 38983 solver.cpp:219] Iteration 62000 (3.57427 iter/s, 27.9777s/100 iters), loss = 0.307879
I0420 17:40:51.781700 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 17:40:51.781705 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:40:51.781729 38983 solver.cpp:238]     Train net output #2: loss = 0.307879 (* 1 = 0.307879 loss)
I0420 17:40:51.781735 38983 sgd_solver.cpp:105] Iteration 62000, lr = 0.0001
I0420 17:41:14.743074 38983 solver.cpp:219] Iteration 62100 (4.35515 iter/s, 22.9613s/100 iters), loss = 0.148947
I0420 17:41:14.743259 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 17:41:14.743265 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:41:14.743273 38983 solver.cpp:238]     Train net output #2: loss = 0.148947 (* 1 = 0.148947 loss)
I0420 17:41:14.743276 38983 sgd_solver.cpp:105] Iteration 62100, lr = 0.0001
I0420 17:41:37.670325 38983 solver.cpp:219] Iteration 62200 (4.36205 iter/s, 22.925s/100 iters), loss = 0.285243
I0420 17:41:37.670380 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:41:37.670387 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:41:37.670394 38983 solver.cpp:238]     Train net output #2: loss = 0.285243 (* 1 = 0.285243 loss)
I0420 17:41:37.670398 38983 sgd_solver.cpp:105] Iteration 62200, lr = 0.0001
I0420 17:42:00.769932 38983 solver.cpp:219] Iteration 62300 (4.32912 iter/s, 23.0994s/100 iters), loss = 0.329161
I0420 17:42:00.770089 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:42:00.770097 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:42:00.770102 38983 solver.cpp:238]     Train net output #2: loss = 0.329161 (* 1 = 0.329161 loss)
I0420 17:42:00.770107 38983 sgd_solver.cpp:105] Iteration 62300, lr = 0.0001
I0420 17:42:10.676394 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:42:24.670825 38983 solver.cpp:219] Iteration 62400 (4.18407 iter/s, 23.9002s/100 iters), loss = 0.273157
I0420 17:42:24.670874 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:42:24.670879 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:42:24.670886 38983 solver.cpp:238]     Train net output #2: loss = 0.273157 (* 1 = 0.273157 loss)
I0420 17:42:24.670889 38983 sgd_solver.cpp:105] Iteration 62400, lr = 0.0001
I0420 17:42:47.571161 38983 solver.cpp:219] Iteration 62500 (4.36719 iter/s, 22.898s/100 iters), loss = 0.248529
I0420 17:42:47.571388 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:42:47.571396 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:42:47.571403 38983 solver.cpp:238]     Train net output #2: loss = 0.248529 (* 1 = 0.248529 loss)
I0420 17:42:47.571408 38983 sgd_solver.cpp:105] Iteration 62500, lr = 0.0001
I0420 17:43:10.575103 38983 solver.cpp:219] Iteration 62600 (4.3472 iter/s, 23.0033s/100 iters), loss = 0.317631
I0420 17:43:10.575158 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 17:43:10.575163 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:43:10.575170 38983 solver.cpp:238]     Train net output #2: loss = 0.317631 (* 1 = 0.317631 loss)
I0420 17:43:10.575175 38983 sgd_solver.cpp:105] Iteration 62600, lr = 0.0001
I0420 17:43:33.493366 38983 solver.cpp:219] Iteration 62700 (4.36374 iter/s, 22.9161s/100 iters), loss = 0.240678
I0420 17:43:33.493506 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:43:33.493530 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:43:33.493536 38983 solver.cpp:238]     Train net output #2: loss = 0.240677 (* 1 = 0.240677 loss)
I0420 17:43:33.493541 38983 sgd_solver.cpp:105] Iteration 62700, lr = 0.0001
I0420 17:43:40.467785 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:43:56.460381 38983 solver.cpp:219] Iteration 62800 (4.35409 iter/s, 22.9669s/100 iters), loss = 0.3026
I0420 17:43:56.460438 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:43:56.460443 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:43:56.460449 38983 solver.cpp:238]     Train net output #2: loss = 0.3026 (* 1 = 0.3026 loss)
I0420 17:43:56.460453 38983 sgd_solver.cpp:105] Iteration 62800, lr = 0.0001
I0420 17:44:19.396028 38983 solver.cpp:219] Iteration 62900 (4.36044 iter/s, 22.9335s/100 iters), loss = 0.327551
I0420 17:44:19.396143 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 17:44:19.396150 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:44:19.396157 38983 solver.cpp:238]     Train net output #2: loss = 0.327551 (* 1 = 0.327551 loss)
I0420 17:44:19.396162 38983 sgd_solver.cpp:105] Iteration 62900, lr = 0.0001
I0420 17:44:42.149374 38983 solver.cpp:331] Iteration 63000, Testing net (#0)
I0420 17:44:47.040380 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:44:47.278133 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8633
I0420 17:44:47.278161 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9944
I0420 17:44:47.278184 38983 solver.cpp:398]     Test net output #2: loss = 0.442687 (* 1 = 0.442687 loss)
I0420 17:44:47.392482 38983 solver.cpp:219] Iteration 63000 (3.5719 iter/s, 27.9963s/100 iters), loss = 0.348156
I0420 17:44:47.392503 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 17:44:47.392524 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:44:47.392530 38983 solver.cpp:238]     Train net output #2: loss = 0.348156 (* 1 = 0.348156 loss)
I0420 17:44:47.392536 38983 sgd_solver.cpp:105] Iteration 63000, lr = 0.0001
I0420 17:45:10.382246 38983 solver.cpp:219] Iteration 63100 (4.34979 iter/s, 22.9896s/100 iters), loss = 0.23747
I0420 17:45:10.382367 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:45:10.382375 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:45:10.382380 38983 solver.cpp:238]     Train net output #2: loss = 0.23747 (* 1 = 0.23747 loss)
I0420 17:45:10.382385 38983 sgd_solver.cpp:105] Iteration 63100, lr = 0.0001
I0420 17:45:14.987541 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:45:33.294821 38983 solver.cpp:219] Iteration 63200 (4.36485 iter/s, 22.9103s/100 iters), loss = 0.335741
I0420 17:45:33.294875 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:45:33.294881 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:45:33.294888 38983 solver.cpp:238]     Train net output #2: loss = 0.335741 (* 1 = 0.335741 loss)
I0420 17:45:33.294891 38983 sgd_solver.cpp:105] Iteration 63200, lr = 0.0001
I0420 17:45:56.269640 38983 solver.cpp:219] Iteration 63300 (4.35261 iter/s, 22.9747s/100 iters), loss = 0.385083
I0420 17:45:56.269819 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0420 17:45:56.269826 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:45:56.269832 38983 solver.cpp:238]     Train net output #2: loss = 0.385082 (* 1 = 0.385082 loss)
I0420 17:45:56.269836 38983 sgd_solver.cpp:105] Iteration 63300, lr = 0.0001
I0420 17:46:19.208920 38983 solver.cpp:219] Iteration 63400 (4.35976 iter/s, 22.9371s/100 iters), loss = 0.272542
I0420 17:46:19.208973 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:46:19.208979 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:46:19.208986 38983 solver.cpp:238]     Train net output #2: loss = 0.272542 (* 1 = 0.272542 loss)
I0420 17:46:19.208989 38983 sgd_solver.cpp:105] Iteration 63400, lr = 0.0001
I0420 17:46:42.149070 38983 solver.cpp:219] Iteration 63500 (4.35921 iter/s, 22.9399s/100 iters), loss = 0.235703
I0420 17:46:42.149242 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 17:46:42.149250 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:46:42.149256 38983 solver.cpp:238]     Train net output #2: loss = 0.235703 (* 1 = 0.235703 loss)
I0420 17:46:42.149261 38983 sgd_solver.cpp:105] Iteration 63500, lr = 0.0001
I0420 17:46:44.762691 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:47:05.128799 38983 solver.cpp:219] Iteration 63600 (4.35207 iter/s, 22.9776s/100 iters), loss = 0.304933
I0420 17:47:05.128854 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:47:05.128859 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:47:05.128865 38983 solver.cpp:238]     Train net output #2: loss = 0.304933 (* 1 = 0.304933 loss)
I0420 17:47:05.128870 38983 sgd_solver.cpp:105] Iteration 63600, lr = 0.0001
I0420 17:47:28.046494 38983 solver.cpp:219] Iteration 63700 (4.36346 iter/s, 22.9176s/100 iters), loss = 0.229474
I0420 17:47:28.046648 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:47:28.046654 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:47:28.046661 38983 solver.cpp:238]     Train net output #2: loss = 0.229474 (* 1 = 0.229474 loss)
I0420 17:47:28.046665 38983 sgd_solver.cpp:105] Iteration 63700, lr = 0.0001
I0420 17:47:51.040495 38983 solver.cpp:219] Iteration 63800 (4.34941 iter/s, 22.9916s/100 iters), loss = 0.419865
I0420 17:47:51.040546 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 17:47:51.040551 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 17:47:51.040558 38983 solver.cpp:238]     Train net output #2: loss = 0.419865 (* 1 = 0.419865 loss)
I0420 17:47:51.040562 38983 sgd_solver.cpp:105] Iteration 63800, lr = 0.0001
I0420 17:48:13.944591 38983 solver.cpp:219] Iteration 63900 (4.36647 iter/s, 22.9018s/100 iters), loss = 0.213022
I0420 17:48:13.944715 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:48:13.944721 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:48:13.944727 38983 solver.cpp:238]     Train net output #2: loss = 0.213022 (* 1 = 0.213022 loss)
I0420 17:48:13.944732 38983 sgd_solver.cpp:105] Iteration 63900, lr = 0.0001
I0420 17:48:14.438542 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:48:36.731613 38983 solver.cpp:331] Iteration 64000, Testing net (#0)
I0420 17:48:41.612982 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:48:41.756214 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8629
I0420 17:48:41.756240 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 17:48:41.756264 38983 solver.cpp:398]     Test net output #2: loss = 0.443373 (* 1 = 0.443373 loss)
I0420 17:48:41.977048 38983 solver.cpp:219] Iteration 64000 (3.56759 iter/s, 28.0301s/100 iters), loss = 0.244114
I0420 17:48:41.977069 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:48:41.977092 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:48:41.977097 38983 solver.cpp:238]     Train net output #2: loss = 0.244114 (* 1 = 0.244114 loss)
I0420 17:48:41.977102 38983 sgd_solver.cpp:105] Iteration 64000, lr = 0.0001
I0420 17:49:04.936635 38983 solver.cpp:219] Iteration 64100 (4.35591 iter/s, 22.9573s/100 iters), loss = 0.304316
I0420 17:49:04.936866 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:49:04.936874 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:49:04.936882 38983 solver.cpp:238]     Train net output #2: loss = 0.304316 (* 1 = 0.304316 loss)
I0420 17:49:04.936887 38983 sgd_solver.cpp:105] Iteration 64100, lr = 0.0001
I0420 17:49:27.874996 38983 solver.cpp:219] Iteration 64200 (4.35957 iter/s, 22.938s/100 iters), loss = 0.370452
I0420 17:49:27.875046 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 17:49:27.875052 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:49:27.875058 38983 solver.cpp:238]     Train net output #2: loss = 0.370452 (* 1 = 0.370452 loss)
I0420 17:49:27.875062 38983 sgd_solver.cpp:105] Iteration 64200, lr = 0.0001
I0420 17:49:49.055198 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:49:50.858587 38983 solver.cpp:219] Iteration 64300 (4.35135 iter/s, 22.9814s/100 iters), loss = 0.314353
I0420 17:49:50.858640 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:49:50.858645 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:49:50.858652 38983 solver.cpp:238]     Train net output #2: loss = 0.314352 (* 1 = 0.314352 loss)
I0420 17:49:50.858656 38983 sgd_solver.cpp:105] Iteration 64300, lr = 0.0001
I0420 17:50:13.781270 38983 solver.cpp:219] Iteration 64400 (4.36251 iter/s, 22.9226s/100 iters), loss = 0.249194
I0420 17:50:13.781323 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:50:13.781328 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:50:13.781334 38983 solver.cpp:238]     Train net output #2: loss = 0.249194 (* 1 = 0.249194 loss)
I0420 17:50:13.781338 38983 sgd_solver.cpp:105] Iteration 64400, lr = 0.0001
I0420 17:50:36.753237 38983 solver.cpp:219] Iteration 64500 (4.35355 iter/s, 22.9698s/100 iters), loss = 0.197822
I0420 17:50:36.753442 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 17:50:36.753448 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:50:36.753454 38983 solver.cpp:238]     Train net output #2: loss = 0.197821 (* 1 = 0.197821 loss)
I0420 17:50:36.753458 38983 sgd_solver.cpp:105] Iteration 64500, lr = 0.0001
I0420 17:50:59.672144 38983 solver.cpp:219] Iteration 64600 (4.36325 iter/s, 22.9187s/100 iters), loss = 0.213103
I0420 17:50:59.672195 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:50:59.672200 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:50:59.672207 38983 solver.cpp:238]     Train net output #2: loss = 0.213103 (* 1 = 0.213103 loss)
I0420 17:50:59.672211 38983 sgd_solver.cpp:105] Iteration 64600, lr = 0.0001
I0420 17:51:18.763840 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:51:22.671406 38983 solver.cpp:219] Iteration 64700 (4.34839 iter/s, 22.997s/100 iters), loss = 0.225252
I0420 17:51:22.671458 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 17:51:22.671463 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:51:22.671470 38983 solver.cpp:238]     Train net output #2: loss = 0.225252 (* 1 = 0.225252 loss)
I0420 17:51:22.671474 38983 sgd_solver.cpp:105] Iteration 64700, lr = 0.0001
I0420 17:51:45.570124 38983 solver.cpp:219] Iteration 64800 (4.36712 iter/s, 22.8984s/100 iters), loss = 0.358135
I0420 17:51:45.570178 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:51:45.570183 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:51:45.570189 38983 solver.cpp:238]     Train net output #2: loss = 0.358135 (* 1 = 0.358135 loss)
I0420 17:51:45.570194 38983 sgd_solver.cpp:105] Iteration 64800, lr = 0.0001
I0420 17:52:08.742589 38983 solver.cpp:219] Iteration 64900 (4.31549 iter/s, 23.1723s/100 iters), loss = 0.309418
I0420 17:52:08.742676 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 17:52:08.742691 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:52:08.742697 38983 solver.cpp:238]     Train net output #2: loss = 0.309418 (* 1 = 0.309418 loss)
I0420 17:52:08.742700 38983 sgd_solver.cpp:105] Iteration 64900, lr = 0.0001
I0420 17:52:32.515548 38983 solver.cpp:331] Iteration 65000, Testing net (#0)
I0420 17:52:37.442447 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:52:37.585085 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8631
I0420 17:52:37.585111 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 17:52:37.585136 38983 solver.cpp:398]     Test net output #2: loss = 0.44331 (* 1 = 0.44331 loss)
I0420 17:52:37.791021 38983 solver.cpp:219] Iteration 65000 (3.44266 iter/s, 29.0473s/100 iters), loss = 0.339584
I0420 17:52:37.791043 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 17:52:37.791064 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:52:37.791069 38983 solver.cpp:238]     Train net output #2: loss = 0.339583 (* 1 = 0.339583 loss)
I0420 17:52:37.791075 38983 sgd_solver.cpp:105] Iteration 65000, lr = 0.0001
I0420 17:52:54.832446 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:53:00.791184 38983 solver.cpp:219] Iteration 65100 (4.34821 iter/s, 22.998s/100 iters), loss = 0.20733
I0420 17:53:00.791236 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:53:00.791241 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:53:00.791247 38983 solver.cpp:238]     Train net output #2: loss = 0.20733 (* 1 = 0.20733 loss)
I0420 17:53:00.791251 38983 sgd_solver.cpp:105] Iteration 65100, lr = 0.0001
I0420 17:53:23.707170 38983 solver.cpp:219] Iteration 65200 (4.36379 iter/s, 22.9159s/100 iters), loss = 0.268393
I0420 17:53:23.707226 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 17:53:23.707231 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:53:23.707238 38983 solver.cpp:238]     Train net output #2: loss = 0.268393 (* 1 = 0.268393 loss)
I0420 17:53:23.707242 38983 sgd_solver.cpp:105] Iteration 65200, lr = 0.0001
I0420 17:53:46.695824 38983 solver.cpp:219] Iteration 65300 (4.35042 iter/s, 22.9863s/100 iters), loss = 0.324087
I0420 17:53:46.696012 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:53:46.696018 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:53:46.696025 38983 solver.cpp:238]     Train net output #2: loss = 0.324087 (* 1 = 0.324087 loss)
I0420 17:53:46.696030 38983 sgd_solver.cpp:105] Iteration 65300, lr = 0.0001
I0420 17:54:09.602887 38983 solver.cpp:219] Iteration 65400 (4.36552 iter/s, 22.9068s/100 iters), loss = 0.264874
I0420 17:54:09.602942 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:54:09.602947 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:54:09.602954 38983 solver.cpp:238]     Train net output #2: loss = 0.264874 (* 1 = 0.264874 loss)
I0420 17:54:09.602958 38983 sgd_solver.cpp:105] Iteration 65400, lr = 0.0001
I0420 17:54:24.311774 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:54:32.579511 38983 solver.cpp:219] Iteration 65500 (4.35268 iter/s, 22.9743s/100 iters), loss = 0.303791
I0420 17:54:32.579562 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:54:32.579566 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:54:32.579573 38983 solver.cpp:238]     Train net output #2: loss = 0.303791 (* 1 = 0.303791 loss)
I0420 17:54:32.579577 38983 sgd_solver.cpp:105] Iteration 65500, lr = 0.0001
I0420 17:54:55.445396 38983 solver.cpp:219] Iteration 65600 (4.37376 iter/s, 22.8636s/100 iters), loss = 0.249858
I0420 17:54:55.445606 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:54:55.445614 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:54:55.445622 38983 solver.cpp:238]     Train net output #2: loss = 0.249858 (* 1 = 0.249858 loss)
I0420 17:54:55.445627 38983 sgd_solver.cpp:105] Iteration 65600, lr = 0.0001
I0420 17:55:18.460686 38983 solver.cpp:219] Iteration 65700 (4.34539 iter/s, 23.0129s/100 iters), loss = 0.250925
I0420 17:55:18.460739 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:55:18.460746 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:55:18.460752 38983 solver.cpp:238]     Train net output #2: loss = 0.250925 (* 1 = 0.250925 loss)
I0420 17:55:18.460755 38983 sgd_solver.cpp:105] Iteration 65700, lr = 0.0001
I0420 17:55:41.340934 38983 solver.cpp:219] Iteration 65800 (4.371 iter/s, 22.8781s/100 iters), loss = 0.257861
I0420 17:55:41.341720 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 17:55:41.341743 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:55:41.341750 38983 solver.cpp:238]     Train net output #2: loss = 0.257861 (* 1 = 0.257861 loss)
I0420 17:55:41.341754 38983 sgd_solver.cpp:105] Iteration 65800, lr = 0.0001
I0420 17:55:54.025475 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:56:04.342064 38983 solver.cpp:219] Iteration 65900 (4.34802 iter/s, 22.999s/100 iters), loss = 0.352434
I0420 17:56:04.342115 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 17:56:04.342120 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:56:04.342128 38983 solver.cpp:238]     Train net output #2: loss = 0.352434 (* 1 = 0.352434 loss)
I0420 17:56:04.342133 38983 sgd_solver.cpp:105] Iteration 65900, lr = 0.0001
I0420 17:56:27.069941 38983 solver.cpp:331] Iteration 66000, Testing net (#0)
I0420 17:56:31.934742 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:56:32.168926 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8625
I0420 17:56:32.168952 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 17:56:32.168977 38983 solver.cpp:398]     Test net output #2: loss = 0.444391 (* 1 = 0.444391 loss)
I0420 17:56:32.355254 38983 solver.cpp:219] Iteration 66000 (3.57003 iter/s, 28.011s/100 iters), loss = 0.217548
I0420 17:56:32.355278 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 17:56:32.355298 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:56:32.355305 38983 solver.cpp:238]     Train net output #2: loss = 0.217548 (* 1 = 0.217548 loss)
I0420 17:56:32.355311 38983 sgd_solver.cpp:105] Iteration 66000, lr = 0.0001
I0420 17:56:55.282660 38983 solver.cpp:219] Iteration 66100 (4.36163 iter/s, 22.9272s/100 iters), loss = 0.3478
I0420 17:56:55.282718 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 17:56:55.282723 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:56:55.282730 38983 solver.cpp:238]     Train net output #2: loss = 0.3478 (* 1 = 0.3478 loss)
I0420 17:56:55.282734 38983 sgd_solver.cpp:105] Iteration 66100, lr = 0.0001
I0420 17:57:18.265436 38983 solver.cpp:219] Iteration 66200 (4.3515 iter/s, 22.9806s/100 iters), loss = 0.31146
I0420 17:57:18.265559 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 17:57:18.265566 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:57:18.265573 38983 solver.cpp:238]     Train net output #2: loss = 0.31146 (* 1 = 0.31146 loss)
I0420 17:57:18.265578 38983 sgd_solver.cpp:105] Iteration 66200, lr = 0.0001
I0420 17:57:28.612124 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:57:41.198662 38983 solver.cpp:219] Iteration 66300 (4.36053 iter/s, 22.933s/100 iters), loss = 0.316332
I0420 17:57:41.198712 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:57:41.198719 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:57:41.198724 38983 solver.cpp:238]     Train net output #2: loss = 0.316332 (* 1 = 0.316332 loss)
I0420 17:57:41.198729 38983 sgd_solver.cpp:105] Iteration 66300, lr = 0.0001
I0420 17:58:04.199851 38983 solver.cpp:219] Iteration 66400 (4.34803 iter/s, 22.9989s/100 iters), loss = 0.179544
I0420 17:58:04.200016 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 17:58:04.200022 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:58:04.200028 38983 solver.cpp:238]     Train net output #2: loss = 0.179544 (* 1 = 0.179544 loss)
I0420 17:58:04.200033 38983 sgd_solver.cpp:105] Iteration 66400, lr = 0.0001
I0420 17:58:27.104724 38983 solver.cpp:219] Iteration 66500 (4.36592 iter/s, 22.9047s/100 iters), loss = 0.251685
I0420 17:58:27.104763 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:58:27.104784 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:58:27.104791 38983 solver.cpp:238]     Train net output #2: loss = 0.251685 (* 1 = 0.251685 loss)
I0420 17:58:27.104796 38983 sgd_solver.cpp:105] Iteration 66500, lr = 0.0001
I0420 17:58:50.089803 38983 solver.cpp:219] Iteration 66600 (4.35107 iter/s, 22.9828s/100 iters), loss = 0.334383
I0420 17:58:50.089995 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 17:58:50.090003 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:58:50.090009 38983 solver.cpp:238]     Train net output #2: loss = 0.334383 (* 1 = 0.334383 loss)
I0420 17:58:50.090013 38983 sgd_solver.cpp:105] Iteration 66600, lr = 0.0001
I0420 17:58:58.402498 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 17:59:13.006376 38983 solver.cpp:219] Iteration 66700 (4.36371 iter/s, 22.9163s/100 iters), loss = 0.21872
I0420 17:59:13.006430 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 17:59:13.006435 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:59:13.006443 38983 solver.cpp:238]     Train net output #2: loss = 0.21872 (* 1 = 0.21872 loss)
I0420 17:59:13.006446 38983 sgd_solver.cpp:105] Iteration 66700, lr = 0.0001
I0420 17:59:35.991195 38983 solver.cpp:219] Iteration 66800 (4.35111 iter/s, 22.9826s/100 iters), loss = 0.348082
I0420 17:59:35.991344 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 17:59:35.991351 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 17:59:35.991358 38983 solver.cpp:238]     Train net output #2: loss = 0.348081 (* 1 = 0.348081 loss)
I0420 17:59:35.991363 38983 sgd_solver.cpp:105] Iteration 66800, lr = 0.0001
I0420 17:59:58.915889 38983 solver.cpp:219] Iteration 66900 (4.36215 iter/s, 22.9245s/100 iters), loss = 0.410164
I0420 17:59:58.915943 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 17:59:58.915948 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 17:59:58.915956 38983 solver.cpp:238]     Train net output #2: loss = 0.410164 (* 1 = 0.410164 loss)
I0420 17:59:58.915959 38983 sgd_solver.cpp:105] Iteration 66900, lr = 0.0001
I0420 18:00:21.686980 38983 solver.cpp:331] Iteration 67000, Testing net (#0)
I0420 18:00:26.551785 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:00:26.688282 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8639
I0420 18:00:26.688310 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9939
I0420 18:00:26.688335 38983 solver.cpp:398]     Test net output #2: loss = 0.443172 (* 1 = 0.443172 loss)
I0420 18:00:26.894605 38983 solver.cpp:219] Iteration 67000 (3.57444 iter/s, 27.9764s/100 iters), loss = 0.303175
I0420 18:00:26.894625 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 18:00:26.894646 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:00:26.894652 38983 solver.cpp:238]     Train net output #2: loss = 0.303175 (* 1 = 0.303175 loss)
I0420 18:00:26.894659 38983 sgd_solver.cpp:105] Iteration 67000, lr = 0.0001
I0420 18:00:33.177531 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:00:49.895972 38983 solver.cpp:219] Iteration 67100 (4.34801 iter/s, 22.999s/100 iters), loss = 0.270818
I0420 18:00:49.896009 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:00:49.896030 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:00:49.896039 38983 solver.cpp:238]     Train net output #2: loss = 0.270818 (* 1 = 0.270818 loss)
I0420 18:00:49.896042 38983 sgd_solver.cpp:105] Iteration 67100, lr = 0.0001
I0420 18:01:12.801129 38983 solver.cpp:219] Iteration 67200 (4.36586 iter/s, 22.905s/100 iters), loss = 0.296808
I0420 18:01:12.801383 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 18:01:12.801391 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:01:12.801398 38983 solver.cpp:238]     Train net output #2: loss = 0.296808 (* 1 = 0.296808 loss)
I0420 18:01:12.801403 38983 sgd_solver.cpp:105] Iteration 67200, lr = 0.0001
I0420 18:01:35.827023 38983 solver.cpp:219] Iteration 67300 (4.34299 iter/s, 23.0256s/100 iters), loss = 0.306504
I0420 18:01:35.827074 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 18:01:35.827080 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:01:35.827085 38983 solver.cpp:238]     Train net output #2: loss = 0.306504 (* 1 = 0.306504 loss)
I0420 18:01:35.827090 38983 sgd_solver.cpp:105] Iteration 67300, lr = 0.0001
I0420 18:01:58.744693 38983 solver.cpp:219] Iteration 67400 (4.36387 iter/s, 22.9154s/100 iters), loss = 0.235617
I0420 18:01:58.744874 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 18:01:58.744881 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:01:58.744889 38983 solver.cpp:238]     Train net output #2: loss = 0.235617 (* 1 = 0.235617 loss)
I0420 18:01:58.744895 38983 sgd_solver.cpp:105] Iteration 67400, lr = 0.0001
I0420 18:02:02.683497 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:02:22.412860 38983 solver.cpp:219] Iteration 67500 (4.22549 iter/s, 23.6659s/100 iters), loss = 0.201422
I0420 18:02:22.412919 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:02:22.412924 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:02:22.412930 38983 solver.cpp:238]     Train net output #2: loss = 0.201422 (* 1 = 0.201422 loss)
I0420 18:02:22.412935 38983 sgd_solver.cpp:105] Iteration 67500, lr = 0.0001
I0420 18:02:45.854517 38983 solver.cpp:219] Iteration 67600 (4.26633 iter/s, 23.4393s/100 iters), loss = 0.336257
I0420 18:02:45.854732 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:02:45.854739 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:02:45.854745 38983 solver.cpp:238]     Train net output #2: loss = 0.336257 (* 1 = 0.336257 loss)
I0420 18:02:45.854750 38983 sgd_solver.cpp:105] Iteration 67600, lr = 0.0001
I0420 18:03:08.717732 38983 solver.cpp:219] Iteration 67700 (4.37428 iter/s, 22.8609s/100 iters), loss = 0.201796
I0420 18:03:08.717793 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 18:03:08.717799 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:03:08.717806 38983 solver.cpp:238]     Train net output #2: loss = 0.201796 (* 1 = 0.201796 loss)
I0420 18:03:08.717810 38983 sgd_solver.cpp:105] Iteration 67700, lr = 0.0001
I0420 18:03:31.693092 38983 solver.cpp:219] Iteration 67800 (4.3529 iter/s, 22.9732s/100 iters), loss = 0.256976
I0420 18:03:31.693226 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 18:03:31.693234 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:03:31.693241 38983 solver.cpp:238]     Train net output #2: loss = 0.256976 (* 1 = 0.256976 loss)
I0420 18:03:31.693245 38983 sgd_solver.cpp:105] Iteration 67800, lr = 0.0001
I0420 18:03:33.529000 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:03:54.549105 38983 solver.cpp:219] Iteration 67900 (4.37563 iter/s, 22.8538s/100 iters), loss = 0.260908
I0420 18:03:54.549162 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 18:03:54.549167 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:03:54.549175 38983 solver.cpp:238]     Train net output #2: loss = 0.260907 (* 1 = 0.260907 loss)
I0420 18:03:54.549180 38983 sgd_solver.cpp:105] Iteration 67900, lr = 0.0001
I0420 18:04:17.273437 38983 solver.cpp:331] Iteration 68000, Testing net (#0)
I0420 18:04:22.103044 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:04:22.277617 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8641
I0420 18:04:22.277654 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9941
I0420 18:04:22.277678 38983 solver.cpp:398]     Test net output #2: loss = 0.442716 (* 1 = 0.442716 loss)
I0420 18:04:22.446499 38983 solver.cpp:219] Iteration 68000 (3.58485 iter/s, 27.8951s/100 iters), loss = 0.184798
I0420 18:04:22.446521 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 18:04:22.446542 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:04:22.446548 38983 solver.cpp:238]     Train net output #2: loss = 0.184798 (* 1 = 0.184798 loss)
I0420 18:04:22.446553 38983 sgd_solver.cpp:105] Iteration 68000, lr = 0.0001
I0420 18:04:45.443801 38983 solver.cpp:219] Iteration 68100 (4.34877 iter/s, 22.995s/100 iters), loss = 0.347383
I0420 18:04:45.443856 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:04:45.443862 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:04:45.443868 38983 solver.cpp:238]     Train net output #2: loss = 0.347383 (* 1 = 0.347383 loss)
I0420 18:04:45.443873 38983 sgd_solver.cpp:105] Iteration 68100, lr = 0.0001
I0420 18:05:08.172330 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:05:08.310431 38983 solver.cpp:219] Iteration 68200 (4.37362 iter/s, 22.8644s/100 iters), loss = 0.313877
I0420 18:05:08.310490 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 18:05:08.310495 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:05:08.310503 38983 solver.cpp:238]     Train net output #2: loss = 0.313877 (* 1 = 0.313877 loss)
I0420 18:05:08.310506 38983 sgd_solver.cpp:105] Iteration 68200, lr = 0.0001
I0420 18:05:31.384845 38983 solver.cpp:219] Iteration 68300 (4.33422 iter/s, 23.0722s/100 iters), loss = 0.280642
I0420 18:05:31.384901 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:05:31.384905 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:05:31.384912 38983 solver.cpp:238]     Train net output #2: loss = 0.280641 (* 1 = 0.280641 loss)
I0420 18:05:31.384917 38983 sgd_solver.cpp:105] Iteration 68300, lr = 0.0001
I0420 18:05:54.302115 38983 solver.cpp:219] Iteration 68400 (4.36355 iter/s, 22.9171s/100 iters), loss = 0.42833
I0420 18:05:54.302294 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 18:05:54.302301 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:05:54.302309 38983 solver.cpp:238]     Train net output #2: loss = 0.428329 (* 1 = 0.428329 loss)
I0420 18:05:54.302314 38983 sgd_solver.cpp:105] Iteration 68400, lr = 0.0001
I0420 18:06:17.301903 38983 solver.cpp:219] Iteration 68500 (4.34829 iter/s, 22.9976s/100 iters), loss = 0.364873
I0420 18:06:17.301954 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 18:06:17.301959 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:06:17.301965 38983 solver.cpp:238]     Train net output #2: loss = 0.364872 (* 1 = 0.364872 loss)
I0420 18:06:17.301970 38983 sgd_solver.cpp:105] Iteration 68500, lr = 0.0001
I0420 18:06:37.691833 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:06:40.189954 38983 solver.cpp:219] Iteration 68600 (4.36953 iter/s, 22.8858s/100 iters), loss = 0.321877
I0420 18:06:40.190007 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:06:40.190012 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0420 18:06:40.190019 38983 solver.cpp:238]     Train net output #2: loss = 0.321877 (* 1 = 0.321877 loss)
I0420 18:06:40.190023 38983 sgd_solver.cpp:105] Iteration 68600, lr = 0.0001
I0420 18:07:03.190865 38983 solver.cpp:219] Iteration 68700 (4.34811 iter/s, 22.9985s/100 iters), loss = 0.389263
I0420 18:07:03.190919 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 18:07:03.190924 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:07:03.190930 38983 solver.cpp:238]     Train net output #2: loss = 0.389263 (* 1 = 0.389263 loss)
I0420 18:07:03.190935 38983 sgd_solver.cpp:105] Iteration 68700, lr = 0.0001
I0420 18:07:26.074663 38983 solver.cpp:219] Iteration 68800 (4.37032 iter/s, 22.8816s/100 iters), loss = 0.227755
I0420 18:07:26.074790 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:07:26.074797 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:07:26.074805 38983 solver.cpp:238]     Train net output #2: loss = 0.227755 (* 1 = 0.227755 loss)
I0420 18:07:26.074808 38983 sgd_solver.cpp:105] Iteration 68800, lr = 0.0001
I0420 18:07:49.096112 38983 solver.cpp:219] Iteration 68900 (4.34421 iter/s, 23.0191s/100 iters), loss = 0.218944
I0420 18:07:49.096163 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:07:49.096168 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:07:49.096175 38983 solver.cpp:238]     Train net output #2: loss = 0.218944 (* 1 = 0.218944 loss)
I0420 18:07:49.096179 38983 sgd_solver.cpp:105] Iteration 68900, lr = 0.0001
I0420 18:08:07.470971 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:08:11.867835 38983 solver.cpp:331] Iteration 69000, Testing net (#0)
I0420 18:08:16.644565 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:08:16.858280 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8633
I0420 18:08:16.858306 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 18:08:16.858330 38983 solver.cpp:398]     Test net output #2: loss = 0.442853 (* 1 = 0.442853 loss)
I0420 18:08:17.088371 38983 solver.cpp:219] Iteration 69000 (3.57268 iter/s, 27.9902s/100 iters), loss = 0.287583
I0420 18:08:17.088392 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:08:17.088413 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:08:17.088418 38983 solver.cpp:238]     Train net output #2: loss = 0.287583 (* 1 = 0.287583 loss)
I0420 18:08:17.088424 38983 sgd_solver.cpp:105] Iteration 69000, lr = 0.0001
I0420 18:08:39.965826 38983 solver.cpp:219] Iteration 69100 (4.37159 iter/s, 22.875s/100 iters), loss = 0.376432
I0420 18:08:39.966007 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 18:08:39.966014 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 18:08:39.966022 38983 solver.cpp:238]     Train net output #2: loss = 0.376431 (* 1 = 0.376431 loss)
I0420 18:08:39.966025 38983 sgd_solver.cpp:105] Iteration 69100, lr = 0.0001
I0420 18:09:02.969069 38983 solver.cpp:219] Iteration 69200 (4.34764 iter/s, 23.001s/100 iters), loss = 0.219202
I0420 18:09:02.969123 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 18:09:02.969128 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:09:02.969135 38983 solver.cpp:238]     Train net output #2: loss = 0.219202 (* 1 = 0.219202 loss)
I0420 18:09:02.969138 38983 sgd_solver.cpp:105] Iteration 69200, lr = 0.0001
I0420 18:09:25.847167 38983 solver.cpp:219] Iteration 69300 (4.37144 iter/s, 22.8758s/100 iters), loss = 0.311865
I0420 18:09:25.847290 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 18:09:25.847297 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:09:25.847304 38983 solver.cpp:238]     Train net output #2: loss = 0.311865 (* 1 = 0.311865 loss)
I0420 18:09:25.847308 38983 sgd_solver.cpp:105] Iteration 69300, lr = 0.0001
I0420 18:09:41.959751 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:09:48.852646 38983 solver.cpp:219] Iteration 69400 (4.34723 iter/s, 23.0032s/100 iters), loss = 0.330404
I0420 18:09:48.852701 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 18:09:48.852707 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:09:48.852713 38983 solver.cpp:238]     Train net output #2: loss = 0.330404 (* 1 = 0.330404 loss)
I0420 18:09:48.852717 38983 sgd_solver.cpp:105] Iteration 69400, lr = 0.0001
I0420 18:10:11.774724 38983 solver.cpp:219] Iteration 69500 (4.36302 iter/s, 22.9199s/100 iters), loss = 0.250114
I0420 18:10:11.774930 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 18:10:11.774936 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:10:11.774942 38983 solver.cpp:238]     Train net output #2: loss = 0.250114 (* 1 = 0.250114 loss)
I0420 18:10:11.774947 38983 sgd_solver.cpp:105] Iteration 69500, lr = 0.0001
I0420 18:10:34.740110 38983 solver.cpp:219] Iteration 69600 (4.35444 iter/s, 22.9651s/100 iters), loss = 0.160446
I0420 18:10:34.740164 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 18:10:34.740170 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:10:34.740176 38983 solver.cpp:238]     Train net output #2: loss = 0.160446 (* 1 = 0.160446 loss)
I0420 18:10:34.740180 38983 sgd_solver.cpp:105] Iteration 69600, lr = 0.0001
I0420 18:10:57.685799 38983 solver.cpp:219] Iteration 69700 (4.35854 iter/s, 22.9435s/100 iters), loss = 0.335844
I0420 18:10:57.685991 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 18:10:57.685997 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:10:57.686003 38983 solver.cpp:238]     Train net output #2: loss = 0.335844 (* 1 = 0.335844 loss)
I0420 18:10:57.686008 38983 sgd_solver.cpp:105] Iteration 69700, lr = 0.0001
I0420 18:11:11.737412 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:11:20.627084 38983 solver.cpp:219] Iteration 69800 (4.35899 iter/s, 22.9411s/100 iters), loss = 0.247608
I0420 18:11:20.627132 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 18:11:20.627137 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:11:20.627144 38983 solver.cpp:238]     Train net output #2: loss = 0.247608 (* 1 = 0.247608 loss)
I0420 18:11:20.627148 38983 sgd_solver.cpp:105] Iteration 69800, lr = 0.0001
I0420 18:11:43.589740 38983 solver.cpp:219] Iteration 69900 (4.35533 iter/s, 22.9604s/100 iters), loss = 0.309843
I0420 18:11:43.589892 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:11:43.589900 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:11:43.589906 38983 solver.cpp:238]     Train net output #2: loss = 0.309843 (* 1 = 0.309843 loss)
I0420 18:11:43.589910 38983 sgd_solver.cpp:105] Iteration 69900, lr = 0.0001
I0420 18:12:06.311318 38983 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_finetune_quant_0.09_iter_70000.caffemodel
I0420 18:12:06.370090 38983 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_finetune_quant_0.09_iter_70000.solverstate
I0420 18:12:06.398079 38983 solver.cpp:331] Iteration 70000, Testing net (#0)
I0420 18:12:11.311292 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:12:11.476300 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8627
I0420 18:12:11.476326 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9944
I0420 18:12:11.476351 38983 solver.cpp:398]     Test net output #2: loss = 0.443527 (* 1 = 0.443527 loss)
I0420 18:12:11.662777 38983 solver.cpp:219] Iteration 70000 (3.56214 iter/s, 28.073s/100 iters), loss = 0.233301
I0420 18:12:11.662797 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:12:11.662818 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:12:11.662824 38983 solver.cpp:238]     Train net output #2: loss = 0.233301 (* 1 = 0.233301 loss)
I0420 18:12:11.662830 38983 sgd_solver.cpp:105] Iteration 70000, lr = 0.0001
I0420 18:12:35.830328 38983 solver.cpp:219] Iteration 70100 (4.13819 iter/s, 24.1652s/100 iters), loss = 0.235643
I0420 18:12:35.830453 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:12:35.830461 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:12:35.830466 38983 solver.cpp:238]     Train net output #2: loss = 0.235643 (* 1 = 0.235643 loss)
I0420 18:12:35.830471 38983 sgd_solver.cpp:105] Iteration 70100, lr = 0.0001
I0420 18:12:47.785750 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:12:58.802294 38983 solver.cpp:219] Iteration 70200 (4.35316 iter/s, 22.9718s/100 iters), loss = 0.263734
I0420 18:12:58.802350 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:12:58.802355 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:12:58.802361 38983 solver.cpp:238]     Train net output #2: loss = 0.263734 (* 1 = 0.263734 loss)
I0420 18:12:58.802366 38983 sgd_solver.cpp:105] Iteration 70200, lr = 0.0001
I0420 18:13:21.752954 38983 solver.cpp:219] Iteration 70300 (4.35759 iter/s, 22.9485s/100 iters), loss = 0.339545
I0420 18:13:21.753161 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 18:13:21.753168 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:13:21.753175 38983 solver.cpp:238]     Train net output #2: loss = 0.339545 (* 1 = 0.339545 loss)
I0420 18:13:21.753180 38983 sgd_solver.cpp:105] Iteration 70300, lr = 0.0001
I0420 18:13:44.687413 38983 solver.cpp:219] Iteration 70400 (4.36032 iter/s, 22.9341s/100 iters), loss = 0.26265
I0420 18:13:44.687463 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 18:13:44.687467 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:13:44.687474 38983 solver.cpp:238]     Train net output #2: loss = 0.26265 (* 1 = 0.26265 loss)
I0420 18:13:44.687479 38983 sgd_solver.cpp:105] Iteration 70400, lr = 0.0001
I0420 18:14:07.673023 38983 solver.cpp:219] Iteration 70500 (4.35096 iter/s, 22.9834s/100 iters), loss = 0.279301
I0420 18:14:07.673213 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 18:14:07.673220 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:14:07.673228 38983 solver.cpp:238]     Train net output #2: loss = 0.279301 (* 1 = 0.279301 loss)
I0420 18:14:07.673231 38983 sgd_solver.cpp:105] Iteration 70500, lr = 0.0001
I0420 18:14:17.284476 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:14:30.581660 38983 solver.cpp:219] Iteration 70600 (4.36524 iter/s, 22.9083s/100 iters), loss = 0.367004
I0420 18:14:30.581717 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 18:14:30.581723 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:14:30.581729 38983 solver.cpp:238]     Train net output #2: loss = 0.367004 (* 1 = 0.367004 loss)
I0420 18:14:30.581734 38983 sgd_solver.cpp:105] Iteration 70600, lr = 0.0001
I0420 18:14:53.596664 38983 solver.cpp:219] Iteration 70700 (4.34542 iter/s, 23.0128s/100 iters), loss = 0.388532
I0420 18:14:53.596834 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 18:14:53.596840 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:14:53.596848 38983 solver.cpp:238]     Train net output #2: loss = 0.388532 (* 1 = 0.388532 loss)
I0420 18:14:53.596851 38983 sgd_solver.cpp:105] Iteration 70700, lr = 0.0001
I0420 18:15:16.503474 38983 solver.cpp:219] Iteration 70800 (4.36588 iter/s, 22.9049s/100 iters), loss = 0.286267
I0420 18:15:16.503530 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:15:16.503535 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:15:16.503541 38983 solver.cpp:238]     Train net output #2: loss = 0.286267 (* 1 = 0.286267 loss)
I0420 18:15:16.503545 38983 sgd_solver.cpp:105] Iteration 70800, lr = 0.0001
I0420 18:15:39.488593 38983 solver.cpp:219] Iteration 70900 (4.35066 iter/s, 22.985s/100 iters), loss = 0.351815
I0420 18:15:39.488761 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 18:15:39.488786 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:15:39.488793 38983 solver.cpp:238]     Train net output #2: loss = 0.351815 (* 1 = 0.351815 loss)
I0420 18:15:39.488797 38983 sgd_solver.cpp:105] Iteration 70900, lr = 0.0001
I0420 18:15:47.083571 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:16:02.203112 38983 solver.cpp:331] Iteration 71000, Testing net (#0)
I0420 18:16:07.025595 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:16:07.260637 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8634
I0420 18:16:07.260663 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9944
I0420 18:16:07.260690 38983 solver.cpp:398]     Test net output #2: loss = 0.443022 (* 1 = 0.443022 loss)
I0420 18:16:07.482780 38983 solver.cpp:219] Iteration 71000 (3.57244 iter/s, 27.992s/100 iters), loss = 0.28796
I0420 18:16:07.482801 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 18:16:07.482822 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:16:07.482828 38983 solver.cpp:238]     Train net output #2: loss = 0.28796 (* 1 = 0.28796 loss)
I0420 18:16:07.482834 38983 sgd_solver.cpp:105] Iteration 71000, lr = 0.0001
I0420 18:16:30.380821 38983 solver.cpp:219] Iteration 71100 (4.36721 iter/s, 22.8979s/100 iters), loss = 0.214625
I0420 18:16:30.381016 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 18:16:30.381022 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:16:30.381028 38983 solver.cpp:238]     Train net output #2: loss = 0.214625 (* 1 = 0.214625 loss)
I0420 18:16:30.381033 38983 sgd_solver.cpp:105] Iteration 71100, lr = 0.0001
I0420 18:16:53.381343 38983 solver.cpp:219] Iteration 71200 (4.34816 iter/s, 22.9982s/100 iters), loss = 0.286186
I0420 18:16:53.381394 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:16:53.381399 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:16:53.381405 38983 solver.cpp:238]     Train net output #2: loss = 0.286186 (* 1 = 0.286186 loss)
I0420 18:16:53.381409 38983 sgd_solver.cpp:105] Iteration 71200, lr = 0.0001
I0420 18:17:16.271800 38983 solver.cpp:219] Iteration 71300 (4.36866 iter/s, 22.8903s/100 iters), loss = 0.321078
I0420 18:17:16.271965 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 18:17:16.271972 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:17:16.271980 38983 solver.cpp:238]     Train net output #2: loss = 0.321078 (* 1 = 0.321078 loss)
I0420 18:17:16.271983 38983 sgd_solver.cpp:105] Iteration 71300, lr = 0.0001
I0420 18:17:21.860821 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:17:39.273797 38983 solver.cpp:219] Iteration 71400 (4.34788 iter/s, 22.9997s/100 iters), loss = 0.256483
I0420 18:17:39.273850 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:17:39.273855 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:17:39.273861 38983 solver.cpp:238]     Train net output #2: loss = 0.256483 (* 1 = 0.256483 loss)
I0420 18:17:39.273866 38983 sgd_solver.cpp:105] Iteration 71400, lr = 0.0001
I0420 18:18:02.153020 38983 solver.cpp:219] Iteration 71500 (4.3712 iter/s, 22.877s/100 iters), loss = 0.245024
I0420 18:18:02.153249 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 18:18:02.153256 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:18:02.153264 38983 solver.cpp:238]     Train net output #2: loss = 0.245024 (* 1 = 0.245024 loss)
I0420 18:18:02.153267 38983 sgd_solver.cpp:105] Iteration 71500, lr = 0.0001
I0420 18:18:25.171156 38983 solver.cpp:219] Iteration 71600 (4.34483 iter/s, 23.0159s/100 iters), loss = 0.191532
I0420 18:18:25.171203 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 18:18:25.171208 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:18:25.171216 38983 solver.cpp:238]     Train net output #2: loss = 0.191532 (* 1 = 0.191532 loss)
I0420 18:18:25.171219 38983 sgd_solver.cpp:105] Iteration 71600, lr = 0.0001
I0420 18:18:48.071975 38983 solver.cpp:219] Iteration 71700 (4.36709 iter/s, 22.8986s/100 iters), loss = 0.253911
I0420 18:18:48.072160 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:18:48.072166 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:18:48.072173 38983 solver.cpp:238]     Train net output #2: loss = 0.25391 (* 1 = 0.25391 loss)
I0420 18:18:48.072177 38983 sgd_solver.cpp:105] Iteration 71700, lr = 0.0001
I0420 18:18:51.382709 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:19:11.062813 38983 solver.cpp:219] Iteration 71800 (4.34988 iter/s, 22.9891s/100 iters), loss = 0.421599
I0420 18:19:11.062867 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 18:19:11.062872 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:19:11.062878 38983 solver.cpp:238]     Train net output #2: loss = 0.421599 (* 1 = 0.421599 loss)
I0420 18:19:11.062882 38983 sgd_solver.cpp:105] Iteration 71800, lr = 0.0001
I0420 18:19:33.973258 38983 solver.cpp:219] Iteration 71900 (4.36525 iter/s, 22.9082s/100 iters), loss = 0.125239
I0420 18:19:33.973354 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0420 18:19:33.973361 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:19:33.973368 38983 solver.cpp:238]     Train net output #2: loss = 0.125239 (* 1 = 0.125239 loss)
I0420 18:19:33.973372 38983 sgd_solver.cpp:105] Iteration 71900, lr = 0.0001
I0420 18:19:56.721886 38983 solver.cpp:331] Iteration 72000, Testing net (#0)
I0420 18:20:01.642588 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:20:01.855942 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.863
I0420 18:20:01.855963 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 18:20:01.855986 38983 solver.cpp:398]     Test net output #2: loss = 0.443196 (* 1 = 0.443196 loss)
I0420 18:20:01.997895 38983 solver.cpp:219] Iteration 72000 (3.5683 iter/s, 28.0245s/100 iters), loss = 0.200456
I0420 18:20:01.997916 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 18:20:01.997937 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:20:01.997943 38983 solver.cpp:238]     Train net output #2: loss = 0.200456 (* 1 = 0.200456 loss)
I0420 18:20:01.997948 38983 sgd_solver.cpp:105] Iteration 72000, lr = 0.0001
I0420 18:20:24.992760 38983 solver.cpp:219] Iteration 72100 (4.34923 iter/s, 22.9926s/100 iters), loss = 0.300998
I0420 18:20:24.992919 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 18:20:24.992926 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 18:20:24.992933 38983 solver.cpp:238]     Train net output #2: loss = 0.300998 (* 1 = 0.300998 loss)
I0420 18:20:24.992938 38983 sgd_solver.cpp:105] Iteration 72100, lr = 0.0001
I0420 18:20:26.182749 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:20:47.900465 38983 solver.cpp:219] Iteration 72200 (4.36577 iter/s, 22.9055s/100 iters), loss = 0.270057
I0420 18:20:47.900501 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 18:20:47.900521 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:20:47.900528 38983 solver.cpp:238]     Train net output #2: loss = 0.270057 (* 1 = 0.270057 loss)
I0420 18:20:47.900532 38983 sgd_solver.cpp:105] Iteration 72200, lr = 0.0001
I0420 18:21:10.910619 38983 solver.cpp:219] Iteration 72300 (4.34633 iter/s, 23.0079s/100 iters), loss = 0.28221
I0420 18:21:10.910845 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:21:10.910852 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:21:10.910858 38983 solver.cpp:238]     Train net output #2: loss = 0.282209 (* 1 = 0.282209 loss)
I0420 18:21:10.910863 38983 sgd_solver.cpp:105] Iteration 72300, lr = 0.0001
I0420 18:21:33.788501 38983 solver.cpp:219] Iteration 72400 (4.37146 iter/s, 22.8756s/100 iters), loss = 0.296542
I0420 18:21:33.788539 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 18:21:33.788560 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:21:33.788568 38983 solver.cpp:238]     Train net output #2: loss = 0.296542 (* 1 = 0.296542 loss)
I0420 18:21:33.788571 38983 sgd_solver.cpp:105] Iteration 72400, lr = 0.0001
I0420 18:21:55.727478 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:21:56.802539 38983 solver.cpp:219] Iteration 72500 (4.34519 iter/s, 23.0139s/100 iters), loss = 0.289014
I0420 18:21:56.802585 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 18:21:56.802592 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:21:56.802597 38983 solver.cpp:238]     Train net output #2: loss = 0.289014 (* 1 = 0.289014 loss)
I0420 18:21:56.802601 38983 sgd_solver.cpp:105] Iteration 72500, lr = 0.0001
I0420 18:22:19.725025 38983 solver.cpp:219] Iteration 72600 (4.36295 iter/s, 22.9203s/100 iters), loss = 0.25013
I0420 18:22:19.725080 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:22:19.725085 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:22:19.725090 38983 solver.cpp:238]     Train net output #2: loss = 0.25013 (* 1 = 0.25013 loss)
I0420 18:22:19.725095 38983 sgd_solver.cpp:105] Iteration 72600, lr = 0.0001
I0420 18:22:43.846323 38983 solver.cpp:219] Iteration 72700 (4.14573 iter/s, 24.1212s/100 iters), loss = 0.291242
I0420 18:22:43.846485 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:22:43.846493 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:22:43.846500 38983 solver.cpp:238]     Train net output #2: loss = 0.291242 (* 1 = 0.291242 loss)
I0420 18:22:43.846504 38983 sgd_solver.cpp:105] Iteration 72700, lr = 0.0001
I0420 18:23:06.831151 38983 solver.cpp:219] Iteration 72800 (4.35074 iter/s, 22.9846s/100 iters), loss = 0.336559
I0420 18:23:06.831207 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 18:23:06.831213 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:23:06.831219 38983 solver.cpp:238]     Train net output #2: loss = 0.336559 (* 1 = 0.336559 loss)
I0420 18:23:06.831224 38983 sgd_solver.cpp:105] Iteration 72800, lr = 0.0001
I0420 18:23:26.612826 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:23:29.824172 38983 solver.cpp:219] Iteration 72900 (4.34958 iter/s, 22.9907s/100 iters), loss = 0.230947
I0420 18:23:29.824223 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:23:29.824228 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:23:29.824234 38983 solver.cpp:238]     Train net output #2: loss = 0.230947 (* 1 = 0.230947 loss)
I0420 18:23:29.824237 38983 sgd_solver.cpp:105] Iteration 72900, lr = 0.0001
I0420 18:23:52.596190 38983 solver.cpp:331] Iteration 73000, Testing net (#0)
I0420 18:23:57.392787 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:23:57.625489 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8643
I0420 18:23:57.625516 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9942
I0420 18:23:57.625540 38983 solver.cpp:398]     Test net output #2: loss = 0.44268 (* 1 = 0.44268 loss)
I0420 18:23:57.853334 38983 solver.cpp:219] Iteration 73000 (3.568 iter/s, 28.0269s/100 iters), loss = 0.325544
I0420 18:23:57.853355 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:23:57.853376 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 18:23:57.853382 38983 solver.cpp:238]     Train net output #2: loss = 0.325544 (* 1 = 0.325544 loss)
I0420 18:23:57.853389 38983 sgd_solver.cpp:105] Iteration 73000, lr = 0.0001
I0420 18:24:20.732911 38983 solver.cpp:219] Iteration 73100 (4.37113 iter/s, 22.8774s/100 iters), loss = 0.384814
I0420 18:24:20.732966 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 18:24:20.732971 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:24:20.732977 38983 solver.cpp:238]     Train net output #2: loss = 0.384814 (* 1 = 0.384814 loss)
I0420 18:24:20.732981 38983 sgd_solver.cpp:105] Iteration 73100, lr = 0.0001
I0420 18:24:43.734102 38983 solver.cpp:219] Iteration 73200 (4.34801 iter/s, 22.999s/100 iters), loss = 0.252804
I0420 18:24:43.734361 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 18:24:43.734369 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:24:43.734376 38983 solver.cpp:238]     Train net output #2: loss = 0.252804 (* 1 = 0.252804 loss)
I0420 18:24:43.734381 38983 sgd_solver.cpp:105] Iteration 73200, lr = 0.0001
I0420 18:25:01.410943 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:25:06.635390 38983 solver.cpp:219] Iteration 73300 (4.367 iter/s, 22.899s/100 iters), loss = 0.203489
I0420 18:25:06.635448 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 18:25:06.635454 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:25:06.635460 38983 solver.cpp:238]     Train net output #2: loss = 0.203489 (* 1 = 0.203489 loss)
I0420 18:25:06.635464 38983 sgd_solver.cpp:105] Iteration 73300, lr = 0.0001
I0420 18:25:29.637056 38983 solver.cpp:219] Iteration 73400 (4.34794 iter/s, 22.9994s/100 iters), loss = 0.367195
I0420 18:25:29.637213 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:25:29.637220 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:25:29.637226 38983 solver.cpp:238]     Train net output #2: loss = 0.367195 (* 1 = 0.367195 loss)
I0420 18:25:29.637231 38983 sgd_solver.cpp:105] Iteration 73400, lr = 0.0001
I0420 18:25:52.559011 38983 solver.cpp:219] Iteration 73500 (4.36305 iter/s, 22.9198s/100 iters), loss = 0.288192
I0420 18:25:52.559065 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 18:25:52.559070 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:25:52.559077 38983 solver.cpp:238]     Train net output #2: loss = 0.288192 (* 1 = 0.288192 loss)
I0420 18:25:52.559082 38983 sgd_solver.cpp:105] Iteration 73500, lr = 0.0001
I0420 18:26:15.509734 38983 solver.cpp:219] Iteration 73600 (4.3572 iter/s, 22.9505s/100 iters), loss = 0.29469
I0420 18:26:15.509918 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:26:15.509924 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:26:15.509932 38983 solver.cpp:238]     Train net output #2: loss = 0.29469 (* 1 = 0.29469 loss)
I0420 18:26:15.509937 38983 sgd_solver.cpp:105] Iteration 73600, lr = 0.0001
I0420 18:26:30.905917 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:26:38.458024 38983 solver.cpp:219] Iteration 73700 (4.35804 iter/s, 22.9461s/100 iters), loss = 0.184107
I0420 18:26:38.458076 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 18:26:38.458081 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:26:38.458088 38983 solver.cpp:238]     Train net output #2: loss = 0.184107 (* 1 = 0.184107 loss)
I0420 18:26:38.458092 38983 sgd_solver.cpp:105] Iteration 73700, lr = 0.0001
I0420 18:27:01.389061 38983 solver.cpp:219] Iteration 73800 (4.36093 iter/s, 22.9309s/100 iters), loss = 0.335584
I0420 18:27:01.389246 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 18:27:01.389253 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:27:01.389259 38983 solver.cpp:238]     Train net output #2: loss = 0.335584 (* 1 = 0.335584 loss)
I0420 18:27:01.389263 38983 sgd_solver.cpp:105] Iteration 73800, lr = 0.0001
I0420 18:27:24.370682 38983 solver.cpp:219] Iteration 73900 (4.35174 iter/s, 22.9793s/100 iters), loss = 0.363756
I0420 18:27:24.370736 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 18:27:24.370743 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:27:24.370748 38983 solver.cpp:238]     Train net output #2: loss = 0.363756 (* 1 = 0.363756 loss)
I0420 18:27:24.370753 38983 sgd_solver.cpp:105] Iteration 73900, lr = 0.0001
I0420 18:27:47.082578 38983 solver.cpp:331] Iteration 74000, Testing net (#0)
I0420 18:27:51.965476 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:27:52.207595 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8635
I0420 18:27:52.207623 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9944
I0420 18:27:52.207645 38983 solver.cpp:398]     Test net output #2: loss = 0.442141 (* 1 = 0.442141 loss)
I0420 18:27:52.368590 38983 solver.cpp:219] Iteration 74000 (3.5717 iter/s, 27.9978s/100 iters), loss = 0.276341
I0420 18:27:52.368612 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 18:27:52.368631 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:27:52.368638 38983 solver.cpp:238]     Train net output #2: loss = 0.276341 (* 1 = 0.276341 loss)
I0420 18:27:52.368643 38983 sgd_solver.cpp:105] Iteration 74000, lr = 0.0001
I0420 18:28:05.720618 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:28:15.327755 38983 solver.cpp:219] Iteration 74100 (4.35558 iter/s, 22.959s/100 iters), loss = 0.302376
I0420 18:28:15.327813 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:28:15.327819 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:28:15.327826 38983 solver.cpp:238]     Train net output #2: loss = 0.302376 (* 1 = 0.302376 loss)
I0420 18:28:15.327831 38983 sgd_solver.cpp:105] Iteration 74100, lr = 0.0001
I0420 18:28:38.267915 38983 solver.cpp:219] Iteration 74200 (4.35957 iter/s, 22.938s/100 iters), loss = 0.383267
I0420 18:28:38.268093 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 18:28:38.268100 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:28:38.268107 38983 solver.cpp:238]     Train net output #2: loss = 0.383267 (* 1 = 0.383267 loss)
I0420 18:28:38.268111 38983 sgd_solver.cpp:105] Iteration 74200, lr = 0.0001
I0420 18:29:01.199322 38983 solver.cpp:219] Iteration 74300 (4.36085 iter/s, 22.9313s/100 iters), loss = 0.374821
I0420 18:29:01.199379 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 18:29:01.199384 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:29:01.199391 38983 solver.cpp:238]     Train net output #2: loss = 0.374821 (* 1 = 0.374821 loss)
I0420 18:29:01.199395 38983 sgd_solver.cpp:105] Iteration 74300, lr = 0.0001
I0420 18:29:24.181341 38983 solver.cpp:219] Iteration 74400 (4.35165 iter/s, 22.9798s/100 iters), loss = 0.337074
I0420 18:29:24.181531 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:29:24.181537 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:29:24.181545 38983 solver.cpp:238]     Train net output #2: loss = 0.337074 (* 1 = 0.337074 loss)
I0420 18:29:24.181548 38983 sgd_solver.cpp:105] Iteration 74400, lr = 0.0001
I0420 18:29:35.472175 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:29:47.097422 38983 solver.cpp:219] Iteration 74500 (4.36381 iter/s, 22.9158s/100 iters), loss = 0.383166
I0420 18:29:47.097477 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 18:29:47.097482 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:29:47.097488 38983 solver.cpp:238]     Train net output #2: loss = 0.383166 (* 1 = 0.383166 loss)
I0420 18:29:47.097492 38983 sgd_solver.cpp:105] Iteration 74500, lr = 0.0001
I0420 18:30:10.088886 38983 solver.cpp:219] Iteration 74600 (4.34948 iter/s, 22.9913s/100 iters), loss = 0.20353
I0420 18:30:10.089130 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 18:30:10.089138 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:30:10.089145 38983 solver.cpp:238]     Train net output #2: loss = 0.20353 (* 1 = 0.20353 loss)
I0420 18:30:10.089149 38983 sgd_solver.cpp:105] Iteration 74600, lr = 0.0001
I0420 18:30:32.970913 38983 solver.cpp:219] Iteration 74700 (4.37067 iter/s, 22.8798s/100 iters), loss = 0.266677
I0420 18:30:32.970968 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 18:30:32.970973 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:30:32.970980 38983 solver.cpp:238]     Train net output #2: loss = 0.266677 (* 1 = 0.266677 loss)
I0420 18:30:32.970984 38983 sgd_solver.cpp:105] Iteration 74700, lr = 0.0001
I0420 18:30:55.983904 38983 solver.cpp:219] Iteration 74800 (4.3458 iter/s, 23.0107s/100 iters), loss = 0.388649
I0420 18:30:55.984099 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:30:55.984105 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:30:55.984112 38983 solver.cpp:238]     Train net output #2: loss = 0.388648 (* 1 = 0.388648 loss)
I0420 18:30:55.984117 38983 sgd_solver.cpp:105] Iteration 74800, lr = 0.0001
I0420 18:31:04.986352 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:31:18.873853 38983 solver.cpp:219] Iteration 74900 (4.36916 iter/s, 22.8877s/100 iters), loss = 0.336198
I0420 18:31:18.873908 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:31:18.873914 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:31:18.873919 38983 solver.cpp:238]     Train net output #2: loss = 0.336198 (* 1 = 0.336198 loss)
I0420 18:31:18.873924 38983 sgd_solver.cpp:105] Iteration 74900, lr = 0.0001
I0420 18:31:41.650933 38983 solver.cpp:331] Iteration 75000, Testing net (#0)
I0420 18:31:46.562305 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:31:46.731024 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8638
I0420 18:31:46.731065 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9946
I0420 18:31:46.731089 38983 solver.cpp:398]     Test net output #2: loss = 0.441963 (* 1 = 0.441963 loss)
I0420 18:31:46.915333 38983 solver.cpp:219] Iteration 75000 (3.56644 iter/s, 28.0392s/100 iters), loss = 0.324531
I0420 18:31:46.915362 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:31:46.915385 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:31:46.915392 38983 solver.cpp:238]     Train net output #2: loss = 0.324531 (* 1 = 0.324531 loss)
I0420 18:31:46.915398 38983 sgd_solver.cpp:105] Iteration 75000, lr = 0.0001
I0420 18:32:09.922590 38983 solver.cpp:219] Iteration 75100 (4.34687 iter/s, 23.0051s/100 iters), loss = 0.436331
I0420 18:32:09.922631 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 18:32:09.922636 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:32:09.922642 38983 solver.cpp:238]     Train net output #2: loss = 0.436331 (* 1 = 0.436331 loss)
I0420 18:32:09.922646 38983 sgd_solver.cpp:105] Iteration 75100, lr = 0.0001
I0420 18:32:32.792662 38983 solver.cpp:219] Iteration 75200 (4.37296 iter/s, 22.8678s/100 iters), loss = 0.290121
I0420 18:32:32.793743 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 18:32:32.793751 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:32:32.793757 38983 solver.cpp:238]     Train net output #2: loss = 0.290121 (* 1 = 0.290121 loss)
I0420 18:32:32.793761 38983 sgd_solver.cpp:105] Iteration 75200, lr = 0.0001
I0420 18:32:39.755311 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:32:56.984735 38983 solver.cpp:219] Iteration 75300 (4.13399 iter/s, 24.1897s/100 iters), loss = 0.276405
I0420 18:32:56.984777 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 18:32:56.984783 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:32:56.984789 38983 solver.cpp:238]     Train net output #2: loss = 0.276405 (* 1 = 0.276405 loss)
I0420 18:32:56.984794 38983 sgd_solver.cpp:105] Iteration 75300, lr = 0.0001
I0420 18:33:19.943424 38983 solver.cpp:219] Iteration 75400 (4.35566 iter/s, 22.9586s/100 iters), loss = 0.357667
I0420 18:33:19.943655 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:33:19.943663 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:33:19.943670 38983 solver.cpp:238]     Train net output #2: loss = 0.357667 (* 1 = 0.357667 loss)
I0420 18:33:19.943675 38983 sgd_solver.cpp:105] Iteration 75400, lr = 0.0001
I0420 18:33:42.887542 38983 solver.cpp:219] Iteration 75500 (4.35886 iter/s, 22.9418s/100 iters), loss = 0.299341
I0420 18:33:42.887593 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:33:42.887598 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 18:33:42.887605 38983 solver.cpp:238]     Train net output #2: loss = 0.299341 (* 1 = 0.299341 loss)
I0420 18:33:42.887609 38983 sgd_solver.cpp:105] Iteration 75500, lr = 0.0001
I0420 18:34:05.811327 38983 solver.cpp:219] Iteration 75600 (4.36231 iter/s, 22.9237s/100 iters), loss = 0.249982
I0420 18:34:05.811497 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 18:34:05.811506 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:34:05.811512 38983 solver.cpp:238]     Train net output #2: loss = 0.249982 (* 1 = 0.249982 loss)
I0420 18:34:05.811517 38983 sgd_solver.cpp:105] Iteration 75600, lr = 0.0001
I0420 18:34:10.428778 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:34:28.795094 38983 solver.cpp:219] Iteration 75700 (4.35131 iter/s, 22.9816s/100 iters), loss = 0.3203
I0420 18:34:28.795150 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 18:34:28.795156 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:34:28.795161 38983 solver.cpp:238]     Train net output #2: loss = 0.3203 (* 1 = 0.3203 loss)
I0420 18:34:28.795166 38983 sgd_solver.cpp:105] Iteration 75700, lr = 0.0001
I0420 18:34:51.699060 38983 solver.cpp:219] Iteration 75800 (4.36613 iter/s, 22.9036s/100 iters), loss = 0.319404
I0420 18:34:51.699265 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:34:51.699272 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:34:51.699278 38983 solver.cpp:238]     Train net output #2: loss = 0.319404 (* 1 = 0.319404 loss)
I0420 18:34:51.699283 38983 sgd_solver.cpp:105] Iteration 75800, lr = 0.0001
I0420 18:35:14.692096 38983 solver.cpp:219] Iteration 75900 (4.34954 iter/s, 22.9909s/100 iters), loss = 0.237271
I0420 18:35:14.692149 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:35:14.692155 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:35:14.692162 38983 solver.cpp:238]     Train net output #2: loss = 0.237271 (* 1 = 0.237271 loss)
I0420 18:35:14.692167 38983 sgd_solver.cpp:105] Iteration 75900, lr = 0.0001
I0420 18:35:37.405760 38983 solver.cpp:331] Iteration 76000, Testing net (#0)
I0420 18:35:42.245847 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:35:42.473364 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8639
I0420 18:35:42.473392 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 18:35:42.473415 38983 solver.cpp:398]     Test net output #2: loss = 0.441911 (* 1 = 0.441911 loss)
I0420 18:35:42.683887 38983 solver.cpp:219] Iteration 76000 (3.57276 iter/s, 27.9895s/100 iters), loss = 0.278913
I0420 18:35:42.683925 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:35:42.683931 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:35:42.683936 38983 solver.cpp:238]     Train net output #2: loss = 0.278913 (* 1 = 0.278913 loss)
I0420 18:35:42.683943 38983 sgd_solver.cpp:105] Iteration 76000, lr = 0.0001
I0420 18:35:45.181789 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:36:05.579459 38983 solver.cpp:219] Iteration 76100 (4.36768 iter/s, 22.8955s/100 iters), loss = 0.36911
I0420 18:36:05.579514 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0420 18:36:05.579519 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:36:05.579526 38983 solver.cpp:238]     Train net output #2: loss = 0.36911 (* 1 = 0.36911 loss)
I0420 18:36:05.579530 38983 sgd_solver.cpp:105] Iteration 76100, lr = 0.0001
I0420 18:36:28.581159 38983 solver.cpp:219] Iteration 76200 (4.34797 iter/s, 22.9992s/100 iters), loss = 0.285
I0420 18:36:28.581393 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:36:28.581400 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:36:28.581408 38983 solver.cpp:238]     Train net output #2: loss = 0.284999 (* 1 = 0.284999 loss)
I0420 18:36:28.581411 38983 sgd_solver.cpp:105] Iteration 76200, lr = 0.0001
I0420 18:36:51.472707 38983 solver.cpp:219] Iteration 76300 (4.3689 iter/s, 22.8891s/100 iters), loss = 0.357623
I0420 18:36:51.472764 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0420 18:36:51.472769 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:36:51.472774 38983 solver.cpp:238]     Train net output #2: loss = 0.357623 (* 1 = 0.357623 loss)
I0420 18:36:51.472779 38983 sgd_solver.cpp:105] Iteration 76300, lr = 0.0001
I0420 18:37:14.480170 38983 solver.cpp:219] Iteration 76400 (4.34685 iter/s, 23.0052s/100 iters), loss = 0.253486
I0420 18:37:14.480360 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:37:14.480367 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:37:14.480375 38983 solver.cpp:238]     Train net output #2: loss = 0.253485 (* 1 = 0.253485 loss)
I0420 18:37:14.480378 38983 sgd_solver.cpp:105] Iteration 76400, lr = 0.0001
I0420 18:37:14.959688 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:37:37.356963 38983 solver.cpp:219] Iteration 76500 (4.37173 iter/s, 22.8743s/100 iters), loss = 0.365853
I0420 18:37:37.357017 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 18:37:37.357023 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:37:37.357029 38983 solver.cpp:238]     Train net output #2: loss = 0.365853 (* 1 = 0.365853 loss)
I0420 18:37:37.357033 38983 sgd_solver.cpp:105] Iteration 76500, lr = 0.0001
I0420 18:38:00.369237 38983 solver.cpp:219] Iteration 76600 (4.34595 iter/s, 23.01s/100 iters), loss = 0.225196
I0420 18:38:00.369380 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:38:00.369387 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:38:00.369393 38983 solver.cpp:238]     Train net output #2: loss = 0.225196 (* 1 = 0.225196 loss)
I0420 18:38:00.369398 38983 sgd_solver.cpp:105] Iteration 76600, lr = 0.0001
I0420 18:38:23.294526 38983 solver.cpp:219] Iteration 76700 (4.36243 iter/s, 22.923s/100 iters), loss = 0.27154
I0420 18:38:23.294582 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:38:23.294589 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:38:23.294595 38983 solver.cpp:238]     Train net output #2: loss = 0.27154 (* 1 = 0.27154 loss)
I0420 18:38:23.294600 38983 sgd_solver.cpp:105] Iteration 76700, lr = 0.0001
I0420 18:38:44.497905 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:38:46.296497 38983 solver.cpp:219] Iteration 76800 (4.34789 iter/s, 22.9997s/100 iters), loss = 0.336094
I0420 18:38:46.296547 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:38:46.296553 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:38:46.296561 38983 solver.cpp:238]     Train net output #2: loss = 0.336094 (* 1 = 0.336094 loss)
I0420 18:38:46.296564 38983 sgd_solver.cpp:105] Iteration 76800, lr = 0.0001
I0420 18:39:09.193239 38983 solver.cpp:219] Iteration 76900 (4.36785 iter/s, 22.8945s/100 iters), loss = 0.412086
I0420 18:39:09.193295 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 18:39:09.193301 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 18:39:09.193307 38983 solver.cpp:238]     Train net output #2: loss = 0.412086 (* 1 = 0.412086 loss)
I0420 18:39:09.193311 38983 sgd_solver.cpp:105] Iteration 76900, lr = 0.0001
I0420 18:39:31.957134 38983 solver.cpp:331] Iteration 77000, Testing net (#0)
I0420 18:39:36.839983 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:39:37.048770 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8636
I0420 18:39:37.048797 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9943
I0420 18:39:37.048821 38983 solver.cpp:398]     Test net output #2: loss = 0.443469 (* 1 = 0.443469 loss)
I0420 18:39:37.190958 38983 solver.cpp:219] Iteration 77000 (3.572 iter/s, 27.9955s/100 iters), loss = 0.31444
I0420 18:39:37.190981 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:39:37.191002 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:39:37.191009 38983 solver.cpp:238]     Train net output #2: loss = 0.314439 (* 1 = 0.314439 loss)
I0420 18:39:37.191015 38983 sgd_solver.cpp:105] Iteration 77000, lr = 0.0001
I0420 18:40:00.200098 38983 solver.cpp:219] Iteration 77100 (4.34653 iter/s, 23.0069s/100 iters), loss = 0.205027
I0420 18:40:00.200151 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0420 18:40:00.200157 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:40:00.200163 38983 solver.cpp:238]     Train net output #2: loss = 0.205027 (* 1 = 0.205027 loss)
I0420 18:40:00.200167 38983 sgd_solver.cpp:105] Iteration 77100, lr = 0.0001
I0420 18:40:19.289810 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:40:23.092643 38983 solver.cpp:219] Iteration 77200 (4.36865 iter/s, 22.8904s/100 iters), loss = 0.28729
I0420 18:40:23.092700 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 18:40:23.092706 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:40:23.092712 38983 solver.cpp:238]     Train net output #2: loss = 0.28729 (* 1 = 0.28729 loss)
I0420 18:40:23.092717 38983 sgd_solver.cpp:105] Iteration 77200, lr = 0.0001
I0420 18:40:46.087657 38983 solver.cpp:219] Iteration 77300 (4.34881 iter/s, 22.9948s/100 iters), loss = 0.312574
I0420 18:40:46.087709 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 18:40:46.087714 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:40:46.087721 38983 solver.cpp:238]     Train net output #2: loss = 0.312574 (* 1 = 0.312574 loss)
I0420 18:40:46.087725 38983 sgd_solver.cpp:105] Iteration 77300, lr = 0.0001
I0420 18:41:09.007144 38983 solver.cpp:219] Iteration 77400 (4.36352 iter/s, 22.9173s/100 iters), loss = 0.378006
I0420 18:41:09.007306 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:41:09.007313 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:41:09.007319 38983 solver.cpp:238]     Train net output #2: loss = 0.378006 (* 1 = 0.378006 loss)
I0420 18:41:09.007323 38983 sgd_solver.cpp:105] Iteration 77400, lr = 0.0001
I0420 18:41:31.973963 38983 solver.cpp:219] Iteration 77500 (4.35415 iter/s, 22.9666s/100 iters), loss = 0.216937
I0420 18:41:31.974017 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 18:41:31.974023 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:41:31.974030 38983 solver.cpp:238]     Train net output #2: loss = 0.216937 (* 1 = 0.216937 loss)
I0420 18:41:31.974033 38983 sgd_solver.cpp:105] Iteration 77500, lr = 0.0001
I0420 18:41:48.970578 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:41:54.924732 38983 solver.cpp:219] Iteration 77600 (4.35757 iter/s, 22.9486s/100 iters), loss = 0.261676
I0420 18:41:54.924788 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:41:54.924793 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:41:54.924800 38983 solver.cpp:238]     Train net output #2: loss = 0.261676 (* 1 = 0.261676 loss)
I0420 18:41:54.924804 38983 sgd_solver.cpp:105] Iteration 77600, lr = 0.0001
I0420 18:42:17.870113 38983 solver.cpp:219] Iteration 77700 (4.35819 iter/s, 22.9453s/100 iters), loss = 0.334614
I0420 18:42:17.870148 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:42:17.870169 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:42:17.870177 38983 solver.cpp:238]     Train net output #2: loss = 0.334614 (* 1 = 0.334614 loss)
I0420 18:42:17.870182 38983 sgd_solver.cpp:105] Iteration 77700, lr = 0.0001
I0420 18:42:40.840705 38983 solver.cpp:219] Iteration 77800 (4.35382 iter/s, 22.9683s/100 iters), loss = 0.429183
I0420 18:42:40.840962 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0420 18:42:40.840970 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:42:40.840977 38983 solver.cpp:238]     Train net output #2: loss = 0.429183 (* 1 = 0.429183 loss)
I0420 18:42:40.840982 38983 sgd_solver.cpp:105] Iteration 77800, lr = 0.0001
I0420 18:43:05.086493 38983 solver.cpp:219] Iteration 77900 (4.12449 iter/s, 24.2454s/100 iters), loss = 0.232398
I0420 18:43:05.086545 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 18:43:05.086550 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:43:05.086557 38983 solver.cpp:238]     Train net output #2: loss = 0.232398 (* 1 = 0.232398 loss)
I0420 18:43:05.086561 38983 sgd_solver.cpp:105] Iteration 77900, lr = 0.0001
I0420 18:43:19.771335 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:43:27.819474 38983 solver.cpp:331] Iteration 78000, Testing net (#0)
I0420 18:43:32.644917 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:43:32.881641 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8638
I0420 18:43:32.881669 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9941
I0420 18:43:32.881695 38983 solver.cpp:398]     Test net output #2: loss = 0.443204 (* 1 = 0.443204 loss)
I0420 18:43:33.103554 38983 solver.cpp:219] Iteration 78000 (3.56954 iter/s, 28.0148s/100 iters), loss = 0.288236
I0420 18:43:33.103575 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 18:43:33.103596 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 18:43:33.103601 38983 solver.cpp:238]     Train net output #2: loss = 0.288235 (* 1 = 0.288235 loss)
I0420 18:43:33.103607 38983 sgd_solver.cpp:105] Iteration 78000, lr = 0.0001
I0420 18:43:56.009487 38983 solver.cpp:219] Iteration 78100 (4.3657 iter/s, 22.9058s/100 iters), loss = 0.310589
I0420 18:43:56.009551 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:43:56.009572 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:43:56.009578 38983 solver.cpp:238]     Train net output #2: loss = 0.310589 (* 1 = 0.310589 loss)
I0420 18:43:56.009582 38983 sgd_solver.cpp:105] Iteration 78100, lr = 0.0001
I0420 18:44:19.015913 38983 solver.cpp:219] Iteration 78200 (4.34703 iter/s, 23.0042s/100 iters), loss = 0.19211
I0420 18:44:19.015964 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0420 18:44:19.015969 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:44:19.015976 38983 solver.cpp:238]     Train net output #2: loss = 0.19211 (* 1 = 0.19211 loss)
I0420 18:44:19.015980 38983 sgd_solver.cpp:105] Iteration 78200, lr = 0.0001
I0420 18:44:41.890836 38983 solver.cpp:219] Iteration 78300 (4.37168 iter/s, 22.8745s/100 iters), loss = 0.273507
I0420 18:44:41.891028 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:44:41.891036 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:44:41.891041 38983 solver.cpp:238]     Train net output #2: loss = 0.273507 (* 1 = 0.273507 loss)
I0420 18:44:41.891047 38983 sgd_solver.cpp:105] Iteration 78300, lr = 0.0001
I0420 18:44:54.580976 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:45:04.885943 38983 solver.cpp:219] Iteration 78400 (4.34918 iter/s, 22.9928s/100 iters), loss = 0.276244
I0420 18:45:04.885996 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 18:45:04.886003 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:45:04.886009 38983 solver.cpp:238]     Train net output #2: loss = 0.276244 (* 1 = 0.276244 loss)
I0420 18:45:04.886013 38983 sgd_solver.cpp:105] Iteration 78400, lr = 0.0001
I0420 18:45:27.754225 38983 solver.cpp:219] Iteration 78500 (4.3733 iter/s, 22.8661s/100 iters), loss = 0.298763
I0420 18:45:27.754485 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 18:45:27.754493 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:45:27.754500 38983 solver.cpp:238]     Train net output #2: loss = 0.298762 (* 1 = 0.298762 loss)
I0420 18:45:27.754504 38983 sgd_solver.cpp:105] Iteration 78500, lr = 0.0001
I0420 18:45:50.766595 38983 solver.cpp:219] Iteration 78600 (4.34593 iter/s, 23.01s/100 iters), loss = 0.365746
I0420 18:45:50.766649 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0420 18:45:50.766655 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:45:50.766661 38983 solver.cpp:238]     Train net output #2: loss = 0.365746 (* 1 = 0.365746 loss)
I0420 18:45:50.766665 38983 sgd_solver.cpp:105] Iteration 78600, lr = 0.0001
I0420 18:46:13.659569 38983 solver.cpp:219] Iteration 78700 (4.36857 iter/s, 22.8908s/100 iters), loss = 0.24528
I0420 18:46:13.659696 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:46:13.659703 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:46:13.659710 38983 solver.cpp:238]     Train net output #2: loss = 0.24528 (* 1 = 0.24528 loss)
I0420 18:46:13.659714 38983 sgd_solver.cpp:105] Iteration 78700, lr = 0.0001
I0420 18:46:24.059780 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:46:36.642231 38983 solver.cpp:219] Iteration 78800 (4.35155 iter/s, 22.9803s/100 iters), loss = 0.354923
I0420 18:46:36.642287 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:46:36.642292 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:46:36.642298 38983 solver.cpp:238]     Train net output #2: loss = 0.354923 (* 1 = 0.354923 loss)
I0420 18:46:36.642302 38983 sgd_solver.cpp:105] Iteration 78800, lr = 0.0001
I0420 18:46:59.557075 38983 solver.cpp:219] Iteration 78900 (4.36442 iter/s, 22.9126s/100 iters), loss = 0.131924
I0420 18:46:59.557276 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0420 18:46:59.557281 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:46:59.557288 38983 solver.cpp:238]     Train net output #2: loss = 0.131924 (* 1 = 0.131924 loss)
I0420 18:46:59.557294 38983 sgd_solver.cpp:105] Iteration 78900, lr = 0.0001
I0420 18:47:22.320099 38983 solver.cpp:331] Iteration 79000, Testing net (#0)
I0420 18:47:27.222448 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:47:27.446816 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.8623
I0420 18:47:27.446840 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.9941
I0420 18:47:27.446863 38983 solver.cpp:398]     Test net output #2: loss = 0.444093 (* 1 = 0.444093 loss)
I0420 18:47:27.571044 38983 solver.cpp:219] Iteration 79000 (3.56966 iter/s, 28.0138s/100 iters), loss = 0.283023
I0420 18:47:27.571066 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:47:27.571087 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:47:27.571092 38983 solver.cpp:238]     Train net output #2: loss = 0.283022 (* 1 = 0.283022 loss)
I0420 18:47:27.571099 38983 sgd_solver.cpp:105] Iteration 79000, lr = 0.0001
I0420 18:47:50.569021 38983 solver.cpp:219] Iteration 79100 (4.34865 iter/s, 22.9957s/100 iters), loss = 0.432729
I0420 18:47:50.569114 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0420 18:47:50.569121 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:47:50.569128 38983 solver.cpp:238]     Train net output #2: loss = 0.432729 (* 1 = 0.432729 loss)
I0420 18:47:50.569133 38983 sgd_solver.cpp:105] Iteration 79100, lr = 0.0001
I0420 18:47:58.864013 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:48:13.455622 38983 solver.cpp:219] Iteration 79200 (4.36984 iter/s, 22.8841s/100 iters), loss = 0.285774
I0420 18:48:13.455677 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0420 18:48:13.455685 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:48:13.455693 38983 solver.cpp:238]     Train net output #2: loss = 0.285774 (* 1 = 0.285774 loss)
I0420 18:48:13.455696 38983 sgd_solver.cpp:105] Iteration 79200, lr = 0.0001
I0420 18:48:36.441365 38983 solver.cpp:219] Iteration 79300 (4.35056 iter/s, 22.9855s/100 iters), loss = 0.412948
I0420 18:48:36.441581 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0420 18:48:36.441589 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.96875
I0420 18:48:36.441596 38983 solver.cpp:238]     Train net output #2: loss = 0.412948 (* 1 = 0.412948 loss)
I0420 18:48:36.441601 38983 sgd_solver.cpp:105] Iteration 79300, lr = 0.0001
I0420 18:48:59.367364 38983 solver.cpp:219] Iteration 79400 (4.36228 iter/s, 22.9238s/100 iters), loss = 0.350734
I0420 18:48:59.367416 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0420 18:48:59.367422 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:48:59.367429 38983 solver.cpp:238]     Train net output #2: loss = 0.350734 (* 1 = 0.350734 loss)
I0420 18:48:59.367432 38983 sgd_solver.cpp:105] Iteration 79400, lr = 0.0001
I0420 18:49:22.344198 38983 solver.cpp:219] Iteration 79500 (4.35223 iter/s, 22.9767s/100 iters), loss = 0.254858
I0420 18:49:22.344393 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0420 18:49:22.344400 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:49:22.344406 38983 solver.cpp:238]     Train net output #2: loss = 0.254858 (* 1 = 0.254858 loss)
I0420 18:49:22.344410 38983 sgd_solver.cpp:105] Iteration 79500, lr = 0.0001
I0420 18:49:28.567664 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:49:45.299708 38983 solver.cpp:219] Iteration 79600 (4.35668 iter/s, 22.9532s/100 iters), loss = 0.299153
I0420 18:49:45.299762 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0420 18:49:45.299767 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:49:45.299774 38983 solver.cpp:238]     Train net output #2: loss = 0.299153 (* 1 = 0.299153 loss)
I0420 18:49:45.299778 38983 sgd_solver.cpp:105] Iteration 79600, lr = 0.0001
I0420 18:50:08.247371 38983 solver.cpp:219] Iteration 79700 (4.35775 iter/s, 22.9476s/100 iters), loss = 0.312763
I0420 18:50:08.247561 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0420 18:50:08.247568 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0420 18:50:08.247575 38983 solver.cpp:238]     Train net output #2: loss = 0.312763 (* 1 = 0.312763 loss)
I0420 18:50:08.247580 38983 sgd_solver.cpp:105] Iteration 79700, lr = 0.0001
I0420 18:50:31.237823 38983 solver.cpp:219] Iteration 79800 (4.35007 iter/s, 22.9882s/100 iters), loss = 0.331785
I0420 18:50:31.237876 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0420 18:50:31.237881 38983 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0420 18:50:31.237889 38983 solver.cpp:238]     Train net output #2: loss = 0.331785 (* 1 = 0.331785 loss)
I0420 18:50:31.237892 38983 sgd_solver.cpp:105] Iteration 79800, lr = 0.0001
I0420 18:50:54.144345 38983 solver.cpp:219] Iteration 79900 (4.36557 iter/s, 22.9065s/100 iters), loss = 0.256706
I0420 18:50:54.144515 38983 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0420 18:50:54.144522 38983 solver.cpp:238]     Train net output #1: acctop5 = 1
I0420 18:50:54.144528 38983 solver.cpp:238]     Train net output #2: loss = 0.256706 (* 1 = 0.256706 loss)
I0420 18:50:54.144533 38983 sgd_solver.cpp:105] Iteration 79900, lr = 0.0001
I0420 18:50:58.095389 38987 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:51:16.911739 38983 solver.cpp:448] Snapshotting to binary proto file model/ResNet20_finetune_quant_0.09_iter_80000.caffemodel
I0420 18:51:16.934237 38983 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model/ResNet20_finetune_quant_0.09_iter_80000.solverstate
I0420 18:51:17.021237 38983 solver.cpp:311] Iteration 80000, loss = 0.209341
I0420 18:51:17.021258 38983 solver.cpp:331] Iteration 80000, Testing net (#0)
I0420 18:51:21.866372 38988 data_layer.cpp:73] Restarting data prefetching from start.
I0420 18:51:22.058158 38983 solver.cpp:398]     Test net output #0: acctop1 = 0.863
I0420 18:51:22.058182 38983 solver.cpp:398]     Test net output #1: acctop5 = 0.994
I0420 18:51:22.058205 38983 solver.cpp:398]     Test net output #2: loss = 0.444169 (* 1 = 0.444169 loss)
I0420 18:51:22.058209 38983 solver.cpp:316] Optimization Done.
I0420 18:51:22.058212 38983 caffe.cpp:259] Optimization Done.
