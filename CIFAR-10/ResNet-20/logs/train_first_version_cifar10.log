I0417 10:26:57.431061 22508 caffe.cpp:218] Using GPUs 0
I0417 10:26:57.470113 22508 caffe.cpp:223] GPU 0: Tesla K40c
I0417 10:26:57.809757 22508 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "/optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20"
solver_mode: GPU
device_id: 0
net: "resnet20_relu_msra_cifar10.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 48000
stepvalue: 64000
I0417 10:26:57.810662 22508 solver.cpp:87] Creating training net from net file: resnet20_relu_msra_cifar10.prototxt
I0417 10:26:57.812690 22508 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet20_relu_msra_cifar10.prototxt
I0417 10:26:57.812702 22508 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0417 10:26:57.812964 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0417 10:26:57.812975 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv1
I0417 10:26:57.812983 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_1_bn_a
I0417 10:26:57.812988 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_1_bn_b
I0417 10:26:57.812995 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_2_bn_a
I0417 10:26:57.812999 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_2_bn_b
I0417 10:26:57.813004 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_3_bn_a
I0417 10:26:57.813009 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map16_3_bn_b
I0417 10:26:57.813014 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_proj
I0417 10:26:57.813019 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_a
I0417 10:26:57.813022 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_1_bn_b
I0417 10:26:57.813027 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_2_bn_a
I0417 10:26:57.813031 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_2_bn_b
I0417 10:26:57.813036 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_3_bn_a
I0417 10:26:57.813042 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map32_3_bn_b
I0417 10:26:57.813047 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_proj
I0417 10:26:57.813051 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_a
I0417 10:26:57.813058 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_1_bn_b
I0417 10:26:57.813063 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_2_bn_a
I0417 10:26:57.813068 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_2_bn_b
I0417 10:26:57.813073 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_3_bn_a
I0417 10:26:57.813077 22508 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer map64_3_bn_b
I0417 10:26:57.813580 22508 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
    mean_file: "/optimus_data/backed_up/cifar10/cifar10-zca-whitened/mean.binaryproto"
  }
  data_param {
    source: "/optimus_data/backed_up/cifar10/cifar10-zca-whitened/cifar-train-leveldb/"
    batch_size: 128
    backend: LEVELDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "map16_1_conv_a"
  type: "Convolution"
  bottom: "conv1"
  top: "map16_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_a"
  type: "BatchNorm"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_1_scale_a"
  type: "Scale"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_relu_a"
  type: "ReLU"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
}
layer {
  name: "map16_1_conv_b"
  type: "Convolution"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_b"
  type: "BatchNorm"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_1_scale_b"
  type: "Scale"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_eltsum"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "map16_1_conv_b"
  top: "map16_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_1_relu_after_sum"
  type: "ReLU"
  bottom: "map16_1_eltsum"
  top: "map16_1_eltsum"
}
layer {
  name: "map16_2_conv_a"
  type: "Convolution"
  bottom: "map16_1_eltsum"
  top: "map16_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_a"
  type: "BatchNorm"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_2_scale_a"
  type: "Scale"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_relu_a"
  type: "ReLU"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
}
layer {
  name: "map16_2_conv_b"
  type: "Convolution"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_b"
  type: "BatchNorm"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_2_scale_b"
  type: "Scale"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_eltsum"
  type: "Eltwise"
  bottom: "map16_1_eltsum"
  bottom: "map16_2_conv_b"
  top: "map16_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_2_relu_after_sum"
  type: "ReLU"
  bottom: "map16_2_eltsum"
  top: "map16_2_eltsum"
}
layer {
  name: "map16_3_conv_a"
  type: "Convolution"
  bottom: "map16_2_eltsum"
  top: "map16_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_a"
  type: "BatchNorm"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_3_scale_a"
  type: "Scale"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_relu_a"
  type: "ReLU"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
}
layer {
  name: "map16_3_conv_b"
  type: "Convolution"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_b"
  type: "BatchNorm"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map16_3_scale_b"
  type: "Scale"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_eltsum"
  type: "Eltwise"
  bottom: "map16_2_eltsum"
  bottom: "map16_3_conv_b"
  top: "map16_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_3_relu_after_sum"
  type: "ReLU"
  bottom: "map16_3_eltsum"
  top: "map16_3_eltsum"
}
layer {
  name: "map32_1_conv_proj"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_proj"
  type: "BatchNorm"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_proj"
  type: "Scale"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_conv_a"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_a"
  type: "BatchNorm"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_a"
  type: "Scale"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_relu_a"
  type: "ReLU"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
}
layer {
  name: "map32_1_conv_b"
  type: "Convolution"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_b"
  type: "BatchNorm"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_1_scale_b"
  type: "Scale"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_eltsum"
  type: "Eltwise"
  bottom: "map32_1_conv_proj"
  bottom: "map32_1_conv_b"
  top: "map32_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_1_relu_after_sum"
  type: "ReLU"
  bottom: "map32_1_eltsum"
  top: "map32_1_eltsum"
}
layer {
  name: "map32_2_conv_a"
  type: "Convolution"
  bottom: "map32_1_eltsum"
  top: "map32_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_a"
  type: "BatchNorm"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_2_scale_a"
  type: "Scale"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_relu_a"
  type: "ReLU"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
}
layer {
  name: "map32_2_conv_b"
  type: "Convolution"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_b"
  type: "BatchNorm"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_2_scale_b"
  type: "Scale"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_eltsum"
  type: "Eltwise"
  bottom: "map32_1_eltsum"
  bottom: "map32_2_conv_b"
  top: "map32_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_2_relu_after_sum"
  type: "ReLU"
  bottom: "map32_2_eltsum"
  top: "map32_2_eltsum"
}
layer {
  name: "map32_3_conv_a"
  type: "Convolution"
  bottom: "map32_2_eltsum"
  top: "map32_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_a"
  type: "BatchNorm"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_3_scale_a"
  type: "Scale"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_relu_a"
  type: "ReLU"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
}
layer {
  name: "map32_3_conv_b"
  type: "Convolution"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_b"
  type: "BatchNorm"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map32_3_scale_b"
  type: "Scale"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_eltsum"
  type: "Eltwise"
  bottom: "map32_2_eltsum"
  bottom: "map32_3_conv_b"
  top: "map32_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_3_relu_after_sum"
  type: "ReLU"
  bottom: "map32_3_eltsum"
  top: "map32_3_eltsum"
}
layer {
  name: "map64_1_conv_proj"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_proj"
  type: "BatchNorm"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_proj"
  type: "Scale"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_conv_a"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_a"
  type: "BatchNorm"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_a"
  type: "Scale"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_relu_a"
  type: "ReLU"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
}
layer {
  name: "map64_1_conv_b"
  type: "Convolution"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_b"
  type: "BatchNorm"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_1_scale_b"
  type: "Scale"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_eltsum"
  type: "Eltwise"
  bottom: "map64_1_conv_proj"
  bottom: "map64_1_conv_b"
  top: "map64_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_1_relu_after_sum"
  type: "ReLU"
  bottom: "map64_1_eltsum"
  top: "map64_1_eltsum"
}
layer {
  name: "map64_2_conv_a"
  type: "Convolution"
  bottom: "map64_1_eltsum"
  top: "map64_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_a"
  type: "BatchNorm"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_2_scale_a"
  type: "Scale"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_relu_a"
  type: "ReLU"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
}
layer {
  name: "map64_2_conv_b"
  type: "Convolution"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_b"
  type: "BatchNorm"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_2_scale_b"
  type: "Scale"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_eltsum"
  type: "Eltwise"
  bottom: "map64_1_eltsum"
  bottom: "map64_2_conv_b"
  top: "map64_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_2_relu_after_sum"
  type: "ReLU"
  bottom: "map64_2_eltsum"
  top: "map64_2_eltsum"
}
layer {
  name: "map64_3_conv_a"
  type: "Convolution"
  bottom: "map64_2_eltsum"
  top: "map64_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_a"
  type: "BatchNorm"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_3_scale_a"
  type: "Scale"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_relu_a"
  type: "ReLU"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
}
layer {
  name: "map64_3_conv_b"
  type: "Convolution"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_b"
  type: "BatchNorm"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "map64_3_scale_b"
  type: "Scale"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_eltsum"
  type: "Eltwise"
  bottom: "map64_2_eltsum"
  bottom: "map64_3_conv_b"
  top: "map64_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_3_relu_after_sum"
  type: "ReLU"
  bottom: "map64_3_eltsum"
  top: "map64_3_eltsum"
}
layer {
  name: "pool_global"
  type: "Pooling"
  bottom: "map64_3_eltsum"
  top: "pool_global"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_global"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc/top1"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc/top5"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop5"
  accuracy_param {
    top_k: 5
  }
}
I0417 10:26:57.814030 22508 layer_factory.hpp:77] Creating layer data
I0417 10:26:57.815647 22508 db_leveldb.cpp:18] Opened leveldb /optimus_data/backed_up/cifar10/cifar10-zca-whitened/cifar-train-leveldb/
I0417 10:26:57.815739 22508 net.cpp:84] Creating Layer data
I0417 10:26:57.815764 22508 net.cpp:380] data -> data
I0417 10:26:57.815804 22508 net.cpp:380] data -> label
I0417 10:26:57.815819 22508 data_transformer.cpp:25] Loading mean file from: /optimus_data/backed_up/cifar10/cifar10-zca-whitened/mean.binaryproto
I0417 10:26:57.817553 22508 data_layer.cpp:45] output data size: 128,3,32,32
I0417 10:26:57.823091 22508 net.cpp:122] Setting up data
I0417 10:26:57.823120 22508 net.cpp:129] Top shape: 128 3 32 32 (393216)
I0417 10:26:57.823125 22508 net.cpp:129] Top shape: 128 (128)
I0417 10:26:57.823127 22508 net.cpp:137] Memory required for data: 1573376
I0417 10:26:57.823134 22508 layer_factory.hpp:77] Creating layer label_data_1_split
I0417 10:26:57.823164 22508 net.cpp:84] Creating Layer label_data_1_split
I0417 10:26:57.823189 22508 net.cpp:406] label_data_1_split <- label
I0417 10:26:57.823213 22508 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0417 10:26:57.823220 22508 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0417 10:26:57.823225 22508 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0417 10:26:57.823381 22508 net.cpp:122] Setting up label_data_1_split
I0417 10:26:57.823390 22508 net.cpp:129] Top shape: 128 (128)
I0417 10:26:57.823392 22508 net.cpp:129] Top shape: 128 (128)
I0417 10:26:57.823396 22508 net.cpp:129] Top shape: 128 (128)
I0417 10:26:57.823413 22508 net.cpp:137] Memory required for data: 1574912
I0417 10:26:57.823417 22508 layer_factory.hpp:77] Creating layer conv1
I0417 10:26:57.823438 22508 net.cpp:84] Creating Layer conv1
I0417 10:26:57.823442 22508 net.cpp:406] conv1 <- data
I0417 10:26:57.823447 22508 net.cpp:380] conv1 -> conv1
I0417 10:26:57.968418 22508 net.cpp:122] Setting up conv1
I0417 10:26:57.968449 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.968453 22508 net.cpp:137] Memory required for data: 9963520
I0417 10:26:57.968473 22508 layer_factory.hpp:77] Creating layer bn_conv1
I0417 10:26:57.968487 22508 net.cpp:84] Creating Layer bn_conv1
I0417 10:26:57.968492 22508 net.cpp:406] bn_conv1 <- conv1
I0417 10:26:57.968497 22508 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0417 10:26:57.968639 22508 net.cpp:122] Setting up bn_conv1
I0417 10:26:57.968647 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.968649 22508 net.cpp:137] Memory required for data: 18352128
I0417 10:26:57.968658 22508 layer_factory.hpp:77] Creating layer scale_conv1
I0417 10:26:57.968669 22508 net.cpp:84] Creating Layer scale_conv1
I0417 10:26:57.968672 22508 net.cpp:406] scale_conv1 <- conv1
I0417 10:26:57.968677 22508 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0417 10:26:57.968725 22508 layer_factory.hpp:77] Creating layer scale_conv1
I0417 10:26:57.968817 22508 net.cpp:122] Setting up scale_conv1
I0417 10:26:57.968824 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.968827 22508 net.cpp:137] Memory required for data: 26740736
I0417 10:26:57.968832 22508 layer_factory.hpp:77] Creating layer relu_conv1
I0417 10:26:57.968840 22508 net.cpp:84] Creating Layer relu_conv1
I0417 10:26:57.968855 22508 net.cpp:406] relu_conv1 <- conv1
I0417 10:26:57.968859 22508 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0417 10:26:57.969368 22508 net.cpp:122] Setting up relu_conv1
I0417 10:26:57.969379 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.969383 22508 net.cpp:137] Memory required for data: 35129344
I0417 10:26:57.969385 22508 layer_factory.hpp:77] Creating layer conv1_relu_conv1_0_split
I0417 10:26:57.969390 22508 net.cpp:84] Creating Layer conv1_relu_conv1_0_split
I0417 10:26:57.969393 22508 net.cpp:406] conv1_relu_conv1_0_split <- conv1
I0417 10:26:57.969398 22508 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_0
I0417 10:26:57.969404 22508 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_1
I0417 10:26:57.969434 22508 net.cpp:122] Setting up conv1_relu_conv1_0_split
I0417 10:26:57.969439 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.969442 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.969444 22508 net.cpp:137] Memory required for data: 51906560
I0417 10:26:57.969447 22508 layer_factory.hpp:77] Creating layer map16_1_conv_a
I0417 10:26:57.969456 22508 net.cpp:84] Creating Layer map16_1_conv_a
I0417 10:26:57.969460 22508 net.cpp:406] map16_1_conv_a <- conv1_relu_conv1_0_split_0
I0417 10:26:57.969465 22508 net.cpp:380] map16_1_conv_a -> map16_1_conv_a
I0417 10:26:57.970454 22508 net.cpp:122] Setting up map16_1_conv_a
I0417 10:26:57.970466 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.970469 22508 net.cpp:137] Memory required for data: 60295168
I0417 10:26:57.970476 22508 layer_factory.hpp:77] Creating layer map16_1_bn_a
I0417 10:26:57.970484 22508 net.cpp:84] Creating Layer map16_1_bn_a
I0417 10:26:57.970486 22508 net.cpp:406] map16_1_bn_a <- map16_1_conv_a
I0417 10:26:57.970490 22508 net.cpp:367] map16_1_bn_a -> map16_1_conv_a (in-place)
I0417 10:26:57.970621 22508 net.cpp:122] Setting up map16_1_bn_a
I0417 10:26:57.970628 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.970630 22508 net.cpp:137] Memory required for data: 68683776
I0417 10:26:57.970636 22508 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0417 10:26:57.970643 22508 net.cpp:84] Creating Layer map16_1_scale_a
I0417 10:26:57.970645 22508 net.cpp:406] map16_1_scale_a <- map16_1_conv_a
I0417 10:26:57.970680 22508 net.cpp:367] map16_1_scale_a -> map16_1_conv_a (in-place)
I0417 10:26:57.970721 22508 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0417 10:26:57.970801 22508 net.cpp:122] Setting up map16_1_scale_a
I0417 10:26:57.970808 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.970809 22508 net.cpp:137] Memory required for data: 77072384
I0417 10:26:57.970814 22508 layer_factory.hpp:77] Creating layer map16_1_relu_a
I0417 10:26:57.970820 22508 net.cpp:84] Creating Layer map16_1_relu_a
I0417 10:26:57.970824 22508 net.cpp:406] map16_1_relu_a <- map16_1_conv_a
I0417 10:26:57.970827 22508 net.cpp:367] map16_1_relu_a -> map16_1_conv_a (in-place)
I0417 10:26:57.971415 22508 net.cpp:122] Setting up map16_1_relu_a
I0417 10:26:57.971426 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.971439 22508 net.cpp:137] Memory required for data: 85460992
I0417 10:26:57.971443 22508 layer_factory.hpp:77] Creating layer map16_1_conv_b
I0417 10:26:57.971464 22508 net.cpp:84] Creating Layer map16_1_conv_b
I0417 10:26:57.971467 22508 net.cpp:406] map16_1_conv_b <- map16_1_conv_a
I0417 10:26:57.971474 22508 net.cpp:380] map16_1_conv_b -> map16_1_conv_b
I0417 10:26:57.972939 22508 net.cpp:122] Setting up map16_1_conv_b
I0417 10:26:57.972950 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.972952 22508 net.cpp:137] Memory required for data: 93849600
I0417 10:26:57.972959 22508 layer_factory.hpp:77] Creating layer map16_1_bn_b
I0417 10:26:57.972966 22508 net.cpp:84] Creating Layer map16_1_bn_b
I0417 10:26:57.972970 22508 net.cpp:406] map16_1_bn_b <- map16_1_conv_b
I0417 10:26:57.972973 22508 net.cpp:367] map16_1_bn_b -> map16_1_conv_b (in-place)
I0417 10:26:57.973112 22508 net.cpp:122] Setting up map16_1_bn_b
I0417 10:26:57.973119 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.973121 22508 net.cpp:137] Memory required for data: 102238208
I0417 10:26:57.973129 22508 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0417 10:26:57.973136 22508 net.cpp:84] Creating Layer map16_1_scale_b
I0417 10:26:57.973140 22508 net.cpp:406] map16_1_scale_b <- map16_1_conv_b
I0417 10:26:57.973145 22508 net.cpp:367] map16_1_scale_b -> map16_1_conv_b (in-place)
I0417 10:26:57.973189 22508 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0417 10:26:57.973299 22508 net.cpp:122] Setting up map16_1_scale_b
I0417 10:26:57.973309 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.973310 22508 net.cpp:137] Memory required for data: 110626816
I0417 10:26:57.973315 22508 layer_factory.hpp:77] Creating layer map16_1_eltsum
I0417 10:26:57.973325 22508 net.cpp:84] Creating Layer map16_1_eltsum
I0417 10:26:57.973330 22508 net.cpp:406] map16_1_eltsum <- conv1_relu_conv1_0_split_1
I0417 10:26:57.973332 22508 net.cpp:406] map16_1_eltsum <- map16_1_conv_b
I0417 10:26:57.973336 22508 net.cpp:380] map16_1_eltsum -> map16_1_eltsum
I0417 10:26:57.973362 22508 net.cpp:122] Setting up map16_1_eltsum
I0417 10:26:57.973367 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.973371 22508 net.cpp:137] Memory required for data: 119015424
I0417 10:26:57.973372 22508 layer_factory.hpp:77] Creating layer map16_1_relu_after_sum
I0417 10:26:57.973378 22508 net.cpp:84] Creating Layer map16_1_relu_after_sum
I0417 10:26:57.973382 22508 net.cpp:406] map16_1_relu_after_sum <- map16_1_eltsum
I0417 10:26:57.973386 22508 net.cpp:367] map16_1_relu_after_sum -> map16_1_eltsum (in-place)
I0417 10:26:57.973533 22508 net.cpp:122] Setting up map16_1_relu_after_sum
I0417 10:26:57.973542 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.973546 22508 net.cpp:137] Memory required for data: 127404032
I0417 10:26:57.973547 22508 layer_factory.hpp:77] Creating layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0417 10:26:57.973556 22508 net.cpp:84] Creating Layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0417 10:26:57.973559 22508 net.cpp:406] map16_1_eltsum_map16_1_relu_after_sum_0_split <- map16_1_eltsum
I0417 10:26:57.973563 22508 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0417 10:26:57.973583 22508 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0417 10:26:57.973620 22508 net.cpp:122] Setting up map16_1_eltsum_map16_1_relu_after_sum_0_split
I0417 10:26:57.973626 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.973629 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.973631 22508 net.cpp:137] Memory required for data: 144181248
I0417 10:26:57.973634 22508 layer_factory.hpp:77] Creating layer map16_2_conv_a
I0417 10:26:57.973644 22508 net.cpp:84] Creating Layer map16_2_conv_a
I0417 10:26:57.973647 22508 net.cpp:406] map16_2_conv_a <- map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0417 10:26:57.973654 22508 net.cpp:380] map16_2_conv_a -> map16_2_conv_a
I0417 10:26:57.975095 22508 net.cpp:122] Setting up map16_2_conv_a
I0417 10:26:57.975106 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.975108 22508 net.cpp:137] Memory required for data: 152569856
I0417 10:26:57.975113 22508 layer_factory.hpp:77] Creating layer map16_2_bn_a
I0417 10:26:57.975121 22508 net.cpp:84] Creating Layer map16_2_bn_a
I0417 10:26:57.975124 22508 net.cpp:406] map16_2_bn_a <- map16_2_conv_a
I0417 10:26:57.975128 22508 net.cpp:367] map16_2_bn_a -> map16_2_conv_a (in-place)
I0417 10:26:57.975278 22508 net.cpp:122] Setting up map16_2_bn_a
I0417 10:26:57.975296 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.975299 22508 net.cpp:137] Memory required for data: 160958464
I0417 10:26:57.975306 22508 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0417 10:26:57.975311 22508 net.cpp:84] Creating Layer map16_2_scale_a
I0417 10:26:57.975316 22508 net.cpp:406] map16_2_scale_a <- map16_2_conv_a
I0417 10:26:57.975332 22508 net.cpp:367] map16_2_scale_a -> map16_2_conv_a (in-place)
I0417 10:26:57.975361 22508 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0417 10:26:57.975450 22508 net.cpp:122] Setting up map16_2_scale_a
I0417 10:26:57.975456 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.975458 22508 net.cpp:137] Memory required for data: 169347072
I0417 10:26:57.975463 22508 layer_factory.hpp:77] Creating layer map16_2_relu_a
I0417 10:26:57.975468 22508 net.cpp:84] Creating Layer map16_2_relu_a
I0417 10:26:57.975471 22508 net.cpp:406] map16_2_relu_a <- map16_2_conv_a
I0417 10:26:57.975477 22508 net.cpp:367] map16_2_relu_a -> map16_2_conv_a (in-place)
I0417 10:26:57.976038 22508 net.cpp:122] Setting up map16_2_relu_a
I0417 10:26:57.976048 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.976063 22508 net.cpp:137] Memory required for data: 177735680
I0417 10:26:57.976065 22508 layer_factory.hpp:77] Creating layer map16_2_conv_b
I0417 10:26:57.976075 22508 net.cpp:84] Creating Layer map16_2_conv_b
I0417 10:26:57.976078 22508 net.cpp:406] map16_2_conv_b <- map16_2_conv_a
I0417 10:26:57.976084 22508 net.cpp:380] map16_2_conv_b -> map16_2_conv_b
I0417 10:26:57.977247 22508 net.cpp:122] Setting up map16_2_conv_b
I0417 10:26:57.977257 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.977260 22508 net.cpp:137] Memory required for data: 186124288
I0417 10:26:57.977265 22508 layer_factory.hpp:77] Creating layer map16_2_bn_b
I0417 10:26:57.977274 22508 net.cpp:84] Creating Layer map16_2_bn_b
I0417 10:26:57.977277 22508 net.cpp:406] map16_2_bn_b <- map16_2_conv_b
I0417 10:26:57.977283 22508 net.cpp:367] map16_2_bn_b -> map16_2_conv_b (in-place)
I0417 10:26:57.977439 22508 net.cpp:122] Setting up map16_2_bn_b
I0417 10:26:57.977445 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.977447 22508 net.cpp:137] Memory required for data: 194512896
I0417 10:26:57.977457 22508 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0417 10:26:57.977464 22508 net.cpp:84] Creating Layer map16_2_scale_b
I0417 10:26:57.977468 22508 net.cpp:406] map16_2_scale_b <- map16_2_conv_b
I0417 10:26:57.977483 22508 net.cpp:367] map16_2_scale_b -> map16_2_conv_b (in-place)
I0417 10:26:57.977527 22508 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0417 10:26:57.977617 22508 net.cpp:122] Setting up map16_2_scale_b
I0417 10:26:57.977624 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.977627 22508 net.cpp:137] Memory required for data: 202901504
I0417 10:26:57.977632 22508 layer_factory.hpp:77] Creating layer map16_2_eltsum
I0417 10:26:57.977639 22508 net.cpp:84] Creating Layer map16_2_eltsum
I0417 10:26:57.977643 22508 net.cpp:406] map16_2_eltsum <- map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0417 10:26:57.977645 22508 net.cpp:406] map16_2_eltsum <- map16_2_conv_b
I0417 10:26:57.977650 22508 net.cpp:380] map16_2_eltsum -> map16_2_eltsum
I0417 10:26:57.977671 22508 net.cpp:122] Setting up map16_2_eltsum
I0417 10:26:57.977676 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.977679 22508 net.cpp:137] Memory required for data: 211290112
I0417 10:26:57.977680 22508 layer_factory.hpp:77] Creating layer map16_2_relu_after_sum
I0417 10:26:57.977684 22508 net.cpp:84] Creating Layer map16_2_relu_after_sum
I0417 10:26:57.977687 22508 net.cpp:406] map16_2_relu_after_sum <- map16_2_eltsum
I0417 10:26:57.977692 22508 net.cpp:367] map16_2_relu_after_sum -> map16_2_eltsum (in-place)
I0417 10:26:57.978271 22508 net.cpp:122] Setting up map16_2_relu_after_sum
I0417 10:26:57.978281 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.978296 22508 net.cpp:137] Memory required for data: 219678720
I0417 10:26:57.978299 22508 layer_factory.hpp:77] Creating layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0417 10:26:57.978304 22508 net.cpp:84] Creating Layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0417 10:26:57.978307 22508 net.cpp:406] map16_2_eltsum_map16_2_relu_after_sum_0_split <- map16_2_eltsum
I0417 10:26:57.978312 22508 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0417 10:26:57.978319 22508 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0417 10:26:57.978391 22508 net.cpp:122] Setting up map16_2_eltsum_map16_2_relu_after_sum_0_split
I0417 10:26:57.978397 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.978400 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.978402 22508 net.cpp:137] Memory required for data: 236455936
I0417 10:26:57.978404 22508 layer_factory.hpp:77] Creating layer map16_3_conv_a
I0417 10:26:57.978415 22508 net.cpp:84] Creating Layer map16_3_conv_a
I0417 10:26:57.978420 22508 net.cpp:406] map16_3_conv_a <- map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0417 10:26:57.978423 22508 net.cpp:380] map16_3_conv_a -> map16_3_conv_a
I0417 10:26:57.979892 22508 net.cpp:122] Setting up map16_3_conv_a
I0417 10:26:57.979904 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.979918 22508 net.cpp:137] Memory required for data: 244844544
I0417 10:26:57.979923 22508 layer_factory.hpp:77] Creating layer map16_3_bn_a
I0417 10:26:57.979931 22508 net.cpp:84] Creating Layer map16_3_bn_a
I0417 10:26:57.979934 22508 net.cpp:406] map16_3_bn_a <- map16_3_conv_a
I0417 10:26:57.979940 22508 net.cpp:367] map16_3_bn_a -> map16_3_conv_a (in-place)
I0417 10:26:57.980131 22508 net.cpp:122] Setting up map16_3_bn_a
I0417 10:26:57.980139 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.980140 22508 net.cpp:137] Memory required for data: 253233152
I0417 10:26:57.980146 22508 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0417 10:26:57.980155 22508 net.cpp:84] Creating Layer map16_3_scale_a
I0417 10:26:57.980157 22508 net.cpp:406] map16_3_scale_a <- map16_3_conv_a
I0417 10:26:57.980161 22508 net.cpp:367] map16_3_scale_a -> map16_3_conv_a (in-place)
I0417 10:26:57.980201 22508 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0417 10:26:57.980293 22508 net.cpp:122] Setting up map16_3_scale_a
I0417 10:26:57.980298 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.980300 22508 net.cpp:137] Memory required for data: 261621760
I0417 10:26:57.980317 22508 layer_factory.hpp:77] Creating layer map16_3_relu_a
I0417 10:26:57.980324 22508 net.cpp:84] Creating Layer map16_3_relu_a
I0417 10:26:57.980326 22508 net.cpp:406] map16_3_relu_a <- map16_3_conv_a
I0417 10:26:57.980330 22508 net.cpp:367] map16_3_relu_a -> map16_3_conv_a (in-place)
I0417 10:26:57.980486 22508 net.cpp:122] Setting up map16_3_relu_a
I0417 10:26:57.980495 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.980499 22508 net.cpp:137] Memory required for data: 270010368
I0417 10:26:57.980501 22508 layer_factory.hpp:77] Creating layer map16_3_conv_b
I0417 10:26:57.980511 22508 net.cpp:84] Creating Layer map16_3_conv_b
I0417 10:26:57.980515 22508 net.cpp:406] map16_3_conv_b <- map16_3_conv_a
I0417 10:26:57.980522 22508 net.cpp:380] map16_3_conv_b -> map16_3_conv_b
I0417 10:26:57.981978 22508 net.cpp:122] Setting up map16_3_conv_b
I0417 10:26:57.981989 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.981992 22508 net.cpp:137] Memory required for data: 278398976
I0417 10:26:57.981997 22508 layer_factory.hpp:77] Creating layer map16_3_bn_b
I0417 10:26:57.982007 22508 net.cpp:84] Creating Layer map16_3_bn_b
I0417 10:26:57.982009 22508 net.cpp:406] map16_3_bn_b <- map16_3_conv_b
I0417 10:26:57.982015 22508 net.cpp:367] map16_3_bn_b -> map16_3_conv_b (in-place)
I0417 10:26:57.982194 22508 net.cpp:122] Setting up map16_3_bn_b
I0417 10:26:57.982201 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.982203 22508 net.cpp:137] Memory required for data: 286787584
I0417 10:26:57.982209 22508 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0417 10:26:57.982218 22508 net.cpp:84] Creating Layer map16_3_scale_b
I0417 10:26:57.982220 22508 net.cpp:406] map16_3_scale_b <- map16_3_conv_b
I0417 10:26:57.982224 22508 net.cpp:367] map16_3_scale_b -> map16_3_conv_b (in-place)
I0417 10:26:57.982252 22508 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0417 10:26:57.982343 22508 net.cpp:122] Setting up map16_3_scale_b
I0417 10:26:57.982350 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.982354 22508 net.cpp:137] Memory required for data: 295176192
I0417 10:26:57.982358 22508 layer_factory.hpp:77] Creating layer map16_3_eltsum
I0417 10:26:57.982364 22508 net.cpp:84] Creating Layer map16_3_eltsum
I0417 10:26:57.982367 22508 net.cpp:406] map16_3_eltsum <- map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0417 10:26:57.982372 22508 net.cpp:406] map16_3_eltsum <- map16_3_conv_b
I0417 10:26:57.982376 22508 net.cpp:380] map16_3_eltsum -> map16_3_eltsum
I0417 10:26:57.982396 22508 net.cpp:122] Setting up map16_3_eltsum
I0417 10:26:57.982401 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.982404 22508 net.cpp:137] Memory required for data: 303564800
I0417 10:26:57.982406 22508 layer_factory.hpp:77] Creating layer map16_3_relu_after_sum
I0417 10:26:57.982410 22508 net.cpp:84] Creating Layer map16_3_relu_after_sum
I0417 10:26:57.982414 22508 net.cpp:406] map16_3_relu_after_sum <- map16_3_eltsum
I0417 10:26:57.982419 22508 net.cpp:367] map16_3_relu_after_sum -> map16_3_eltsum (in-place)
I0417 10:26:57.982996 22508 net.cpp:122] Setting up map16_3_relu_after_sum
I0417 10:26:57.983006 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.983021 22508 net.cpp:137] Memory required for data: 311953408
I0417 10:26:57.983023 22508 layer_factory.hpp:77] Creating layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0417 10:26:57.983028 22508 net.cpp:84] Creating Layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0417 10:26:57.983031 22508 net.cpp:406] map16_3_eltsum_map16_3_relu_after_sum_0_split <- map16_3_eltsum
I0417 10:26:57.983037 22508 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0417 10:26:57.983044 22508 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0417 10:26:57.983079 22508 net.cpp:122] Setting up map16_3_eltsum_map16_3_relu_after_sum_0_split
I0417 10:26:57.983085 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.983103 22508 net.cpp:129] Top shape: 128 16 32 32 (2097152)
I0417 10:26:57.983106 22508 net.cpp:137] Memory required for data: 328730624
I0417 10:26:57.983109 22508 layer_factory.hpp:77] Creating layer map32_1_conv_proj
I0417 10:26:57.983119 22508 net.cpp:84] Creating Layer map32_1_conv_proj
I0417 10:26:57.983124 22508 net.cpp:406] map32_1_conv_proj <- map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0417 10:26:57.983129 22508 net.cpp:380] map32_1_conv_proj -> map32_1_conv_proj
I0417 10:26:57.985278 22508 net.cpp:122] Setting up map32_1_conv_proj
I0417 10:26:57.985291 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.985294 22508 net.cpp:137] Memory required for data: 332924928
I0417 10:26:57.985299 22508 layer_factory.hpp:77] Creating layer map32_1_bn_proj
I0417 10:26:57.985318 22508 net.cpp:84] Creating Layer map32_1_bn_proj
I0417 10:26:57.985322 22508 net.cpp:406] map32_1_bn_proj <- map32_1_conv_proj
I0417 10:26:57.985327 22508 net.cpp:367] map32_1_bn_proj -> map32_1_conv_proj (in-place)
I0417 10:26:57.985481 22508 net.cpp:122] Setting up map32_1_bn_proj
I0417 10:26:57.985487 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.985491 22508 net.cpp:137] Memory required for data: 337119232
I0417 10:26:57.985496 22508 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0417 10:26:57.985502 22508 net.cpp:84] Creating Layer map32_1_scale_proj
I0417 10:26:57.985504 22508 net.cpp:406] map32_1_scale_proj <- map32_1_conv_proj
I0417 10:26:57.985520 22508 net.cpp:367] map32_1_scale_proj -> map32_1_conv_proj (in-place)
I0417 10:26:57.985550 22508 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0417 10:26:57.985641 22508 net.cpp:122] Setting up map32_1_scale_proj
I0417 10:26:57.985647 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.985649 22508 net.cpp:137] Memory required for data: 341313536
I0417 10:26:57.985654 22508 layer_factory.hpp:77] Creating layer map32_1_conv_a
I0417 10:26:57.985666 22508 net.cpp:84] Creating Layer map32_1_conv_a
I0417 10:26:57.985669 22508 net.cpp:406] map32_1_conv_a <- map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0417 10:26:57.985679 22508 net.cpp:380] map32_1_conv_a -> map32_1_conv_a
I0417 10:26:57.987241 22508 net.cpp:122] Setting up map32_1_conv_a
I0417 10:26:57.987251 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.987256 22508 net.cpp:137] Memory required for data: 345507840
I0417 10:26:57.987260 22508 layer_factory.hpp:77] Creating layer map32_1_bn_a
I0417 10:26:57.987280 22508 net.cpp:84] Creating Layer map32_1_bn_a
I0417 10:26:57.987283 22508 net.cpp:406] map32_1_bn_a <- map32_1_conv_a
I0417 10:26:57.987287 22508 net.cpp:367] map32_1_bn_a -> map32_1_conv_a (in-place)
I0417 10:26:57.987453 22508 net.cpp:122] Setting up map32_1_bn_a
I0417 10:26:57.987459 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.987462 22508 net.cpp:137] Memory required for data: 349702144
I0417 10:26:57.987468 22508 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0417 10:26:57.987475 22508 net.cpp:84] Creating Layer map32_1_scale_a
I0417 10:26:57.987478 22508 net.cpp:406] map32_1_scale_a <- map32_1_conv_a
I0417 10:26:57.987483 22508 net.cpp:367] map32_1_scale_a -> map32_1_conv_a (in-place)
I0417 10:26:57.987514 22508 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0417 10:26:57.987607 22508 net.cpp:122] Setting up map32_1_scale_a
I0417 10:26:57.987613 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.987615 22508 net.cpp:137] Memory required for data: 353896448
I0417 10:26:57.987620 22508 layer_factory.hpp:77] Creating layer map32_1_relu_a
I0417 10:26:57.987625 22508 net.cpp:84] Creating Layer map32_1_relu_a
I0417 10:26:57.987628 22508 net.cpp:406] map32_1_relu_a <- map32_1_conv_a
I0417 10:26:57.987633 22508 net.cpp:367] map32_1_relu_a -> map32_1_conv_a (in-place)
I0417 10:26:57.988211 22508 net.cpp:122] Setting up map32_1_relu_a
I0417 10:26:57.988222 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.988236 22508 net.cpp:137] Memory required for data: 358090752
I0417 10:26:57.988250 22508 layer_factory.hpp:77] Creating layer map32_1_conv_b
I0417 10:26:57.988260 22508 net.cpp:84] Creating Layer map32_1_conv_b
I0417 10:26:57.988265 22508 net.cpp:406] map32_1_conv_b <- map32_1_conv_a
I0417 10:26:57.988271 22508 net.cpp:380] map32_1_conv_b -> map32_1_conv_b
I0417 10:26:57.990003 22508 net.cpp:122] Setting up map32_1_conv_b
I0417 10:26:57.990015 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.990028 22508 net.cpp:137] Memory required for data: 362285056
I0417 10:26:57.990042 22508 layer_factory.hpp:77] Creating layer map32_1_bn_b
I0417 10:26:57.990052 22508 net.cpp:84] Creating Layer map32_1_bn_b
I0417 10:26:57.990056 22508 net.cpp:406] map32_1_bn_b <- map32_1_conv_b
I0417 10:26:57.990061 22508 net.cpp:367] map32_1_bn_b -> map32_1_conv_b (in-place)
I0417 10:26:57.990224 22508 net.cpp:122] Setting up map32_1_bn_b
I0417 10:26:57.990232 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.990234 22508 net.cpp:137] Memory required for data: 366479360
I0417 10:26:57.990241 22508 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0417 10:26:57.990248 22508 net.cpp:84] Creating Layer map32_1_scale_b
I0417 10:26:57.990252 22508 net.cpp:406] map32_1_scale_b <- map32_1_conv_b
I0417 10:26:57.990254 22508 net.cpp:367] map32_1_scale_b -> map32_1_conv_b (in-place)
I0417 10:26:57.990288 22508 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0417 10:26:57.990381 22508 net.cpp:122] Setting up map32_1_scale_b
I0417 10:26:57.990387 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.990389 22508 net.cpp:137] Memory required for data: 370673664
I0417 10:26:57.990394 22508 layer_factory.hpp:77] Creating layer map32_1_eltsum
I0417 10:26:57.990399 22508 net.cpp:84] Creating Layer map32_1_eltsum
I0417 10:26:57.990404 22508 net.cpp:406] map32_1_eltsum <- map32_1_conv_proj
I0417 10:26:57.990409 22508 net.cpp:406] map32_1_eltsum <- map32_1_conv_b
I0417 10:26:57.990413 22508 net.cpp:380] map32_1_eltsum -> map32_1_eltsum
I0417 10:26:57.990430 22508 net.cpp:122] Setting up map32_1_eltsum
I0417 10:26:57.990437 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.990440 22508 net.cpp:137] Memory required for data: 374867968
I0417 10:26:57.990442 22508 layer_factory.hpp:77] Creating layer map32_1_relu_after_sum
I0417 10:26:57.990447 22508 net.cpp:84] Creating Layer map32_1_relu_after_sum
I0417 10:26:57.990449 22508 net.cpp:406] map32_1_relu_after_sum <- map32_1_eltsum
I0417 10:26:57.990454 22508 net.cpp:367] map32_1_relu_after_sum -> map32_1_eltsum (in-place)
I0417 10:26:57.990602 22508 net.cpp:122] Setting up map32_1_relu_after_sum
I0417 10:26:57.990612 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.990615 22508 net.cpp:137] Memory required for data: 379062272
I0417 10:26:57.990618 22508 layer_factory.hpp:77] Creating layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0417 10:26:57.990622 22508 net.cpp:84] Creating Layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0417 10:26:57.990628 22508 net.cpp:406] map32_1_eltsum_map32_1_relu_after_sum_0_split <- map32_1_eltsum
I0417 10:26:57.990631 22508 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0417 10:26:57.990636 22508 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0417 10:26:57.990674 22508 net.cpp:122] Setting up map32_1_eltsum_map32_1_relu_after_sum_0_split
I0417 10:26:57.990679 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.990682 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.990684 22508 net.cpp:137] Memory required for data: 387450880
I0417 10:26:57.990686 22508 layer_factory.hpp:77] Creating layer map32_2_conv_a
I0417 10:26:57.990695 22508 net.cpp:84] Creating Layer map32_2_conv_a
I0417 10:26:57.990700 22508 net.cpp:406] map32_2_conv_a <- map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0417 10:26:57.990705 22508 net.cpp:380] map32_2_conv_a -> map32_2_conv_a
I0417 10:26:57.992431 22508 net.cpp:122] Setting up map32_2_conv_a
I0417 10:26:57.992444 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.992460 22508 net.cpp:137] Memory required for data: 391645184
I0417 10:26:57.992465 22508 layer_factory.hpp:77] Creating layer map32_2_bn_a
I0417 10:26:57.992472 22508 net.cpp:84] Creating Layer map32_2_bn_a
I0417 10:26:57.992476 22508 net.cpp:406] map32_2_bn_a <- map32_2_conv_a
I0417 10:26:57.992482 22508 net.cpp:367] map32_2_bn_a -> map32_2_conv_a (in-place)
I0417 10:26:57.992656 22508 net.cpp:122] Setting up map32_2_bn_a
I0417 10:26:57.992663 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.992666 22508 net.cpp:137] Memory required for data: 395839488
I0417 10:26:57.992671 22508 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0417 10:26:57.992679 22508 net.cpp:84] Creating Layer map32_2_scale_a
I0417 10:26:57.992684 22508 net.cpp:406] map32_2_scale_a <- map32_2_conv_a
I0417 10:26:57.992688 22508 net.cpp:367] map32_2_scale_a -> map32_2_conv_a (in-place)
I0417 10:26:57.992717 22508 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0417 10:26:57.992811 22508 net.cpp:122] Setting up map32_2_scale_a
I0417 10:26:57.992818 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.992820 22508 net.cpp:137] Memory required for data: 400033792
I0417 10:26:57.992825 22508 layer_factory.hpp:77] Creating layer map32_2_relu_a
I0417 10:26:57.992830 22508 net.cpp:84] Creating Layer map32_2_relu_a
I0417 10:26:57.992833 22508 net.cpp:406] map32_2_relu_a <- map32_2_conv_a
I0417 10:26:57.992836 22508 net.cpp:367] map32_2_relu_a -> map32_2_conv_a (in-place)
I0417 10:26:57.992988 22508 net.cpp:122] Setting up map32_2_relu_a
I0417 10:26:57.992996 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.993000 22508 net.cpp:137] Memory required for data: 404228096
I0417 10:26:57.993001 22508 layer_factory.hpp:77] Creating layer map32_2_conv_b
I0417 10:26:57.993010 22508 net.cpp:84] Creating Layer map32_2_conv_b
I0417 10:26:57.993015 22508 net.cpp:406] map32_2_conv_b <- map32_2_conv_a
I0417 10:26:57.993021 22508 net.cpp:380] map32_2_conv_b -> map32_2_conv_b
I0417 10:26:57.994693 22508 net.cpp:122] Setting up map32_2_conv_b
I0417 10:26:57.994704 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.994707 22508 net.cpp:137] Memory required for data: 408422400
I0417 10:26:57.994712 22508 layer_factory.hpp:77] Creating layer map32_2_bn_b
I0417 10:26:57.994729 22508 net.cpp:84] Creating Layer map32_2_bn_b
I0417 10:26:57.994734 22508 net.cpp:406] map32_2_bn_b <- map32_2_conv_b
I0417 10:26:57.994740 22508 net.cpp:367] map32_2_bn_b -> map32_2_conv_b (in-place)
I0417 10:26:57.994920 22508 net.cpp:122] Setting up map32_2_bn_b
I0417 10:26:57.994925 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.994928 22508 net.cpp:137] Memory required for data: 412616704
I0417 10:26:57.994933 22508 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0417 10:26:57.994940 22508 net.cpp:84] Creating Layer map32_2_scale_b
I0417 10:26:57.994942 22508 net.cpp:406] map32_2_scale_b <- map32_2_conv_b
I0417 10:26:57.994946 22508 net.cpp:367] map32_2_scale_b -> map32_2_conv_b (in-place)
I0417 10:26:57.994981 22508 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0417 10:26:57.995076 22508 net.cpp:122] Setting up map32_2_scale_b
I0417 10:26:57.995084 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.995085 22508 net.cpp:137] Memory required for data: 416811008
I0417 10:26:57.995090 22508 layer_factory.hpp:77] Creating layer map32_2_eltsum
I0417 10:26:57.995096 22508 net.cpp:84] Creating Layer map32_2_eltsum
I0417 10:26:57.995100 22508 net.cpp:406] map32_2_eltsum <- map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0417 10:26:57.995102 22508 net.cpp:406] map32_2_eltsum <- map32_2_conv_b
I0417 10:26:57.995107 22508 net.cpp:380] map32_2_eltsum -> map32_2_eltsum
I0417 10:26:57.995126 22508 net.cpp:122] Setting up map32_2_eltsum
I0417 10:26:57.995131 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.995144 22508 net.cpp:137] Memory required for data: 421005312
I0417 10:26:57.995147 22508 layer_factory.hpp:77] Creating layer map32_2_relu_after_sum
I0417 10:26:57.995151 22508 net.cpp:84] Creating Layer map32_2_relu_after_sum
I0417 10:26:57.995154 22508 net.cpp:406] map32_2_relu_after_sum <- map32_2_eltsum
I0417 10:26:57.995159 22508 net.cpp:367] map32_2_relu_after_sum -> map32_2_eltsum (in-place)
I0417 10:26:57.995719 22508 net.cpp:122] Setting up map32_2_relu_after_sum
I0417 10:26:57.995730 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.995733 22508 net.cpp:137] Memory required for data: 425199616
I0417 10:26:57.995736 22508 layer_factory.hpp:77] Creating layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0417 10:26:57.995743 22508 net.cpp:84] Creating Layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0417 10:26:57.995748 22508 net.cpp:406] map32_2_eltsum_map32_2_relu_after_sum_0_split <- map32_2_eltsum
I0417 10:26:57.995753 22508 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0417 10:26:57.995760 22508 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0417 10:26:57.995800 22508 net.cpp:122] Setting up map32_2_eltsum_map32_2_relu_after_sum_0_split
I0417 10:26:57.995806 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.995810 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.995811 22508 net.cpp:137] Memory required for data: 433588224
I0417 10:26:57.995815 22508 layer_factory.hpp:77] Creating layer map32_3_conv_a
I0417 10:26:57.995823 22508 net.cpp:84] Creating Layer map32_3_conv_a
I0417 10:26:57.995827 22508 net.cpp:406] map32_3_conv_a <- map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0417 10:26:57.995833 22508 net.cpp:380] map32_3_conv_a -> map32_3_conv_a
I0417 10:26:57.997576 22508 net.cpp:122] Setting up map32_3_conv_a
I0417 10:26:57.997587 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.997601 22508 net.cpp:137] Memory required for data: 437782528
I0417 10:26:57.997606 22508 layer_factory.hpp:77] Creating layer map32_3_bn_a
I0417 10:26:57.997615 22508 net.cpp:84] Creating Layer map32_3_bn_a
I0417 10:26:57.997619 22508 net.cpp:406] map32_3_bn_a <- map32_3_conv_a
I0417 10:26:57.997625 22508 net.cpp:367] map32_3_bn_a -> map32_3_conv_a (in-place)
I0417 10:26:57.997787 22508 net.cpp:122] Setting up map32_3_bn_a
I0417 10:26:57.997793 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.997795 22508 net.cpp:137] Memory required for data: 441976832
I0417 10:26:57.997802 22508 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0417 10:26:57.997809 22508 net.cpp:84] Creating Layer map32_3_scale_a
I0417 10:26:57.997814 22508 net.cpp:406] map32_3_scale_a <- map32_3_conv_a
I0417 10:26:57.997818 22508 net.cpp:367] map32_3_scale_a -> map32_3_conv_a (in-place)
I0417 10:26:57.997846 22508 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0417 10:26:57.997942 22508 net.cpp:122] Setting up map32_3_scale_a
I0417 10:26:57.997948 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.997951 22508 net.cpp:137] Memory required for data: 446171136
I0417 10:26:57.997956 22508 layer_factory.hpp:77] Creating layer map32_3_relu_a
I0417 10:26:57.997961 22508 net.cpp:84] Creating Layer map32_3_relu_a
I0417 10:26:57.997963 22508 net.cpp:406] map32_3_relu_a <- map32_3_conv_a
I0417 10:26:57.997967 22508 net.cpp:367] map32_3_relu_a -> map32_3_conv_a (in-place)
I0417 10:26:57.998122 22508 net.cpp:122] Setting up map32_3_relu_a
I0417 10:26:57.998131 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.998132 22508 net.cpp:137] Memory required for data: 450365440
I0417 10:26:57.998136 22508 layer_factory.hpp:77] Creating layer map32_3_conv_b
I0417 10:26:57.998152 22508 net.cpp:84] Creating Layer map32_3_conv_b
I0417 10:26:57.998157 22508 net.cpp:406] map32_3_conv_b <- map32_3_conv_a
I0417 10:26:57.998162 22508 net.cpp:380] map32_3_conv_b -> map32_3_conv_b
I0417 10:26:57.999879 22508 net.cpp:122] Setting up map32_3_conv_b
I0417 10:26:57.999902 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:57.999905 22508 net.cpp:137] Memory required for data: 454559744
I0417 10:26:57.999912 22508 layer_factory.hpp:77] Creating layer map32_3_bn_b
I0417 10:26:57.999919 22508 net.cpp:84] Creating Layer map32_3_bn_b
I0417 10:26:57.999923 22508 net.cpp:406] map32_3_bn_b <- map32_3_conv_b
I0417 10:26:57.999929 22508 net.cpp:367] map32_3_bn_b -> map32_3_conv_b (in-place)
I0417 10:26:58.000107 22508 net.cpp:122] Setting up map32_3_bn_b
I0417 10:26:58.000113 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:58.000115 22508 net.cpp:137] Memory required for data: 458754048
I0417 10:26:58.000121 22508 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0417 10:26:58.000128 22508 net.cpp:84] Creating Layer map32_3_scale_b
I0417 10:26:58.000133 22508 net.cpp:406] map32_3_scale_b <- map32_3_conv_b
I0417 10:26:58.000138 22508 net.cpp:367] map32_3_scale_b -> map32_3_conv_b (in-place)
I0417 10:26:58.000172 22508 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0417 10:26:58.000270 22508 net.cpp:122] Setting up map32_3_scale_b
I0417 10:26:58.000277 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:58.000279 22508 net.cpp:137] Memory required for data: 462948352
I0417 10:26:58.000283 22508 layer_factory.hpp:77] Creating layer map32_3_eltsum
I0417 10:26:58.000289 22508 net.cpp:84] Creating Layer map32_3_eltsum
I0417 10:26:58.000293 22508 net.cpp:406] map32_3_eltsum <- map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0417 10:26:58.000296 22508 net.cpp:406] map32_3_eltsum <- map32_3_conv_b
I0417 10:26:58.000300 22508 net.cpp:380] map32_3_eltsum -> map32_3_eltsum
I0417 10:26:58.000319 22508 net.cpp:122] Setting up map32_3_eltsum
I0417 10:26:58.000324 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:58.000326 22508 net.cpp:137] Memory required for data: 467142656
I0417 10:26:58.000329 22508 layer_factory.hpp:77] Creating layer map32_3_relu_after_sum
I0417 10:26:58.000332 22508 net.cpp:84] Creating Layer map32_3_relu_after_sum
I0417 10:26:58.000336 22508 net.cpp:406] map32_3_relu_after_sum <- map32_3_eltsum
I0417 10:26:58.000341 22508 net.cpp:367] map32_3_relu_after_sum -> map32_3_eltsum (in-place)
I0417 10:26:58.000493 22508 net.cpp:122] Setting up map32_3_relu_after_sum
I0417 10:26:58.000500 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:58.000504 22508 net.cpp:137] Memory required for data: 471336960
I0417 10:26:58.000505 22508 layer_factory.hpp:77] Creating layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0417 10:26:58.000510 22508 net.cpp:84] Creating Layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0417 10:26:58.000514 22508 net.cpp:406] map32_3_eltsum_map32_3_relu_after_sum_0_split <- map32_3_eltsum
I0417 10:26:58.000520 22508 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0417 10:26:58.000525 22508 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0417 10:26:58.000560 22508 net.cpp:122] Setting up map32_3_eltsum_map32_3_relu_after_sum_0_split
I0417 10:26:58.000567 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:58.000571 22508 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I0417 10:26:58.000572 22508 net.cpp:137] Memory required for data: 479725568
I0417 10:26:58.000574 22508 layer_factory.hpp:77] Creating layer map64_1_conv_proj
I0417 10:26:58.000583 22508 net.cpp:84] Creating Layer map64_1_conv_proj
I0417 10:26:58.000587 22508 net.cpp:406] map64_1_conv_proj <- map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0417 10:26:58.000591 22508 net.cpp:380] map64_1_conv_proj -> map64_1_conv_proj
I0417 10:26:58.003000 22508 net.cpp:122] Setting up map64_1_conv_proj
I0417 10:26:58.003012 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.003016 22508 net.cpp:137] Memory required for data: 481822720
I0417 10:26:58.003033 22508 layer_factory.hpp:77] Creating layer map64_1_bn_proj
I0417 10:26:58.003063 22508 net.cpp:84] Creating Layer map64_1_bn_proj
I0417 10:26:58.003067 22508 net.cpp:406] map64_1_bn_proj <- map64_1_conv_proj
I0417 10:26:58.003072 22508 net.cpp:367] map64_1_bn_proj -> map64_1_conv_proj (in-place)
I0417 10:26:58.003252 22508 net.cpp:122] Setting up map64_1_bn_proj
I0417 10:26:58.003259 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.003262 22508 net.cpp:137] Memory required for data: 483919872
I0417 10:26:58.003268 22508 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0417 10:26:58.003274 22508 net.cpp:84] Creating Layer map64_1_scale_proj
I0417 10:26:58.003278 22508 net.cpp:406] map64_1_scale_proj <- map64_1_conv_proj
I0417 10:26:58.003281 22508 net.cpp:367] map64_1_scale_proj -> map64_1_conv_proj (in-place)
I0417 10:26:58.003319 22508 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0417 10:26:58.003417 22508 net.cpp:122] Setting up map64_1_scale_proj
I0417 10:26:58.003424 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.003427 22508 net.cpp:137] Memory required for data: 486017024
I0417 10:26:58.003432 22508 layer_factory.hpp:77] Creating layer map64_1_conv_a
I0417 10:26:58.003442 22508 net.cpp:84] Creating Layer map64_1_conv_a
I0417 10:26:58.003446 22508 net.cpp:406] map64_1_conv_a <- map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0417 10:26:58.003454 22508 net.cpp:380] map64_1_conv_a -> map64_1_conv_a
I0417 10:26:58.005417 22508 net.cpp:122] Setting up map64_1_conv_a
I0417 10:26:58.005429 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.005432 22508 net.cpp:137] Memory required for data: 488114176
I0417 10:26:58.005437 22508 layer_factory.hpp:77] Creating layer map64_1_bn_a
I0417 10:26:58.005447 22508 net.cpp:84] Creating Layer map64_1_bn_a
I0417 10:26:58.005450 22508 net.cpp:406] map64_1_bn_a <- map64_1_conv_a
I0417 10:26:58.005456 22508 net.cpp:367] map64_1_bn_a -> map64_1_conv_a (in-place)
I0417 10:26:58.005628 22508 net.cpp:122] Setting up map64_1_bn_a
I0417 10:26:58.005635 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.005637 22508 net.cpp:137] Memory required for data: 490211328
I0417 10:26:58.005643 22508 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0417 10:26:58.005650 22508 net.cpp:84] Creating Layer map64_1_scale_a
I0417 10:26:58.005652 22508 net.cpp:406] map64_1_scale_a <- map64_1_conv_a
I0417 10:26:58.005657 22508 net.cpp:367] map64_1_scale_a -> map64_1_conv_a (in-place)
I0417 10:26:58.005689 22508 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0417 10:26:58.005789 22508 net.cpp:122] Setting up map64_1_scale_a
I0417 10:26:58.005795 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.005797 22508 net.cpp:137] Memory required for data: 492308480
I0417 10:26:58.005802 22508 layer_factory.hpp:77] Creating layer map64_1_relu_a
I0417 10:26:58.005810 22508 net.cpp:84] Creating Layer map64_1_relu_a
I0417 10:26:58.005812 22508 net.cpp:406] map64_1_relu_a <- map64_1_conv_a
I0417 10:26:58.005815 22508 net.cpp:367] map64_1_relu_a -> map64_1_conv_a (in-place)
I0417 10:26:58.006384 22508 net.cpp:122] Setting up map64_1_relu_a
I0417 10:26:58.006394 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.006409 22508 net.cpp:137] Memory required for data: 494405632
I0417 10:26:58.006412 22508 layer_factory.hpp:77] Creating layer map64_1_conv_b
I0417 10:26:58.006422 22508 net.cpp:84] Creating Layer map64_1_conv_b
I0417 10:26:58.006427 22508 net.cpp:406] map64_1_conv_b <- map64_1_conv_a
I0417 10:26:58.006433 22508 net.cpp:380] map64_1_conv_b -> map64_1_conv_b
I0417 10:26:58.009299 22508 net.cpp:122] Setting up map64_1_conv_b
I0417 10:26:58.009310 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.009315 22508 net.cpp:137] Memory required for data: 496502784
I0417 10:26:58.009335 22508 layer_factory.hpp:77] Creating layer map64_1_bn_b
I0417 10:26:58.009341 22508 net.cpp:84] Creating Layer map64_1_bn_b
I0417 10:26:58.009344 22508 net.cpp:406] map64_1_bn_b <- map64_1_conv_b
I0417 10:26:58.009351 22508 net.cpp:367] map64_1_bn_b -> map64_1_conv_b (in-place)
I0417 10:26:58.009549 22508 net.cpp:122] Setting up map64_1_bn_b
I0417 10:26:58.009559 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.009562 22508 net.cpp:137] Memory required for data: 498599936
I0417 10:26:58.009568 22508 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0417 10:26:58.009574 22508 net.cpp:84] Creating Layer map64_1_scale_b
I0417 10:26:58.009577 22508 net.cpp:406] map64_1_scale_b <- map64_1_conv_b
I0417 10:26:58.009582 22508 net.cpp:367] map64_1_scale_b -> map64_1_conv_b (in-place)
I0417 10:26:58.009614 22508 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0417 10:26:58.009717 22508 net.cpp:122] Setting up map64_1_scale_b
I0417 10:26:58.009726 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.009729 22508 net.cpp:137] Memory required for data: 500697088
I0417 10:26:58.009734 22508 layer_factory.hpp:77] Creating layer map64_1_eltsum
I0417 10:26:58.009739 22508 net.cpp:84] Creating Layer map64_1_eltsum
I0417 10:26:58.009742 22508 net.cpp:406] map64_1_eltsum <- map64_1_conv_proj
I0417 10:26:58.009748 22508 net.cpp:406] map64_1_eltsum <- map64_1_conv_b
I0417 10:26:58.009752 22508 net.cpp:380] map64_1_eltsum -> map64_1_eltsum
I0417 10:26:58.009771 22508 net.cpp:122] Setting up map64_1_eltsum
I0417 10:26:58.009776 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.009779 22508 net.cpp:137] Memory required for data: 502794240
I0417 10:26:58.009781 22508 layer_factory.hpp:77] Creating layer map64_1_relu_after_sum
I0417 10:26:58.009785 22508 net.cpp:84] Creating Layer map64_1_relu_after_sum
I0417 10:26:58.009789 22508 net.cpp:406] map64_1_relu_after_sum <- map64_1_eltsum
I0417 10:26:58.009794 22508 net.cpp:367] map64_1_relu_after_sum -> map64_1_eltsum (in-place)
I0417 10:26:58.010367 22508 net.cpp:122] Setting up map64_1_relu_after_sum
I0417 10:26:58.010378 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.010381 22508 net.cpp:137] Memory required for data: 504891392
I0417 10:26:58.010385 22508 layer_factory.hpp:77] Creating layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0417 10:26:58.010390 22508 net.cpp:84] Creating Layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0417 10:26:58.010404 22508 net.cpp:406] map64_1_eltsum_map64_1_relu_after_sum_0_split <- map64_1_eltsum
I0417 10:26:58.010409 22508 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0417 10:26:58.010416 22508 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0417 10:26:58.010455 22508 net.cpp:122] Setting up map64_1_eltsum_map64_1_relu_after_sum_0_split
I0417 10:26:58.010462 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.010464 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.010466 22508 net.cpp:137] Memory required for data: 509085696
I0417 10:26:58.010469 22508 layer_factory.hpp:77] Creating layer map64_2_conv_a
I0417 10:26:58.010479 22508 net.cpp:84] Creating Layer map64_2_conv_a
I0417 10:26:58.010483 22508 net.cpp:406] map64_2_conv_a <- map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0417 10:26:58.010488 22508 net.cpp:380] map64_2_conv_a -> map64_2_conv_a
I0417 10:26:58.012951 22508 net.cpp:122] Setting up map64_2_conv_a
I0417 10:26:58.012962 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.012976 22508 net.cpp:137] Memory required for data: 511182848
I0417 10:26:58.012981 22508 layer_factory.hpp:77] Creating layer map64_2_bn_a
I0417 10:26:58.012989 22508 net.cpp:84] Creating Layer map64_2_bn_a
I0417 10:26:58.012992 22508 net.cpp:406] map64_2_bn_a <- map64_2_conv_a
I0417 10:26:58.012998 22508 net.cpp:367] map64_2_bn_a -> map64_2_conv_a (in-place)
I0417 10:26:58.013180 22508 net.cpp:122] Setting up map64_2_bn_a
I0417 10:26:58.013186 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.013190 22508 net.cpp:137] Memory required for data: 513280000
I0417 10:26:58.013195 22508 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0417 10:26:58.013212 22508 net.cpp:84] Creating Layer map64_2_scale_a
I0417 10:26:58.013232 22508 net.cpp:406] map64_2_scale_a <- map64_2_conv_a
I0417 10:26:58.013237 22508 net.cpp:367] map64_2_scale_a -> map64_2_conv_a (in-place)
I0417 10:26:58.013276 22508 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0417 10:26:58.013382 22508 net.cpp:122] Setting up map64_2_scale_a
I0417 10:26:58.013388 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.013391 22508 net.cpp:137] Memory required for data: 515377152
I0417 10:26:58.013396 22508 layer_factory.hpp:77] Creating layer map64_2_relu_a
I0417 10:26:58.013402 22508 net.cpp:84] Creating Layer map64_2_relu_a
I0417 10:26:58.013406 22508 net.cpp:406] map64_2_relu_a <- map64_2_conv_a
I0417 10:26:58.013409 22508 net.cpp:367] map64_2_relu_a -> map64_2_conv_a (in-place)
I0417 10:26:58.013567 22508 net.cpp:122] Setting up map64_2_relu_a
I0417 10:26:58.013577 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.013581 22508 net.cpp:137] Memory required for data: 517474304
I0417 10:26:58.013584 22508 layer_factory.hpp:77] Creating layer map64_2_conv_b
I0417 10:26:58.013593 22508 net.cpp:84] Creating Layer map64_2_conv_b
I0417 10:26:58.013597 22508 net.cpp:406] map64_2_conv_b <- map64_2_conv_a
I0417 10:26:58.013602 22508 net.cpp:380] map64_2_conv_b -> map64_2_conv_b
I0417 10:26:58.015961 22508 net.cpp:122] Setting up map64_2_conv_b
I0417 10:26:58.015972 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.015975 22508 net.cpp:137] Memory required for data: 519571456
I0417 10:26:58.015980 22508 layer_factory.hpp:77] Creating layer map64_2_bn_b
I0417 10:26:58.016001 22508 net.cpp:84] Creating Layer map64_2_bn_b
I0417 10:26:58.016005 22508 net.cpp:406] map64_2_bn_b <- map64_2_conv_b
I0417 10:26:58.016010 22508 net.cpp:367] map64_2_bn_b -> map64_2_conv_b (in-place)
I0417 10:26:58.016187 22508 net.cpp:122] Setting up map64_2_bn_b
I0417 10:26:58.016194 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.016196 22508 net.cpp:137] Memory required for data: 521668608
I0417 10:26:58.016227 22508 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0417 10:26:58.016234 22508 net.cpp:84] Creating Layer map64_2_scale_b
I0417 10:26:58.016239 22508 net.cpp:406] map64_2_scale_b <- map64_2_conv_b
I0417 10:26:58.016254 22508 net.cpp:367] map64_2_scale_b -> map64_2_conv_b (in-place)
I0417 10:26:58.016288 22508 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0417 10:26:58.016392 22508 net.cpp:122] Setting up map64_2_scale_b
I0417 10:26:58.016398 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.016400 22508 net.cpp:137] Memory required for data: 523765760
I0417 10:26:58.016404 22508 layer_factory.hpp:77] Creating layer map64_2_eltsum
I0417 10:26:58.016410 22508 net.cpp:84] Creating Layer map64_2_eltsum
I0417 10:26:58.016413 22508 net.cpp:406] map64_2_eltsum <- map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0417 10:26:58.016428 22508 net.cpp:406] map64_2_eltsum <- map64_2_conv_b
I0417 10:26:58.016436 22508 net.cpp:380] map64_2_eltsum -> map64_2_eltsum
I0417 10:26:58.016453 22508 net.cpp:122] Setting up map64_2_eltsum
I0417 10:26:58.016459 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.016461 22508 net.cpp:137] Memory required for data: 525862912
I0417 10:26:58.016463 22508 layer_factory.hpp:77] Creating layer map64_2_relu_after_sum
I0417 10:26:58.016469 22508 net.cpp:84] Creating Layer map64_2_relu_after_sum
I0417 10:26:58.016474 22508 net.cpp:406] map64_2_relu_after_sum <- map64_2_eltsum
I0417 10:26:58.016476 22508 net.cpp:367] map64_2_relu_after_sum -> map64_2_eltsum (in-place)
I0417 10:26:58.017048 22508 net.cpp:122] Setting up map64_2_relu_after_sum
I0417 10:26:58.017060 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.017061 22508 net.cpp:137] Memory required for data: 527960064
I0417 10:26:58.017065 22508 layer_factory.hpp:77] Creating layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0417 10:26:58.017069 22508 net.cpp:84] Creating Layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0417 10:26:58.017073 22508 net.cpp:406] map64_2_eltsum_map64_2_relu_after_sum_0_split <- map64_2_eltsum
I0417 10:26:58.017102 22508 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0417 10:26:58.017109 22508 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0417 10:26:58.017150 22508 net.cpp:122] Setting up map64_2_eltsum_map64_2_relu_after_sum_0_split
I0417 10:26:58.017156 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.017159 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.017161 22508 net.cpp:137] Memory required for data: 532154368
I0417 10:26:58.017164 22508 layer_factory.hpp:77] Creating layer map64_3_conv_a
I0417 10:26:58.017180 22508 net.cpp:84] Creating Layer map64_3_conv_a
I0417 10:26:58.017184 22508 net.cpp:406] map64_3_conv_a <- map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0417 10:26:58.017190 22508 net.cpp:380] map64_3_conv_a -> map64_3_conv_a
I0417 10:26:58.019279 22508 net.cpp:122] Setting up map64_3_conv_a
I0417 10:26:58.019291 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.019295 22508 net.cpp:137] Memory required for data: 534251520
I0417 10:26:58.019300 22508 layer_factory.hpp:77] Creating layer map64_3_bn_a
I0417 10:26:58.019309 22508 net.cpp:84] Creating Layer map64_3_bn_a
I0417 10:26:58.019314 22508 net.cpp:406] map64_3_bn_a <- map64_3_conv_a
I0417 10:26:58.019320 22508 net.cpp:367] map64_3_bn_a -> map64_3_conv_a (in-place)
I0417 10:26:58.019507 22508 net.cpp:122] Setting up map64_3_bn_a
I0417 10:26:58.019515 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.019516 22508 net.cpp:137] Memory required for data: 536348672
I0417 10:26:58.019522 22508 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0417 10:26:58.019531 22508 net.cpp:84] Creating Layer map64_3_scale_a
I0417 10:26:58.019534 22508 net.cpp:406] map64_3_scale_a <- map64_3_conv_a
I0417 10:26:58.019538 22508 net.cpp:367] map64_3_scale_a -> map64_3_conv_a (in-place)
I0417 10:26:58.019575 22508 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0417 10:26:58.019680 22508 net.cpp:122] Setting up map64_3_scale_a
I0417 10:26:58.019685 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.019687 22508 net.cpp:137] Memory required for data: 538445824
I0417 10:26:58.019692 22508 layer_factory.hpp:77] Creating layer map64_3_relu_a
I0417 10:26:58.019700 22508 net.cpp:84] Creating Layer map64_3_relu_a
I0417 10:26:58.019702 22508 net.cpp:406] map64_3_relu_a <- map64_3_conv_a
I0417 10:26:58.019706 22508 net.cpp:367] map64_3_relu_a -> map64_3_conv_a (in-place)
I0417 10:26:58.020288 22508 net.cpp:122] Setting up map64_3_relu_a
I0417 10:26:58.020299 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.020303 22508 net.cpp:137] Memory required for data: 540542976
I0417 10:26:58.020306 22508 layer_factory.hpp:77] Creating layer map64_3_conv_b
I0417 10:26:58.020315 22508 net.cpp:84] Creating Layer map64_3_conv_b
I0417 10:26:58.020319 22508 net.cpp:406] map64_3_conv_b <- map64_3_conv_a
I0417 10:26:58.020324 22508 net.cpp:380] map64_3_conv_b -> map64_3_conv_b
I0417 10:26:58.022666 22508 net.cpp:122] Setting up map64_3_conv_b
I0417 10:26:58.022677 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.022681 22508 net.cpp:137] Memory required for data: 542640128
I0417 10:26:58.022687 22508 layer_factory.hpp:77] Creating layer map64_3_bn_b
I0417 10:26:58.022706 22508 net.cpp:84] Creating Layer map64_3_bn_b
I0417 10:26:58.022709 22508 net.cpp:406] map64_3_bn_b <- map64_3_conv_b
I0417 10:26:58.022716 22508 net.cpp:367] map64_3_bn_b -> map64_3_conv_b (in-place)
I0417 10:26:58.022902 22508 net.cpp:122] Setting up map64_3_bn_b
I0417 10:26:58.022908 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.022910 22508 net.cpp:137] Memory required for data: 544737280
I0417 10:26:58.022917 22508 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0417 10:26:58.022924 22508 net.cpp:84] Creating Layer map64_3_scale_b
I0417 10:26:58.022927 22508 net.cpp:406] map64_3_scale_b <- map64_3_conv_b
I0417 10:26:58.022943 22508 net.cpp:367] map64_3_scale_b -> map64_3_conv_b (in-place)
I0417 10:26:58.022980 22508 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0417 10:26:58.023092 22508 net.cpp:122] Setting up map64_3_scale_b
I0417 10:26:58.023098 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.023102 22508 net.cpp:137] Memory required for data: 546834432
I0417 10:26:58.023105 22508 layer_factory.hpp:77] Creating layer map64_3_eltsum
I0417 10:26:58.023113 22508 net.cpp:84] Creating Layer map64_3_eltsum
I0417 10:26:58.023116 22508 net.cpp:406] map64_3_eltsum <- map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0417 10:26:58.023120 22508 net.cpp:406] map64_3_eltsum <- map64_3_conv_b
I0417 10:26:58.023128 22508 net.cpp:380] map64_3_eltsum -> map64_3_eltsum
I0417 10:26:58.023144 22508 net.cpp:122] Setting up map64_3_eltsum
I0417 10:26:58.023151 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.023154 22508 net.cpp:137] Memory required for data: 548931584
I0417 10:26:58.023156 22508 layer_factory.hpp:77] Creating layer map64_3_relu_after_sum
I0417 10:26:58.023160 22508 net.cpp:84] Creating Layer map64_3_relu_after_sum
I0417 10:26:58.023164 22508 net.cpp:406] map64_3_relu_after_sum <- map64_3_eltsum
I0417 10:26:58.023174 22508 net.cpp:367] map64_3_relu_after_sum -> map64_3_eltsum (in-place)
I0417 10:26:58.023331 22508 net.cpp:122] Setting up map64_3_relu_after_sum
I0417 10:26:58.023339 22508 net.cpp:129] Top shape: 128 64 8 8 (524288)
I0417 10:26:58.023341 22508 net.cpp:137] Memory required for data: 551028736
I0417 10:26:58.023344 22508 layer_factory.hpp:77] Creating layer pool_global
I0417 10:26:58.023353 22508 net.cpp:84] Creating Layer pool_global
I0417 10:26:58.023356 22508 net.cpp:406] pool_global <- map64_3_eltsum
I0417 10:26:58.023360 22508 net.cpp:380] pool_global -> pool_global
I0417 10:26:58.024025 22508 net.cpp:122] Setting up pool_global
I0417 10:26:58.024036 22508 net.cpp:129] Top shape: 128 64 1 1 (8192)
I0417 10:26:58.024039 22508 net.cpp:137] Memory required for data: 551061504
I0417 10:26:58.024042 22508 layer_factory.hpp:77] Creating layer score
I0417 10:26:58.024063 22508 net.cpp:84] Creating Layer score
I0417 10:26:58.024066 22508 net.cpp:406] score <- pool_global
I0417 10:26:58.024075 22508 net.cpp:380] score -> score
I0417 10:26:58.024205 22508 net.cpp:122] Setting up score
I0417 10:26:58.024219 22508 net.cpp:129] Top shape: 128 10 (1280)
I0417 10:26:58.024220 22508 net.cpp:137] Memory required for data: 551066624
I0417 10:26:58.024225 22508 layer_factory.hpp:77] Creating layer score_score_0_split
I0417 10:26:58.024245 22508 net.cpp:84] Creating Layer score_score_0_split
I0417 10:26:58.024247 22508 net.cpp:406] score_score_0_split <- score
I0417 10:26:58.024252 22508 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0417 10:26:58.024258 22508 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0417 10:26:58.024266 22508 net.cpp:380] score_score_0_split -> score_score_0_split_2
I0417 10:26:58.024307 22508 net.cpp:122] Setting up score_score_0_split
I0417 10:26:58.024313 22508 net.cpp:129] Top shape: 128 10 (1280)
I0417 10:26:58.024317 22508 net.cpp:129] Top shape: 128 10 (1280)
I0417 10:26:58.024319 22508 net.cpp:129] Top shape: 128 10 (1280)
I0417 10:26:58.024322 22508 net.cpp:137] Memory required for data: 551081984
I0417 10:26:58.024323 22508 layer_factory.hpp:77] Creating layer loss
I0417 10:26:58.024329 22508 net.cpp:84] Creating Layer loss
I0417 10:26:58.024333 22508 net.cpp:406] loss <- score_score_0_split_0
I0417 10:26:58.024338 22508 net.cpp:406] loss <- label_data_1_split_0
I0417 10:26:58.024343 22508 net.cpp:380] loss -> loss
I0417 10:26:58.024354 22508 layer_factory.hpp:77] Creating layer loss
I0417 10:26:58.024602 22508 net.cpp:122] Setting up loss
I0417 10:26:58.024613 22508 net.cpp:129] Top shape: (1)
I0417 10:26:58.024616 22508 net.cpp:132]     with loss weight 1
I0417 10:26:58.024641 22508 net.cpp:137] Memory required for data: 551081988
I0417 10:26:58.024644 22508 layer_factory.hpp:77] Creating layer acc/top1
I0417 10:26:58.024652 22508 net.cpp:84] Creating Layer acc/top1
I0417 10:26:58.024667 22508 net.cpp:406] acc/top1 <- score_score_0_split_1
I0417 10:26:58.024672 22508 net.cpp:406] acc/top1 <- label_data_1_split_1
I0417 10:26:58.024677 22508 net.cpp:380] acc/top1 -> acctop1
I0417 10:26:58.024688 22508 net.cpp:122] Setting up acc/top1
I0417 10:26:58.024693 22508 net.cpp:129] Top shape: (1)
I0417 10:26:58.024695 22508 net.cpp:137] Memory required for data: 551081992
I0417 10:26:58.024698 22508 layer_factory.hpp:77] Creating layer acc/top5
I0417 10:26:58.024704 22508 net.cpp:84] Creating Layer acc/top5
I0417 10:26:58.024708 22508 net.cpp:406] acc/top5 <- score_score_0_split_2
I0417 10:26:58.024711 22508 net.cpp:406] acc/top5 <- label_data_1_split_2
I0417 10:26:58.024715 22508 net.cpp:380] acc/top5 -> acctop5
I0417 10:26:58.024721 22508 net.cpp:122] Setting up acc/top5
I0417 10:26:58.024725 22508 net.cpp:129] Top shape: (1)
I0417 10:26:58.024727 22508 net.cpp:137] Memory required for data: 551081996
I0417 10:26:58.024729 22508 net.cpp:200] acc/top5 does not need backward computation.
I0417 10:26:58.024732 22508 net.cpp:200] acc/top1 does not need backward computation.
I0417 10:26:58.024735 22508 net.cpp:198] loss needs backward computation.
I0417 10:26:58.024739 22508 net.cpp:198] score_score_0_split needs backward computation.
I0417 10:26:58.024742 22508 net.cpp:198] score needs backward computation.
I0417 10:26:58.024744 22508 net.cpp:198] pool_global needs backward computation.
I0417 10:26:58.024747 22508 net.cpp:198] map64_3_relu_after_sum needs backward computation.
I0417 10:26:58.024749 22508 net.cpp:198] map64_3_eltsum needs backward computation.
I0417 10:26:58.024752 22508 net.cpp:198] map64_3_scale_b needs backward computation.
I0417 10:26:58.024755 22508 net.cpp:198] map64_3_bn_b needs backward computation.
I0417 10:26:58.024757 22508 net.cpp:198] map64_3_conv_b needs backward computation.
I0417 10:26:58.024760 22508 net.cpp:198] map64_3_relu_a needs backward computation.
I0417 10:26:58.024762 22508 net.cpp:198] map64_3_scale_a needs backward computation.
I0417 10:26:58.024765 22508 net.cpp:198] map64_3_bn_a needs backward computation.
I0417 10:26:58.024766 22508 net.cpp:198] map64_3_conv_a needs backward computation.
I0417 10:26:58.024770 22508 net.cpp:198] map64_2_eltsum_map64_2_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.024771 22508 net.cpp:198] map64_2_relu_after_sum needs backward computation.
I0417 10:26:58.024775 22508 net.cpp:198] map64_2_eltsum needs backward computation.
I0417 10:26:58.024778 22508 net.cpp:198] map64_2_scale_b needs backward computation.
I0417 10:26:58.024780 22508 net.cpp:198] map64_2_bn_b needs backward computation.
I0417 10:26:58.024783 22508 net.cpp:198] map64_2_conv_b needs backward computation.
I0417 10:26:58.024785 22508 net.cpp:198] map64_2_relu_a needs backward computation.
I0417 10:26:58.024787 22508 net.cpp:198] map64_2_scale_a needs backward computation.
I0417 10:26:58.024790 22508 net.cpp:198] map64_2_bn_a needs backward computation.
I0417 10:26:58.024791 22508 net.cpp:198] map64_2_conv_a needs backward computation.
I0417 10:26:58.024794 22508 net.cpp:198] map64_1_eltsum_map64_1_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.024796 22508 net.cpp:198] map64_1_relu_after_sum needs backward computation.
I0417 10:26:58.024799 22508 net.cpp:198] map64_1_eltsum needs backward computation.
I0417 10:26:58.024802 22508 net.cpp:198] map64_1_scale_b needs backward computation.
I0417 10:26:58.024804 22508 net.cpp:198] map64_1_bn_b needs backward computation.
I0417 10:26:58.024806 22508 net.cpp:198] map64_1_conv_b needs backward computation.
I0417 10:26:58.024809 22508 net.cpp:198] map64_1_relu_a needs backward computation.
I0417 10:26:58.024811 22508 net.cpp:198] map64_1_scale_a needs backward computation.
I0417 10:26:58.024813 22508 net.cpp:198] map64_1_bn_a needs backward computation.
I0417 10:26:58.024816 22508 net.cpp:198] map64_1_conv_a needs backward computation.
I0417 10:26:58.024818 22508 net.cpp:198] map64_1_scale_proj needs backward computation.
I0417 10:26:58.024821 22508 net.cpp:198] map64_1_bn_proj needs backward computation.
I0417 10:26:58.024832 22508 net.cpp:198] map64_1_conv_proj needs backward computation.
I0417 10:26:58.024835 22508 net.cpp:198] map32_3_eltsum_map32_3_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.024838 22508 net.cpp:198] map32_3_relu_after_sum needs backward computation.
I0417 10:26:58.024840 22508 net.cpp:198] map32_3_eltsum needs backward computation.
I0417 10:26:58.024843 22508 net.cpp:198] map32_3_scale_b needs backward computation.
I0417 10:26:58.024845 22508 net.cpp:198] map32_3_bn_b needs backward computation.
I0417 10:26:58.024847 22508 net.cpp:198] map32_3_conv_b needs backward computation.
I0417 10:26:58.024850 22508 net.cpp:198] map32_3_relu_a needs backward computation.
I0417 10:26:58.024852 22508 net.cpp:198] map32_3_scale_a needs backward computation.
I0417 10:26:58.024854 22508 net.cpp:198] map32_3_bn_a needs backward computation.
I0417 10:26:58.024857 22508 net.cpp:198] map32_3_conv_a needs backward computation.
I0417 10:26:58.024859 22508 net.cpp:198] map32_2_eltsum_map32_2_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.024862 22508 net.cpp:198] map32_2_relu_after_sum needs backward computation.
I0417 10:26:58.024864 22508 net.cpp:198] map32_2_eltsum needs backward computation.
I0417 10:26:58.024866 22508 net.cpp:198] map32_2_scale_b needs backward computation.
I0417 10:26:58.024869 22508 net.cpp:198] map32_2_bn_b needs backward computation.
I0417 10:26:58.024871 22508 net.cpp:198] map32_2_conv_b needs backward computation.
I0417 10:26:58.024873 22508 net.cpp:198] map32_2_relu_a needs backward computation.
I0417 10:26:58.024875 22508 net.cpp:198] map32_2_scale_a needs backward computation.
I0417 10:26:58.024878 22508 net.cpp:198] map32_2_bn_a needs backward computation.
I0417 10:26:58.024880 22508 net.cpp:198] map32_2_conv_a needs backward computation.
I0417 10:26:58.024883 22508 net.cpp:198] map32_1_eltsum_map32_1_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.024885 22508 net.cpp:198] map32_1_relu_after_sum needs backward computation.
I0417 10:26:58.024888 22508 net.cpp:198] map32_1_eltsum needs backward computation.
I0417 10:26:58.024890 22508 net.cpp:198] map32_1_scale_b needs backward computation.
I0417 10:26:58.024893 22508 net.cpp:198] map32_1_bn_b needs backward computation.
I0417 10:26:58.024894 22508 net.cpp:198] map32_1_conv_b needs backward computation.
I0417 10:26:58.024897 22508 net.cpp:198] map32_1_relu_a needs backward computation.
I0417 10:26:58.024899 22508 net.cpp:198] map32_1_scale_a needs backward computation.
I0417 10:26:58.024901 22508 net.cpp:198] map32_1_bn_a needs backward computation.
I0417 10:26:58.024904 22508 net.cpp:198] map32_1_conv_a needs backward computation.
I0417 10:26:58.024906 22508 net.cpp:198] map32_1_scale_proj needs backward computation.
I0417 10:26:58.024909 22508 net.cpp:198] map32_1_bn_proj needs backward computation.
I0417 10:26:58.024910 22508 net.cpp:198] map32_1_conv_proj needs backward computation.
I0417 10:26:58.024914 22508 net.cpp:198] map16_3_eltsum_map16_3_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.024916 22508 net.cpp:198] map16_3_relu_after_sum needs backward computation.
I0417 10:26:58.024919 22508 net.cpp:198] map16_3_eltsum needs backward computation.
I0417 10:26:58.024921 22508 net.cpp:198] map16_3_scale_b needs backward computation.
I0417 10:26:58.024924 22508 net.cpp:198] map16_3_bn_b needs backward computation.
I0417 10:26:58.024925 22508 net.cpp:198] map16_3_conv_b needs backward computation.
I0417 10:26:58.024929 22508 net.cpp:198] map16_3_relu_a needs backward computation.
I0417 10:26:58.024930 22508 net.cpp:198] map16_3_scale_a needs backward computation.
I0417 10:26:58.024932 22508 net.cpp:198] map16_3_bn_a needs backward computation.
I0417 10:26:58.024935 22508 net.cpp:198] map16_3_conv_a needs backward computation.
I0417 10:26:58.024936 22508 net.cpp:198] map16_2_eltsum_map16_2_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.024940 22508 net.cpp:198] map16_2_relu_after_sum needs backward computation.
I0417 10:26:58.024947 22508 net.cpp:198] map16_2_eltsum needs backward computation.
I0417 10:26:58.024951 22508 net.cpp:198] map16_2_scale_b needs backward computation.
I0417 10:26:58.024953 22508 net.cpp:198] map16_2_bn_b needs backward computation.
I0417 10:26:58.024955 22508 net.cpp:198] map16_2_conv_b needs backward computation.
I0417 10:26:58.024957 22508 net.cpp:198] map16_2_relu_a needs backward computation.
I0417 10:26:58.024960 22508 net.cpp:198] map16_2_scale_a needs backward computation.
I0417 10:26:58.024962 22508 net.cpp:198] map16_2_bn_a needs backward computation.
I0417 10:26:58.024965 22508 net.cpp:198] map16_2_conv_a needs backward computation.
I0417 10:26:58.024966 22508 net.cpp:198] map16_1_eltsum_map16_1_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.024969 22508 net.cpp:198] map16_1_relu_after_sum needs backward computation.
I0417 10:26:58.024971 22508 net.cpp:198] map16_1_eltsum needs backward computation.
I0417 10:26:58.024974 22508 net.cpp:198] map16_1_scale_b needs backward computation.
I0417 10:26:58.024976 22508 net.cpp:198] map16_1_bn_b needs backward computation.
I0417 10:26:58.024979 22508 net.cpp:198] map16_1_conv_b needs backward computation.
I0417 10:26:58.024981 22508 net.cpp:198] map16_1_relu_a needs backward computation.
I0417 10:26:58.024983 22508 net.cpp:198] map16_1_scale_a needs backward computation.
I0417 10:26:58.024986 22508 net.cpp:198] map16_1_bn_a needs backward computation.
I0417 10:26:58.024988 22508 net.cpp:198] map16_1_conv_a needs backward computation.
I0417 10:26:58.024991 22508 net.cpp:198] conv1_relu_conv1_0_split needs backward computation.
I0417 10:26:58.024993 22508 net.cpp:198] relu_conv1 needs backward computation.
I0417 10:26:58.024996 22508 net.cpp:198] scale_conv1 needs backward computation.
I0417 10:26:58.024997 22508 net.cpp:198] bn_conv1 needs backward computation.
I0417 10:26:58.025001 22508 net.cpp:198] conv1 needs backward computation.
I0417 10:26:58.025003 22508 net.cpp:200] label_data_1_split does not need backward computation.
I0417 10:26:58.025007 22508 net.cpp:200] data does not need backward computation.
I0417 10:26:58.025010 22508 net.cpp:242] This network produces output acctop1
I0417 10:26:58.025012 22508 net.cpp:242] This network produces output acctop5
I0417 10:26:58.025015 22508 net.cpp:242] This network produces output loss
I0417 10:26:58.025065 22508 net.cpp:255] Network initialization done.
I0417 10:26:58.027416 22508 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: resnet20_relu_msra_cifar10.prototxt
I0417 10:26:58.027428 22508 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0417 10:26:58.027437 22508 solver.cpp:173] Creating test net (#0) specified by net file: resnet20_relu_msra_cifar10.prototxt
I0417 10:26:58.027564 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0417 10:26:58.027573 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv1
I0417 10:26:58.027580 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_1_bn_a
I0417 10:26:58.027585 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_1_bn_b
I0417 10:26:58.027590 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_2_bn_a
I0417 10:26:58.027597 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_2_bn_b
I0417 10:26:58.027602 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_3_bn_a
I0417 10:26:58.027606 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map16_3_bn_b
I0417 10:26:58.027613 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_proj
I0417 10:26:58.027617 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_a
I0417 10:26:58.027633 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_1_bn_b
I0417 10:26:58.027639 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_2_bn_a
I0417 10:26:58.027645 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_2_bn_b
I0417 10:26:58.027650 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_3_bn_a
I0417 10:26:58.027655 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map32_3_bn_b
I0417 10:26:58.027662 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_proj
I0417 10:26:58.027667 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_a
I0417 10:26:58.027673 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_1_bn_b
I0417 10:26:58.027678 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_2_bn_a
I0417 10:26:58.027683 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_2_bn_b
I0417 10:26:58.027688 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_3_bn_a
I0417 10:26:58.027694 22508 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer map64_3_bn_b
I0417 10:26:58.028159 22508 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 32
    mean_file: "/optimus_data/backed_up/cifar10/cifar10-zca-whitened/mean.binaryproto"
  }
  data_param {
    source: "/optimus_data/backed_up/cifar10/cifar10-zca-whitened/cifar-test-leveldb/"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "map16_1_conv_a"
  type: "Convolution"
  bottom: "conv1"
  top: "map16_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_a"
  type: "BatchNorm"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_1_scale_a"
  type: "Scale"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_relu_a"
  type: "ReLU"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_a"
}
layer {
  name: "map16_1_conv_b"
  type: "Convolution"
  bottom: "map16_1_conv_a"
  top: "map16_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_1_bn_b"
  type: "BatchNorm"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_1_scale_b"
  type: "Scale"
  bottom: "map16_1_conv_b"
  top: "map16_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_1_eltsum"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "map16_1_conv_b"
  top: "map16_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_1_relu_after_sum"
  type: "ReLU"
  bottom: "map16_1_eltsum"
  top: "map16_1_eltsum"
}
layer {
  name: "map16_2_conv_a"
  type: "Convolution"
  bottom: "map16_1_eltsum"
  top: "map16_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_a"
  type: "BatchNorm"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_2_scale_a"
  type: "Scale"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_relu_a"
  type: "ReLU"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_a"
}
layer {
  name: "map16_2_conv_b"
  type: "Convolution"
  bottom: "map16_2_conv_a"
  top: "map16_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_2_bn_b"
  type: "BatchNorm"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_2_scale_b"
  type: "Scale"
  bottom: "map16_2_conv_b"
  top: "map16_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_2_eltsum"
  type: "Eltwise"
  bottom: "map16_1_eltsum"
  bottom: "map16_2_conv_b"
  top: "map16_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_2_relu_after_sum"
  type: "ReLU"
  bottom: "map16_2_eltsum"
  top: "map16_2_eltsum"
}
layer {
  name: "map16_3_conv_a"
  type: "Convolution"
  bottom: "map16_2_eltsum"
  top: "map16_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_a"
  type: "BatchNorm"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_3_scale_a"
  type: "Scale"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_relu_a"
  type: "ReLU"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_a"
}
layer {
  name: "map16_3_conv_b"
  type: "Convolution"
  bottom: "map16_3_conv_a"
  top: "map16_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map16_3_bn_b"
  type: "BatchNorm"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map16_3_scale_b"
  type: "Scale"
  bottom: "map16_3_conv_b"
  top: "map16_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map16_3_eltsum"
  type: "Eltwise"
  bottom: "map16_2_eltsum"
  bottom: "map16_3_conv_b"
  top: "map16_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map16_3_relu_after_sum"
  type: "ReLU"
  bottom: "map16_3_eltsum"
  top: "map16_3_eltsum"
}
layer {
  name: "map32_1_conv_proj"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_proj"
  type: "BatchNorm"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_proj"
  type: "Scale"
  bottom: "map32_1_conv_proj"
  top: "map32_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_conv_a"
  type: "Convolution"
  bottom: "map16_3_eltsum"
  top: "map32_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_a"
  type: "BatchNorm"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_a"
  type: "Scale"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_relu_a"
  type: "ReLU"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_a"
}
layer {
  name: "map32_1_conv_b"
  type: "Convolution"
  bottom: "map32_1_conv_a"
  top: "map32_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_1_bn_b"
  type: "BatchNorm"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_1_scale_b"
  type: "Scale"
  bottom: "map32_1_conv_b"
  top: "map32_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_1_eltsum"
  type: "Eltwise"
  bottom: "map32_1_conv_proj"
  bottom: "map32_1_conv_b"
  top: "map32_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_1_relu_after_sum"
  type: "ReLU"
  bottom: "map32_1_eltsum"
  top: "map32_1_eltsum"
}
layer {
  name: "map32_2_conv_a"
  type: "Convolution"
  bottom: "map32_1_eltsum"
  top: "map32_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_a"
  type: "BatchNorm"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_2_scale_a"
  type: "Scale"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_relu_a"
  type: "ReLU"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_a"
}
layer {
  name: "map32_2_conv_b"
  type: "Convolution"
  bottom: "map32_2_conv_a"
  top: "map32_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_2_bn_b"
  type: "BatchNorm"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_2_scale_b"
  type: "Scale"
  bottom: "map32_2_conv_b"
  top: "map32_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_2_eltsum"
  type: "Eltwise"
  bottom: "map32_1_eltsum"
  bottom: "map32_2_conv_b"
  top: "map32_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_2_relu_after_sum"
  type: "ReLU"
  bottom: "map32_2_eltsum"
  top: "map32_2_eltsum"
}
layer {
  name: "map32_3_conv_a"
  type: "Convolution"
  bottom: "map32_2_eltsum"
  top: "map32_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_a"
  type: "BatchNorm"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_3_scale_a"
  type: "Scale"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_relu_a"
  type: "ReLU"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_a"
}
layer {
  name: "map32_3_conv_b"
  type: "Convolution"
  bottom: "map32_3_conv_a"
  top: "map32_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map32_3_bn_b"
  type: "BatchNorm"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map32_3_scale_b"
  type: "Scale"
  bottom: "map32_3_conv_b"
  top: "map32_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map32_3_eltsum"
  type: "Eltwise"
  bottom: "map32_2_eltsum"
  bottom: "map32_3_conv_b"
  top: "map32_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map32_3_relu_after_sum"
  type: "ReLU"
  bottom: "map32_3_eltsum"
  top: "map32_3_eltsum"
}
layer {
  name: "map64_1_conv_proj"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_proj"
  type: "BatchNorm"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_proj"
  type: "Scale"
  bottom: "map64_1_conv_proj"
  top: "map64_1_conv_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_conv_a"
  type: "Convolution"
  bottom: "map32_3_eltsum"
  top: "map64_1_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_a"
  type: "BatchNorm"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_a"
  type: "Scale"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_relu_a"
  type: "ReLU"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_a"
}
layer {
  name: "map64_1_conv_b"
  type: "Convolution"
  bottom: "map64_1_conv_a"
  top: "map64_1_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_1_bn_b"
  type: "BatchNorm"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_1_scale_b"
  type: "Scale"
  bottom: "map64_1_conv_b"
  top: "map64_1_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_1_eltsum"
  type: "Eltwise"
  bottom: "map64_1_conv_proj"
  bottom: "map64_1_conv_b"
  top: "map64_1_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_1_relu_after_sum"
  type: "ReLU"
  bottom: "map64_1_eltsum"
  top: "map64_1_eltsum"
}
layer {
  name: "map64_2_conv_a"
  type: "Convolution"
  bottom: "map64_1_eltsum"
  top: "map64_2_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_a"
  type: "BatchNorm"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_2_scale_a"
  type: "Scale"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_relu_a"
  type: "ReLU"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_a"
}
layer {
  name: "map64_2_conv_b"
  type: "Convolution"
  bottom: "map64_2_conv_a"
  top: "map64_2_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_2_bn_b"
  type: "BatchNorm"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_2_scale_b"
  type: "Scale"
  bottom: "map64_2_conv_b"
  top: "map64_2_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_2_eltsum"
  type: "Eltwise"
  bottom: "map64_1_eltsum"
  bottom: "map64_2_conv_b"
  top: "map64_2_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_2_relu_after_sum"
  type: "ReLU"
  bottom: "map64_2_eltsum"
  top: "map64_2_eltsum"
}
layer {
  name: "map64_3_conv_a"
  type: "Convolution"
  bottom: "map64_2_eltsum"
  top: "map64_3_conv_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_a"
  type: "BatchNorm"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_3_scale_a"
  type: "Scale"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_relu_a"
  type: "ReLU"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_a"
}
layer {
  name: "map64_3_conv_b"
  type: "Convolution"
  bottom: "map64_3_conv_a"
  top: "map64_3_conv_b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "map64_3_bn_b"
  type: "BatchNorm"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "map64_3_scale_b"
  type: "Scale"
  bottom: "map64_3_conv_b"
  top: "map64_3_conv_b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "map64_3_eltsum"
  type: "Eltwise"
  bottom: "map64_2_eltsum"
  bottom: "map64_3_conv_b"
  top: "map64_3_eltsum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "map64_3_relu_after_sum"
  type: "ReLU"
  bottom: "map64_3_eltsum"
  top: "map64_3_eltsum"
}
layer {
  name: "pool_global"
  type: "Pooling"
  bottom: "map64_3_eltsum"
  top: "pool_global"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_global"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc/top1"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "acc/top5"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "acctop5"
  accuracy_param {
    top_k: 5
  }
}
I0417 10:26:58.028522 22508 layer_factory.hpp:77] Creating layer data
I0417 10:26:58.029681 22508 db_leveldb.cpp:18] Opened leveldb /optimus_data/backed_up/cifar10/cifar10-zca-whitened/cifar-test-leveldb/
I0417 10:26:58.029791 22508 net.cpp:84] Creating Layer data
I0417 10:26:58.029799 22508 net.cpp:380] data -> data
I0417 10:26:58.029808 22508 net.cpp:380] data -> label
I0417 10:26:58.029814 22508 data_transformer.cpp:25] Loading mean file from: /optimus_data/backed_up/cifar10/cifar10-zca-whitened/mean.binaryproto
I0417 10:26:58.029996 22508 data_layer.cpp:45] output data size: 100,3,32,32
I0417 10:26:58.034979 22508 net.cpp:122] Setting up data
I0417 10:26:58.034991 22508 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0417 10:26:58.035006 22508 net.cpp:129] Top shape: 100 (100)
I0417 10:26:58.035009 22508 net.cpp:137] Memory required for data: 1229200
I0417 10:26:58.035012 22508 layer_factory.hpp:77] Creating layer label_data_1_split
I0417 10:26:58.035017 22508 net.cpp:84] Creating Layer label_data_1_split
I0417 10:26:58.035020 22508 net.cpp:406] label_data_1_split <- label
I0417 10:26:58.035027 22508 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0417 10:26:58.035034 22508 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0417 10:26:58.035050 22508 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0417 10:26:58.035240 22508 net.cpp:122] Setting up label_data_1_split
I0417 10:26:58.035248 22508 net.cpp:129] Top shape: 100 (100)
I0417 10:26:58.035251 22508 net.cpp:129] Top shape: 100 (100)
I0417 10:26:58.035256 22508 net.cpp:129] Top shape: 100 (100)
I0417 10:26:58.035259 22508 net.cpp:137] Memory required for data: 1230400
I0417 10:26:58.035262 22508 layer_factory.hpp:77] Creating layer conv1
I0417 10:26:58.035274 22508 net.cpp:84] Creating Layer conv1
I0417 10:26:58.035276 22508 net.cpp:406] conv1 <- data
I0417 10:26:58.035281 22508 net.cpp:380] conv1 -> conv1
I0417 10:26:58.037089 22508 net.cpp:122] Setting up conv1
I0417 10:26:58.037099 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.037114 22508 net.cpp:137] Memory required for data: 7784000
I0417 10:26:58.037124 22508 layer_factory.hpp:77] Creating layer bn_conv1
I0417 10:26:58.037133 22508 net.cpp:84] Creating Layer bn_conv1
I0417 10:26:58.037138 22508 net.cpp:406] bn_conv1 <- conv1
I0417 10:26:58.037154 22508 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0417 10:26:58.037358 22508 net.cpp:122] Setting up bn_conv1
I0417 10:26:58.037366 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.037369 22508 net.cpp:137] Memory required for data: 14337600
I0417 10:26:58.037379 22508 layer_factory.hpp:77] Creating layer scale_conv1
I0417 10:26:58.037386 22508 net.cpp:84] Creating Layer scale_conv1
I0417 10:26:58.037390 22508 net.cpp:406] scale_conv1 <- conv1
I0417 10:26:58.037395 22508 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0417 10:26:58.037436 22508 layer_factory.hpp:77] Creating layer scale_conv1
I0417 10:26:58.037546 22508 net.cpp:122] Setting up scale_conv1
I0417 10:26:58.037552 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.037555 22508 net.cpp:137] Memory required for data: 20891200
I0417 10:26:58.037561 22508 layer_factory.hpp:77] Creating layer relu_conv1
I0417 10:26:58.037569 22508 net.cpp:84] Creating Layer relu_conv1
I0417 10:26:58.037571 22508 net.cpp:406] relu_conv1 <- conv1
I0417 10:26:58.037575 22508 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0417 10:26:58.038185 22508 net.cpp:122] Setting up relu_conv1
I0417 10:26:58.038197 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.038199 22508 net.cpp:137] Memory required for data: 27444800
I0417 10:26:58.038203 22508 layer_factory.hpp:77] Creating layer conv1_relu_conv1_0_split
I0417 10:26:58.038206 22508 net.cpp:84] Creating Layer conv1_relu_conv1_0_split
I0417 10:26:58.038223 22508 net.cpp:406] conv1_relu_conv1_0_split <- conv1
I0417 10:26:58.038228 22508 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_0
I0417 10:26:58.038233 22508 net.cpp:380] conv1_relu_conv1_0_split -> conv1_relu_conv1_0_split_1
I0417 10:26:58.038283 22508 net.cpp:122] Setting up conv1_relu_conv1_0_split
I0417 10:26:58.038290 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.038293 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.038295 22508 net.cpp:137] Memory required for data: 40552000
I0417 10:26:58.038298 22508 layer_factory.hpp:77] Creating layer map16_1_conv_a
I0417 10:26:58.038307 22508 net.cpp:84] Creating Layer map16_1_conv_a
I0417 10:26:58.038311 22508 net.cpp:406] map16_1_conv_a <- conv1_relu_conv1_0_split_0
I0417 10:26:58.038317 22508 net.cpp:380] map16_1_conv_a -> map16_1_conv_a
I0417 10:26:58.040109 22508 net.cpp:122] Setting up map16_1_conv_a
I0417 10:26:58.040122 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.040136 22508 net.cpp:137] Memory required for data: 47105600
I0417 10:26:58.040144 22508 layer_factory.hpp:77] Creating layer map16_1_bn_a
I0417 10:26:58.040156 22508 net.cpp:84] Creating Layer map16_1_bn_a
I0417 10:26:58.040161 22508 net.cpp:406] map16_1_bn_a <- map16_1_conv_a
I0417 10:26:58.040179 22508 net.cpp:367] map16_1_bn_a -> map16_1_conv_a (in-place)
I0417 10:26:58.040496 22508 net.cpp:122] Setting up map16_1_bn_a
I0417 10:26:58.040503 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.040506 22508 net.cpp:137] Memory required for data: 53659200
I0417 10:26:58.040513 22508 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0417 10:26:58.040520 22508 net.cpp:84] Creating Layer map16_1_scale_a
I0417 10:26:58.040524 22508 net.cpp:406] map16_1_scale_a <- map16_1_conv_a
I0417 10:26:58.040529 22508 net.cpp:367] map16_1_scale_a -> map16_1_conv_a (in-place)
I0417 10:26:58.040575 22508 layer_factory.hpp:77] Creating layer map16_1_scale_a
I0417 10:26:58.040709 22508 net.cpp:122] Setting up map16_1_scale_a
I0417 10:26:58.040715 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.040719 22508 net.cpp:137] Memory required for data: 60212800
I0417 10:26:58.040724 22508 layer_factory.hpp:77] Creating layer map16_1_relu_a
I0417 10:26:58.040729 22508 net.cpp:84] Creating Layer map16_1_relu_a
I0417 10:26:58.040732 22508 net.cpp:406] map16_1_relu_a <- map16_1_conv_a
I0417 10:26:58.040740 22508 net.cpp:367] map16_1_relu_a -> map16_1_conv_a (in-place)
I0417 10:26:58.040902 22508 net.cpp:122] Setting up map16_1_relu_a
I0417 10:26:58.040910 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.040913 22508 net.cpp:137] Memory required for data: 66766400
I0417 10:26:58.040915 22508 layer_factory.hpp:77] Creating layer map16_1_conv_b
I0417 10:26:58.040925 22508 net.cpp:84] Creating Layer map16_1_conv_b
I0417 10:26:58.040930 22508 net.cpp:406] map16_1_conv_b <- map16_1_conv_a
I0417 10:26:58.040936 22508 net.cpp:380] map16_1_conv_b -> map16_1_conv_b
I0417 10:26:58.043138 22508 net.cpp:122] Setting up map16_1_conv_b
I0417 10:26:58.043150 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.043165 22508 net.cpp:137] Memory required for data: 73320000
I0417 10:26:58.043176 22508 layer_factory.hpp:77] Creating layer map16_1_bn_b
I0417 10:26:58.043184 22508 net.cpp:84] Creating Layer map16_1_bn_b
I0417 10:26:58.043187 22508 net.cpp:406] map16_1_bn_b <- map16_1_conv_b
I0417 10:26:58.043192 22508 net.cpp:367] map16_1_bn_b -> map16_1_conv_b (in-place)
I0417 10:26:58.043385 22508 net.cpp:122] Setting up map16_1_bn_b
I0417 10:26:58.043391 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.043395 22508 net.cpp:137] Memory required for data: 79873600
I0417 10:26:58.043403 22508 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0417 10:26:58.043409 22508 net.cpp:84] Creating Layer map16_1_scale_b
I0417 10:26:58.043412 22508 net.cpp:406] map16_1_scale_b <- map16_1_conv_b
I0417 10:26:58.043416 22508 net.cpp:367] map16_1_scale_b -> map16_1_conv_b (in-place)
I0417 10:26:58.043475 22508 layer_factory.hpp:77] Creating layer map16_1_scale_b
I0417 10:26:58.043588 22508 net.cpp:122] Setting up map16_1_scale_b
I0417 10:26:58.043596 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.043598 22508 net.cpp:137] Memory required for data: 86427200
I0417 10:26:58.043603 22508 layer_factory.hpp:77] Creating layer map16_1_eltsum
I0417 10:26:58.043609 22508 net.cpp:84] Creating Layer map16_1_eltsum
I0417 10:26:58.043612 22508 net.cpp:406] map16_1_eltsum <- conv1_relu_conv1_0_split_1
I0417 10:26:58.043617 22508 net.cpp:406] map16_1_eltsum <- map16_1_conv_b
I0417 10:26:58.043622 22508 net.cpp:380] map16_1_eltsum -> map16_1_eltsum
I0417 10:26:58.043645 22508 net.cpp:122] Setting up map16_1_eltsum
I0417 10:26:58.043650 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.043653 22508 net.cpp:137] Memory required for data: 92980800
I0417 10:26:58.043655 22508 layer_factory.hpp:77] Creating layer map16_1_relu_after_sum
I0417 10:26:58.043661 22508 net.cpp:84] Creating Layer map16_1_relu_after_sum
I0417 10:26:58.043665 22508 net.cpp:406] map16_1_relu_after_sum <- map16_1_eltsum
I0417 10:26:58.043668 22508 net.cpp:367] map16_1_relu_after_sum -> map16_1_eltsum (in-place)
I0417 10:26:58.043828 22508 net.cpp:122] Setting up map16_1_relu_after_sum
I0417 10:26:58.043836 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.043840 22508 net.cpp:137] Memory required for data: 99534400
I0417 10:26:58.043843 22508 layer_factory.hpp:77] Creating layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0417 10:26:58.043850 22508 net.cpp:84] Creating Layer map16_1_eltsum_map16_1_relu_after_sum_0_split
I0417 10:26:58.043855 22508 net.cpp:406] map16_1_eltsum_map16_1_relu_after_sum_0_split <- map16_1_eltsum
I0417 10:26:58.043861 22508 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0417 10:26:58.043867 22508 net.cpp:380] map16_1_eltsum_map16_1_relu_after_sum_0_split -> map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0417 10:26:58.043908 22508 net.cpp:122] Setting up map16_1_eltsum_map16_1_relu_after_sum_0_split
I0417 10:26:58.043915 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.043917 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.043920 22508 net.cpp:137] Memory required for data: 112641600
I0417 10:26:58.043922 22508 layer_factory.hpp:77] Creating layer map16_2_conv_a
I0417 10:26:58.043931 22508 net.cpp:84] Creating Layer map16_2_conv_a
I0417 10:26:58.043936 22508 net.cpp:406] map16_2_conv_a <- map16_1_eltsum_map16_1_relu_after_sum_0_split_0
I0417 10:26:58.043941 22508 net.cpp:380] map16_2_conv_a -> map16_2_conv_a
I0417 10:26:58.045542 22508 net.cpp:122] Setting up map16_2_conv_a
I0417 10:26:58.045554 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.045568 22508 net.cpp:137] Memory required for data: 119195200
I0417 10:26:58.045574 22508 layer_factory.hpp:77] Creating layer map16_2_bn_a
I0417 10:26:58.045581 22508 net.cpp:84] Creating Layer map16_2_bn_a
I0417 10:26:58.045584 22508 net.cpp:406] map16_2_bn_a <- map16_2_conv_a
I0417 10:26:58.045588 22508 net.cpp:367] map16_2_bn_a -> map16_2_conv_a (in-place)
I0417 10:26:58.045778 22508 net.cpp:122] Setting up map16_2_bn_a
I0417 10:26:58.045785 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.045788 22508 net.cpp:137] Memory required for data: 125748800
I0417 10:26:58.045794 22508 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0417 10:26:58.045799 22508 net.cpp:84] Creating Layer map16_2_scale_a
I0417 10:26:58.045801 22508 net.cpp:406] map16_2_scale_a <- map16_2_conv_a
I0417 10:26:58.045805 22508 net.cpp:367] map16_2_scale_a -> map16_2_conv_a (in-place)
I0417 10:26:58.045845 22508 layer_factory.hpp:77] Creating layer map16_2_scale_a
I0417 10:26:58.045954 22508 net.cpp:122] Setting up map16_2_scale_a
I0417 10:26:58.045961 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.045964 22508 net.cpp:137] Memory required for data: 132302400
I0417 10:26:58.045969 22508 layer_factory.hpp:77] Creating layer map16_2_relu_a
I0417 10:26:58.045985 22508 net.cpp:84] Creating Layer map16_2_relu_a
I0417 10:26:58.045990 22508 net.cpp:406] map16_2_relu_a <- map16_2_conv_a
I0417 10:26:58.045994 22508 net.cpp:367] map16_2_relu_a -> map16_2_conv_a (in-place)
I0417 10:26:58.046566 22508 net.cpp:122] Setting up map16_2_relu_a
I0417 10:26:58.046577 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.046581 22508 net.cpp:137] Memory required for data: 138856000
I0417 10:26:58.046584 22508 layer_factory.hpp:77] Creating layer map16_2_conv_b
I0417 10:26:58.046593 22508 net.cpp:84] Creating Layer map16_2_conv_b
I0417 10:26:58.046597 22508 net.cpp:406] map16_2_conv_b <- map16_2_conv_a
I0417 10:26:58.046602 22508 net.cpp:380] map16_2_conv_b -> map16_2_conv_b
I0417 10:26:58.048179 22508 net.cpp:122] Setting up map16_2_conv_b
I0417 10:26:58.048189 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.048204 22508 net.cpp:137] Memory required for data: 145409600
I0417 10:26:58.048210 22508 layer_factory.hpp:77] Creating layer map16_2_bn_b
I0417 10:26:58.048216 22508 net.cpp:84] Creating Layer map16_2_bn_b
I0417 10:26:58.048219 22508 net.cpp:406] map16_2_bn_b <- map16_2_conv_b
I0417 10:26:58.048224 22508 net.cpp:367] map16_2_bn_b -> map16_2_conv_b (in-place)
I0417 10:26:58.048415 22508 net.cpp:122] Setting up map16_2_bn_b
I0417 10:26:58.048421 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.048424 22508 net.cpp:137] Memory required for data: 151963200
I0417 10:26:58.048434 22508 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0417 10:26:58.048440 22508 net.cpp:84] Creating Layer map16_2_scale_b
I0417 10:26:58.048444 22508 net.cpp:406] map16_2_scale_b <- map16_2_conv_b
I0417 10:26:58.048447 22508 net.cpp:367] map16_2_scale_b -> map16_2_conv_b (in-place)
I0417 10:26:58.048487 22508 layer_factory.hpp:77] Creating layer map16_2_scale_b
I0417 10:26:58.048598 22508 net.cpp:122] Setting up map16_2_scale_b
I0417 10:26:58.048604 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.048605 22508 net.cpp:137] Memory required for data: 158516800
I0417 10:26:58.048610 22508 layer_factory.hpp:77] Creating layer map16_2_eltsum
I0417 10:26:58.048615 22508 net.cpp:84] Creating Layer map16_2_eltsum
I0417 10:26:58.048619 22508 net.cpp:406] map16_2_eltsum <- map16_1_eltsum_map16_1_relu_after_sum_0_split_1
I0417 10:26:58.048622 22508 net.cpp:406] map16_2_eltsum <- map16_2_conv_b
I0417 10:26:58.048627 22508 net.cpp:380] map16_2_eltsum -> map16_2_eltsum
I0417 10:26:58.048652 22508 net.cpp:122] Setting up map16_2_eltsum
I0417 10:26:58.048658 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.048660 22508 net.cpp:137] Memory required for data: 165070400
I0417 10:26:58.048662 22508 layer_factory.hpp:77] Creating layer map16_2_relu_after_sum
I0417 10:26:58.048666 22508 net.cpp:84] Creating Layer map16_2_relu_after_sum
I0417 10:26:58.048669 22508 net.cpp:406] map16_2_relu_after_sum <- map16_2_eltsum
I0417 10:26:58.048672 22508 net.cpp:367] map16_2_relu_after_sum -> map16_2_eltsum (in-place)
I0417 10:26:58.048830 22508 net.cpp:122] Setting up map16_2_relu_after_sum
I0417 10:26:58.048838 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.048840 22508 net.cpp:137] Memory required for data: 171624000
I0417 10:26:58.048843 22508 layer_factory.hpp:77] Creating layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0417 10:26:58.048847 22508 net.cpp:84] Creating Layer map16_2_eltsum_map16_2_relu_after_sum_0_split
I0417 10:26:58.048851 22508 net.cpp:406] map16_2_eltsum_map16_2_relu_after_sum_0_split <- map16_2_eltsum
I0417 10:26:58.048856 22508 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0417 10:26:58.048871 22508 net.cpp:380] map16_2_eltsum_map16_2_relu_after_sum_0_split -> map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0417 10:26:58.048910 22508 net.cpp:122] Setting up map16_2_eltsum_map16_2_relu_after_sum_0_split
I0417 10:26:58.048916 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.048931 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.048933 22508 net.cpp:137] Memory required for data: 184731200
I0417 10:26:58.048936 22508 layer_factory.hpp:77] Creating layer map16_3_conv_a
I0417 10:26:58.048945 22508 net.cpp:84] Creating Layer map16_3_conv_a
I0417 10:26:58.048949 22508 net.cpp:406] map16_3_conv_a <- map16_2_eltsum_map16_2_relu_after_sum_0_split_0
I0417 10:26:58.048954 22508 net.cpp:380] map16_3_conv_a -> map16_3_conv_a
I0417 10:26:58.050528 22508 net.cpp:122] Setting up map16_3_conv_a
I0417 10:26:58.050539 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.050554 22508 net.cpp:137] Memory required for data: 191284800
I0417 10:26:58.050559 22508 layer_factory.hpp:77] Creating layer map16_3_bn_a
I0417 10:26:58.050565 22508 net.cpp:84] Creating Layer map16_3_bn_a
I0417 10:26:58.050568 22508 net.cpp:406] map16_3_bn_a <- map16_3_conv_a
I0417 10:26:58.050575 22508 net.cpp:367] map16_3_bn_a -> map16_3_conv_a (in-place)
I0417 10:26:58.050765 22508 net.cpp:122] Setting up map16_3_bn_a
I0417 10:26:58.050771 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.050773 22508 net.cpp:137] Memory required for data: 197838400
I0417 10:26:58.050779 22508 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0417 10:26:58.050787 22508 net.cpp:84] Creating Layer map16_3_scale_a
I0417 10:26:58.050789 22508 net.cpp:406] map16_3_scale_a <- map16_3_conv_a
I0417 10:26:58.050793 22508 net.cpp:367] map16_3_scale_a -> map16_3_conv_a (in-place)
I0417 10:26:58.050833 22508 layer_factory.hpp:77] Creating layer map16_3_scale_a
I0417 10:26:58.050947 22508 net.cpp:122] Setting up map16_3_scale_a
I0417 10:26:58.050953 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.050956 22508 net.cpp:137] Memory required for data: 204392000
I0417 10:26:58.050961 22508 layer_factory.hpp:77] Creating layer map16_3_relu_a
I0417 10:26:58.050966 22508 net.cpp:84] Creating Layer map16_3_relu_a
I0417 10:26:58.050968 22508 net.cpp:406] map16_3_relu_a <- map16_3_conv_a
I0417 10:26:58.050971 22508 net.cpp:367] map16_3_relu_a -> map16_3_conv_a (in-place)
I0417 10:26:58.051133 22508 net.cpp:122] Setting up map16_3_relu_a
I0417 10:26:58.051141 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.051144 22508 net.cpp:137] Memory required for data: 210945600
I0417 10:26:58.051146 22508 layer_factory.hpp:77] Creating layer map16_3_conv_b
I0417 10:26:58.051156 22508 net.cpp:84] Creating Layer map16_3_conv_b
I0417 10:26:58.051158 22508 net.cpp:406] map16_3_conv_b <- map16_3_conv_a
I0417 10:26:58.051165 22508 net.cpp:380] map16_3_conv_b -> map16_3_conv_b
I0417 10:26:58.052759 22508 net.cpp:122] Setting up map16_3_conv_b
I0417 10:26:58.052772 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.052773 22508 net.cpp:137] Memory required for data: 217499200
I0417 10:26:58.052778 22508 layer_factory.hpp:77] Creating layer map16_3_bn_b
I0417 10:26:58.052789 22508 net.cpp:84] Creating Layer map16_3_bn_b
I0417 10:26:58.052793 22508 net.cpp:406] map16_3_bn_b <- map16_3_conv_b
I0417 10:26:58.052800 22508 net.cpp:367] map16_3_bn_b -> map16_3_conv_b (in-place)
I0417 10:26:58.052989 22508 net.cpp:122] Setting up map16_3_bn_b
I0417 10:26:58.052995 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.052997 22508 net.cpp:137] Memory required for data: 224052800
I0417 10:26:58.053002 22508 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0417 10:26:58.053011 22508 net.cpp:84] Creating Layer map16_3_scale_b
I0417 10:26:58.053016 22508 net.cpp:406] map16_3_scale_b <- map16_3_conv_b
I0417 10:26:58.053020 22508 net.cpp:367] map16_3_scale_b -> map16_3_conv_b (in-place)
I0417 10:26:58.053058 22508 layer_factory.hpp:77] Creating layer map16_3_scale_b
I0417 10:26:58.053172 22508 net.cpp:122] Setting up map16_3_scale_b
I0417 10:26:58.053179 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.053182 22508 net.cpp:137] Memory required for data: 230606400
I0417 10:26:58.053186 22508 layer_factory.hpp:77] Creating layer map16_3_eltsum
I0417 10:26:58.053202 22508 net.cpp:84] Creating Layer map16_3_eltsum
I0417 10:26:58.053206 22508 net.cpp:406] map16_3_eltsum <- map16_2_eltsum_map16_2_relu_after_sum_0_split_1
I0417 10:26:58.053210 22508 net.cpp:406] map16_3_eltsum <- map16_3_conv_b
I0417 10:26:58.053215 22508 net.cpp:380] map16_3_eltsum -> map16_3_eltsum
I0417 10:26:58.053242 22508 net.cpp:122] Setting up map16_3_eltsum
I0417 10:26:58.053253 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.053256 22508 net.cpp:137] Memory required for data: 237160000
I0417 10:26:58.053259 22508 layer_factory.hpp:77] Creating layer map16_3_relu_after_sum
I0417 10:26:58.053263 22508 net.cpp:84] Creating Layer map16_3_relu_after_sum
I0417 10:26:58.053266 22508 net.cpp:406] map16_3_relu_after_sum <- map16_3_eltsum
I0417 10:26:58.053269 22508 net.cpp:367] map16_3_relu_after_sum -> map16_3_eltsum (in-place)
I0417 10:26:58.053830 22508 net.cpp:122] Setting up map16_3_relu_after_sum
I0417 10:26:58.053840 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.053844 22508 net.cpp:137] Memory required for data: 243713600
I0417 10:26:58.053848 22508 layer_factory.hpp:77] Creating layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0417 10:26:58.053853 22508 net.cpp:84] Creating Layer map16_3_eltsum_map16_3_relu_after_sum_0_split
I0417 10:26:58.053858 22508 net.cpp:406] map16_3_eltsum_map16_3_relu_after_sum_0_split <- map16_3_eltsum
I0417 10:26:58.053861 22508 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0417 10:26:58.053869 22508 net.cpp:380] map16_3_eltsum_map16_3_relu_after_sum_0_split -> map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0417 10:26:58.053912 22508 net.cpp:122] Setting up map16_3_eltsum_map16_3_relu_after_sum_0_split
I0417 10:26:58.053918 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.053921 22508 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I0417 10:26:58.053925 22508 net.cpp:137] Memory required for data: 256820800
I0417 10:26:58.053926 22508 layer_factory.hpp:77] Creating layer map32_1_conv_proj
I0417 10:26:58.053936 22508 net.cpp:84] Creating Layer map32_1_conv_proj
I0417 10:26:58.053938 22508 net.cpp:406] map32_1_conv_proj <- map16_3_eltsum_map16_3_relu_after_sum_0_split_0
I0417 10:26:58.053946 22508 net.cpp:380] map32_1_conv_proj -> map32_1_conv_proj
I0417 10:26:58.055613 22508 net.cpp:122] Setting up map32_1_conv_proj
I0417 10:26:58.055624 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.055629 22508 net.cpp:137] Memory required for data: 260097600
I0417 10:26:58.055635 22508 layer_factory.hpp:77] Creating layer map32_1_bn_proj
I0417 10:26:58.055641 22508 net.cpp:84] Creating Layer map32_1_bn_proj
I0417 10:26:58.055645 22508 net.cpp:406] map32_1_bn_proj <- map32_1_conv_proj
I0417 10:26:58.055651 22508 net.cpp:367] map32_1_bn_proj -> map32_1_conv_proj (in-place)
I0417 10:26:58.055840 22508 net.cpp:122] Setting up map32_1_bn_proj
I0417 10:26:58.055845 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.055847 22508 net.cpp:137] Memory required for data: 263374400
I0417 10:26:58.055853 22508 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0417 10:26:58.055860 22508 net.cpp:84] Creating Layer map32_1_scale_proj
I0417 10:26:58.055862 22508 net.cpp:406] map32_1_scale_proj <- map32_1_conv_proj
I0417 10:26:58.055866 22508 net.cpp:367] map32_1_scale_proj -> map32_1_conv_proj (in-place)
I0417 10:26:58.055907 22508 layer_factory.hpp:77] Creating layer map32_1_scale_proj
I0417 10:26:58.056013 22508 net.cpp:122] Setting up map32_1_scale_proj
I0417 10:26:58.056020 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.056022 22508 net.cpp:137] Memory required for data: 266651200
I0417 10:26:58.056027 22508 layer_factory.hpp:77] Creating layer map32_1_conv_a
I0417 10:26:58.056036 22508 net.cpp:84] Creating Layer map32_1_conv_a
I0417 10:26:58.056041 22508 net.cpp:406] map32_1_conv_a <- map16_3_eltsum_map16_3_relu_after_sum_0_split_1
I0417 10:26:58.056047 22508 net.cpp:380] map32_1_conv_a -> map32_1_conv_a
I0417 10:26:58.057358 22508 net.cpp:122] Setting up map32_1_conv_a
I0417 10:26:58.057370 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.057374 22508 net.cpp:137] Memory required for data: 269928000
I0417 10:26:58.057380 22508 layer_factory.hpp:77] Creating layer map32_1_bn_a
I0417 10:26:58.057389 22508 net.cpp:84] Creating Layer map32_1_bn_a
I0417 10:26:58.057392 22508 net.cpp:406] map32_1_bn_a <- map32_1_conv_a
I0417 10:26:58.057396 22508 net.cpp:367] map32_1_bn_a -> map32_1_conv_a (in-place)
I0417 10:26:58.057582 22508 net.cpp:122] Setting up map32_1_bn_a
I0417 10:26:58.057588 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.057591 22508 net.cpp:137] Memory required for data: 273204800
I0417 10:26:58.057596 22508 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0417 10:26:58.057602 22508 net.cpp:84] Creating Layer map32_1_scale_a
I0417 10:26:58.057605 22508 net.cpp:406] map32_1_scale_a <- map32_1_conv_a
I0417 10:26:58.057610 22508 net.cpp:367] map32_1_scale_a -> map32_1_conv_a (in-place)
I0417 10:26:58.057647 22508 layer_factory.hpp:77] Creating layer map32_1_scale_a
I0417 10:26:58.057754 22508 net.cpp:122] Setting up map32_1_scale_a
I0417 10:26:58.057760 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.057763 22508 net.cpp:137] Memory required for data: 276481600
I0417 10:26:58.057767 22508 layer_factory.hpp:77] Creating layer map32_1_relu_a
I0417 10:26:58.057775 22508 net.cpp:84] Creating Layer map32_1_relu_a
I0417 10:26:58.057777 22508 net.cpp:406] map32_1_relu_a <- map32_1_conv_a
I0417 10:26:58.057780 22508 net.cpp:367] map32_1_relu_a -> map32_1_conv_a (in-place)
I0417 10:26:58.058347 22508 net.cpp:122] Setting up map32_1_relu_a
I0417 10:26:58.058358 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.058362 22508 net.cpp:137] Memory required for data: 279758400
I0417 10:26:58.058365 22508 layer_factory.hpp:77] Creating layer map32_1_conv_b
I0417 10:26:58.058378 22508 net.cpp:84] Creating Layer map32_1_conv_b
I0417 10:26:58.058382 22508 net.cpp:406] map32_1_conv_b <- map32_1_conv_a
I0417 10:26:58.058388 22508 net.cpp:380] map32_1_conv_b -> map32_1_conv_b
I0417 10:26:58.060590 22508 net.cpp:122] Setting up map32_1_conv_b
I0417 10:26:58.060600 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.060605 22508 net.cpp:137] Memory required for data: 283035200
I0417 10:26:58.060619 22508 layer_factory.hpp:77] Creating layer map32_1_bn_b
I0417 10:26:58.060626 22508 net.cpp:84] Creating Layer map32_1_bn_b
I0417 10:26:58.060631 22508 net.cpp:406] map32_1_bn_b <- map32_1_conv_b
I0417 10:26:58.060637 22508 net.cpp:367] map32_1_bn_b -> map32_1_conv_b (in-place)
I0417 10:26:58.060832 22508 net.cpp:122] Setting up map32_1_bn_b
I0417 10:26:58.060838 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.060842 22508 net.cpp:137] Memory required for data: 286312000
I0417 10:26:58.060847 22508 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0417 10:26:58.060853 22508 net.cpp:84] Creating Layer map32_1_scale_b
I0417 10:26:58.060855 22508 net.cpp:406] map32_1_scale_b <- map32_1_conv_b
I0417 10:26:58.060858 22508 net.cpp:367] map32_1_scale_b -> map32_1_conv_b (in-place)
I0417 10:26:58.060900 22508 layer_factory.hpp:77] Creating layer map32_1_scale_b
I0417 10:26:58.061012 22508 net.cpp:122] Setting up map32_1_scale_b
I0417 10:26:58.061018 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.061020 22508 net.cpp:137] Memory required for data: 289588800
I0417 10:26:58.061025 22508 layer_factory.hpp:77] Creating layer map32_1_eltsum
I0417 10:26:58.061033 22508 net.cpp:84] Creating Layer map32_1_eltsum
I0417 10:26:58.061035 22508 net.cpp:406] map32_1_eltsum <- map32_1_conv_proj
I0417 10:26:58.061038 22508 net.cpp:406] map32_1_eltsum <- map32_1_conv_b
I0417 10:26:58.061043 22508 net.cpp:380] map32_1_eltsum -> map32_1_eltsum
I0417 10:26:58.061061 22508 net.cpp:122] Setting up map32_1_eltsum
I0417 10:26:58.061067 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.061069 22508 net.cpp:137] Memory required for data: 292865600
I0417 10:26:58.061084 22508 layer_factory.hpp:77] Creating layer map32_1_relu_after_sum
I0417 10:26:58.061089 22508 net.cpp:84] Creating Layer map32_1_relu_after_sum
I0417 10:26:58.061094 22508 net.cpp:406] map32_1_relu_after_sum <- map32_1_eltsum
I0417 10:26:58.061096 22508 net.cpp:367] map32_1_relu_after_sum -> map32_1_eltsum (in-place)
I0417 10:26:58.061271 22508 net.cpp:122] Setting up map32_1_relu_after_sum
I0417 10:26:58.061280 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.061282 22508 net.cpp:137] Memory required for data: 296142400
I0417 10:26:58.061285 22508 layer_factory.hpp:77] Creating layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0417 10:26:58.061290 22508 net.cpp:84] Creating Layer map32_1_eltsum_map32_1_relu_after_sum_0_split
I0417 10:26:58.061295 22508 net.cpp:406] map32_1_eltsum_map32_1_relu_after_sum_0_split <- map32_1_eltsum
I0417 10:26:58.061298 22508 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0417 10:26:58.061303 22508 net.cpp:380] map32_1_eltsum_map32_1_relu_after_sum_0_split -> map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0417 10:26:58.061352 22508 net.cpp:122] Setting up map32_1_eltsum_map32_1_relu_after_sum_0_split
I0417 10:26:58.061357 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.061360 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.061362 22508 net.cpp:137] Memory required for data: 302696000
I0417 10:26:58.061365 22508 layer_factory.hpp:77] Creating layer map32_2_conv_a
I0417 10:26:58.061373 22508 net.cpp:84] Creating Layer map32_2_conv_a
I0417 10:26:58.061377 22508 net.cpp:406] map32_2_conv_a <- map32_1_eltsum_map32_1_relu_after_sum_0_split_0
I0417 10:26:58.061383 22508 net.cpp:380] map32_2_conv_a -> map32_2_conv_a
I0417 10:26:58.063596 22508 net.cpp:122] Setting up map32_2_conv_a
I0417 10:26:58.063607 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.063611 22508 net.cpp:137] Memory required for data: 305972800
I0417 10:26:58.063616 22508 layer_factory.hpp:77] Creating layer map32_2_bn_a
I0417 10:26:58.063624 22508 net.cpp:84] Creating Layer map32_2_bn_a
I0417 10:26:58.063628 22508 net.cpp:406] map32_2_bn_a <- map32_2_conv_a
I0417 10:26:58.063632 22508 net.cpp:367] map32_2_bn_a -> map32_2_conv_a (in-place)
I0417 10:26:58.063824 22508 net.cpp:122] Setting up map32_2_bn_a
I0417 10:26:58.063830 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.063832 22508 net.cpp:137] Memory required for data: 309249600
I0417 10:26:58.063838 22508 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0417 10:26:58.063845 22508 net.cpp:84] Creating Layer map32_2_scale_a
I0417 10:26:58.063848 22508 net.cpp:406] map32_2_scale_a <- map32_2_conv_a
I0417 10:26:58.063853 22508 net.cpp:367] map32_2_scale_a -> map32_2_conv_a (in-place)
I0417 10:26:58.063894 22508 layer_factory.hpp:77] Creating layer map32_2_scale_a
I0417 10:26:58.064012 22508 net.cpp:122] Setting up map32_2_scale_a
I0417 10:26:58.064018 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.064020 22508 net.cpp:137] Memory required for data: 312526400
I0417 10:26:58.064024 22508 layer_factory.hpp:77] Creating layer map32_2_relu_a
I0417 10:26:58.064033 22508 net.cpp:84] Creating Layer map32_2_relu_a
I0417 10:26:58.064038 22508 net.cpp:406] map32_2_relu_a <- map32_2_conv_a
I0417 10:26:58.064040 22508 net.cpp:367] map32_2_relu_a -> map32_2_conv_a (in-place)
I0417 10:26:58.064604 22508 net.cpp:122] Setting up map32_2_relu_a
I0417 10:26:58.064615 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.064618 22508 net.cpp:137] Memory required for data: 315803200
I0417 10:26:58.064621 22508 layer_factory.hpp:77] Creating layer map32_2_conv_b
I0417 10:26:58.064630 22508 net.cpp:84] Creating Layer map32_2_conv_b
I0417 10:26:58.064635 22508 net.cpp:406] map32_2_conv_b <- map32_2_conv_a
I0417 10:26:58.064641 22508 net.cpp:380] map32_2_conv_b -> map32_2_conv_b
I0417 10:26:58.066042 22508 net.cpp:122] Setting up map32_2_conv_b
I0417 10:26:58.066064 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.066067 22508 net.cpp:137] Memory required for data: 319080000
I0417 10:26:58.066072 22508 layer_factory.hpp:77] Creating layer map32_2_bn_b
I0417 10:26:58.066082 22508 net.cpp:84] Creating Layer map32_2_bn_b
I0417 10:26:58.066087 22508 net.cpp:406] map32_2_bn_b <- map32_2_conv_b
I0417 10:26:58.066092 22508 net.cpp:367] map32_2_bn_b -> map32_2_conv_b (in-place)
I0417 10:26:58.066293 22508 net.cpp:122] Setting up map32_2_bn_b
I0417 10:26:58.066298 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.066301 22508 net.cpp:137] Memory required for data: 322356800
I0417 10:26:58.066306 22508 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0417 10:26:58.066314 22508 net.cpp:84] Creating Layer map32_2_scale_b
I0417 10:26:58.066318 22508 net.cpp:406] map32_2_scale_b <- map32_2_conv_b
I0417 10:26:58.066323 22508 net.cpp:367] map32_2_scale_b -> map32_2_conv_b (in-place)
I0417 10:26:58.066362 22508 layer_factory.hpp:77] Creating layer map32_2_scale_b
I0417 10:26:58.066475 22508 net.cpp:122] Setting up map32_2_scale_b
I0417 10:26:58.066481 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.066484 22508 net.cpp:137] Memory required for data: 325633600
I0417 10:26:58.066488 22508 layer_factory.hpp:77] Creating layer map32_2_eltsum
I0417 10:26:58.066498 22508 net.cpp:84] Creating Layer map32_2_eltsum
I0417 10:26:58.066501 22508 net.cpp:406] map32_2_eltsum <- map32_1_eltsum_map32_1_relu_after_sum_0_split_1
I0417 10:26:58.066504 22508 net.cpp:406] map32_2_eltsum <- map32_2_conv_b
I0417 10:26:58.066509 22508 net.cpp:380] map32_2_eltsum -> map32_2_eltsum
I0417 10:26:58.066529 22508 net.cpp:122] Setting up map32_2_eltsum
I0417 10:26:58.066534 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.066537 22508 net.cpp:137] Memory required for data: 328910400
I0417 10:26:58.066540 22508 layer_factory.hpp:77] Creating layer map32_2_relu_after_sum
I0417 10:26:58.066543 22508 net.cpp:84] Creating Layer map32_2_relu_after_sum
I0417 10:26:58.066546 22508 net.cpp:406] map32_2_relu_after_sum <- map32_2_eltsum
I0417 10:26:58.066550 22508 net.cpp:367] map32_2_relu_after_sum -> map32_2_eltsum (in-place)
I0417 10:26:58.067107 22508 net.cpp:122] Setting up map32_2_relu_after_sum
I0417 10:26:58.067117 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.067121 22508 net.cpp:137] Memory required for data: 332187200
I0417 10:26:58.067124 22508 layer_factory.hpp:77] Creating layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0417 10:26:58.067131 22508 net.cpp:84] Creating Layer map32_2_eltsum_map32_2_relu_after_sum_0_split
I0417 10:26:58.067134 22508 net.cpp:406] map32_2_eltsum_map32_2_relu_after_sum_0_split <- map32_2_eltsum
I0417 10:26:58.067139 22508 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0417 10:26:58.067148 22508 net.cpp:380] map32_2_eltsum_map32_2_relu_after_sum_0_split -> map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0417 10:26:58.067198 22508 net.cpp:122] Setting up map32_2_eltsum_map32_2_relu_after_sum_0_split
I0417 10:26:58.067207 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.067210 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.067222 22508 net.cpp:137] Memory required for data: 338740800
I0417 10:26:58.067224 22508 layer_factory.hpp:77] Creating layer map32_3_conv_a
I0417 10:26:58.067236 22508 net.cpp:84] Creating Layer map32_3_conv_a
I0417 10:26:58.067239 22508 net.cpp:406] map32_3_conv_a <- map32_2_eltsum_map32_2_relu_after_sum_0_split_0
I0417 10:26:58.067245 22508 net.cpp:380] map32_3_conv_a -> map32_3_conv_a
I0417 10:26:58.069041 22508 net.cpp:122] Setting up map32_3_conv_a
I0417 10:26:58.069052 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.069057 22508 net.cpp:137] Memory required for data: 342017600
I0417 10:26:58.069062 22508 layer_factory.hpp:77] Creating layer map32_3_bn_a
I0417 10:26:58.069069 22508 net.cpp:84] Creating Layer map32_3_bn_a
I0417 10:26:58.069075 22508 net.cpp:406] map32_3_bn_a <- map32_3_conv_a
I0417 10:26:58.069090 22508 net.cpp:367] map32_3_bn_a -> map32_3_conv_a (in-place)
I0417 10:26:58.069291 22508 net.cpp:122] Setting up map32_3_bn_a
I0417 10:26:58.069298 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.069301 22508 net.cpp:137] Memory required for data: 345294400
I0417 10:26:58.069308 22508 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0417 10:26:58.069314 22508 net.cpp:84] Creating Layer map32_3_scale_a
I0417 10:26:58.069319 22508 net.cpp:406] map32_3_scale_a <- map32_3_conv_a
I0417 10:26:58.069322 22508 net.cpp:367] map32_3_scale_a -> map32_3_conv_a (in-place)
I0417 10:26:58.069363 22508 layer_factory.hpp:77] Creating layer map32_3_scale_a
I0417 10:26:58.069476 22508 net.cpp:122] Setting up map32_3_scale_a
I0417 10:26:58.069483 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.069485 22508 net.cpp:137] Memory required for data: 348571200
I0417 10:26:58.069489 22508 layer_factory.hpp:77] Creating layer map32_3_relu_a
I0417 10:26:58.069494 22508 net.cpp:84] Creating Layer map32_3_relu_a
I0417 10:26:58.069497 22508 net.cpp:406] map32_3_relu_a <- map32_3_conv_a
I0417 10:26:58.069502 22508 net.cpp:367] map32_3_relu_a -> map32_3_conv_a (in-place)
I0417 10:26:58.069661 22508 net.cpp:122] Setting up map32_3_relu_a
I0417 10:26:58.069669 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.069671 22508 net.cpp:137] Memory required for data: 351848000
I0417 10:26:58.069674 22508 layer_factory.hpp:77] Creating layer map32_3_conv_b
I0417 10:26:58.069687 22508 net.cpp:84] Creating Layer map32_3_conv_b
I0417 10:26:58.069691 22508 net.cpp:406] map32_3_conv_b <- map32_3_conv_a
I0417 10:26:58.069700 22508 net.cpp:380] map32_3_conv_b -> map32_3_conv_b
I0417 10:26:58.071498 22508 net.cpp:122] Setting up map32_3_conv_b
I0417 10:26:58.071511 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.071516 22508 net.cpp:137] Memory required for data: 355124800
I0417 10:26:58.071521 22508 layer_factory.hpp:77] Creating layer map32_3_bn_b
I0417 10:26:58.071528 22508 net.cpp:84] Creating Layer map32_3_bn_b
I0417 10:26:58.071532 22508 net.cpp:406] map32_3_bn_b <- map32_3_conv_b
I0417 10:26:58.071537 22508 net.cpp:367] map32_3_bn_b -> map32_3_conv_b (in-place)
I0417 10:26:58.071734 22508 net.cpp:122] Setting up map32_3_bn_b
I0417 10:26:58.071741 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.071743 22508 net.cpp:137] Memory required for data: 358401600
I0417 10:26:58.071749 22508 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0417 10:26:58.071754 22508 net.cpp:84] Creating Layer map32_3_scale_b
I0417 10:26:58.071758 22508 net.cpp:406] map32_3_scale_b <- map32_3_conv_b
I0417 10:26:58.071761 22508 net.cpp:367] map32_3_scale_b -> map32_3_conv_b (in-place)
I0417 10:26:58.071801 22508 layer_factory.hpp:77] Creating layer map32_3_scale_b
I0417 10:26:58.071913 22508 net.cpp:122] Setting up map32_3_scale_b
I0417 10:26:58.071920 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.071923 22508 net.cpp:137] Memory required for data: 361678400
I0417 10:26:58.071928 22508 layer_factory.hpp:77] Creating layer map32_3_eltsum
I0417 10:26:58.071933 22508 net.cpp:84] Creating Layer map32_3_eltsum
I0417 10:26:58.071935 22508 net.cpp:406] map32_3_eltsum <- map32_2_eltsum_map32_2_relu_after_sum_0_split_1
I0417 10:26:58.071939 22508 net.cpp:406] map32_3_eltsum <- map32_3_conv_b
I0417 10:26:58.071944 22508 net.cpp:380] map32_3_eltsum -> map32_3_eltsum
I0417 10:26:58.071964 22508 net.cpp:122] Setting up map32_3_eltsum
I0417 10:26:58.071969 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.071971 22508 net.cpp:137] Memory required for data: 364955200
I0417 10:26:58.071974 22508 layer_factory.hpp:77] Creating layer map32_3_relu_after_sum
I0417 10:26:58.071977 22508 net.cpp:84] Creating Layer map32_3_relu_after_sum
I0417 10:26:58.071979 22508 net.cpp:406] map32_3_relu_after_sum <- map32_3_eltsum
I0417 10:26:58.071985 22508 net.cpp:367] map32_3_relu_after_sum -> map32_3_eltsum (in-place)
I0417 10:26:58.072559 22508 net.cpp:122] Setting up map32_3_relu_after_sum
I0417 10:26:58.072569 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.072573 22508 net.cpp:137] Memory required for data: 368232000
I0417 10:26:58.072576 22508 layer_factory.hpp:77] Creating layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0417 10:26:58.072582 22508 net.cpp:84] Creating Layer map32_3_eltsum_map32_3_relu_after_sum_0_split
I0417 10:26:58.072587 22508 net.cpp:406] map32_3_eltsum_map32_3_relu_after_sum_0_split <- map32_3_eltsum
I0417 10:26:58.072592 22508 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0417 10:26:58.072597 22508 net.cpp:380] map32_3_eltsum_map32_3_relu_after_sum_0_split -> map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0417 10:26:58.072640 22508 net.cpp:122] Setting up map32_3_eltsum_map32_3_relu_after_sum_0_split
I0417 10:26:58.072646 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.072649 22508 net.cpp:129] Top shape: 100 32 16 16 (819200)
I0417 10:26:58.072651 22508 net.cpp:137] Memory required for data: 374785600
I0417 10:26:58.072654 22508 layer_factory.hpp:77] Creating layer map64_1_conv_proj
I0417 10:26:58.072662 22508 net.cpp:84] Creating Layer map64_1_conv_proj
I0417 10:26:58.072665 22508 net.cpp:406] map64_1_conv_proj <- map32_3_eltsum_map32_3_relu_after_sum_0_split_0
I0417 10:26:58.072672 22508 net.cpp:380] map64_1_conv_proj -> map64_1_conv_proj
I0417 10:26:58.074317 22508 net.cpp:122] Setting up map64_1_conv_proj
I0417 10:26:58.074329 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.074333 22508 net.cpp:137] Memory required for data: 376424000
I0417 10:26:58.074339 22508 layer_factory.hpp:77] Creating layer map64_1_bn_proj
I0417 10:26:58.074347 22508 net.cpp:84] Creating Layer map64_1_bn_proj
I0417 10:26:58.074352 22508 net.cpp:406] map64_1_bn_proj <- map64_1_conv_proj
I0417 10:26:58.074357 22508 net.cpp:367] map64_1_bn_proj -> map64_1_conv_proj (in-place)
I0417 10:26:58.074554 22508 net.cpp:122] Setting up map64_1_bn_proj
I0417 10:26:58.074561 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.074563 22508 net.cpp:137] Memory required for data: 378062400
I0417 10:26:58.074569 22508 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0417 10:26:58.074576 22508 net.cpp:84] Creating Layer map64_1_scale_proj
I0417 10:26:58.074580 22508 net.cpp:406] map64_1_scale_proj <- map64_1_conv_proj
I0417 10:26:58.074584 22508 net.cpp:367] map64_1_scale_proj -> map64_1_conv_proj (in-place)
I0417 10:26:58.074625 22508 layer_factory.hpp:77] Creating layer map64_1_scale_proj
I0417 10:26:58.074741 22508 net.cpp:122] Setting up map64_1_scale_proj
I0417 10:26:58.074748 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.074750 22508 net.cpp:137] Memory required for data: 379700800
I0417 10:26:58.074755 22508 layer_factory.hpp:77] Creating layer map64_1_conv_a
I0417 10:26:58.074767 22508 net.cpp:84] Creating Layer map64_1_conv_a
I0417 10:26:58.074772 22508 net.cpp:406] map64_1_conv_a <- map32_3_eltsum_map32_3_relu_after_sum_0_split_1
I0417 10:26:58.074777 22508 net.cpp:380] map64_1_conv_a -> map64_1_conv_a
I0417 10:26:58.076810 22508 net.cpp:122] Setting up map64_1_conv_a
I0417 10:26:58.076822 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.076827 22508 net.cpp:137] Memory required for data: 381339200
I0417 10:26:58.076831 22508 layer_factory.hpp:77] Creating layer map64_1_bn_a
I0417 10:26:58.076838 22508 net.cpp:84] Creating Layer map64_1_bn_a
I0417 10:26:58.076843 22508 net.cpp:406] map64_1_bn_a <- map64_1_conv_a
I0417 10:26:58.076848 22508 net.cpp:367] map64_1_bn_a -> map64_1_conv_a (in-place)
I0417 10:26:58.077049 22508 net.cpp:122] Setting up map64_1_bn_a
I0417 10:26:58.077056 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.077059 22508 net.cpp:137] Memory required for data: 382977600
I0417 10:26:58.077064 22508 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0417 10:26:58.077069 22508 net.cpp:84] Creating Layer map64_1_scale_a
I0417 10:26:58.077095 22508 net.cpp:406] map64_1_scale_a <- map64_1_conv_a
I0417 10:26:58.077100 22508 net.cpp:367] map64_1_scale_a -> map64_1_conv_a (in-place)
I0417 10:26:58.077155 22508 layer_factory.hpp:77] Creating layer map64_1_scale_a
I0417 10:26:58.077281 22508 net.cpp:122] Setting up map64_1_scale_a
I0417 10:26:58.077288 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.077291 22508 net.cpp:137] Memory required for data: 384616000
I0417 10:26:58.077296 22508 layer_factory.hpp:77] Creating layer map64_1_relu_a
I0417 10:26:58.077301 22508 net.cpp:84] Creating Layer map64_1_relu_a
I0417 10:26:58.077304 22508 net.cpp:406] map64_1_relu_a <- map64_1_conv_a
I0417 10:26:58.077307 22508 net.cpp:367] map64_1_relu_a -> map64_1_conv_a (in-place)
I0417 10:26:58.077877 22508 net.cpp:122] Setting up map64_1_relu_a
I0417 10:26:58.077886 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.077889 22508 net.cpp:137] Memory required for data: 386254400
I0417 10:26:58.077903 22508 layer_factory.hpp:77] Creating layer map64_1_conv_b
I0417 10:26:58.077913 22508 net.cpp:84] Creating Layer map64_1_conv_b
I0417 10:26:58.077919 22508 net.cpp:406] map64_1_conv_b <- map64_1_conv_a
I0417 10:26:58.077924 22508 net.cpp:380] map64_1_conv_b -> map64_1_conv_b
I0417 10:26:58.080595 22508 net.cpp:122] Setting up map64_1_conv_b
I0417 10:26:58.080606 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.080610 22508 net.cpp:137] Memory required for data: 387892800
I0417 10:26:58.080616 22508 layer_factory.hpp:77] Creating layer map64_1_bn_b
I0417 10:26:58.080621 22508 net.cpp:84] Creating Layer map64_1_bn_b
I0417 10:26:58.080626 22508 net.cpp:406] map64_1_bn_b <- map64_1_conv_b
I0417 10:26:58.080631 22508 net.cpp:367] map64_1_bn_b -> map64_1_conv_b (in-place)
I0417 10:26:58.080840 22508 net.cpp:122] Setting up map64_1_bn_b
I0417 10:26:58.080847 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.080849 22508 net.cpp:137] Memory required for data: 389531200
I0417 10:26:58.080855 22508 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0417 10:26:58.080862 22508 net.cpp:84] Creating Layer map64_1_scale_b
I0417 10:26:58.080864 22508 net.cpp:406] map64_1_scale_b <- map64_1_conv_b
I0417 10:26:58.080869 22508 net.cpp:367] map64_1_scale_b -> map64_1_conv_b (in-place)
I0417 10:26:58.080912 22508 layer_factory.hpp:77] Creating layer map64_1_scale_b
I0417 10:26:58.081027 22508 net.cpp:122] Setting up map64_1_scale_b
I0417 10:26:58.081034 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.081037 22508 net.cpp:137] Memory required for data: 391169600
I0417 10:26:58.081042 22508 layer_factory.hpp:77] Creating layer map64_1_eltsum
I0417 10:26:58.081046 22508 net.cpp:84] Creating Layer map64_1_eltsum
I0417 10:26:58.081049 22508 net.cpp:406] map64_1_eltsum <- map64_1_conv_proj
I0417 10:26:58.081053 22508 net.cpp:406] map64_1_eltsum <- map64_1_conv_b
I0417 10:26:58.081058 22508 net.cpp:380] map64_1_eltsum -> map64_1_eltsum
I0417 10:26:58.081084 22508 net.cpp:122] Setting up map64_1_eltsum
I0417 10:26:58.081090 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.081092 22508 net.cpp:137] Memory required for data: 392808000
I0417 10:26:58.081094 22508 layer_factory.hpp:77] Creating layer map64_1_relu_after_sum
I0417 10:26:58.081099 22508 net.cpp:84] Creating Layer map64_1_relu_after_sum
I0417 10:26:58.081102 22508 net.cpp:406] map64_1_relu_after_sum <- map64_1_eltsum
I0417 10:26:58.081105 22508 net.cpp:367] map64_1_relu_after_sum -> map64_1_eltsum (in-place)
I0417 10:26:58.081666 22508 net.cpp:122] Setting up map64_1_relu_after_sum
I0417 10:26:58.081676 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.081681 22508 net.cpp:137] Memory required for data: 394446400
I0417 10:26:58.081683 22508 layer_factory.hpp:77] Creating layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0417 10:26:58.081689 22508 net.cpp:84] Creating Layer map64_1_eltsum_map64_1_relu_after_sum_0_split
I0417 10:26:58.081693 22508 net.cpp:406] map64_1_eltsum_map64_1_relu_after_sum_0_split <- map64_1_eltsum
I0417 10:26:58.081710 22508 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0417 10:26:58.081717 22508 net.cpp:380] map64_1_eltsum_map64_1_relu_after_sum_0_split -> map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0417 10:26:58.081763 22508 net.cpp:122] Setting up map64_1_eltsum_map64_1_relu_after_sum_0_split
I0417 10:26:58.081769 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.081773 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.081774 22508 net.cpp:137] Memory required for data: 397723200
I0417 10:26:58.081776 22508 layer_factory.hpp:77] Creating layer map64_2_conv_a
I0417 10:26:58.081784 22508 net.cpp:84] Creating Layer map64_2_conv_a
I0417 10:26:58.081789 22508 net.cpp:406] map64_2_conv_a <- map64_1_eltsum_map64_1_relu_after_sum_0_split_0
I0417 10:26:58.081794 22508 net.cpp:380] map64_2_conv_a -> map64_2_conv_a
I0417 10:26:58.084339 22508 net.cpp:122] Setting up map64_2_conv_a
I0417 10:26:58.084352 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.084355 22508 net.cpp:137] Memory required for data: 399361600
I0417 10:26:58.084360 22508 layer_factory.hpp:77] Creating layer map64_2_bn_a
I0417 10:26:58.084368 22508 net.cpp:84] Creating Layer map64_2_bn_a
I0417 10:26:58.084372 22508 net.cpp:406] map64_2_bn_a <- map64_2_conv_a
I0417 10:26:58.084378 22508 net.cpp:367] map64_2_bn_a -> map64_2_conv_a (in-place)
I0417 10:26:58.084581 22508 net.cpp:122] Setting up map64_2_bn_a
I0417 10:26:58.084589 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.084590 22508 net.cpp:137] Memory required for data: 401000000
I0417 10:26:58.084596 22508 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0417 10:26:58.084604 22508 net.cpp:84] Creating Layer map64_2_scale_a
I0417 10:26:58.084607 22508 net.cpp:406] map64_2_scale_a <- map64_2_conv_a
I0417 10:26:58.084611 22508 net.cpp:367] map64_2_scale_a -> map64_2_conv_a (in-place)
I0417 10:26:58.084652 22508 layer_factory.hpp:77] Creating layer map64_2_scale_a
I0417 10:26:58.084774 22508 net.cpp:122] Setting up map64_2_scale_a
I0417 10:26:58.084779 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.084781 22508 net.cpp:137] Memory required for data: 402638400
I0417 10:26:58.084786 22508 layer_factory.hpp:77] Creating layer map64_2_relu_a
I0417 10:26:58.084794 22508 net.cpp:84] Creating Layer map64_2_relu_a
I0417 10:26:58.084796 22508 net.cpp:406] map64_2_relu_a <- map64_2_conv_a
I0417 10:26:58.084800 22508 net.cpp:367] map64_2_relu_a -> map64_2_conv_a (in-place)
I0417 10:26:58.084961 22508 net.cpp:122] Setting up map64_2_relu_a
I0417 10:26:58.084969 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.084971 22508 net.cpp:137] Memory required for data: 404276800
I0417 10:26:58.084975 22508 layer_factory.hpp:77] Creating layer map64_2_conv_b
I0417 10:26:58.084983 22508 net.cpp:84] Creating Layer map64_2_conv_b
I0417 10:26:58.084987 22508 net.cpp:406] map64_2_conv_b <- map64_2_conv_a
I0417 10:26:58.084992 22508 net.cpp:380] map64_2_conv_b -> map64_2_conv_b
I0417 10:26:58.087548 22508 net.cpp:122] Setting up map64_2_conv_b
I0417 10:26:58.087559 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.087563 22508 net.cpp:137] Memory required for data: 405915200
I0417 10:26:58.087568 22508 layer_factory.hpp:77] Creating layer map64_2_bn_b
I0417 10:26:58.087576 22508 net.cpp:84] Creating Layer map64_2_bn_b
I0417 10:26:58.087580 22508 net.cpp:406] map64_2_bn_b <- map64_2_conv_b
I0417 10:26:58.087586 22508 net.cpp:367] map64_2_bn_b -> map64_2_conv_b (in-place)
I0417 10:26:58.087792 22508 net.cpp:122] Setting up map64_2_bn_b
I0417 10:26:58.087807 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.087810 22508 net.cpp:137] Memory required for data: 407553600
I0417 10:26:58.087829 22508 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0417 10:26:58.087836 22508 net.cpp:84] Creating Layer map64_2_scale_b
I0417 10:26:58.087838 22508 net.cpp:406] map64_2_scale_b <- map64_2_conv_b
I0417 10:26:58.087846 22508 net.cpp:367] map64_2_scale_b -> map64_2_conv_b (in-place)
I0417 10:26:58.087904 22508 layer_factory.hpp:77] Creating layer map64_2_scale_b
I0417 10:26:58.088024 22508 net.cpp:122] Setting up map64_2_scale_b
I0417 10:26:58.088032 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.088033 22508 net.cpp:137] Memory required for data: 409192000
I0417 10:26:58.088038 22508 layer_factory.hpp:77] Creating layer map64_2_eltsum
I0417 10:26:58.088043 22508 net.cpp:84] Creating Layer map64_2_eltsum
I0417 10:26:58.088047 22508 net.cpp:406] map64_2_eltsum <- map64_1_eltsum_map64_1_relu_after_sum_0_split_1
I0417 10:26:58.088049 22508 net.cpp:406] map64_2_eltsum <- map64_2_conv_b
I0417 10:26:58.088053 22508 net.cpp:380] map64_2_eltsum -> map64_2_eltsum
I0417 10:26:58.088078 22508 net.cpp:122] Setting up map64_2_eltsum
I0417 10:26:58.088083 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.088085 22508 net.cpp:137] Memory required for data: 410830400
I0417 10:26:58.088088 22508 layer_factory.hpp:77] Creating layer map64_2_relu_after_sum
I0417 10:26:58.088093 22508 net.cpp:84] Creating Layer map64_2_relu_after_sum
I0417 10:26:58.088096 22508 net.cpp:406] map64_2_relu_after_sum <- map64_2_eltsum
I0417 10:26:58.088101 22508 net.cpp:367] map64_2_relu_after_sum -> map64_2_eltsum (in-place)
I0417 10:26:58.089061 22508 net.cpp:122] Setting up map64_2_relu_after_sum
I0417 10:26:58.089071 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.089076 22508 net.cpp:137] Memory required for data: 412468800
I0417 10:26:58.089078 22508 layer_factory.hpp:77] Creating layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0417 10:26:58.089084 22508 net.cpp:84] Creating Layer map64_2_eltsum_map64_2_relu_after_sum_0_split
I0417 10:26:58.089088 22508 net.cpp:406] map64_2_eltsum_map64_2_relu_after_sum_0_split <- map64_2_eltsum
I0417 10:26:58.089093 22508 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0417 10:26:58.089099 22508 net.cpp:380] map64_2_eltsum_map64_2_relu_after_sum_0_split -> map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0417 10:26:58.089146 22508 net.cpp:122] Setting up map64_2_eltsum_map64_2_relu_after_sum_0_split
I0417 10:26:58.089153 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.089155 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.089157 22508 net.cpp:137] Memory required for data: 415745600
I0417 10:26:58.089159 22508 layer_factory.hpp:77] Creating layer map64_3_conv_a
I0417 10:26:58.089174 22508 net.cpp:84] Creating Layer map64_3_conv_a
I0417 10:26:58.089179 22508 net.cpp:406] map64_3_conv_a <- map64_2_eltsum_map64_2_relu_after_sum_0_split_0
I0417 10:26:58.089184 22508 net.cpp:380] map64_3_conv_a -> map64_3_conv_a
I0417 10:26:58.091367 22508 net.cpp:122] Setting up map64_3_conv_a
I0417 10:26:58.091378 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.091383 22508 net.cpp:137] Memory required for data: 417384000
I0417 10:26:58.091388 22508 layer_factory.hpp:77] Creating layer map64_3_bn_a
I0417 10:26:58.091395 22508 net.cpp:84] Creating Layer map64_3_bn_a
I0417 10:26:58.091399 22508 net.cpp:406] map64_3_bn_a <- map64_3_conv_a
I0417 10:26:58.091404 22508 net.cpp:367] map64_3_bn_a -> map64_3_conv_a (in-place)
I0417 10:26:58.091619 22508 net.cpp:122] Setting up map64_3_bn_a
I0417 10:26:58.091625 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.091627 22508 net.cpp:137] Memory required for data: 419022400
I0417 10:26:58.091634 22508 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0417 10:26:58.091639 22508 net.cpp:84] Creating Layer map64_3_scale_a
I0417 10:26:58.091652 22508 net.cpp:406] map64_3_scale_a <- map64_3_conv_a
I0417 10:26:58.091656 22508 net.cpp:367] map64_3_scale_a -> map64_3_conv_a (in-place)
I0417 10:26:58.091713 22508 layer_factory.hpp:77] Creating layer map64_3_scale_a
I0417 10:26:58.091831 22508 net.cpp:122] Setting up map64_3_scale_a
I0417 10:26:58.091840 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.091843 22508 net.cpp:137] Memory required for data: 420660800
I0417 10:26:58.091861 22508 layer_factory.hpp:77] Creating layer map64_3_relu_a
I0417 10:26:58.091866 22508 net.cpp:84] Creating Layer map64_3_relu_a
I0417 10:26:58.091869 22508 net.cpp:406] map64_3_relu_a <- map64_3_conv_a
I0417 10:26:58.091873 22508 net.cpp:367] map64_3_relu_a -> map64_3_conv_a (in-place)
I0417 10:26:58.092433 22508 net.cpp:122] Setting up map64_3_relu_a
I0417 10:26:58.092444 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.092448 22508 net.cpp:137] Memory required for data: 422299200
I0417 10:26:58.092452 22508 layer_factory.hpp:77] Creating layer map64_3_conv_b
I0417 10:26:58.092461 22508 net.cpp:84] Creating Layer map64_3_conv_b
I0417 10:26:58.092465 22508 net.cpp:406] map64_3_conv_b <- map64_3_conv_a
I0417 10:26:58.092470 22508 net.cpp:380] map64_3_conv_b -> map64_3_conv_b
I0417 10:26:58.095031 22508 net.cpp:122] Setting up map64_3_conv_b
I0417 10:26:58.095043 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.095049 22508 net.cpp:137] Memory required for data: 423937600
I0417 10:26:58.095054 22508 layer_factory.hpp:77] Creating layer map64_3_bn_b
I0417 10:26:58.095060 22508 net.cpp:84] Creating Layer map64_3_bn_b
I0417 10:26:58.095064 22508 net.cpp:406] map64_3_bn_b <- map64_3_conv_b
I0417 10:26:58.095070 22508 net.cpp:367] map64_3_bn_b -> map64_3_conv_b (in-place)
I0417 10:26:58.095289 22508 net.cpp:122] Setting up map64_3_bn_b
I0417 10:26:58.095297 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.095299 22508 net.cpp:137] Memory required for data: 425576000
I0417 10:26:58.095305 22508 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0417 10:26:58.095309 22508 net.cpp:84] Creating Layer map64_3_scale_b
I0417 10:26:58.095312 22508 net.cpp:406] map64_3_scale_b <- map64_3_conv_b
I0417 10:26:58.095316 22508 net.cpp:367] map64_3_scale_b -> map64_3_conv_b (in-place)
I0417 10:26:58.095371 22508 layer_factory.hpp:77] Creating layer map64_3_scale_b
I0417 10:26:58.095489 22508 net.cpp:122] Setting up map64_3_scale_b
I0417 10:26:58.095495 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.095497 22508 net.cpp:137] Memory required for data: 427214400
I0417 10:26:58.095501 22508 layer_factory.hpp:77] Creating layer map64_3_eltsum
I0417 10:26:58.095506 22508 net.cpp:84] Creating Layer map64_3_eltsum
I0417 10:26:58.095510 22508 net.cpp:406] map64_3_eltsum <- map64_2_eltsum_map64_2_relu_after_sum_0_split_1
I0417 10:26:58.095525 22508 net.cpp:406] map64_3_eltsum <- map64_3_conv_b
I0417 10:26:58.095528 22508 net.cpp:380] map64_3_eltsum -> map64_3_eltsum
I0417 10:26:58.095554 22508 net.cpp:122] Setting up map64_3_eltsum
I0417 10:26:58.095561 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.095562 22508 net.cpp:137] Memory required for data: 428852800
I0417 10:26:58.095564 22508 layer_factory.hpp:77] Creating layer map64_3_relu_after_sum
I0417 10:26:58.095569 22508 net.cpp:84] Creating Layer map64_3_relu_after_sum
I0417 10:26:58.095573 22508 net.cpp:406] map64_3_relu_after_sum <- map64_3_eltsum
I0417 10:26:58.095577 22508 net.cpp:367] map64_3_relu_after_sum -> map64_3_eltsum (in-place)
I0417 10:26:58.095737 22508 net.cpp:122] Setting up map64_3_relu_after_sum
I0417 10:26:58.095746 22508 net.cpp:129] Top shape: 100 64 8 8 (409600)
I0417 10:26:58.095749 22508 net.cpp:137] Memory required for data: 430491200
I0417 10:26:58.095752 22508 layer_factory.hpp:77] Creating layer pool_global
I0417 10:26:58.095757 22508 net.cpp:84] Creating Layer pool_global
I0417 10:26:58.095760 22508 net.cpp:406] pool_global <- map64_3_eltsum
I0417 10:26:58.095764 22508 net.cpp:380] pool_global -> pool_global
I0417 10:26:58.096354 22508 net.cpp:122] Setting up pool_global
I0417 10:26:58.096366 22508 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0417 10:26:58.096369 22508 net.cpp:137] Memory required for data: 430516800
I0417 10:26:58.096372 22508 layer_factory.hpp:77] Creating layer score
I0417 10:26:58.096377 22508 net.cpp:84] Creating Layer score
I0417 10:26:58.096381 22508 net.cpp:406] score <- pool_global
I0417 10:26:58.096387 22508 net.cpp:380] score -> score
I0417 10:26:58.096539 22508 net.cpp:122] Setting up score
I0417 10:26:58.096545 22508 net.cpp:129] Top shape: 100 10 (1000)
I0417 10:26:58.096549 22508 net.cpp:137] Memory required for data: 430520800
I0417 10:26:58.096552 22508 layer_factory.hpp:77] Creating layer score_score_0_split
I0417 10:26:58.096561 22508 net.cpp:84] Creating Layer score_score_0_split
I0417 10:26:58.096565 22508 net.cpp:406] score_score_0_split <- score
I0417 10:26:58.096570 22508 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0417 10:26:58.096575 22508 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0417 10:26:58.096580 22508 net.cpp:380] score_score_0_split -> score_score_0_split_2
I0417 10:26:58.096634 22508 net.cpp:122] Setting up score_score_0_split
I0417 10:26:58.096639 22508 net.cpp:129] Top shape: 100 10 (1000)
I0417 10:26:58.096642 22508 net.cpp:129] Top shape: 100 10 (1000)
I0417 10:26:58.096645 22508 net.cpp:129] Top shape: 100 10 (1000)
I0417 10:26:58.096647 22508 net.cpp:137] Memory required for data: 430532800
I0417 10:26:58.096650 22508 layer_factory.hpp:77] Creating layer loss
I0417 10:26:58.096654 22508 net.cpp:84] Creating Layer loss
I0417 10:26:58.096658 22508 net.cpp:406] loss <- score_score_0_split_0
I0417 10:26:58.096662 22508 net.cpp:406] loss <- label_data_1_split_0
I0417 10:26:58.096667 22508 net.cpp:380] loss -> loss
I0417 10:26:58.096673 22508 layer_factory.hpp:77] Creating layer loss
I0417 10:26:58.096927 22508 net.cpp:122] Setting up loss
I0417 10:26:58.096936 22508 net.cpp:129] Top shape: (1)
I0417 10:26:58.096940 22508 net.cpp:132]     with loss weight 1
I0417 10:26:58.096946 22508 net.cpp:137] Memory required for data: 430532804
I0417 10:26:58.096948 22508 layer_factory.hpp:77] Creating layer acc/top1
I0417 10:26:58.096953 22508 net.cpp:84] Creating Layer acc/top1
I0417 10:26:58.096956 22508 net.cpp:406] acc/top1 <- score_score_0_split_1
I0417 10:26:58.096961 22508 net.cpp:406] acc/top1 <- label_data_1_split_1
I0417 10:26:58.096963 22508 net.cpp:380] acc/top1 -> acctop1
I0417 10:26:58.096971 22508 net.cpp:122] Setting up acc/top1
I0417 10:26:58.096976 22508 net.cpp:129] Top shape: (1)
I0417 10:26:58.096977 22508 net.cpp:137] Memory required for data: 430532808
I0417 10:26:58.096981 22508 layer_factory.hpp:77] Creating layer acc/top5
I0417 10:26:58.096985 22508 net.cpp:84] Creating Layer acc/top5
I0417 10:26:58.096989 22508 net.cpp:406] acc/top5 <- score_score_0_split_2
I0417 10:26:58.096992 22508 net.cpp:406] acc/top5 <- label_data_1_split_2
I0417 10:26:58.096995 22508 net.cpp:380] acc/top5 -> acctop5
I0417 10:26:58.097002 22508 net.cpp:122] Setting up acc/top5
I0417 10:26:58.097005 22508 net.cpp:129] Top shape: (1)
I0417 10:26:58.097007 22508 net.cpp:137] Memory required for data: 430532812
I0417 10:26:58.097009 22508 net.cpp:200] acc/top5 does not need backward computation.
I0417 10:26:58.097012 22508 net.cpp:200] acc/top1 does not need backward computation.
I0417 10:26:58.097015 22508 net.cpp:198] loss needs backward computation.
I0417 10:26:58.097018 22508 net.cpp:198] score_score_0_split needs backward computation.
I0417 10:26:58.097020 22508 net.cpp:198] score needs backward computation.
I0417 10:26:58.097023 22508 net.cpp:198] pool_global needs backward computation.
I0417 10:26:58.097026 22508 net.cpp:198] map64_3_relu_after_sum needs backward computation.
I0417 10:26:58.097028 22508 net.cpp:198] map64_3_eltsum needs backward computation.
I0417 10:26:58.097031 22508 net.cpp:198] map64_3_scale_b needs backward computation.
I0417 10:26:58.097035 22508 net.cpp:198] map64_3_bn_b needs backward computation.
I0417 10:26:58.097038 22508 net.cpp:198] map64_3_conv_b needs backward computation.
I0417 10:26:58.097040 22508 net.cpp:198] map64_3_relu_a needs backward computation.
I0417 10:26:58.097043 22508 net.cpp:198] map64_3_scale_a needs backward computation.
I0417 10:26:58.097045 22508 net.cpp:198] map64_3_bn_a needs backward computation.
I0417 10:26:58.097048 22508 net.cpp:198] map64_3_conv_a needs backward computation.
I0417 10:26:58.097050 22508 net.cpp:198] map64_2_eltsum_map64_2_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.097064 22508 net.cpp:198] map64_2_relu_after_sum needs backward computation.
I0417 10:26:58.097067 22508 net.cpp:198] map64_2_eltsum needs backward computation.
I0417 10:26:58.097069 22508 net.cpp:198] map64_2_scale_b needs backward computation.
I0417 10:26:58.097072 22508 net.cpp:198] map64_2_bn_b needs backward computation.
I0417 10:26:58.097074 22508 net.cpp:198] map64_2_conv_b needs backward computation.
I0417 10:26:58.097076 22508 net.cpp:198] map64_2_relu_a needs backward computation.
I0417 10:26:58.097079 22508 net.cpp:198] map64_2_scale_a needs backward computation.
I0417 10:26:58.097081 22508 net.cpp:198] map64_2_bn_a needs backward computation.
I0417 10:26:58.097084 22508 net.cpp:198] map64_2_conv_a needs backward computation.
I0417 10:26:58.097085 22508 net.cpp:198] map64_1_eltsum_map64_1_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.097088 22508 net.cpp:198] map64_1_relu_after_sum needs backward computation.
I0417 10:26:58.097090 22508 net.cpp:198] map64_1_eltsum needs backward computation.
I0417 10:26:58.097093 22508 net.cpp:198] map64_1_scale_b needs backward computation.
I0417 10:26:58.097095 22508 net.cpp:198] map64_1_bn_b needs backward computation.
I0417 10:26:58.097098 22508 net.cpp:198] map64_1_conv_b needs backward computation.
I0417 10:26:58.097100 22508 net.cpp:198] map64_1_relu_a needs backward computation.
I0417 10:26:58.097102 22508 net.cpp:198] map64_1_scale_a needs backward computation.
I0417 10:26:58.097105 22508 net.cpp:198] map64_1_bn_a needs backward computation.
I0417 10:26:58.097107 22508 net.cpp:198] map64_1_conv_a needs backward computation.
I0417 10:26:58.097110 22508 net.cpp:198] map64_1_scale_proj needs backward computation.
I0417 10:26:58.097112 22508 net.cpp:198] map64_1_bn_proj needs backward computation.
I0417 10:26:58.097115 22508 net.cpp:198] map64_1_conv_proj needs backward computation.
I0417 10:26:58.097116 22508 net.cpp:198] map32_3_eltsum_map32_3_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.097120 22508 net.cpp:198] map32_3_relu_after_sum needs backward computation.
I0417 10:26:58.097121 22508 net.cpp:198] map32_3_eltsum needs backward computation.
I0417 10:26:58.097124 22508 net.cpp:198] map32_3_scale_b needs backward computation.
I0417 10:26:58.097126 22508 net.cpp:198] map32_3_bn_b needs backward computation.
I0417 10:26:58.097129 22508 net.cpp:198] map32_3_conv_b needs backward computation.
I0417 10:26:58.097131 22508 net.cpp:198] map32_3_relu_a needs backward computation.
I0417 10:26:58.097133 22508 net.cpp:198] map32_3_scale_a needs backward computation.
I0417 10:26:58.097136 22508 net.cpp:198] map32_3_bn_a needs backward computation.
I0417 10:26:58.097137 22508 net.cpp:198] map32_3_conv_a needs backward computation.
I0417 10:26:58.097141 22508 net.cpp:198] map32_2_eltsum_map32_2_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.097142 22508 net.cpp:198] map32_2_relu_after_sum needs backward computation.
I0417 10:26:58.097146 22508 net.cpp:198] map32_2_eltsum needs backward computation.
I0417 10:26:58.097147 22508 net.cpp:198] map32_2_scale_b needs backward computation.
I0417 10:26:58.097151 22508 net.cpp:198] map32_2_bn_b needs backward computation.
I0417 10:26:58.097152 22508 net.cpp:198] map32_2_conv_b needs backward computation.
I0417 10:26:58.097154 22508 net.cpp:198] map32_2_relu_a needs backward computation.
I0417 10:26:58.097157 22508 net.cpp:198] map32_2_scale_a needs backward computation.
I0417 10:26:58.097159 22508 net.cpp:198] map32_2_bn_a needs backward computation.
I0417 10:26:58.097162 22508 net.cpp:198] map32_2_conv_a needs backward computation.
I0417 10:26:58.097163 22508 net.cpp:198] map32_1_eltsum_map32_1_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.097170 22508 net.cpp:198] map32_1_relu_after_sum needs backward computation.
I0417 10:26:58.097173 22508 net.cpp:198] map32_1_eltsum needs backward computation.
I0417 10:26:58.097177 22508 net.cpp:198] map32_1_scale_b needs backward computation.
I0417 10:26:58.097178 22508 net.cpp:198] map32_1_bn_b needs backward computation.
I0417 10:26:58.097189 22508 net.cpp:198] map32_1_conv_b needs backward computation.
I0417 10:26:58.097193 22508 net.cpp:198] map32_1_relu_a needs backward computation.
I0417 10:26:58.097194 22508 net.cpp:198] map32_1_scale_a needs backward computation.
I0417 10:26:58.097196 22508 net.cpp:198] map32_1_bn_a needs backward computation.
I0417 10:26:58.097198 22508 net.cpp:198] map32_1_conv_a needs backward computation.
I0417 10:26:58.097201 22508 net.cpp:198] map32_1_scale_proj needs backward computation.
I0417 10:26:58.097203 22508 net.cpp:198] map32_1_bn_proj needs backward computation.
I0417 10:26:58.097205 22508 net.cpp:198] map32_1_conv_proj needs backward computation.
I0417 10:26:58.097208 22508 net.cpp:198] map16_3_eltsum_map16_3_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.097210 22508 net.cpp:198] map16_3_relu_after_sum needs backward computation.
I0417 10:26:58.097213 22508 net.cpp:198] map16_3_eltsum needs backward computation.
I0417 10:26:58.097216 22508 net.cpp:198] map16_3_scale_b needs backward computation.
I0417 10:26:58.097218 22508 net.cpp:198] map16_3_bn_b needs backward computation.
I0417 10:26:58.097220 22508 net.cpp:198] map16_3_conv_b needs backward computation.
I0417 10:26:58.097223 22508 net.cpp:198] map16_3_relu_a needs backward computation.
I0417 10:26:58.097224 22508 net.cpp:198] map16_3_scale_a needs backward computation.
I0417 10:26:58.097228 22508 net.cpp:198] map16_3_bn_a needs backward computation.
I0417 10:26:58.097229 22508 net.cpp:198] map16_3_conv_a needs backward computation.
I0417 10:26:58.097231 22508 net.cpp:198] map16_2_eltsum_map16_2_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.097234 22508 net.cpp:198] map16_2_relu_after_sum needs backward computation.
I0417 10:26:58.097236 22508 net.cpp:198] map16_2_eltsum needs backward computation.
I0417 10:26:58.097239 22508 net.cpp:198] map16_2_scale_b needs backward computation.
I0417 10:26:58.097241 22508 net.cpp:198] map16_2_bn_b needs backward computation.
I0417 10:26:58.097244 22508 net.cpp:198] map16_2_conv_b needs backward computation.
I0417 10:26:58.097245 22508 net.cpp:198] map16_2_relu_a needs backward computation.
I0417 10:26:58.097249 22508 net.cpp:198] map16_2_scale_a needs backward computation.
I0417 10:26:58.097250 22508 net.cpp:198] map16_2_bn_a needs backward computation.
I0417 10:26:58.097252 22508 net.cpp:198] map16_2_conv_a needs backward computation.
I0417 10:26:58.097254 22508 net.cpp:198] map16_1_eltsum_map16_1_relu_after_sum_0_split needs backward computation.
I0417 10:26:58.097257 22508 net.cpp:198] map16_1_relu_after_sum needs backward computation.
I0417 10:26:58.097259 22508 net.cpp:198] map16_1_eltsum needs backward computation.
I0417 10:26:58.097262 22508 net.cpp:198] map16_1_scale_b needs backward computation.
I0417 10:26:58.097265 22508 net.cpp:198] map16_1_bn_b needs backward computation.
I0417 10:26:58.097267 22508 net.cpp:198] map16_1_conv_b needs backward computation.
I0417 10:26:58.097270 22508 net.cpp:198] map16_1_relu_a needs backward computation.
I0417 10:26:58.097271 22508 net.cpp:198] map16_1_scale_a needs backward computation.
I0417 10:26:58.097275 22508 net.cpp:198] map16_1_bn_a needs backward computation.
I0417 10:26:58.097276 22508 net.cpp:198] map16_1_conv_a needs backward computation.
I0417 10:26:58.097278 22508 net.cpp:198] conv1_relu_conv1_0_split needs backward computation.
I0417 10:26:58.097281 22508 net.cpp:198] relu_conv1 needs backward computation.
I0417 10:26:58.097283 22508 net.cpp:198] scale_conv1 needs backward computation.
I0417 10:26:58.097285 22508 net.cpp:198] bn_conv1 needs backward computation.
I0417 10:26:58.097288 22508 net.cpp:198] conv1 needs backward computation.
I0417 10:26:58.097291 22508 net.cpp:200] label_data_1_split does not need backward computation.
I0417 10:26:58.097295 22508 net.cpp:200] data does not need backward computation.
I0417 10:26:58.097298 22508 net.cpp:242] This network produces output acctop1
I0417 10:26:58.097301 22508 net.cpp:242] This network produces output acctop5
I0417 10:26:58.097311 22508 net.cpp:242] This network produces output loss
I0417 10:26:58.097362 22508 net.cpp:255] Network initialization done.
I0417 10:26:58.097612 22508 solver.cpp:56] Solver scaffolding done.
I0417 10:26:58.102581 22508 caffe.cpp:248] Starting Optimization
I0417 10:26:58.102593 22508 solver.cpp:273] Solving 
I0417 10:26:58.102596 22508 solver.cpp:274] Learning Rate Policy: multistep
I0417 10:26:58.105659 22508 solver.cpp:331] Iteration 0, Testing net (#0)
I0417 10:27:01.087460 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:27:01.208326 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.1
I0417 10:27:01.208346 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.5
I0417 10:27:01.208358 22508 solver.cpp:398]     Test net output #2: loss = 87.3365 (* 1 = 87.3365 loss)
I0417 10:27:01.396371 22508 solver.cpp:219] Iteration 0 (0 iter/s, 3.29367s/100 iters), loss = 2.31871
I0417 10:27:01.396390 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.101562
I0417 10:27:01.396396 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.4375
I0417 10:27:01.396402 22508 solver.cpp:238]     Train net output #2: loss = 2.31871 (* 1 = 2.31871 loss)
I0417 10:27:01.396419 22508 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0417 10:27:23.411337 22508 solver.cpp:219] Iteration 100 (4.54247 iter/s, 22.0145s/100 iters), loss = 2.32918
I0417 10:27:23.411398 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.0546875
I0417 10:27:23.411406 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.476562
I0417 10:27:23.411417 22508 solver.cpp:238]     Train net output #2: loss = 2.32918 (* 1 = 2.32918 loss)
I0417 10:27:23.411425 22508 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0417 10:27:45.400298 22508 solver.cpp:219] Iteration 200 (4.54785 iter/s, 21.9884s/100 iters), loss = 2.30487
I0417 10:27:45.400414 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.101562
I0417 10:27:45.400424 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.53125
I0417 10:27:45.400431 22508 solver.cpp:238]     Train net output #2: loss = 2.30487 (* 1 = 2.30487 loss)
I0417 10:27:45.400436 22508 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0417 10:28:07.406319 22508 solver.cpp:219] Iteration 300 (4.54433 iter/s, 22.0054s/100 iters), loss = 2.31279
I0417 10:28:07.406355 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.09375
I0417 10:28:07.406363 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.453125
I0417 10:28:07.406371 22508 solver.cpp:238]     Train net output #2: loss = 2.31279 (* 1 = 2.31279 loss)
I0417 10:28:07.406378 22508 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0417 10:28:26.350611 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:28:29.439436 22508 solver.cpp:219] Iteration 400 (4.53873 iter/s, 22.0326s/100 iters), loss = 2.28584
I0417 10:28:29.439476 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.101562
I0417 10:28:29.439482 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.59375
I0417 10:28:29.439491 22508 solver.cpp:238]     Train net output #2: loss = 2.28584 (* 1 = 2.28584 loss)
I0417 10:28:29.439496 22508 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0417 10:28:51.441148 22508 solver.cpp:219] Iteration 500 (4.54521 iter/s, 22.0012s/100 iters), loss = 2.20248
I0417 10:28:51.441189 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.109375
I0417 10:28:51.441195 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.664062
I0417 10:28:51.441203 22508 solver.cpp:238]     Train net output #2: loss = 2.20248 (* 1 = 2.20248 loss)
I0417 10:28:51.441208 22508 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0417 10:29:13.427357 22508 solver.cpp:219] Iteration 600 (4.54842 iter/s, 21.9857s/100 iters), loss = 2.13535
I0417 10:29:13.427531 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.210938
I0417 10:29:13.427544 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.71875
I0417 10:29:13.427556 22508 solver.cpp:238]     Train net output #2: loss = 2.13535 (* 1 = 2.13535 loss)
I0417 10:29:13.427567 22508 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0417 10:29:35.404014 22508 solver.cpp:219] Iteration 700 (4.55042 iter/s, 21.976s/100 iters), loss = 1.8367
I0417 10:29:35.404049 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.257812
I0417 10:29:35.404057 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.867188
I0417 10:29:35.404063 22508 solver.cpp:238]     Train net output #2: loss = 1.8367 (* 1 = 1.8367 loss)
I0417 10:29:35.404068 22508 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0417 10:29:52.283407 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:29:57.331388 22508 solver.cpp:219] Iteration 800 (4.56062 iter/s, 21.9269s/100 iters), loss = 1.52191
I0417 10:29:57.331420 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.5
I0417 10:29:57.331428 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.882812
I0417 10:29:57.331434 22508 solver.cpp:238]     Train net output #2: loss = 1.52191 (* 1 = 1.52191 loss)
I0417 10:29:57.331439 22508 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0417 10:30:19.304276 22508 solver.cpp:219] Iteration 900 (4.55117 iter/s, 21.9724s/100 iters), loss = 1.63249
I0417 10:30:19.304324 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.382812
I0417 10:30:19.304332 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.898438
I0417 10:30:19.304339 22508 solver.cpp:238]     Train net output #2: loss = 1.63249 (* 1 = 1.63249 loss)
I0417 10:30:19.304344 22508 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0417 10:30:41.017611 22508 solver.cpp:331] Iteration 1000, Testing net (#0)
I0417 10:30:43.959148 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:30:44.079938 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.1
I0417 10:30:44.079962 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.5
I0417 10:30:44.079972 22508 solver.cpp:398]     Test net output #2: loss = 9.58501 (* 1 = 9.58501 loss)
I0417 10:30:44.295358 22508 solver.cpp:219] Iteration 1000 (4.00152 iter/s, 24.9905s/100 iters), loss = 1.20941
I0417 10:30:44.295382 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.585938
I0417 10:30:44.295387 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0417 10:30:44.295393 22508 solver.cpp:238]     Train net output #2: loss = 1.20941 (* 1 = 1.20941 loss)
I0417 10:30:44.295398 22508 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0417 10:31:06.212054 22508 solver.cpp:219] Iteration 1100 (4.56284 iter/s, 21.9162s/100 iters), loss = 1.12996
I0417 10:31:06.212090 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.59375
I0417 10:31:06.212096 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.960938
I0417 10:31:06.212103 22508 solver.cpp:238]     Train net output #2: loss = 1.12996 (* 1 = 1.12996 loss)
I0417 10:31:06.212107 22508 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0417 10:31:20.940929 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:31:28.185633 22508 solver.cpp:219] Iteration 1200 (4.55103 iter/s, 21.973s/100 iters), loss = 0.955585
I0417 10:31:28.185669 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.710938
I0417 10:31:28.185674 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.960938
I0417 10:31:28.185681 22508 solver.cpp:238]     Train net output #2: loss = 0.955585 (* 1 = 0.955585 loss)
I0417 10:31:28.185686 22508 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0417 10:31:50.123936 22508 solver.cpp:219] Iteration 1300 (4.55835 iter/s, 21.9378s/100 iters), loss = 1.11635
I0417 10:31:50.123975 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.617188
I0417 10:31:50.123980 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.953125
I0417 10:31:50.123987 22508 solver.cpp:238]     Train net output #2: loss = 1.11635 (* 1 = 1.11635 loss)
I0417 10:31:50.123991 22508 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0417 10:32:12.180711 22508 solver.cpp:219] Iteration 1400 (4.53387 iter/s, 22.0562s/100 iters), loss = 0.858748
I0417 10:32:12.180879 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.6875
I0417 10:32:12.180891 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0417 10:32:12.180897 22508 solver.cpp:238]     Train net output #2: loss = 0.858748 (* 1 = 0.858748 loss)
I0417 10:32:12.180902 22508 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0417 10:32:34.222851 22508 solver.cpp:219] Iteration 1500 (4.5369 iter/s, 22.0415s/100 iters), loss = 0.853309
I0417 10:32:34.222892 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.6875
I0417 10:32:34.222898 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.945312
I0417 10:32:34.222904 22508 solver.cpp:238]     Train net output #2: loss = 0.853309 (* 1 = 0.853309 loss)
I0417 10:32:34.222908 22508 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0417 10:32:47.037423 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:32:56.284966 22508 solver.cpp:219] Iteration 1600 (4.53277 iter/s, 22.0616s/100 iters), loss = 0.912297
I0417 10:32:56.285006 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.609375
I0417 10:32:56.285012 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.960938
I0417 10:32:56.285019 22508 solver.cpp:238]     Train net output #2: loss = 0.912297 (* 1 = 0.912297 loss)
I0417 10:32:56.285024 22508 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0417 10:33:18.278293 22508 solver.cpp:219] Iteration 1700 (4.54695 iter/s, 21.9928s/100 iters), loss = 1.07426
I0417 10:33:18.278409 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.632812
I0417 10:33:18.278416 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.921875
I0417 10:33:18.278424 22508 solver.cpp:238]     Train net output #2: loss = 1.07426 (* 1 = 1.07426 loss)
I0417 10:33:18.278429 22508 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0417 10:33:40.176244 22508 solver.cpp:219] Iteration 1800 (4.56677 iter/s, 21.8973s/100 iters), loss = 0.896277
I0417 10:33:40.176278 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.695312
I0417 10:33:40.176283 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:33:40.176290 22508 solver.cpp:238]     Train net output #2: loss = 0.896277 (* 1 = 0.896277 loss)
I0417 10:33:40.176295 22508 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0417 10:34:02.091182 22508 solver.cpp:219] Iteration 1900 (4.56321 iter/s, 21.9144s/100 iters), loss = 1.12571
I0417 10:34:02.091312 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.601562
I0417 10:34:02.091320 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0417 10:34:02.091327 22508 solver.cpp:238]     Train net output #2: loss = 1.12571 (* 1 = 1.12571 loss)
I0417 10:34:02.091331 22508 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0417 10:34:12.828558 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:34:23.795727 22508 solver.cpp:331] Iteration 2000, Testing net (#0)
I0417 10:34:26.732357 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:34:26.852998 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.3533
I0417 10:34:26.853024 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.792
I0417 10:34:26.853034 22508 solver.cpp:398]     Test net output #2: loss = 1.92403 (* 1 = 1.92403 loss)
I0417 10:34:27.069372 22508 solver.cpp:219] Iteration 2000 (4.0036 iter/s, 24.9775s/100 iters), loss = 0.770508
I0417 10:34:27.069396 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.726562
I0417 10:34:27.069401 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:34:27.069406 22508 solver.cpp:238]     Train net output #2: loss = 0.770508 (* 1 = 0.770508 loss)
I0417 10:34:27.069411 22508 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0417 10:34:49.023603 22508 solver.cpp:219] Iteration 2100 (4.55504 iter/s, 21.9537s/100 iters), loss = 0.705423
I0417 10:34:49.023721 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.78125
I0417 10:34:49.023730 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:34:49.023738 22508 solver.cpp:238]     Train net output #2: loss = 0.705423 (* 1 = 0.705423 loss)
I0417 10:34:49.023746 22508 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0417 10:35:10.991148 22508 solver.cpp:219] Iteration 2200 (4.5523 iter/s, 21.9669s/100 iters), loss = 0.761123
I0417 10:35:10.991183 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.726562
I0417 10:35:10.991189 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:35:10.991195 22508 solver.cpp:238]     Train net output #2: loss = 0.761123 (* 1 = 0.761123 loss)
I0417 10:35:10.991200 22508 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0417 10:35:32.937667 22508 solver.cpp:219] Iteration 2300 (4.55664 iter/s, 21.946s/100 iters), loss = 0.753712
I0417 10:35:32.937806 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.757812
I0417 10:35:32.937814 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.945312
I0417 10:35:32.937824 22508 solver.cpp:238]     Train net output #2: loss = 0.753712 (* 1 = 0.753712 loss)
I0417 10:35:32.937827 22508 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0417 10:35:41.492895 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:35:54.848181 22508 solver.cpp:219] Iteration 2400 (4.56415 iter/s, 21.9099s/100 iters), loss = 0.593967
I0417 10:35:54.848215 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0417 10:35:54.848222 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0417 10:35:54.848228 22508 solver.cpp:238]     Train net output #2: loss = 0.593967 (* 1 = 0.593967 loss)
I0417 10:35:54.848232 22508 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0417 10:36:16.799619 22508 solver.cpp:219] Iteration 2500 (4.55562 iter/s, 21.9509s/100 iters), loss = 0.685167
I0417 10:36:16.799731 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.757812
I0417 10:36:16.799738 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.960938
I0417 10:36:16.799746 22508 solver.cpp:238]     Train net output #2: loss = 0.685167 (* 1 = 0.685167 loss)
I0417 10:36:16.799751 22508 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0417 10:36:38.716146 22508 solver.cpp:219] Iteration 2600 (4.56289 iter/s, 21.9159s/100 iters), loss = 0.953984
I0417 10:36:38.716173 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.671875
I0417 10:36:38.716179 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.953125
I0417 10:36:38.716186 22508 solver.cpp:238]     Train net output #2: loss = 0.953984 (* 1 = 0.953984 loss)
I0417 10:36:38.716189 22508 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0417 10:37:00.631922 22508 solver.cpp:219] Iteration 2700 (4.56303 iter/s, 21.9153s/100 iters), loss = 0.60553
I0417 10:37:00.632019 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.78125
I0417 10:37:00.632027 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:37:00.632035 22508 solver.cpp:238]     Train net output #2: loss = 0.60553 (* 1 = 0.60553 loss)
I0417 10:37:00.632041 22508 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0417 10:37:07.214905 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:37:22.608788 22508 solver.cpp:219] Iteration 2800 (4.55036 iter/s, 21.9763s/100 iters), loss = 0.704177
I0417 10:37:22.609338 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.757812
I0417 10:37:22.609345 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:37:22.609352 22508 solver.cpp:238]     Train net output #2: loss = 0.704177 (* 1 = 0.704177 loss)
I0417 10:37:22.609357 22508 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0417 10:37:44.640450 22508 solver.cpp:219] Iteration 2900 (4.53914 iter/s, 22.0306s/100 iters), loss = 0.720687
I0417 10:37:44.640600 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.734375
I0417 10:37:44.640609 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:37:44.640617 22508 solver.cpp:238]     Train net output #2: loss = 0.720687 (* 1 = 0.720687 loss)
I0417 10:37:44.640622 22508 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0417 10:38:06.478878 22508 solver.cpp:331] Iteration 3000, Testing net (#0)
I0417 10:38:09.413208 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:38:09.533861 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.2855
I0417 10:38:09.533885 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.6769
I0417 10:38:09.533892 22508 solver.cpp:398]     Test net output #2: loss = 3.18571 (* 1 = 3.18571 loss)
I0417 10:38:09.749850 22508 solver.cpp:219] Iteration 3000 (3.98268 iter/s, 25.1087s/100 iters), loss = 0.671365
I0417 10:38:09.749884 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.773438
I0417 10:38:09.749891 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:38:09.749897 22508 solver.cpp:238]     Train net output #2: loss = 0.671365 (* 1 = 0.671365 loss)
I0417 10:38:09.749900 22508 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0417 10:38:31.787051 22508 solver.cpp:219] Iteration 3100 (4.53789 iter/s, 22.0367s/100 iters), loss = 0.695668
I0417 10:38:31.787833 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.726562
I0417 10:38:31.787842 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:38:31.787850 22508 solver.cpp:238]     Train net output #2: loss = 0.695668 (* 1 = 0.695668 loss)
I0417 10:38:31.787854 22508 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0417 10:38:36.198856 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:38:53.851948 22508 solver.cpp:219] Iteration 3200 (4.53235 iter/s, 22.0636s/100 iters), loss = 0.619636
I0417 10:38:53.851987 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0417 10:38:53.851994 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:38:53.852000 22508 solver.cpp:238]     Train net output #2: loss = 0.619636 (* 1 = 0.619636 loss)
I0417 10:38:53.852005 22508 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0417 10:39:15.914057 22508 solver.cpp:219] Iteration 3300 (4.53277 iter/s, 22.0616s/100 iters), loss = 0.630074
I0417 10:39:15.914242 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.765625
I0417 10:39:15.914249 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:39:15.914258 22508 solver.cpp:238]     Train net output #2: loss = 0.630074 (* 1 = 0.630074 loss)
I0417 10:39:15.914263 22508 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0417 10:39:37.945340 22508 solver.cpp:219] Iteration 3400 (4.53914 iter/s, 22.0306s/100 iters), loss = 0.545403
I0417 10:39:37.945930 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0417 10:39:37.945937 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.96875
I0417 10:39:37.945945 22508 solver.cpp:238]     Train net output #2: loss = 0.545403 (* 1 = 0.545403 loss)
I0417 10:39:37.945948 22508 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0417 10:39:59.971871 22508 solver.cpp:219] Iteration 3500 (4.5402 iter/s, 22.0254s/100 iters), loss = 0.485612
I0417 10:39:59.971981 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 10:39:59.971988 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:39:59.971997 22508 solver.cpp:238]     Train net output #2: loss = 0.485612 (* 1 = 0.485612 loss)
I0417 10:39:59.972002 22508 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0417 10:40:02.400188 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:40:22.008222 22508 solver.cpp:219] Iteration 3600 (4.53808 iter/s, 22.0357s/100 iters), loss = 0.680761
I0417 10:40:22.008740 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.75
I0417 10:40:22.008749 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0417 10:40:22.008755 22508 solver.cpp:238]     Train net output #2: loss = 0.680761 (* 1 = 0.680761 loss)
I0417 10:40:22.008760 22508 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0417 10:40:44.039245 22508 solver.cpp:219] Iteration 3700 (4.53926 iter/s, 22.03s/100 iters), loss = 0.567359
I0417 10:40:44.039423 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0417 10:40:44.039433 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:40:44.039439 22508 solver.cpp:238]     Train net output #2: loss = 0.567359 (* 1 = 0.567359 loss)
I0417 10:40:44.039444 22508 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0417 10:41:06.075158 22508 solver.cpp:219] Iteration 3800 (4.53819 iter/s, 22.0352s/100 iters), loss = 0.638161
I0417 10:41:06.075212 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.765625
I0417 10:41:06.075218 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0417 10:41:06.075227 22508 solver.cpp:238]     Train net output #2: loss = 0.638161 (* 1 = 0.638161 loss)
I0417 10:41:06.075232 22508 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0417 10:41:28.131948 22508 solver.cpp:219] Iteration 3900 (4.53387 iter/s, 22.0562s/100 iters), loss = 0.531254
I0417 10:41:28.132087 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.804688
I0417 10:41:28.132097 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:41:28.132103 22508 solver.cpp:238]     Train net output #2: loss = 0.531254 (* 1 = 0.531254 loss)
I0417 10:41:28.132110 22508 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0417 10:41:28.577234 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:41:49.994946 22508 solver.cpp:331] Iteration 4000, Testing net (#0)
I0417 10:41:52.944830 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:41:53.065868 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.4562
I0417 10:41:53.065891 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9141
I0417 10:41:53.065898 22508 solver.cpp:398]     Test net output #2: loss = 1.73028 (* 1 = 1.73028 loss)
I0417 10:41:53.284735 22508 solver.cpp:219] Iteration 4000 (3.97581 iter/s, 25.1521s/100 iters), loss = 0.545469
I0417 10:41:53.284759 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0417 10:41:53.284765 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:41:53.284770 22508 solver.cpp:238]     Train net output #2: loss = 0.545469 (* 1 = 0.545469 loss)
I0417 10:41:53.284775 22508 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0417 10:42:15.342720 22508 solver.cpp:219] Iteration 4100 (4.53361 iter/s, 22.0575s/100 iters), loss = 0.642942
I0417 10:42:15.342874 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.757812
I0417 10:42:15.342882 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:42:15.342890 22508 solver.cpp:238]     Train net output #2: loss = 0.642942 (* 1 = 0.642942 loss)
I0417 10:42:15.342895 22508 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0417 10:42:37.425101 22508 solver.cpp:219] Iteration 4200 (4.52863 iter/s, 22.0817s/100 iters), loss = 0.512177
I0417 10:42:37.425153 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0417 10:42:37.425159 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:42:37.425168 22508 solver.cpp:238]     Train net output #2: loss = 0.512177 (* 1 = 0.512177 loss)
I0417 10:42:37.425174 22508 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0417 10:42:57.743511 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:42:59.505025 22508 solver.cpp:219] Iteration 4300 (4.52911 iter/s, 22.0794s/100 iters), loss = 0.477304
I0417 10:42:59.505058 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0417 10:42:59.505064 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:42:59.505072 22508 solver.cpp:238]     Train net output #2: loss = 0.477304 (* 1 = 0.477304 loss)
I0417 10:42:59.505077 22508 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0417 10:43:21.536217 22508 solver.cpp:219] Iteration 4400 (4.53913 iter/s, 22.0307s/100 iters), loss = 0.671634
I0417 10:43:21.536746 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.78125
I0417 10:43:21.536756 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:43:21.536767 22508 solver.cpp:238]     Train net output #2: loss = 0.671634 (* 1 = 0.671634 loss)
I0417 10:43:21.536773 22508 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0417 10:43:43.501381 22508 solver.cpp:219] Iteration 4500 (4.55288 iter/s, 21.9641s/100 iters), loss = 0.408879
I0417 10:43:43.501564 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 10:43:43.501574 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:43:43.501580 22508 solver.cpp:238]     Train net output #2: loss = 0.408879 (* 1 = 0.408879 loss)
I0417 10:43:43.501585 22508 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0417 10:44:05.422924 22508 solver.cpp:219] Iteration 4600 (4.56186 iter/s, 21.9209s/100 iters), loss = 0.368023
I0417 10:44:05.422976 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0417 10:44:05.422983 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:44:05.422991 22508 solver.cpp:238]     Train net output #2: loss = 0.368023 (* 1 = 0.368023 loss)
I0417 10:44:05.422996 22508 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0417 10:44:23.658442 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:44:27.393355 22508 solver.cpp:219] Iteration 4700 (4.55169 iter/s, 21.9699s/100 iters), loss = 0.543168
I0417 10:44:27.393389 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0417 10:44:27.393395 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:44:27.393401 22508 solver.cpp:238]     Train net output #2: loss = 0.543168 (* 1 = 0.543168 loss)
I0417 10:44:27.393405 22508 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0417 10:44:49.295321 22508 solver.cpp:219] Iteration 4800 (4.56591 iter/s, 21.9014s/100 iters), loss = 0.529493
I0417 10:44:49.295358 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0417 10:44:49.295364 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:44:49.295370 22508 solver.cpp:238]     Train net output #2: loss = 0.529493 (* 1 = 0.529493 loss)
I0417 10:44:49.295374 22508 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0417 10:45:11.228097 22508 solver.cpp:219] Iteration 4900 (4.5595 iter/s, 21.9322s/100 iters), loss = 0.517634
I0417 10:45:11.228302 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.78125
I0417 10:45:11.228309 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:45:11.228317 22508 solver.cpp:238]     Train net output #2: loss = 0.517634 (* 1 = 0.517634 loss)
I0417 10:45:11.228320 22508 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0417 10:45:32.975917 22508 solver.cpp:331] Iteration 5000, Testing net (#0)
I0417 10:45:35.912686 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:45:36.033607 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.1695
I0417 10:45:36.033628 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.5782
I0417 10:45:36.033635 22508 solver.cpp:398]     Test net output #2: loss = 3.17608 (* 1 = 3.17608 loss)
I0417 10:45:36.248324 22508 solver.cpp:219] Iteration 5000 (3.99689 iter/s, 25.0195s/100 iters), loss = 0.539022
I0417 10:45:36.248345 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0417 10:45:36.248363 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:45:36.248368 22508 solver.cpp:238]     Train net output #2: loss = 0.539022 (* 1 = 0.539022 loss)
I0417 10:45:36.248373 22508 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0417 10:45:52.466915 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:45:58.169507 22508 solver.cpp:219] Iteration 5100 (4.56191 iter/s, 21.9207s/100 iters), loss = 0.397326
I0417 10:45:58.169540 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0417 10:45:58.169546 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:45:58.169553 22508 solver.cpp:238]     Train net output #2: loss = 0.397326 (* 1 = 0.397326 loss)
I0417 10:45:58.169556 22508 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0417 10:46:20.192566 22508 solver.cpp:219] Iteration 5200 (4.5408 iter/s, 22.0225s/100 iters), loss = 0.672598
I0417 10:46:20.192605 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.773438
I0417 10:46:20.192611 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:46:20.192618 22508 solver.cpp:238]     Train net output #2: loss = 0.672598 (* 1 = 0.672598 loss)
I0417 10:46:20.192622 22508 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0417 10:46:42.250721 22508 solver.cpp:219] Iteration 5300 (4.53358 iter/s, 22.0576s/100 iters), loss = 0.53103
I0417 10:46:42.250895 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0417 10:46:42.250903 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:46:42.250910 22508 solver.cpp:238]     Train net output #2: loss = 0.53103 (* 1 = 0.53103 loss)
I0417 10:46:42.250915 22508 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0417 10:47:04.300494 22508 solver.cpp:219] Iteration 5400 (4.53533 iter/s, 22.0491s/100 iters), loss = 0.354089
I0417 10:47:04.300534 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 10:47:04.300540 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:47:04.300547 22508 solver.cpp:238]     Train net output #2: loss = 0.354089 (* 1 = 0.354089 loss)
I0417 10:47:04.300551 22508 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0417 10:47:18.396586 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:47:26.276319 22508 solver.cpp:219] Iteration 5500 (4.55057 iter/s, 21.9753s/100 iters), loss = 0.468172
I0417 10:47:26.276360 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0417 10:47:26.276367 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:47:26.276377 22508 solver.cpp:238]     Train net output #2: loss = 0.468172 (* 1 = 0.468172 loss)
I0417 10:47:26.276383 22508 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0417 10:47:48.214905 22508 solver.cpp:219] Iteration 5600 (4.55829 iter/s, 21.938s/100 iters), loss = 0.439354
I0417 10:47:48.214942 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0417 10:47:48.214948 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0417 10:47:48.214954 22508 solver.cpp:238]     Train net output #2: loss = 0.439354 (* 1 = 0.439354 loss)
I0417 10:47:48.214960 22508 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0417 10:48:10.121898 22508 solver.cpp:219] Iteration 5700 (4.56486 iter/s, 21.9065s/100 iters), loss = 0.482473
I0417 10:48:10.122004 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.804688
I0417 10:48:10.122012 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0417 10:48:10.122020 22508 solver.cpp:238]     Train net output #2: loss = 0.482473 (* 1 = 0.482473 loss)
I0417 10:48:10.122025 22508 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0417 10:48:32.048707 22508 solver.cpp:219] Iteration 5800 (4.56075 iter/s, 21.9262s/100 iters), loss = 0.462384
I0417 10:48:32.048744 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0417 10:48:32.048750 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.976562
I0417 10:48:32.048756 22508 solver.cpp:238]     Train net output #2: loss = 0.462384 (* 1 = 0.462384 loss)
I0417 10:48:32.048760 22508 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0417 10:48:44.098466 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:48:53.992086 22508 solver.cpp:219] Iteration 5900 (4.55729 iter/s, 21.9428s/100 iters), loss = 0.422984
I0417 10:48:53.992125 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0417 10:48:53.992131 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:48:53.992138 22508 solver.cpp:238]     Train net output #2: loss = 0.422984 (* 1 = 0.422984 loss)
I0417 10:48:53.992143 22508 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0417 10:49:15.780266 22508 solver.cpp:331] Iteration 6000, Testing net (#0)
I0417 10:49:18.726073 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:49:18.847110 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.1147
I0417 10:49:18.847133 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.4918
I0417 10:49:18.847141 22508 solver.cpp:398]     Test net output #2: loss = 4.06574 (* 1 = 4.06574 loss)
I0417 10:49:19.065074 22508 solver.cpp:219] Iteration 6000 (3.98845 iter/s, 25.0724s/100 iters), loss = 0.424768
I0417 10:49:19.065095 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0417 10:49:19.065100 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:49:19.065107 22508 solver.cpp:238]     Train net output #2: loss = 0.424768 (* 1 = 0.424768 loss)
I0417 10:49:19.065114 22508 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0417 10:49:41.008638 22508 solver.cpp:219] Iteration 6100 (4.55725 iter/s, 21.943s/100 iters), loss = 0.58592
I0417 10:49:41.009188 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.796875
I0417 10:49:41.009196 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:49:41.009205 22508 solver.cpp:238]     Train net output #2: loss = 0.58592 (* 1 = 0.58592 loss)
I0417 10:49:41.009209 22508 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0417 10:50:02.961885 22508 solver.cpp:219] Iteration 6200 (4.55535 iter/s, 21.9522s/100 iters), loss = 0.446022
I0417 10:50:02.962055 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0417 10:50:02.962064 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:50:02.962070 22508 solver.cpp:238]     Train net output #2: loss = 0.446022 (* 1 = 0.446022 loss)
I0417 10:50:02.962075 22508 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0417 10:50:12.847625 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:50:24.928802 22508 solver.cpp:219] Iteration 6300 (4.55244 iter/s, 21.9662s/100 iters), loss = 0.559226
I0417 10:50:24.929373 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0417 10:50:24.929381 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:50:24.929389 22508 solver.cpp:238]     Train net output #2: loss = 0.559226 (* 1 = 0.559226 loss)
I0417 10:50:24.929394 22508 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0417 10:50:46.826123 22508 solver.cpp:219] Iteration 6400 (4.56699 iter/s, 21.8962s/100 iters), loss = 0.469439
I0417 10:50:46.826251 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0417 10:50:46.826258 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:50:46.826264 22508 solver.cpp:238]     Train net output #2: loss = 0.469439 (* 1 = 0.469439 loss)
I0417 10:50:46.826269 22508 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0417 10:51:08.781767 22508 solver.cpp:219] Iteration 6500 (4.55477 iter/s, 21.955s/100 iters), loss = 0.482368
I0417 10:51:08.781832 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0417 10:51:08.781839 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:51:08.781846 22508 solver.cpp:238]     Train net output #2: loss = 0.482368 (* 1 = 0.482368 loss)
I0417 10:51:08.781850 22508 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0417 10:51:30.754103 22508 solver.cpp:219] Iteration 6600 (4.55129 iter/s, 21.9718s/100 iters), loss = 0.487883
I0417 10:51:30.754809 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0417 10:51:30.754817 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:51:30.754824 22508 solver.cpp:238]     Train net output #2: loss = 0.487883 (* 1 = 0.487883 loss)
I0417 10:51:30.754828 22508 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0417 10:51:38.687024 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:51:52.823837 22508 solver.cpp:219] Iteration 6700 (4.53134 iter/s, 22.0685s/100 iters), loss = 0.401559
I0417 10:51:52.823886 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0417 10:51:52.823894 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:51:52.823900 22508 solver.cpp:238]     Train net output #2: loss = 0.401559 (* 1 = 0.401559 loss)
I0417 10:51:52.823904 22508 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0417 10:52:14.952564 22508 solver.cpp:219] Iteration 6800 (4.51913 iter/s, 22.1282s/100 iters), loss = 0.52666
I0417 10:52:14.952711 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.789062
I0417 10:52:14.952719 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:52:14.952726 22508 solver.cpp:238]     Train net output #2: loss = 0.52666 (* 1 = 0.52666 loss)
I0417 10:52:14.952731 22508 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0417 10:52:37.015506 22508 solver.cpp:219] Iteration 6900 (4.53262 iter/s, 22.0623s/100 iters), loss = 0.628941
I0417 10:52:37.015539 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.773438
I0417 10:52:37.015545 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:52:37.015552 22508 solver.cpp:238]     Train net output #2: loss = 0.628941 (* 1 = 0.628941 loss)
I0417 10:52:37.015555 22508 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0417 10:52:58.860466 22508 solver.cpp:331] Iteration 7000, Testing net (#0)
I0417 10:53:01.796896 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:53:01.917783 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.1684
I0417 10:53:01.917820 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.6251
I0417 10:53:01.917827 22508 solver.cpp:398]     Test net output #2: loss = 3.39077 (* 1 = 3.39077 loss)
I0417 10:53:02.135821 22508 solver.cpp:219] Iteration 7000 (3.98094 iter/s, 25.1197s/100 iters), loss = 0.363506
I0417 10:53:02.135843 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0417 10:53:02.135848 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:53:02.135854 22508 solver.cpp:238]     Train net output #2: loss = 0.363506 (* 1 = 0.363506 loss)
I0417 10:53:02.135859 22508 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0417 10:53:08.093113 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:53:24.189179 22508 solver.cpp:219] Iteration 7100 (4.53456 iter/s, 22.0528s/100 iters), loss = 0.326263
I0417 10:53:24.189752 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 10:53:24.189760 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:53:24.189766 22508 solver.cpp:238]     Train net output #2: loss = 0.326263 (* 1 = 0.326263 loss)
I0417 10:53:24.189771 22508 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0417 10:53:46.252442 22508 solver.cpp:219] Iteration 7200 (4.53264 iter/s, 22.0622s/100 iters), loss = 0.427821
I0417 10:53:46.252594 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0417 10:53:46.252602 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:53:46.252610 22508 solver.cpp:238]     Train net output #2: loss = 0.427821 (* 1 = 0.427821 loss)
I0417 10:53:46.252614 22508 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0417 10:54:08.313925 22508 solver.cpp:219] Iteration 7300 (4.53292 iter/s, 22.0608s/100 iters), loss = 0.304108
I0417 10:54:08.313977 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 10:54:08.313984 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:54:08.313993 22508 solver.cpp:238]     Train net output #2: loss = 0.304108 (* 1 = 0.304108 loss)
I0417 10:54:08.313997 22508 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0417 10:54:30.316857 22508 solver.cpp:219] Iteration 7400 (4.54496 iter/s, 22.0024s/100 iters), loss = 0.351505
I0417 10:54:30.316974 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0417 10:54:30.316982 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:54:30.316990 22508 solver.cpp:238]     Train net output #2: loss = 0.351505 (* 1 = 0.351505 loss)
I0417 10:54:30.316994 22508 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0417 10:54:34.048743 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:54:52.256090 22508 solver.cpp:219] Iteration 7500 (4.55817 iter/s, 21.9386s/100 iters), loss = 0.396403
I0417 10:54:52.256124 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0417 10:54:52.256129 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:54:52.256135 22508 solver.cpp:238]     Train net output #2: loss = 0.396403 (* 1 = 0.396403 loss)
I0417 10:54:52.256140 22508 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0417 10:55:14.207413 22508 solver.cpp:219] Iteration 7600 (4.55564 iter/s, 21.9508s/100 iters), loss = 0.444982
I0417 10:55:14.208063 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.828125
I0417 10:55:14.208076 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:55:14.208083 22508 solver.cpp:238]     Train net output #2: loss = 0.444982 (* 1 = 0.444982 loss)
I0417 10:55:14.208089 22508 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0417 10:55:36.135504 22508 solver.cpp:219] Iteration 7700 (4.5606 iter/s, 21.927s/100 iters), loss = 0.339409
I0417 10:55:36.135538 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 10:55:36.135543 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:55:36.135550 22508 solver.cpp:238]     Train net output #2: loss = 0.339409 (* 1 = 0.339409 loss)
I0417 10:55:36.135555 22508 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0417 10:55:58.111068 22508 solver.cpp:219] Iteration 7800 (4.55062 iter/s, 21.975s/100 iters), loss = 0.310491
I0417 10:55:58.111529 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 10:55:58.111537 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:55:58.111544 22508 solver.cpp:238]     Train net output #2: loss = 0.310491 (* 1 = 0.310491 loss)
I0417 10:55:58.111548 22508 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0417 10:55:59.873709 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:56:20.106282 22508 solver.cpp:219] Iteration 7900 (4.54664 iter/s, 21.9943s/100 iters), loss = 0.30333
I0417 10:56:20.106318 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 10:56:20.106323 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:56:20.106330 22508 solver.cpp:238]     Train net output #2: loss = 0.30333 (* 1 = 0.30333 loss)
I0417 10:56:20.106334 22508 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0417 10:56:41.878715 22508 solver.cpp:331] Iteration 8000, Testing net (#0)
I0417 10:56:44.821341 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:56:44.942350 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.636
I0417 10:56:44.942373 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9604
I0417 10:56:44.942380 22508 solver.cpp:398]     Test net output #2: loss = 1.2059 (* 1 = 1.2059 loss)
I0417 10:56:45.160064 22508 solver.cpp:219] Iteration 8000 (3.99151 iter/s, 25.0532s/100 iters), loss = 0.347096
I0417 10:56:45.160087 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0417 10:56:45.160092 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:56:45.160097 22508 solver.cpp:238]     Train net output #2: loss = 0.347096 (* 1 = 0.347096 loss)
I0417 10:56:45.160102 22508 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0417 10:57:07.220995 22508 solver.cpp:219] Iteration 8100 (4.53301 iter/s, 22.0604s/100 iters), loss = 0.476327
I0417 10:57:07.221560 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.820312
I0417 10:57:07.221568 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:57:07.221575 22508 solver.cpp:238]     Train net output #2: loss = 0.476327 (* 1 = 0.476327 loss)
I0417 10:57:07.221580 22508 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0417 10:57:29.055702 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:57:29.272544 22508 solver.cpp:219] Iteration 8200 (4.53504 iter/s, 22.0505s/100 iters), loss = 0.356974
I0417 10:57:29.272568 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0417 10:57:29.272574 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:57:29.272580 22508 solver.cpp:238]     Train net output #2: loss = 0.356974 (* 1 = 0.356974 loss)
I0417 10:57:29.272584 22508 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0417 10:57:51.345945 22508 solver.cpp:219] Iteration 8300 (4.53045 iter/s, 22.0729s/100 iters), loss = 0.45217
I0417 10:57:51.345996 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0417 10:57:51.346004 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:57:51.346010 22508 solver.cpp:238]     Train net output #2: loss = 0.45217 (* 1 = 0.45217 loss)
I0417 10:57:51.346014 22508 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0417 10:58:13.405012 22508 solver.cpp:219] Iteration 8400 (4.5334 iter/s, 22.0585s/100 iters), loss = 0.443174
I0417 10:58:13.405246 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0417 10:58:13.405254 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:58:13.405261 22508 solver.cpp:238]     Train net output #2: loss = 0.443174 (* 1 = 0.443174 loss)
I0417 10:58:13.405267 22508 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0417 10:58:35.432798 22508 solver.cpp:219] Iteration 8500 (4.53987 iter/s, 22.0271s/100 iters), loss = 0.425201
I0417 10:58:35.432838 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0417 10:58:35.432843 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 10:58:35.432850 22508 solver.cpp:238]     Train net output #2: loss = 0.425201 (* 1 = 0.425201 loss)
I0417 10:58:35.432854 22508 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0417 10:58:54.994839 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 10:58:57.401285 22508 solver.cpp:219] Iteration 8600 (4.55209 iter/s, 21.968s/100 iters), loss = 0.443798
I0417 10:58:57.401317 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0417 10:58:57.401322 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:58:57.401329 22508 solver.cpp:238]     Train net output #2: loss = 0.443798 (* 1 = 0.443798 loss)
I0417 10:58:57.401334 22508 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0417 10:59:19.436061 22508 solver.cpp:219] Iteration 8700 (4.53839 iter/s, 22.0342s/100 iters), loss = 0.323782
I0417 10:59:19.436100 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 10:59:19.436105 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 10:59:19.436111 22508 solver.cpp:238]     Train net output #2: loss = 0.323782 (* 1 = 0.323782 loss)
I0417 10:59:19.436116 22508 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0417 10:59:41.447000 22508 solver.cpp:219] Iteration 8800 (4.54331 iter/s, 22.0104s/100 iters), loss = 0.265398
I0417 10:59:41.447724 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 10:59:41.447733 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 10:59:41.447741 22508 solver.cpp:238]     Train net output #2: loss = 0.265398 (* 1 = 0.265398 loss)
I0417 10:59:41.447744 22508 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0417 11:00:03.492362 22508 solver.cpp:219] Iteration 8900 (4.53635 iter/s, 22.0441s/100 iters), loss = 0.389084
I0417 11:00:03.492403 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0417 11:00:03.492413 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:00:03.492421 22508 solver.cpp:238]     Train net output #2: loss = 0.389084 (* 1 = 0.389084 loss)
I0417 11:00:03.492429 22508 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0417 11:00:21.123770 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:00:25.286978 22508 solver.cpp:331] Iteration 9000, Testing net (#0)
I0417 11:00:28.229471 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:00:28.350430 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.1959
I0417 11:00:28.350450 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.7261
I0417 11:00:28.350456 22508 solver.cpp:398]     Test net output #2: loss = 4.23125 (* 1 = 4.23125 loss)
I0417 11:00:28.568768 22508 solver.cpp:219] Iteration 9000 (3.98791 iter/s, 25.0758s/100 iters), loss = 0.438829
I0417 11:00:28.568789 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0417 11:00:28.568794 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:00:28.568800 22508 solver.cpp:238]     Train net output #2: loss = 0.438829 (* 1 = 0.438829 loss)
I0417 11:00:28.568805 22508 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0417 11:00:50.535828 22508 solver.cpp:219] Iteration 9100 (4.55238 iter/s, 21.9665s/100 iters), loss = 0.343884
I0417 11:00:50.535866 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:00:50.535871 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:00:50.535877 22508 solver.cpp:238]     Train net output #2: loss = 0.343884 (* 1 = 0.343884 loss)
I0417 11:00:50.535882 22508 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0417 11:01:12.531286 22508 solver.cpp:219] Iteration 9200 (4.5465 iter/s, 21.9949s/100 iters), loss = 0.256065
I0417 11:01:12.531435 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:01:12.531442 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:01:12.531450 22508 solver.cpp:238]     Train net output #2: loss = 0.256065 (* 1 = 0.256065 loss)
I0417 11:01:12.531455 22508 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0417 11:01:34.498517 22508 solver.cpp:219] Iteration 9300 (4.55237 iter/s, 21.9666s/100 iters), loss = 0.363723
I0417 11:01:34.499102 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 11:01:34.499109 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:01:34.499116 22508 solver.cpp:238]     Train net output #2: loss = 0.363723 (* 1 = 0.363723 loss)
I0417 11:01:34.499120 22508 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0417 11:01:49.853761 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:01:56.450647 22508 solver.cpp:219] Iteration 9400 (4.55559 iter/s, 21.9511s/100 iters), loss = 0.372635
I0417 11:01:56.450681 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0417 11:01:56.450686 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:01:56.450695 22508 solver.cpp:238]     Train net output #2: loss = 0.372635 (* 1 = 0.372635 loss)
I0417 11:01:56.450700 22508 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0417 11:02:18.479208 22508 solver.cpp:219] Iteration 9500 (4.53967 iter/s, 22.028s/100 iters), loss = 0.379234
I0417 11:02:18.479647 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 11:02:18.479655 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:02:18.479661 22508 solver.cpp:238]     Train net output #2: loss = 0.379234 (* 1 = 0.379234 loss)
I0417 11:02:18.479665 22508 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0417 11:02:40.527586 22508 solver.cpp:219] Iteration 9600 (4.53567 iter/s, 22.0474s/100 iters), loss = 0.23623
I0417 11:02:40.527741 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 11:02:40.527750 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:02:40.527756 22508 solver.cpp:238]     Train net output #2: loss = 0.23623 (* 1 = 0.23623 loss)
I0417 11:02:40.527761 22508 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0417 11:03:02.527207 22508 solver.cpp:219] Iteration 9700 (4.54567 iter/s, 21.999s/100 iters), loss = 0.391313
I0417 11:03:02.527261 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0417 11:03:02.527267 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:03:02.527274 22508 solver.cpp:238]     Train net output #2: loss = 0.391313 (* 1 = 0.391313 loss)
I0417 11:03:02.527279 22508 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0417 11:03:15.994408 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:03:24.602767 22508 solver.cpp:219] Iteration 9800 (4.53001 iter/s, 22.075s/100 iters), loss = 0.454519
I0417 11:03:24.602809 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0417 11:03:24.602816 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:03:24.602823 22508 solver.cpp:238]     Train net output #2: loss = 0.454519 (* 1 = 0.454519 loss)
I0417 11:03:24.602828 22508 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0417 11:03:46.664527 22508 solver.cpp:219] Iteration 9900 (4.53284 iter/s, 22.0612s/100 iters), loss = 0.413364
I0417 11:03:46.665163 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0417 11:03:46.665179 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:03:46.665186 22508 solver.cpp:238]     Train net output #2: loss = 0.413364 (* 1 = 0.413364 loss)
I0417 11:03:46.665191 22508 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0417 11:04:08.640939 22508 solver.cpp:448] Snapshotting to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_10000.caffemodel
I0417 11:04:08.651311 22508 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_10000.solverstate
I0417 11:04:08.653360 22508 solver.cpp:331] Iteration 10000, Testing net (#0)
I0417 11:04:11.595453 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:04:11.716305 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.5612
I0417 11:04:11.716326 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.8916
I0417 11:04:11.716333 22508 solver.cpp:398]     Test net output #2: loss = 1.84836 (* 1 = 1.84836 loss)
I0417 11:04:11.934466 22508 solver.cpp:219] Iteration 10000 (3.95746 iter/s, 25.2688s/100 iters), loss = 0.318951
I0417 11:04:11.934489 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0417 11:04:11.934494 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:04:11.934499 22508 solver.cpp:238]     Train net output #2: loss = 0.318951 (* 1 = 0.318951 loss)
I0417 11:04:11.934504 22508 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0417 11:04:33.871670 22508 solver.cpp:219] Iteration 10100 (4.55857 iter/s, 21.9367s/100 iters), loss = 0.343285
I0417 11:04:33.871839 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:04:33.871846 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:04:33.871853 22508 solver.cpp:238]     Train net output #2: loss = 0.343285 (* 1 = 0.343285 loss)
I0417 11:04:33.871857 22508 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0417 11:04:45.264179 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:04:55.779768 22508 solver.cpp:219] Iteration 10200 (4.56466 iter/s, 21.9075s/100 iters), loss = 0.36027
I0417 11:04:55.779817 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:04:55.779825 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:04:55.779832 22508 solver.cpp:238]     Train net output #2: loss = 0.36027 (* 1 = 0.36027 loss)
I0417 11:04:55.779836 22508 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0417 11:05:17.705075 22508 solver.cpp:219] Iteration 10300 (4.56105 iter/s, 21.9248s/100 iters), loss = 0.418955
I0417 11:05:17.705736 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0417 11:05:17.705745 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:05:17.705751 22508 solver.cpp:238]     Train net output #2: loss = 0.418955 (* 1 = 0.418955 loss)
I0417 11:05:17.705755 22508 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0417 11:05:39.602964 22508 solver.cpp:219] Iteration 10400 (4.56689 iter/s, 21.8967s/100 iters), loss = 0.234161
I0417 11:05:39.603013 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:05:39.603018 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:05:39.603025 22508 solver.cpp:238]     Train net output #2: loss = 0.234161 (* 1 = 0.234161 loss)
I0417 11:05:39.603030 22508 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0417 11:06:01.592597 22508 solver.cpp:219] Iteration 10500 (4.54771 iter/s, 21.9891s/100 iters), loss = 0.329351
I0417 11:06:01.592710 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 11:06:01.592718 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:06:01.592725 22508 solver.cpp:238]     Train net output #2: loss = 0.329351 (* 1 = 0.329351 loss)
I0417 11:06:01.592730 22508 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0417 11:06:10.840209 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:06:23.603925 22508 solver.cpp:219] Iteration 10600 (4.54324 iter/s, 22.0107s/100 iters), loss = 0.35169
I0417 11:06:23.603976 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0417 11:06:23.603981 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:06:23.603988 22508 solver.cpp:238]     Train net output #2: loss = 0.35169 (* 1 = 0.35169 loss)
I0417 11:06:23.603993 22508 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0417 11:06:45.643949 22508 solver.cpp:219] Iteration 10700 (4.53731 iter/s, 22.0395s/100 iters), loss = 0.269188
I0417 11:06:45.644114 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:06:45.644124 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:06:45.644130 22508 solver.cpp:238]     Train net output #2: loss = 0.269188 (* 1 = 0.269188 loss)
I0417 11:06:45.644135 22508 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0417 11:07:07.674973 22508 solver.cpp:219] Iteration 10800 (4.53919 iter/s, 22.0304s/100 iters), loss = 0.318973
I0417 11:07:07.675009 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:07:07.675014 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:07:07.675020 22508 solver.cpp:238]     Train net output #2: loss = 0.318973 (* 1 = 0.318973 loss)
I0417 11:07:07.675025 22508 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0417 11:07:29.670575 22508 solver.cpp:219] Iteration 10900 (4.54647 iter/s, 21.9951s/100 iters), loss = 0.401147
I0417 11:07:29.671177 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0417 11:07:29.671188 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:07:29.671195 22508 solver.cpp:238]     Train net output #2: loss = 0.401147 (* 1 = 0.401147 loss)
I0417 11:07:29.671200 22508 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0417 11:07:36.948458 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:07:51.482884 22508 solver.cpp:331] Iteration 11000, Testing net (#0)
I0417 11:07:54.420194 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:07:54.540668 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.5902
I0417 11:07:54.540695 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9321
I0417 11:07:54.540714 22508 solver.cpp:398]     Test net output #2: loss = 1.6095 (* 1 = 1.6095 loss)
I0417 11:07:54.758041 22508 solver.cpp:219] Iteration 11000 (3.98624 iter/s, 25.0863s/100 iters), loss = 0.331514
I0417 11:07:54.758065 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 11:07:54.758071 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:07:54.758077 22508 solver.cpp:238]     Train net output #2: loss = 0.331514 (* 1 = 0.331514 loss)
I0417 11:07:54.758085 22508 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0417 11:08:16.839277 22508 solver.cpp:219] Iteration 11100 (4.52884 iter/s, 22.0807s/100 iters), loss = 0.273791
I0417 11:08:16.839776 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:08:16.839783 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:08:16.839790 22508 solver.cpp:238]     Train net output #2: loss = 0.273791 (* 1 = 0.273791 loss)
I0417 11:08:16.839794 22508 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0417 11:08:38.880609 22508 solver.cpp:219] Iteration 11200 (4.53713 iter/s, 22.0403s/100 iters), loss = 0.426832
I0417 11:08:38.880638 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0417 11:08:38.880643 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 11:08:38.880650 22508 solver.cpp:238]     Train net output #2: loss = 0.426832 (* 1 = 0.426832 loss)
I0417 11:08:38.880653 22508 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0417 11:09:00.897311 22508 solver.cpp:219] Iteration 11300 (4.54211 iter/s, 22.0162s/100 iters), loss = 0.297757
I0417 11:09:00.897433 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:09:00.897441 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:09:00.897449 22508 solver.cpp:238]     Train net output #2: loss = 0.297757 (* 1 = 0.297757 loss)
I0417 11:09:00.897454 22508 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0417 11:09:06.173264 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:09:22.926863 22508 solver.cpp:219] Iteration 11400 (4.53948 iter/s, 22.0289s/100 iters), loss = 0.31296
I0417 11:09:22.926903 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:09:22.926913 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:09:22.926921 22508 solver.cpp:238]     Train net output #2: loss = 0.31296 (* 1 = 0.31296 loss)
I0417 11:09:22.926928 22508 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0417 11:09:44.914438 22508 solver.cpp:219] Iteration 11500 (4.54813 iter/s, 21.987s/100 iters), loss = 0.160824
I0417 11:09:44.914608 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:09:44.914616 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:09:44.914623 22508 solver.cpp:238]     Train net output #2: loss = 0.160824 (* 1 = 0.160824 loss)
I0417 11:09:44.914628 22508 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0417 11:10:06.886672 22508 solver.cpp:219] Iteration 11600 (4.55134 iter/s, 21.9716s/100 iters), loss = 0.288951
I0417 11:10:06.887123 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:10:06.887133 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:10:06.887142 22508 solver.cpp:238]     Train net output #2: loss = 0.288951 (* 1 = 0.288951 loss)
I0417 11:10:06.887148 22508 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0417 11:10:28.843932 22508 solver.cpp:219] Iteration 11700 (4.5545 iter/s, 21.9563s/100 iters), loss = 0.367827
I0417 11:10:28.844071 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:10:28.844079 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:10:28.844087 22508 solver.cpp:238]     Train net output #2: loss = 0.367827 (* 1 = 0.367827 loss)
I0417 11:10:28.844091 22508 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0417 11:10:31.938062 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:10:50.830327 22508 solver.cpp:219] Iteration 11800 (4.5484 iter/s, 21.9858s/100 iters), loss = 0.332707
I0417 11:10:50.830366 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 11:10:50.830373 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:10:50.830379 22508 solver.cpp:238]     Train net output #2: loss = 0.332707 (* 1 = 0.332707 loss)
I0417 11:10:50.830382 22508 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0417 11:11:12.749474 22508 solver.cpp:219] Iteration 11900 (4.56233 iter/s, 21.9186s/100 iters), loss = 0.237127
I0417 11:11:12.749611 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:11:12.749619 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:11:12.749625 22508 solver.cpp:238]     Train net output #2: loss = 0.237127 (* 1 = 0.237127 loss)
I0417 11:11:12.749630 22508 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0417 11:11:34.461802 22508 solver.cpp:331] Iteration 12000, Testing net (#0)
I0417 11:11:37.403082 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:11:37.523524 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.2489
I0417 11:11:37.523548 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.7604
I0417 11:11:37.523568 22508 solver.cpp:398]     Test net output #2: loss = 4.10827 (* 1 = 4.10827 loss)
I0417 11:11:37.741858 22508 solver.cpp:219] Iteration 12000 (4.00133 iter/s, 24.9917s/100 iters), loss = 0.245369
I0417 11:11:37.741878 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:11:37.741883 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:11:37.741888 22508 solver.cpp:238]     Train net output #2: loss = 0.245369 (* 1 = 0.245369 loss)
I0417 11:11:37.741894 22508 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0417 11:11:59.679069 22508 solver.cpp:219] Iteration 12100 (4.55857 iter/s, 21.9367s/100 iters), loss = 0.342423
I0417 11:11:59.679250 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 11:11:59.679260 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:11:59.679266 22508 solver.cpp:238]     Train net output #2: loss = 0.342423 (* 1 = 0.342423 loss)
I0417 11:11:59.679271 22508 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0417 11:12:00.785054 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:12:21.661289 22508 solver.cpp:219] Iteration 12200 (4.54927 iter/s, 21.9815s/100 iters), loss = 0.356439
I0417 11:12:21.661854 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:12:21.661860 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 11:12:21.661867 22508 solver.cpp:238]     Train net output #2: loss = 0.356439 (* 1 = 0.356439 loss)
I0417 11:12:21.661872 22508 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0417 11:12:43.627321 22508 solver.cpp:219] Iteration 12300 (4.5527 iter/s, 21.965s/100 iters), loss = 0.452203
I0417 11:12:43.627461 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0417 11:12:43.627470 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:12:43.627475 22508 solver.cpp:238]     Train net output #2: loss = 0.452203 (* 1 = 0.452203 loss)
I0417 11:12:43.627480 22508 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0417 11:13:05.655058 22508 solver.cpp:219] Iteration 12400 (4.53986 iter/s, 22.0271s/100 iters), loss = 0.30879
I0417 11:13:05.655110 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:13:05.655117 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:13:05.655123 22508 solver.cpp:238]     Train net output #2: loss = 0.30879 (* 1 = 0.30879 loss)
I0417 11:13:05.655128 22508 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0417 11:13:26.594815 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:13:27.694679 22508 solver.cpp:219] Iteration 12500 (4.5374 iter/s, 22.0391s/100 iters), loss = 0.330115
I0417 11:13:27.694717 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:13:27.694723 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:13:27.694730 22508 solver.cpp:238]     Train net output #2: loss = 0.330115 (* 1 = 0.330115 loss)
I0417 11:13:27.694736 22508 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0417 11:13:49.804692 22508 solver.cpp:219] Iteration 12600 (4.52295 iter/s, 22.1095s/100 iters), loss = 0.362689
I0417 11:13:49.804730 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0417 11:13:49.804736 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:13:49.804744 22508 solver.cpp:238]     Train net output #2: loss = 0.362689 (* 1 = 0.362689 loss)
I0417 11:13:49.804749 22508 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0417 11:14:11.863327 22508 solver.cpp:219] Iteration 12700 (4.53348 iter/s, 22.0581s/100 iters), loss = 0.432646
I0417 11:14:11.864014 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0417 11:14:11.864024 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:14:11.864032 22508 solver.cpp:238]     Train net output #2: loss = 0.432646 (* 1 = 0.432646 loss)
I0417 11:14:11.864035 22508 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0417 11:14:33.928254 22508 solver.cpp:219] Iteration 12800 (4.53232 iter/s, 22.0637s/100 iters), loss = 0.253872
I0417 11:14:33.928292 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:14:33.928297 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:14:33.928304 22508 solver.cpp:238]     Train net output #2: loss = 0.253872 (* 1 = 0.253872 loss)
I0417 11:14:33.928308 22508 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0417 11:14:52.872176 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:14:55.955005 22508 solver.cpp:219] Iteration 12900 (4.54004 iter/s, 22.0262s/100 iters), loss = 0.282717
I0417 11:14:55.955042 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:14:55.955047 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:14:55.955054 22508 solver.cpp:238]     Train net output #2: loss = 0.282717 (* 1 = 0.282717 loss)
I0417 11:14:55.955059 22508 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0417 11:15:17.795444 22508 solver.cpp:331] Iteration 13000, Testing net (#0)
I0417 11:15:20.738718 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:15:20.859299 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.6153
I0417 11:15:20.859328 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9527
I0417 11:15:20.859346 22508 solver.cpp:398]     Test net output #2: loss = 1.33858 (* 1 = 1.33858 loss)
I0417 11:15:21.077756 22508 solver.cpp:219] Iteration 13000 (3.98055 iter/s, 25.1222s/100 iters), loss = 0.324302
I0417 11:15:21.077788 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0417 11:15:21.077793 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:15:21.077800 22508 solver.cpp:238]     Train net output #2: loss = 0.324302 (* 1 = 0.324302 loss)
I0417 11:15:21.077805 22508 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0417 11:15:43.061291 22508 solver.cpp:219] Iteration 13100 (4.54897 iter/s, 21.983s/100 iters), loss = 0.391661
I0417 11:15:43.061439 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.835938
I0417 11:15:43.061447 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:15:43.061455 22508 solver.cpp:238]     Train net output #2: loss = 0.391661 (* 1 = 0.391661 loss)
I0417 11:15:43.061460 22508 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0417 11:16:05.090276 22508 solver.cpp:219] Iteration 13200 (4.53961 iter/s, 22.0283s/100 iters), loss = 0.31761
I0417 11:16:05.090313 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 11:16:05.090319 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:16:05.090325 22508 solver.cpp:238]     Train net output #2: loss = 0.31761 (* 1 = 0.31761 loss)
I0417 11:16:05.090330 22508 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0417 11:16:22.044304 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:16:27.104220 22508 solver.cpp:219] Iteration 13300 (4.54268 iter/s, 22.0134s/100 iters), loss = 0.216894
I0417 11:16:27.104255 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:16:27.104264 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:16:27.104274 22508 solver.cpp:238]     Train net output #2: loss = 0.216894 (* 1 = 0.216894 loss)
I0417 11:16:27.104279 22508 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0417 11:16:49.119727 22508 solver.cpp:219] Iteration 13400 (4.54236 iter/s, 22.015s/100 iters), loss = 0.361201
I0417 11:16:49.119777 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 11:16:49.119783 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:16:49.119791 22508 solver.cpp:238]     Train net output #2: loss = 0.361201 (* 1 = 0.361201 loss)
I0417 11:16:49.119794 22508 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0417 11:17:11.119892 22508 solver.cpp:219] Iteration 13500 (4.54553 iter/s, 21.9996s/100 iters), loss = 0.224606
I0417 11:17:11.119992 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:17:11.119999 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:17:11.120007 22508 solver.cpp:238]     Train net output #2: loss = 0.224606 (* 1 = 0.224606 loss)
I0417 11:17:11.120010 22508 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0417 11:17:33.104077 22508 solver.cpp:219] Iteration 13600 (4.54885 iter/s, 21.9836s/100 iters), loss = 0.324215
I0417 11:17:33.104681 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0417 11:17:33.104688 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:17:33.104694 22508 solver.cpp:238]     Train net output #2: loss = 0.324215 (* 1 = 0.324215 loss)
I0417 11:17:33.104699 22508 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0417 11:17:47.807410 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:17:55.022433 22508 solver.cpp:219] Iteration 13700 (4.56261 iter/s, 21.9173s/100 iters), loss = 0.296668
I0417 11:17:55.022471 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:17:55.022477 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:17:55.022483 22508 solver.cpp:238]     Train net output #2: loss = 0.296668 (* 1 = 0.296668 loss)
I0417 11:17:55.022487 22508 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0417 11:18:16.984364 22508 solver.cpp:219] Iteration 13800 (4.55344 iter/s, 21.9614s/100 iters), loss = 0.288483
I0417 11:18:16.984410 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:18:16.984416 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:18:16.984422 22508 solver.cpp:238]     Train net output #2: loss = 0.288483 (* 1 = 0.288483 loss)
I0417 11:18:16.984427 22508 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0417 11:18:38.921736 22508 solver.cpp:219] Iteration 13900 (4.55854 iter/s, 21.9368s/100 iters), loss = 0.198108
I0417 11:18:38.921881 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:18:38.921890 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:18:38.921896 22508 solver.cpp:238]     Train net output #2: loss = 0.198108 (* 1 = 0.198108 loss)
I0417 11:18:38.921900 22508 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0417 11:19:00.658779 22508 solver.cpp:331] Iteration 14000, Testing net (#0)
I0417 11:19:03.595634 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:19:03.716377 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.5571
I0417 11:19:03.716400 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9576
I0417 11:19:03.716420 22508 solver.cpp:398]     Test net output #2: loss = 2.34053 (* 1 = 2.34053 loss)
I0417 11:19:03.934980 22508 solver.cpp:219] Iteration 14000 (3.99799 iter/s, 25.0125s/100 iters), loss = 0.172073
I0417 11:19:03.935001 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 11:19:03.935006 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:19:03.935012 22508 solver.cpp:238]     Train net output #2: loss = 0.172073 (* 1 = 0.172073 loss)
I0417 11:19:03.935019 22508 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0417 11:19:16.720005 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:19:25.928905 22508 solver.cpp:219] Iteration 14100 (4.54682 iter/s, 21.9934s/100 iters), loss = 0.284078
I0417 11:19:25.928946 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:19:25.928954 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:19:25.928963 22508 solver.cpp:238]     Train net output #2: loss = 0.284078 (* 1 = 0.284078 loss)
I0417 11:19:25.928969 22508 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0417 11:19:47.850268 22508 solver.cpp:219] Iteration 14200 (4.56187 iter/s, 21.9208s/100 iters), loss = 0.313876
I0417 11:19:47.850383 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:19:47.850390 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:19:47.850397 22508 solver.cpp:238]     Train net output #2: loss = 0.313876 (* 1 = 0.313876 loss)
I0417 11:19:47.850402 22508 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0417 11:20:09.809610 22508 solver.cpp:219] Iteration 14300 (4.554 iter/s, 21.9587s/100 iters), loss = 0.240506
I0417 11:20:09.810158 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:20:09.810164 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:20:09.810174 22508 solver.cpp:238]     Train net output #2: loss = 0.240506 (* 1 = 0.240506 loss)
I0417 11:20:09.810179 22508 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0417 11:20:31.757571 22508 solver.cpp:219] Iteration 14400 (4.55645 iter/s, 21.9469s/100 iters), loss = 0.402042
I0417 11:20:31.757700 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0417 11:20:31.757709 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:20:31.757714 22508 solver.cpp:238]     Train net output #2: loss = 0.402042 (* 1 = 0.402042 loss)
I0417 11:20:31.757719 22508 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0417 11:20:42.508569 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:20:53.683408 22508 solver.cpp:219] Iteration 14500 (4.56096 iter/s, 21.9252s/100 iters), loss = 0.293689
I0417 11:20:53.683457 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 11:20:53.683465 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:20:53.683471 22508 solver.cpp:238]     Train net output #2: loss = 0.293689 (* 1 = 0.293689 loss)
I0417 11:20:53.683475 22508 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0417 11:21:15.624797 22508 solver.cpp:219] Iteration 14600 (4.55771 iter/s, 21.9408s/100 iters), loss = 0.166386
I0417 11:21:15.624964 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 11:21:15.624974 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:21:15.624980 22508 solver.cpp:238]     Train net output #2: loss = 0.166386 (* 1 = 0.166386 loss)
I0417 11:21:15.624984 22508 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0417 11:21:37.538678 22508 solver.cpp:219] Iteration 14700 (4.56345 iter/s, 21.9132s/100 iters), loss = 0.255897
I0417 11:21:37.538710 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:21:37.538715 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:21:37.538722 22508 solver.cpp:238]     Train net output #2: loss = 0.255897 (* 1 = 0.255897 loss)
I0417 11:21:37.538727 22508 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0417 11:21:59.502146 22508 solver.cpp:219] Iteration 14800 (4.55312 iter/s, 21.9629s/100 iters), loss = 0.273358
I0417 11:21:59.502262 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:21:59.502271 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 11:21:59.502279 22508 solver.cpp:238]     Train net output #2: loss = 0.273358 (* 1 = 0.273358 loss)
I0417 11:21:59.502282 22508 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0417 11:22:08.062518 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:22:21.438305 22508 solver.cpp:219] Iteration 14900 (4.55881 iter/s, 21.9356s/100 iters), loss = 0.230096
I0417 11:22:21.438343 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:22:21.438349 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:22:21.438354 22508 solver.cpp:238]     Train net output #2: loss = 0.230096 (* 1 = 0.230096 loss)
I0417 11:22:21.438359 22508 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0417 11:22:43.285377 22508 solver.cpp:331] Iteration 15000, Testing net (#0)
I0417 11:22:46.225642 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:22:46.346192 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.2255
I0417 11:22:46.346218 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.8175
I0417 11:22:46.346226 22508 solver.cpp:398]     Test net output #2: loss = 3.71992 (* 1 = 3.71992 loss)
I0417 11:22:46.565127 22508 solver.cpp:219] Iteration 15000 (3.9799 iter/s, 25.1262s/100 iters), loss = 0.347355
I0417 11:22:46.565148 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:22:46.565153 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:22:46.565158 22508 solver.cpp:238]     Train net output #2: loss = 0.347355 (* 1 = 0.347355 loss)
I0417 11:22:46.565165 22508 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0417 11:23:08.619792 22508 solver.cpp:219] Iteration 15100 (4.53429 iter/s, 22.0541s/100 iters), loss = 0.427054
I0417 11:23:08.619844 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0417 11:23:08.619851 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:23:08.619859 22508 solver.cpp:238]     Train net output #2: loss = 0.427054 (* 1 = 0.427054 loss)
I0417 11:23:08.619865 22508 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0417 11:23:30.643870 22508 solver.cpp:219] Iteration 15200 (4.5406 iter/s, 22.0235s/100 iters), loss = 0.267083
I0417 11:23:30.644070 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:23:30.644080 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:23:30.644088 22508 solver.cpp:238]     Train net output #2: loss = 0.267083 (* 1 = 0.267083 loss)
I0417 11:23:30.644093 22508 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0417 11:23:37.277611 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:23:52.713816 22508 solver.cpp:219] Iteration 15300 (4.53119 iter/s, 22.0693s/100 iters), loss = 0.284526
I0417 11:23:52.713861 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:23:52.713867 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:23:52.713876 22508 solver.cpp:238]     Train net output #2: loss = 0.284526 (* 1 = 0.284526 loss)
I0417 11:23:52.713881 22508 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0417 11:24:14.739598 22508 solver.cpp:219] Iteration 15400 (4.54025 iter/s, 22.0252s/100 iters), loss = 0.23083
I0417 11:24:14.739751 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:24:14.739759 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:24:14.739766 22508 solver.cpp:238]     Train net output #2: loss = 0.23083 (* 1 = 0.23083 loss)
I0417 11:24:14.739771 22508 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0417 11:24:36.738117 22508 solver.cpp:219] Iteration 15500 (4.54589 iter/s, 21.9979s/100 iters), loss = 0.381372
I0417 11:24:36.738154 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 11:24:36.738160 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:24:36.738169 22508 solver.cpp:238]     Train net output #2: loss = 0.381372 (* 1 = 0.381372 loss)
I0417 11:24:36.738175 22508 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0417 11:24:58.722579 22508 solver.cpp:219] Iteration 15600 (4.54878 iter/s, 21.9839s/100 iters), loss = 0.249982
I0417 11:24:58.722676 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:24:58.722685 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:24:58.722693 22508 solver.cpp:238]     Train net output #2: loss = 0.249982 (* 1 = 0.249982 loss)
I0417 11:24:58.722700 22508 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0417 11:25:03.134045 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:25:20.699379 22508 solver.cpp:219] Iteration 15700 (4.55038 iter/s, 21.9762s/100 iters), loss = 0.242017
I0417 11:25:20.699787 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:25:20.699793 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:25:20.699805 22508 solver.cpp:238]     Train net output #2: loss = 0.242017 (* 1 = 0.242017 loss)
I0417 11:25:20.699810 22508 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0417 11:25:42.640075 22508 solver.cpp:219] Iteration 15800 (4.55793 iter/s, 21.9398s/100 iters), loss = 0.320995
I0417 11:25:42.640236 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:25:42.640244 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:25:42.640252 22508 solver.cpp:238]     Train net output #2: loss = 0.320995 (* 1 = 0.320995 loss)
I0417 11:25:42.640256 22508 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0417 11:26:04.571364 22508 solver.cpp:219] Iteration 15900 (4.55983 iter/s, 21.9306s/100 iters), loss = 0.176674
I0417 11:26:04.571418 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0417 11:26:04.571424 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:26:04.571430 22508 solver.cpp:238]     Train net output #2: loss = 0.176674 (* 1 = 0.176674 loss)
I0417 11:26:04.571435 22508 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0417 11:26:26.399070 22508 solver.cpp:331] Iteration 16000, Testing net (#0)
I0417 11:26:29.340975 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:26:29.461520 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.206
I0417 11:26:29.461547 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.6521
I0417 11:26:29.461567 22508 solver.cpp:398]     Test net output #2: loss = 3.8846 (* 1 = 3.8846 loss)
I0417 11:26:29.679157 22508 solver.cpp:219] Iteration 16000 (3.98292 iter/s, 25.1072s/100 iters), loss = 0.195374
I0417 11:26:29.679180 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 11:26:29.679185 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:26:29.679191 22508 solver.cpp:238]     Train net output #2: loss = 0.195374 (* 1 = 0.195374 loss)
I0417 11:26:29.679198 22508 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0417 11:26:32.104380 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:26:51.716655 22508 solver.cpp:219] Iteration 16100 (4.53783 iter/s, 22.037s/100 iters), loss = 0.267397
I0417 11:26:51.716692 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:26:51.716698 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:26:51.716706 22508 solver.cpp:238]     Train net output #2: loss = 0.267397 (* 1 = 0.267397 loss)
I0417 11:26:51.716711 22508 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0417 11:27:13.776623 22508 solver.cpp:219] Iteration 16200 (4.53321 iter/s, 22.0594s/100 iters), loss = 0.256762
I0417 11:27:13.777214 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:27:13.777223 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:27:13.777230 22508 solver.cpp:238]     Train net output #2: loss = 0.256762 (* 1 = 0.256762 loss)
I0417 11:27:13.777237 22508 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0417 11:27:35.817654 22508 solver.cpp:219] Iteration 16300 (4.53722 iter/s, 22.0399s/100 iters), loss = 0.314696
I0417 11:27:35.817692 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.859375
I0417 11:27:35.817698 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:27:35.817705 22508 solver.cpp:238]     Train net output #2: loss = 0.314696 (* 1 = 0.314696 loss)
I0417 11:27:35.817709 22508 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0417 11:27:57.889760 22508 solver.cpp:219] Iteration 16400 (4.53071 iter/s, 22.0716s/100 iters), loss = 0.225218
I0417 11:27:57.889890 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:27:57.889900 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:27:57.889909 22508 solver.cpp:238]     Train net output #2: loss = 0.225218 (* 1 = 0.225218 loss)
I0417 11:27:57.889912 22508 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0417 11:27:58.338677 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:28:19.896993 22508 solver.cpp:219] Iteration 16500 (4.54409 iter/s, 22.0066s/100 iters), loss = 0.362936
I0417 11:28:19.897034 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0417 11:28:19.897040 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:28:19.897047 22508 solver.cpp:238]     Train net output #2: loss = 0.362936 (* 1 = 0.362936 loss)
I0417 11:28:19.897050 22508 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0417 11:28:41.836069 22508 solver.cpp:219] Iteration 16600 (4.55819 iter/s, 21.9385s/100 iters), loss = 0.25478
I0417 11:28:41.836361 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:28:41.836370 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:28:41.836377 22508 solver.cpp:238]     Train net output #2: loss = 0.25478 (* 1 = 0.25478 loss)
I0417 11:28:41.836381 22508 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0417 11:29:03.779415 22508 solver.cpp:219] Iteration 16700 (4.55735 iter/s, 21.9426s/100 iters), loss = 0.213167
I0417 11:29:03.779456 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:29:03.779461 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:29:03.779469 22508 solver.cpp:238]     Train net output #2: loss = 0.213167 (* 1 = 0.213167 loss)
I0417 11:29:03.779472 22508 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0417 11:29:23.952838 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:29:25.701655 22508 solver.cpp:219] Iteration 16800 (4.56169 iter/s, 21.9217s/100 iters), loss = 0.159042
I0417 11:29:25.701683 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:29:25.701689 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:29:25.701695 22508 solver.cpp:238]     Train net output #2: loss = 0.159042 (* 1 = 0.159042 loss)
I0417 11:29:25.701699 22508 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0417 11:29:47.614683 22508 solver.cpp:219] Iteration 16900 (4.5636 iter/s, 21.9125s/100 iters), loss = 0.238266
I0417 11:29:47.614714 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:29:47.614720 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:29:47.614727 22508 solver.cpp:238]     Train net output #2: loss = 0.238266 (* 1 = 0.238266 loss)
I0417 11:29:47.614730 22508 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0417 11:30:09.467005 22508 solver.cpp:331] Iteration 17000, Testing net (#0)
I0417 11:30:12.414263 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:30:12.535178 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.5614
I0417 11:30:12.535207 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9071
I0417 11:30:12.535226 22508 solver.cpp:398]     Test net output #2: loss = 1.93375 (* 1 = 1.93375 loss)
I0417 11:30:12.753845 22508 solver.cpp:219] Iteration 17000 (3.97795 iter/s, 25.1386s/100 iters), loss = 0.218602
I0417 11:30:12.753878 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:30:12.753885 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:30:12.753890 22508 solver.cpp:238]     Train net output #2: loss = 0.218602 (* 1 = 0.218602 loss)
I0417 11:30:12.753895 22508 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0417 11:30:34.790757 22508 solver.cpp:219] Iteration 17100 (4.53795 iter/s, 22.0364s/100 iters), loss = 0.214253
I0417 11:30:34.791368 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:30:34.791374 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:30:34.791381 22508 solver.cpp:238]     Train net output #2: loss = 0.214253 (* 1 = 0.214253 loss)
I0417 11:30:34.791385 22508 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0417 11:30:53.064662 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:30:56.815721 22508 solver.cpp:219] Iteration 17200 (4.54053 iter/s, 22.0239s/100 iters), loss = 0.281895
I0417 11:30:56.815764 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:30:56.815770 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:30:56.815778 22508 solver.cpp:238]     Train net output #2: loss = 0.281895 (* 1 = 0.281895 loss)
I0417 11:30:56.815781 22508 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0417 11:31:18.864717 22508 solver.cpp:219] Iteration 17300 (4.53546 iter/s, 22.0485s/100 iters), loss = 0.284652
I0417 11:31:18.865241 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:31:18.865248 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 11:31:18.865254 22508 solver.cpp:238]     Train net output #2: loss = 0.284652 (* 1 = 0.284652 loss)
I0417 11:31:18.865259 22508 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0417 11:31:40.921850 22508 solver.cpp:219] Iteration 17400 (4.53389 iter/s, 22.0561s/100 iters), loss = 0.296671
I0417 11:31:40.922546 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:31:40.922555 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:31:40.922562 22508 solver.cpp:238]     Train net output #2: loss = 0.296671 (* 1 = 0.296671 loss)
I0417 11:31:40.922567 22508 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0417 11:32:02.985224 22508 solver.cpp:219] Iteration 17500 (4.53264 iter/s, 22.0622s/100 iters), loss = 0.186368
I0417 11:32:02.985277 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:32:02.985283 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:32:02.985291 22508 solver.cpp:238]     Train net output #2: loss = 0.186368 (* 1 = 0.186368 loss)
I0417 11:32:02.985294 22508 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0417 11:32:19.317960 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:32:25.058907 22508 solver.cpp:219] Iteration 17600 (4.53039 iter/s, 22.0731s/100 iters), loss = 0.222112
I0417 11:32:25.058959 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:32:25.058965 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:32:25.058972 22508 solver.cpp:238]     Train net output #2: loss = 0.222112 (* 1 = 0.222112 loss)
I0417 11:32:25.058976 22508 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0417 11:32:47.135646 22508 solver.cpp:219] Iteration 17700 (4.52977 iter/s, 22.0762s/100 iters), loss = 0.350674
I0417 11:32:47.135679 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:32:47.135684 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:32:47.135690 22508 solver.cpp:238]     Train net output #2: loss = 0.350674 (* 1 = 0.350674 loss)
I0417 11:32:47.135694 22508 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0417 11:33:09.142498 22508 solver.cpp:219] Iteration 17800 (4.54415 iter/s, 22.0063s/100 iters), loss = 0.273574
I0417 11:33:09.142627 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:33:09.142634 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:33:09.142642 22508 solver.cpp:238]     Train net output #2: loss = 0.273574 (* 1 = 0.273574 loss)
I0417 11:33:09.142645 22508 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0417 11:33:31.144348 22508 solver.cpp:219] Iteration 17900 (4.5452 iter/s, 22.0012s/100 iters), loss = 0.197209
I0417 11:33:31.144385 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:33:31.144392 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:33:31.144397 22508 solver.cpp:238]     Train net output #2: loss = 0.197209 (* 1 = 0.197209 loss)
I0417 11:33:31.144402 22508 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0417 11:33:45.199074 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:33:52.879969 22508 solver.cpp:331] Iteration 18000, Testing net (#0)
I0417 11:33:55.829815 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:33:55.950996 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.5349
I0417 11:33:55.951022 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9123
I0417 11:33:55.951045 22508 solver.cpp:398]     Test net output #2: loss = 1.88881 (* 1 = 1.88881 loss)
I0417 11:33:56.169194 22508 solver.cpp:219] Iteration 18000 (3.99612 iter/s, 25.0243s/100 iters), loss = 0.315275
I0417 11:33:56.169215 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:33:56.169220 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:33:56.169225 22508 solver.cpp:238]     Train net output #2: loss = 0.315275 (* 1 = 0.315275 loss)
I0417 11:33:56.169231 22508 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0417 11:34:18.142933 22508 solver.cpp:219] Iteration 18100 (4.55099 iter/s, 21.9732s/100 iters), loss = 0.244788
I0417 11:34:18.143059 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:34:18.143069 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:34:18.143076 22508 solver.cpp:238]     Train net output #2: loss = 0.244788 (* 1 = 0.244788 loss)
I0417 11:34:18.143084 22508 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0417 11:34:40.167501 22508 solver.cpp:219] Iteration 18200 (4.54051 iter/s, 22.024s/100 iters), loss = 0.307421
I0417 11:34:40.167537 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:34:40.167543 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:34:40.167551 22508 solver.cpp:238]     Train net output #2: loss = 0.307421 (* 1 = 0.307421 loss)
I0417 11:34:40.167554 22508 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0417 11:35:02.187911 22508 solver.cpp:219] Iteration 18300 (4.54135 iter/s, 22.0199s/100 iters), loss = 0.30093
I0417 11:35:02.188076 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 11:35:02.188084 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:35:02.188091 22508 solver.cpp:238]     Train net output #2: loss = 0.30093 (* 1 = 0.30093 loss)
I0417 11:35:02.188096 22508 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0417 11:35:14.293864 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:35:24.186465 22508 solver.cpp:219] Iteration 18400 (4.54589 iter/s, 21.9979s/100 iters), loss = 0.202054
I0417 11:35:24.186506 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:35:24.186511 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:35:24.186517 22508 solver.cpp:238]     Train net output #2: loss = 0.202054 (* 1 = 0.202054 loss)
I0417 11:35:24.186522 22508 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0417 11:35:46.223592 22508 solver.cpp:219] Iteration 18500 (4.53791 iter/s, 22.0366s/100 iters), loss = 0.249391
I0417 11:35:46.223711 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:35:46.223719 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:35:46.223726 22508 solver.cpp:238]     Train net output #2: loss = 0.249391 (* 1 = 0.249391 loss)
I0417 11:35:46.223731 22508 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0417 11:36:08.246346 22508 solver.cpp:219] Iteration 18600 (4.54088 iter/s, 22.0221s/100 iters), loss = 0.357158
I0417 11:36:08.246384 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 11:36:08.246390 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:36:08.246397 22508 solver.cpp:238]     Train net output #2: loss = 0.357158 (* 1 = 0.357158 loss)
I0417 11:36:08.246402 22508 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0417 11:36:30.277232 22508 solver.cpp:219] Iteration 18700 (4.53919 iter/s, 22.0303s/100 iters), loss = 0.243623
I0417 11:36:30.277391 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:36:30.277400 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:36:30.277407 22508 solver.cpp:238]     Train net output #2: loss = 0.243623 (* 1 = 0.243623 loss)
I0417 11:36:30.277412 22508 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0417 11:36:40.190572 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:36:52.242776 22508 solver.cpp:219] Iteration 18800 (4.55272 iter/s, 21.9649s/100 iters), loss = 0.476519
I0417 11:36:52.242817 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.8125
I0417 11:36:52.242822 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:36:52.242828 22508 solver.cpp:238]     Train net output #2: loss = 0.476519 (* 1 = 0.476519 loss)
I0417 11:36:52.242833 22508 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0417 11:37:14.219532 22508 solver.cpp:219] Iteration 18900 (4.55037 iter/s, 21.9762s/100 iters), loss = 0.218809
I0417 11:37:14.220269 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:37:14.220278 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:37:14.220285 22508 solver.cpp:238]     Train net output #2: loss = 0.218809 (* 1 = 0.218809 loss)
I0417 11:37:14.220290 22508 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0417 11:37:35.977140 22508 solver.cpp:331] Iteration 19000, Testing net (#0)
I0417 11:37:38.918401 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:37:39.038898 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.667
I0417 11:37:39.038924 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9634
I0417 11:37:39.038944 22508 solver.cpp:398]     Test net output #2: loss = 1.28711 (* 1 = 1.28711 loss)
I0417 11:37:39.256705 22508 solver.cpp:219] Iteration 19000 (3.99427 iter/s, 25.0359s/100 iters), loss = 0.217345
I0417 11:37:39.256726 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:37:39.256742 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:37:39.256747 22508 solver.cpp:238]     Train net output #2: loss = 0.217345 (* 1 = 0.217345 loss)
I0417 11:37:39.256753 22508 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0417 11:38:01.217552 22508 solver.cpp:219] Iteration 19100 (4.55367 iter/s, 21.9603s/100 iters), loss = 0.18172
I0417 11:38:01.217713 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 11:38:01.217721 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:38:01.217728 22508 solver.cpp:238]     Train net output #2: loss = 0.18172 (* 1 = 0.18172 loss)
I0417 11:38:01.217733 22508 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0417 11:38:09.106736 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:38:23.144405 22508 solver.cpp:219] Iteration 19200 (4.56075 iter/s, 21.9262s/100 iters), loss = 0.222654
I0417 11:38:23.144444 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:38:23.144449 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:38:23.144456 22508 solver.cpp:238]     Train net output #2: loss = 0.222654 (* 1 = 0.222654 loss)
I0417 11:38:23.144460 22508 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0417 11:38:45.068480 22508 solver.cpp:219] Iteration 19300 (4.56131 iter/s, 21.9235s/100 iters), loss = 0.200252
I0417 11:38:45.068609 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 11:38:45.068616 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:38:45.068624 22508 solver.cpp:238]     Train net output #2: loss = 0.200252 (* 1 = 0.200252 loss)
I0417 11:38:45.068629 22508 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0417 11:39:07.003628 22508 solver.cpp:219] Iteration 19400 (4.55902 iter/s, 21.9345s/100 iters), loss = 0.323325
I0417 11:39:07.003675 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:39:07.003680 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:39:07.003687 22508 solver.cpp:238]     Train net output #2: loss = 0.323325 (* 1 = 0.323325 loss)
I0417 11:39:07.003691 22508 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0417 11:39:28.986871 22508 solver.cpp:219] Iteration 19500 (4.54903 iter/s, 21.9827s/100 iters), loss = 0.343042
I0417 11:39:28.987031 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:39:28.987040 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:39:28.987046 22508 solver.cpp:238]     Train net output #2: loss = 0.343042 (* 1 = 0.343042 loss)
I0417 11:39:28.987051 22508 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0417 11:39:34.929584 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:39:51.020416 22508 solver.cpp:219] Iteration 19600 (4.53867 iter/s, 22.0329s/100 iters), loss = 0.275439
I0417 11:39:51.020455 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:39:51.020462 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:39:51.020467 22508 solver.cpp:238]     Train net output #2: loss = 0.275439 (* 1 = 0.275439 loss)
I0417 11:39:51.020472 22508 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0417 11:40:13.073359 22508 solver.cpp:219] Iteration 19700 (4.53465 iter/s, 22.0524s/100 iters), loss = 0.340774
I0417 11:40:13.074038 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:40:13.074048 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:40:13.074054 22508 solver.cpp:238]     Train net output #2: loss = 0.340774 (* 1 = 0.340774 loss)
I0417 11:40:13.074059 22508 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0417 11:40:35.125254 22508 solver.cpp:219] Iteration 19800 (4.535 iter/s, 22.0507s/100 iters), loss = 0.229139
I0417 11:40:35.125294 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:40:35.125301 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:40:35.125308 22508 solver.cpp:238]     Train net output #2: loss = 0.229139 (* 1 = 0.229139 loss)
I0417 11:40:35.125311 22508 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0417 11:40:57.155153 22508 solver.cpp:219] Iteration 19900 (4.5394 iter/s, 22.0294s/100 iters), loss = 0.159639
I0417 11:40:57.155336 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 11:40:57.155345 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:40:57.155352 22508 solver.cpp:238]     Train net output #2: loss = 0.159639 (* 1 = 0.159639 loss)
I0417 11:40:57.155357 22508 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0417 11:41:00.914468 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:41:19.033982 22508 solver.cpp:448] Snapshotting to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_20000.caffemodel
I0417 11:41:19.041501 22508 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_20000.solverstate
I0417 11:41:19.043484 22508 solver.cpp:331] Iteration 20000, Testing net (#0)
I0417 11:41:21.986683 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:41:22.107625 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.2112
I0417 11:41:22.107652 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.5133
I0417 11:41:22.107672 22508 solver.cpp:398]     Test net output #2: loss = 8.02215 (* 1 = 8.02215 loss)
I0417 11:41:22.325402 22508 solver.cpp:219] Iteration 20000 (3.97306 iter/s, 25.1695s/100 iters), loss = 0.26137
I0417 11:41:22.325434 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:41:22.325440 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:41:22.325446 22508 solver.cpp:238]     Train net output #2: loss = 0.26137 (* 1 = 0.26137 loss)
I0417 11:41:22.325454 22508 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0417 11:41:44.367472 22508 solver.cpp:219] Iteration 20100 (4.53688 iter/s, 22.0416s/100 iters), loss = 0.34893
I0417 11:41:44.367616 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.851562
I0417 11:41:44.367625 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:41:44.367631 22508 solver.cpp:238]     Train net output #2: loss = 0.34893 (* 1 = 0.34893 loss)
I0417 11:41:44.367636 22508 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0417 11:42:06.392678 22508 solver.cpp:219] Iteration 20200 (4.54038 iter/s, 22.0246s/100 iters), loss = 0.291969
I0417 11:42:06.392719 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:42:06.392724 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:42:06.392730 22508 solver.cpp:238]     Train net output #2: loss = 0.291969 (* 1 = 0.291969 loss)
I0417 11:42:06.392735 22508 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0417 11:42:28.401767 22508 solver.cpp:219] Iteration 20300 (4.54369 iter/s, 22.0086s/100 iters), loss = 0.167421
I0417 11:42:28.401922 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:42:28.401931 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:42:28.401938 22508 solver.cpp:238]     Train net output #2: loss = 0.167421 (* 1 = 0.167421 loss)
I0417 11:42:28.401942 22508 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0417 11:42:30.167264 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:42:50.419951 22508 solver.cpp:219] Iteration 20400 (4.54183 iter/s, 22.0175s/100 iters), loss = 0.23901
I0417 11:42:50.419986 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:42:50.419991 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:42:50.419997 22508 solver.cpp:238]     Train net output #2: loss = 0.23901 (* 1 = 0.23901 loss)
I0417 11:42:50.420002 22508 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0417 11:43:12.457314 22508 solver.cpp:219] Iteration 20500 (4.53786 iter/s, 22.0368s/100 iters), loss = 0.241712
I0417 11:43:12.457429 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:43:12.457437 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:43:12.457443 22508 solver.cpp:238]     Train net output #2: loss = 0.241712 (* 1 = 0.241712 loss)
I0417 11:43:12.457448 22508 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0417 11:43:34.523969 22508 solver.cpp:219] Iteration 20600 (4.53185 iter/s, 22.066s/100 iters), loss = 0.342503
I0417 11:43:34.524554 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 11:43:34.524561 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:43:34.524567 22508 solver.cpp:238]     Train net output #2: loss = 0.342503 (* 1 = 0.342503 loss)
I0417 11:43:34.524572 22508 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0417 11:43:56.348986 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:43:56.565934 22508 solver.cpp:219] Iteration 20700 (4.53702 iter/s, 22.0409s/100 iters), loss = 0.186722
I0417 11:43:56.565963 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:43:56.565968 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:43:56.565974 22508 solver.cpp:238]     Train net output #2: loss = 0.186722 (* 1 = 0.186722 loss)
I0417 11:43:56.565979 22508 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0417 11:44:18.616976 22508 solver.cpp:219] Iteration 20800 (4.53504 iter/s, 22.0505s/100 iters), loss = 0.24491
I0417 11:44:18.617019 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:44:18.617027 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:44:18.617034 22508 solver.cpp:238]     Train net output #2: loss = 0.24491 (* 1 = 0.24491 loss)
I0417 11:44:18.617038 22508 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0417 11:44:40.660182 22508 solver.cpp:219] Iteration 20900 (4.53666 iter/s, 22.0427s/100 iters), loss = 0.299864
I0417 11:44:40.660343 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:44:40.660352 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:44:40.660359 22508 solver.cpp:238]     Train net output #2: loss = 0.299864 (* 1 = 0.299864 loss)
I0417 11:44:40.660364 22508 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0417 11:45:02.482923 22508 solver.cpp:331] Iteration 21000, Testing net (#0)
I0417 11:45:05.435061 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:45:05.556293 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.1567
I0417 11:45:05.556320 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.6533
I0417 11:45:05.556344 22508 solver.cpp:398]     Test net output #2: loss = 4.51235 (* 1 = 4.51235 loss)
I0417 11:45:05.774698 22508 solver.cpp:219] Iteration 21000 (3.98187 iter/s, 25.1138s/100 iters), loss = 0.283596
I0417 11:45:05.774734 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:45:05.774740 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:45:05.774746 22508 solver.cpp:238]     Train net output #2: loss = 0.283596 (* 1 = 0.283596 loss)
I0417 11:45:05.774754 22508 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0417 11:45:25.398712 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:45:27.825042 22508 solver.cpp:219] Iteration 21100 (4.53519 iter/s, 22.0498s/100 iters), loss = 0.280275
I0417 11:45:27.825093 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:45:27.825099 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:45:27.825106 22508 solver.cpp:238]     Train net output #2: loss = 0.280275 (* 1 = 0.280275 loss)
I0417 11:45:27.825111 22508 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0417 11:45:49.928264 22508 solver.cpp:219] Iteration 21200 (4.52434 iter/s, 22.1027s/100 iters), loss = 0.298522
I0417 11:45:49.928306 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 11:45:49.928313 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:45:49.928319 22508 solver.cpp:238]     Train net output #2: loss = 0.298522 (* 1 = 0.298522 loss)
I0417 11:45:49.928323 22508 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0417 11:46:11.956769 22508 solver.cpp:219] Iteration 21300 (4.53968 iter/s, 22.028s/100 iters), loss = 0.20538
I0417 11:46:11.956929 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:46:11.956938 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 11:46:11.956944 22508 solver.cpp:238]     Train net output #2: loss = 0.20538 (* 1 = 0.20538 loss)
I0417 11:46:11.956949 22508 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0417 11:46:34.004781 22508 solver.cpp:219] Iteration 21400 (4.53569 iter/s, 22.0474s/100 iters), loss = 0.209497
I0417 11:46:34.005383 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:46:34.005390 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:46:34.005398 22508 solver.cpp:238]     Train net output #2: loss = 0.209497 (* 1 = 0.209497 loss)
I0417 11:46:34.005401 22508 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0417 11:46:51.584401 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:46:55.983036 22508 solver.cpp:219] Iteration 21500 (4.55018 iter/s, 21.9772s/100 iters), loss = 0.186199
I0417 11:46:55.983075 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:46:55.983081 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:46:55.983088 22508 solver.cpp:238]     Train net output #2: loss = 0.186199 (* 1 = 0.186199 loss)
I0417 11:46:55.983093 22508 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0417 11:47:17.995268 22508 solver.cpp:219] Iteration 21600 (4.54304 iter/s, 22.0117s/100 iters), loss = 0.295542
I0417 11:47:17.995299 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:47:17.995304 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:47:17.995311 22508 solver.cpp:238]     Train net output #2: loss = 0.295542 (* 1 = 0.295542 loss)
I0417 11:47:17.995316 22508 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0417 11:47:39.977216 22508 solver.cpp:219] Iteration 21700 (4.5493 iter/s, 21.9814s/100 iters), loss = 0.145851
I0417 11:47:39.977342 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 11:47:39.977350 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:47:39.977356 22508 solver.cpp:238]     Train net output #2: loss = 0.145851 (* 1 = 0.145851 loss)
I0417 11:47:39.977361 22508 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0417 11:48:01.964699 22508 solver.cpp:219] Iteration 21800 (4.54817 iter/s, 21.9869s/100 iters), loss = 0.225351
I0417 11:48:01.964738 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:48:01.964745 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:48:01.964751 22508 solver.cpp:238]     Train net output #2: loss = 0.225351 (* 1 = 0.225351 loss)
I0417 11:48:01.964754 22508 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0417 11:48:17.365236 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:48:23.960337 22508 solver.cpp:219] Iteration 21900 (4.54647 iter/s, 21.9951s/100 iters), loss = 0.183542
I0417 11:48:23.960376 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 11:48:23.960384 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:48:23.960396 22508 solver.cpp:238]     Train net output #2: loss = 0.183542 (* 1 = 0.183542 loss)
I0417 11:48:23.960403 22508 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0417 11:48:45.706356 22508 solver.cpp:331] Iteration 22000, Testing net (#0)
I0417 11:48:48.645068 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:48:48.765871 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.2194
I0417 11:48:48.765893 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.6833
I0417 11:48:48.765905 22508 solver.cpp:398]     Test net output #2: loss = 4.69411 (* 1 = 4.69411 loss)
I0417 11:48:48.983976 22508 solver.cpp:219] Iteration 22000 (3.99632 iter/s, 25.0231s/100 iters), loss = 0.214065
I0417 11:48:48.983999 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:48:48.984009 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:48:48.984017 22508 solver.cpp:238]     Train net output #2: loss = 0.214065 (* 1 = 0.214065 loss)
I0417 11:48:48.984028 22508 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0417 11:49:10.966228 22508 solver.cpp:219] Iteration 22100 (4.54923 iter/s, 21.9817s/100 iters), loss = 0.157101
I0417 11:49:10.966279 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 11:49:10.966285 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:49:10.966292 22508 solver.cpp:238]     Train net output #2: loss = 0.157101 (* 1 = 0.157101 loss)
I0417 11:49:10.966296 22508 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0417 11:49:32.906785 22508 solver.cpp:219] Iteration 22200 (4.55788 iter/s, 21.94s/100 iters), loss = 0.233956
I0417 11:49:32.907536 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:49:32.907544 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:49:32.907552 22508 solver.cpp:238]     Train net output #2: loss = 0.233956 (* 1 = 0.233956 loss)
I0417 11:49:32.907557 22508 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0417 11:49:46.300484 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:49:54.834213 22508 solver.cpp:219] Iteration 22300 (4.56076 iter/s, 21.9262s/100 iters), loss = 0.22432
I0417 11:49:54.834250 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:49:54.834256 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:49:54.834264 22508 solver.cpp:238]     Train net output #2: loss = 0.22432 (* 1 = 0.22432 loss)
I0417 11:49:54.834269 22508 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0417 11:50:16.782454 22508 solver.cpp:219] Iteration 22400 (4.55628 iter/s, 21.9477s/100 iters), loss = 0.290709
I0417 11:50:16.783051 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:50:16.783061 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:50:16.783067 22508 solver.cpp:238]     Train net output #2: loss = 0.290709 (* 1 = 0.290709 loss)
I0417 11:50:16.783071 22508 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0417 11:50:38.742697 22508 solver.cpp:219] Iteration 22500 (4.55391 iter/s, 21.9592s/100 iters), loss = 0.232636
I0417 11:50:38.742733 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:50:38.742739 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:50:38.742745 22508 solver.cpp:238]     Train net output #2: loss = 0.232636 (* 1 = 0.232636 loss)
I0417 11:50:38.742750 22508 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0417 11:51:00.722558 22508 solver.cpp:219] Iteration 22600 (4.54973 iter/s, 21.9793s/100 iters), loss = 0.149271
I0417 11:51:00.722698 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 11:51:00.722707 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:51:00.722713 22508 solver.cpp:238]     Train net output #2: loss = 0.149271 (* 1 = 0.149271 loss)
I0417 11:51:00.722718 22508 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0417 11:51:12.119242 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:51:22.673379 22508 solver.cpp:219] Iteration 22700 (4.55577 iter/s, 21.9502s/100 iters), loss = 0.256735
I0417 11:51:22.673967 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:51:22.673974 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:51:22.673980 22508 solver.cpp:238]     Train net output #2: loss = 0.256735 (* 1 = 0.256735 loss)
I0417 11:51:22.673985 22508 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0417 11:51:44.725261 22508 solver.cpp:219] Iteration 22800 (4.53498 iter/s, 22.0508s/100 iters), loss = 0.260569
I0417 11:51:44.725400 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 11:51:44.725409 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:51:44.725417 22508 solver.cpp:238]     Train net output #2: loss = 0.260569 (* 1 = 0.260569 loss)
I0417 11:51:44.725421 22508 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0417 11:52:06.806001 22508 solver.cpp:219] Iteration 22900 (4.52896 iter/s, 22.0801s/100 iters), loss = 0.126079
I0417 11:52:06.806036 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 11:52:06.806042 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:52:06.806048 22508 solver.cpp:238]     Train net output #2: loss = 0.126079 (* 1 = 0.126079 loss)
I0417 11:52:06.806052 22508 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0417 11:52:28.637024 22508 solver.cpp:331] Iteration 23000, Testing net (#0)
I0417 11:52:31.575031 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:52:31.695380 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.4471
I0417 11:52:31.695407 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.8545
I0417 11:52:31.695427 22508 solver.cpp:398]     Test net output #2: loss = 2.71287 (* 1 = 2.71287 loss)
I0417 11:52:31.914046 22508 solver.cpp:219] Iteration 23000 (3.98288 iter/s, 25.1075s/100 iters), loss = 0.17323
I0417 11:52:31.914077 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:52:31.914083 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:52:31.914089 22508 solver.cpp:238]     Train net output #2: loss = 0.17323 (* 1 = 0.17323 loss)
I0417 11:52:31.914094 22508 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0417 11:52:41.184295 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:52:53.943375 22508 solver.cpp:219] Iteration 23100 (4.53951 iter/s, 22.0288s/100 iters), loss = 0.208375
I0417 11:52:53.943424 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:52:53.943431 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:52:53.943439 22508 solver.cpp:238]     Train net output #2: loss = 0.208375 (* 1 = 0.208375 loss)
I0417 11:52:53.943442 22508 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0417 11:53:15.997045 22508 solver.cpp:219] Iteration 23200 (4.5345 iter/s, 22.0531s/100 iters), loss = 0.173157
I0417 11:53:15.997766 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:53:15.997776 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:53:15.997783 22508 solver.cpp:238]     Train net output #2: loss = 0.173157 (* 1 = 0.173157 loss)
I0417 11:53:15.997787 22508 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0417 11:53:38.065937 22508 solver.cpp:219] Iteration 23300 (4.53152 iter/s, 22.0677s/100 iters), loss = 0.133276
I0417 11:53:38.065971 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0417 11:53:38.065978 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:53:38.065984 22508 solver.cpp:238]     Train net output #2: loss = 0.133276 (* 1 = 0.133276 loss)
I0417 11:53:38.065989 22508 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0417 11:54:00.090739 22508 solver.cpp:219] Iteration 23400 (4.54045 iter/s, 22.0243s/100 iters), loss = 0.268413
I0417 11:54:00.090860 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:54:00.090869 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:54:00.090876 22508 solver.cpp:238]     Train net output #2: loss = 0.268413 (* 1 = 0.268413 loss)
I0417 11:54:00.090880 22508 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0417 11:54:07.367734 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:54:22.124804 22508 solver.cpp:219] Iteration 23500 (4.53855 iter/s, 22.0335s/100 iters), loss = 0.175343
I0417 11:54:22.124840 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:54:22.124846 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:54:22.124852 22508 solver.cpp:238]     Train net output #2: loss = 0.175343 (* 1 = 0.175343 loss)
I0417 11:54:22.124857 22508 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0417 11:54:44.183065 22508 solver.cpp:219] Iteration 23600 (4.53356 iter/s, 22.0577s/100 iters), loss = 0.169255
I0417 11:54:44.183334 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:54:44.183342 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:54:44.183349 22508 solver.cpp:238]     Train net output #2: loss = 0.169255 (* 1 = 0.169255 loss)
I0417 11:54:44.183353 22508 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0417 11:55:06.257796 22508 solver.cpp:219] Iteration 23700 (4.53022 iter/s, 22.074s/100 iters), loss = 0.190704
I0417 11:55:06.257836 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 11:55:06.257843 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:55:06.257848 22508 solver.cpp:238]     Train net output #2: loss = 0.190704 (* 1 = 0.190704 loss)
I0417 11:55:06.257853 22508 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0417 11:55:28.320122 22508 solver.cpp:219] Iteration 23800 (4.53272 iter/s, 22.0618s/100 iters), loss = 0.234799
I0417 11:55:28.320286 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:55:28.320296 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:55:28.320302 22508 solver.cpp:238]     Train net output #2: loss = 0.234799 (* 1 = 0.234799 loss)
I0417 11:55:28.320307 22508 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0417 11:55:33.608172 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:55:50.362649 22508 solver.cpp:219] Iteration 23900 (4.53682 iter/s, 22.0419s/100 iters), loss = 0.266672
I0417 11:55:50.362689 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:55:50.362694 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:55:50.362701 22508 solver.cpp:238]     Train net output #2: loss = 0.266672 (* 1 = 0.266672 loss)
I0417 11:55:50.362705 22508 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0417 11:56:12.145251 22508 solver.cpp:331] Iteration 24000, Testing net (#0)
I0417 11:56:15.089566 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:56:15.210537 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.1788
I0417 11:56:15.210563 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.5251
I0417 11:56:15.210582 22508 solver.cpp:398]     Test net output #2: loss = 7.08626 (* 1 = 7.08626 loss)
I0417 11:56:15.429280 22508 solver.cpp:219] Iteration 24000 (3.98946 iter/s, 25.066s/100 iters), loss = 0.148346
I0417 11:56:15.429312 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:56:15.429317 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:56:15.429323 22508 solver.cpp:238]     Train net output #2: loss = 0.148346 (* 1 = 0.148346 loss)
I0417 11:56:15.429332 22508 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0417 11:56:37.377236 22508 solver.cpp:219] Iteration 24100 (4.55634 iter/s, 21.9474s/100 iters), loss = 0.165268
I0417 11:56:37.377285 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 11:56:37.377290 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:56:37.377297 22508 solver.cpp:238]     Train net output #2: loss = 0.165268 (* 1 = 0.165268 loss)
I0417 11:56:37.377301 22508 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0417 11:56:59.304589 22508 solver.cpp:219] Iteration 24200 (4.56063 iter/s, 21.9268s/100 iters), loss = 0.256982
I0417 11:56:59.304723 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:56:59.304729 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:56:59.304736 22508 solver.cpp:238]     Train net output #2: loss = 0.256982 (* 1 = 0.256982 loss)
I0417 11:56:59.304741 22508 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0417 11:57:02.373982 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:57:21.254690 22508 solver.cpp:219] Iteration 24300 (4.55592 iter/s, 21.9495s/100 iters), loss = 0.252602
I0417 11:57:21.255273 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 11:57:21.255281 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:57:21.255287 22508 solver.cpp:238]     Train net output #2: loss = 0.252602 (* 1 = 0.252602 loss)
I0417 11:57:21.255292 22508 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0417 11:57:43.252744 22508 solver.cpp:219] Iteration 24400 (4.54608 iter/s, 21.997s/100 iters), loss = 0.13234
I0417 11:57:43.252893 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 11:57:43.252902 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:57:43.252908 22508 solver.cpp:238]     Train net output #2: loss = 0.13234 (* 1 = 0.13234 loss)
I0417 11:57:43.252913 22508 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0417 11:58:05.239100 22508 solver.cpp:219] Iteration 24500 (4.54841 iter/s, 21.9857s/100 iters), loss = 0.250845
I0417 11:58:05.239140 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 11:58:05.239146 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:58:05.239152 22508 solver.cpp:238]     Train net output #2: loss = 0.250845 (* 1 = 0.250845 loss)
I0417 11:58:05.239157 22508 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0417 11:58:27.314069 22508 solver.cpp:219] Iteration 24600 (4.53013 iter/s, 22.0744s/100 iters), loss = 0.175979
I0417 11:58:27.314760 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:58:27.314769 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:58:27.314776 22508 solver.cpp:238]     Train net output #2: loss = 0.175979 (* 1 = 0.175979 loss)
I0417 11:58:27.314780 22508 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0417 11:58:28.422667 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:58:49.364112 22508 solver.cpp:219] Iteration 24700 (4.53538 iter/s, 22.0489s/100 iters), loss = 0.27403
I0417 11:58:49.364161 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 11:58:49.364171 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:58:49.364177 22508 solver.cpp:238]     Train net output #2: loss = 0.27403 (* 1 = 0.27403 loss)
I0417 11:58:49.364182 22508 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0417 11:59:11.442497 22508 solver.cpp:219] Iteration 24800 (4.52943 iter/s, 22.0778s/100 iters), loss = 0.30951
I0417 11:59:11.442621 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:59:11.442629 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 11:59:11.442636 22508 solver.cpp:238]     Train net output #2: loss = 0.30951 (* 1 = 0.30951 loss)
I0417 11:59:11.442641 22508 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0417 11:59:33.428822 22508 solver.cpp:219] Iteration 24900 (4.54841 iter/s, 21.9857s/100 iters), loss = 0.170724
I0417 11:59:33.429237 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 11:59:33.429244 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:59:33.429251 22508 solver.cpp:238]     Train net output #2: loss = 0.170724 (* 1 = 0.170724 loss)
I0417 11:59:33.429255 22508 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0417 11:59:54.297230 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:59:55.170181 22508 solver.cpp:331] Iteration 25000, Testing net (#0)
I0417 11:59:58.110705 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 11:59:58.231021 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.3684
I0417 11:59:58.231046 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.8428
I0417 11:59:58.231066 22508 solver.cpp:398]     Test net output #2: loss = 4.17756 (* 1 = 4.17756 loss)
I0417 11:59:58.449306 22508 solver.cpp:219] Iteration 25000 (3.99688 iter/s, 25.0195s/100 iters), loss = 0.218457
I0417 11:59:58.449339 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 11:59:58.449344 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 11:59:58.449349 22508 solver.cpp:238]     Train net output #2: loss = 0.218456 (* 1 = 0.218456 loss)
I0417 11:59:58.449355 22508 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0417 12:00:20.416132 22508 solver.cpp:219] Iteration 25100 (4.55243 iter/s, 21.9663s/100 iters), loss = 0.212765
I0417 12:00:20.416579 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:00:20.416586 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:00:20.416594 22508 solver.cpp:238]     Train net output #2: loss = 0.212765 (* 1 = 0.212765 loss)
I0417 12:00:20.416597 22508 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0417 12:00:42.369118 22508 solver.cpp:219] Iteration 25200 (4.55538 iter/s, 21.952s/100 iters), loss = 0.256287
I0417 12:00:42.369278 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 12:00:42.369287 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:00:42.369294 22508 solver.cpp:238]     Train net output #2: loss = 0.256287 (* 1 = 0.256287 loss)
I0417 12:00:42.369298 22508 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0417 12:01:04.291523 22508 solver.cpp:219] Iteration 25300 (4.56168 iter/s, 21.9218s/100 iters), loss = 0.134753
I0417 12:01:04.291556 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:01:04.291561 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:01:04.291568 22508 solver.cpp:238]     Train net output #2: loss = 0.134753 (* 1 = 0.134753 loss)
I0417 12:01:04.291573 22508 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0417 12:01:23.175943 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:01:26.255059 22508 solver.cpp:219] Iteration 25400 (4.55311 iter/s, 21.963s/100 iters), loss = 0.228743
I0417 12:01:26.255100 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:01:26.255106 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:01:26.255113 22508 solver.cpp:238]     Train net output #2: loss = 0.228743 (* 1 = 0.228743 loss)
I0417 12:01:26.255118 22508 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0417 12:01:48.192816 22508 solver.cpp:219] Iteration 25500 (4.55846 iter/s, 21.9372s/100 iters), loss = 0.258295
I0417 12:01:48.192850 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 12:01:48.192857 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:01:48.192863 22508 solver.cpp:238]     Train net output #2: loss = 0.258295 (* 1 = 0.258295 loss)
I0417 12:01:48.192867 22508 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0417 12:02:10.283874 22508 solver.cpp:219] Iteration 25600 (4.52683 iter/s, 22.0905s/100 iters), loss = 0.240236
I0417 12:02:10.283982 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:02:10.283990 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:02:10.283998 22508 solver.cpp:238]     Train net output #2: loss = 0.240236 (* 1 = 0.240236 loss)
I0417 12:02:10.284001 22508 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0417 12:02:32.342756 22508 solver.cpp:219] Iteration 25700 (4.53345 iter/s, 22.0583s/100 iters), loss = 0.125638
I0417 12:02:32.343353 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 12:02:32.343364 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:02:32.343372 22508 solver.cpp:238]     Train net output #2: loss = 0.125638 (* 1 = 0.125638 loss)
I0417 12:02:32.343379 22508 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0417 12:02:49.303906 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:02:54.375972 22508 solver.cpp:219] Iteration 25800 (4.53883 iter/s, 22.0321s/100 iters), loss = 0.107963
I0417 12:02:54.376022 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0417 12:02:54.376029 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:02:54.376035 22508 solver.cpp:238]     Train net output #2: loss = 0.107963 (* 1 = 0.107963 loss)
I0417 12:02:54.376040 22508 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0417 12:03:16.420416 22508 solver.cpp:219] Iteration 25900 (4.5364 iter/s, 22.0439s/100 iters), loss = 0.194058
I0417 12:03:16.420996 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:03:16.421003 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:03:16.421010 22508 solver.cpp:238]     Train net output #2: loss = 0.194058 (* 1 = 0.194058 loss)
I0417 12:03:16.421015 22508 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0417 12:03:38.260017 22508 solver.cpp:331] Iteration 26000, Testing net (#0)
I0417 12:03:41.201423 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:03:41.321959 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.4153
I0417 12:03:41.321985 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.8688
I0417 12:03:41.322003 22508 solver.cpp:398]     Test net output #2: loss = 2.60205 (* 1 = 2.60205 loss)
I0417 12:03:41.540083 22508 solver.cpp:219] Iteration 26000 (3.98112 iter/s, 25.1185s/100 iters), loss = 0.196964
I0417 12:03:41.540115 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:03:41.540122 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:03:41.540127 22508 solver.cpp:238]     Train net output #2: loss = 0.196963 (* 1 = 0.196963 loss)
I0417 12:03:41.540133 22508 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0417 12:04:03.569672 22508 solver.cpp:219] Iteration 26100 (4.53946 iter/s, 22.0291s/100 iters), loss = 0.269852
I0417 12:04:03.569712 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:04:03.569718 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:04:03.569725 22508 solver.cpp:238]     Train net output #2: loss = 0.269852 (* 1 = 0.269852 loss)
I0417 12:04:03.569730 22508 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0417 12:04:18.366327 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:04:25.613360 22508 solver.cpp:219] Iteration 26200 (4.53656 iter/s, 22.0432s/100 iters), loss = 0.159218
I0417 12:04:25.613394 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 12:04:25.613399 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:04:25.613406 22508 solver.cpp:238]     Train net output #2: loss = 0.159218 (* 1 = 0.159218 loss)
I0417 12:04:25.613410 22508 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0417 12:04:47.629190 22508 solver.cpp:219] Iteration 26300 (4.5423 iter/s, 22.0153s/100 iters), loss = 0.159381
I0417 12:04:47.629227 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:04:47.629236 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:04:47.629246 22508 solver.cpp:238]     Train net output #2: loss = 0.159381 (* 1 = 0.159381 loss)
I0417 12:04:47.629253 22508 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0417 12:05:09.661078 22508 solver.cpp:219] Iteration 26400 (4.53899 iter/s, 22.0314s/100 iters), loss = 0.205879
I0417 12:05:09.661237 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 12:05:09.661245 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:05:09.661252 22508 solver.cpp:238]     Train net output #2: loss = 0.205879 (* 1 = 0.205879 loss)
I0417 12:05:09.661257 22508 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0417 12:05:31.743464 22508 solver.cpp:219] Iteration 26500 (4.52863 iter/s, 22.0817s/100 iters), loss = 0.211303
I0417 12:05:31.744024 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:05:31.744032 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:05:31.744040 22508 solver.cpp:238]     Train net output #2: loss = 0.211303 (* 1 = 0.211303 loss)
I0417 12:05:31.744043 22508 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0417 12:05:44.553082 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:05:53.805871 22508 solver.cpp:219] Iteration 26600 (4.53281 iter/s, 22.0613s/100 iters), loss = 0.172431
I0417 12:05:53.805907 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:05:53.805913 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:05:53.805919 22508 solver.cpp:238]     Train net output #2: loss = 0.172431 (* 1 = 0.172431 loss)
I0417 12:05:53.805923 22508 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0417 12:06:15.852847 22508 solver.cpp:219] Iteration 26700 (4.53588 iter/s, 22.0464s/100 iters), loss = 0.217573
I0417 12:06:15.853001 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 12:06:15.853010 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:06:15.853018 22508 solver.cpp:238]     Train net output #2: loss = 0.217573 (* 1 = 0.217573 loss)
I0417 12:06:15.853024 22508 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0417 12:06:37.924578 22508 solver.cpp:219] Iteration 26800 (4.53082 iter/s, 22.0711s/100 iters), loss = 0.235608
I0417 12:06:37.924618 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:06:37.924624 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:06:37.924631 22508 solver.cpp:238]     Train net output #2: loss = 0.235608 (* 1 = 0.235608 loss)
I0417 12:06:37.924636 22508 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0417 12:07:00.016305 22508 solver.cpp:219] Iteration 26900 (4.52669 iter/s, 22.0912s/100 iters), loss = 0.163419
I0417 12:07:00.016436 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:07:00.016446 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:07:00.016455 22508 solver.cpp:238]     Train net output #2: loss = 0.163419 (* 1 = 0.163419 loss)
I0417 12:07:00.016461 22508 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0417 12:07:10.831395 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:07:21.849005 22508 solver.cpp:331] Iteration 27000, Testing net (#0)
I0417 12:07:24.792915 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:07:24.913260 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.1778
I0417 12:07:24.913287 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.6276
I0417 12:07:24.913307 22508 solver.cpp:398]     Test net output #2: loss = 3.77435 (* 1 = 3.77435 loss)
I0417 12:07:25.131958 22508 solver.cpp:219] Iteration 27000 (3.98169 iter/s, 25.115s/100 iters), loss = 0.188468
I0417 12:07:25.131994 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:07:25.131999 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:07:25.132004 22508 solver.cpp:238]     Train net output #2: loss = 0.188468 (* 1 = 0.188468 loss)
I0417 12:07:25.132010 22508 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0417 12:07:47.175853 22508 solver.cpp:219] Iteration 27100 (4.53651 iter/s, 22.0434s/100 iters), loss = 0.137455
I0417 12:07:47.175981 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:07:47.175989 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:07:47.175997 22508 solver.cpp:238]     Train net output #2: loss = 0.137455 (* 1 = 0.137455 loss)
I0417 12:07:47.176002 22508 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0417 12:08:09.171001 22508 solver.cpp:219] Iteration 27200 (4.54659 iter/s, 21.9945s/100 iters), loss = 0.188131
I0417 12:08:09.171042 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:08:09.171047 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:08:09.171054 22508 solver.cpp:238]     Train net output #2: loss = 0.188131 (* 1 = 0.188131 loss)
I0417 12:08:09.171058 22508 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0417 12:08:31.134894 22508 solver.cpp:219] Iteration 27300 (4.55304 iter/s, 21.9634s/100 iters), loss = 0.164337
I0417 12:08:31.135030 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:08:31.135037 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:08:31.135043 22508 solver.cpp:238]     Train net output #2: loss = 0.164337 (* 1 = 0.164337 loss)
I0417 12:08:31.135048 22508 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0417 12:08:39.673218 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:08:53.059726 22508 solver.cpp:219] Iteration 27400 (4.56117 iter/s, 21.9242s/100 iters), loss = 0.165531
I0417 12:08:53.059764 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:08:53.059769 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:08:53.059777 22508 solver.cpp:238]     Train net output #2: loss = 0.165531 (* 1 = 0.165531 loss)
I0417 12:08:53.059780 22508 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0417 12:09:14.973013 22508 solver.cpp:219] Iteration 27500 (4.56355 iter/s, 21.9128s/100 iters), loss = 0.251682
I0417 12:09:14.973160 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 12:09:14.973175 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:09:14.973181 22508 solver.cpp:238]     Train net output #2: loss = 0.251682 (* 1 = 0.251682 loss)
I0417 12:09:14.973186 22508 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0417 12:09:36.921710 22508 solver.cpp:219] Iteration 27600 (4.55621 iter/s, 21.9481s/100 iters), loss = 0.270643
I0417 12:09:36.922300 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 12:09:36.922307 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:09:36.922314 22508 solver.cpp:238]     Train net output #2: loss = 0.270643 (* 1 = 0.270643 loss)
I0417 12:09:36.922319 22508 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0417 12:09:58.837954 22508 solver.cpp:219] Iteration 27700 (4.56305 iter/s, 21.9152s/100 iters), loss = 0.281421
I0417 12:09:58.838076 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 12:09:58.838085 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:09:58.838091 22508 solver.cpp:238]     Train net output #2: loss = 0.281421 (* 1 = 0.281421 loss)
I0417 12:09:58.838096 22508 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0417 12:10:05.445596 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:10:20.822702 22508 solver.cpp:219] Iteration 27800 (4.54874 iter/s, 21.9841s/100 iters), loss = 0.22861
I0417 12:10:20.822739 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:10:20.822746 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:10:20.822753 22508 solver.cpp:238]     Train net output #2: loss = 0.228609 (* 1 = 0.228609 loss)
I0417 12:10:20.822757 22508 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0417 12:10:42.777410 22508 solver.cpp:219] Iteration 27900 (4.55494 iter/s, 21.9542s/100 iters), loss = 0.250673
I0417 12:10:42.777536 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:10:42.777545 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:10:42.777552 22508 solver.cpp:238]     Train net output #2: loss = 0.250673 (* 1 = 0.250673 loss)
I0417 12:10:42.777556 22508 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0417 12:11:04.570015 22508 solver.cpp:331] Iteration 28000, Testing net (#0)
I0417 12:11:07.510315 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:11:07.631088 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.5728
I0417 12:11:07.631115 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9281
I0417 12:11:07.631134 22508 solver.cpp:398]     Test net output #2: loss = 1.75332 (* 1 = 1.75332 loss)
I0417 12:11:07.849555 22508 solver.cpp:219] Iteration 28000 (3.9886 iter/s, 25.0715s/100 iters), loss = 0.243783
I0417 12:11:07.849587 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:11:07.849592 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:11:07.849598 22508 solver.cpp:238]     Train net output #2: loss = 0.243783 (* 1 = 0.243783 loss)
I0417 12:11:07.849604 22508 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0417 12:11:29.808380 22508 solver.cpp:219] Iteration 28100 (4.55408 iter/s, 21.9583s/100 iters), loss = 0.265628
I0417 12:11:29.808519 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:11:29.808527 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:11:29.808534 22508 solver.cpp:238]     Train net output #2: loss = 0.265628 (* 1 = 0.265628 loss)
I0417 12:11:29.808539 22508 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0417 12:11:34.195710 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:11:51.829010 22508 solver.cpp:219] Iteration 28200 (4.54133 iter/s, 22.02s/100 iters), loss = 0.142628
I0417 12:11:51.829051 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:11:51.829056 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:11:51.829062 22508 solver.cpp:238]     Train net output #2: loss = 0.142628 (* 1 = 0.142628 loss)
I0417 12:11:51.829066 22508 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0417 12:12:13.918931 22508 solver.cpp:219] Iteration 28300 (4.52706 iter/s, 22.0894s/100 iters), loss = 0.270665
I0417 12:12:13.919113 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:12:13.919122 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:12:13.919131 22508 solver.cpp:238]     Train net output #2: loss = 0.270665 (* 1 = 0.270665 loss)
I0417 12:12:13.919137 22508 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0417 12:12:35.983873 22508 solver.cpp:219] Iteration 28400 (4.53222 iter/s, 22.0643s/100 iters), loss = 0.196353
I0417 12:12:35.983916 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:12:35.983925 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:12:35.983934 22508 solver.cpp:238]     Train net output #2: loss = 0.196353 (* 1 = 0.196353 loss)
I0417 12:12:35.983940 22508 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0417 12:12:58.062084 22508 solver.cpp:219] Iteration 28500 (4.52946 iter/s, 22.0777s/100 iters), loss = 0.16538
I0417 12:12:58.062515 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:12:58.062522 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:12:58.062530 22508 solver.cpp:238]     Train net output #2: loss = 0.165379 (* 1 = 0.165379 loss)
I0417 12:12:58.062535 22508 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0417 12:13:00.500433 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:13:20.126549 22508 solver.cpp:219] Iteration 28600 (4.53236 iter/s, 22.0635s/100 iters), loss = 0.230709
I0417 12:13:20.127090 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:13:20.127099 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:13:20.127105 22508 solver.cpp:238]     Train net output #2: loss = 0.230709 (* 1 = 0.230709 loss)
I0417 12:13:20.127110 22508 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0417 12:13:42.215323 22508 solver.cpp:219] Iteration 28700 (4.5274 iter/s, 22.0877s/100 iters), loss = 0.136046
I0417 12:13:42.215476 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:13:42.215484 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:13:42.215492 22508 solver.cpp:238]     Train net output #2: loss = 0.136045 (* 1 = 0.136045 loss)
I0417 12:13:42.215497 22508 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0417 12:14:04.316135 22508 solver.cpp:219] Iteration 28800 (4.52485 iter/s, 22.1002s/100 iters), loss = 0.339575
I0417 12:14:04.316182 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.84375
I0417 12:14:04.316189 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:14:04.316196 22508 solver.cpp:238]     Train net output #2: loss = 0.339575 (* 1 = 0.339575 loss)
I0417 12:14:04.316201 22508 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0417 12:14:26.359098 22508 solver.cpp:219] Iteration 28900 (4.53671 iter/s, 22.0424s/100 iters), loss = 0.180069
I0417 12:14:26.359263 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:14:26.359272 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:14:26.359278 22508 solver.cpp:238]     Train net output #2: loss = 0.180069 (* 1 = 0.180069 loss)
I0417 12:14:26.359283 22508 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0417 12:14:26.806025 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:14:48.208501 22508 solver.cpp:331] Iteration 29000, Testing net (#0)
I0417 12:14:51.154726 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:14:51.275394 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.4205
I0417 12:14:51.275424 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.922
I0417 12:14:51.275442 22508 solver.cpp:398]     Test net output #2: loss = 2.54115 (* 1 = 2.54115 loss)
I0417 12:14:51.492532 22508 solver.cpp:219] Iteration 29000 (3.97888 iter/s, 25.1327s/100 iters), loss = 0.233882
I0417 12:14:51.492564 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:14:51.492569 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:14:51.492575 22508 solver.cpp:238]     Train net output #2: loss = 0.233882 (* 1 = 0.233882 loss)
I0417 12:14:51.492580 22508 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0417 12:15:13.565445 22508 solver.cpp:219] Iteration 29100 (4.53055 iter/s, 22.0724s/100 iters), loss = 0.273967
I0417 12:15:13.570222 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 12:15:13.570233 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:15:13.570242 22508 solver.cpp:238]     Train net output #2: loss = 0.273967 (* 1 = 0.273967 loss)
I0417 12:15:13.570248 22508 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0417 12:15:35.640156 22508 solver.cpp:219] Iteration 29200 (4.53115 iter/s, 22.0694s/100 iters), loss = 0.254114
I0417 12:15:35.640602 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:15:35.640609 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:15:35.640616 22508 solver.cpp:238]     Train net output #2: loss = 0.254114 (* 1 = 0.254114 loss)
I0417 12:15:35.640620 22508 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0417 12:15:55.923127 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:15:57.669901 22508 solver.cpp:219] Iteration 29300 (4.53951 iter/s, 22.0288s/100 iters), loss = 0.262794
I0417 12:15:57.669930 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:15:57.669936 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:15:57.669942 22508 solver.cpp:238]     Train net output #2: loss = 0.262794 (* 1 = 0.262794 loss)
I0417 12:15:57.669946 22508 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0417 12:16:19.805246 22508 solver.cpp:219] Iteration 29400 (4.51777 iter/s, 22.1348s/100 iters), loss = 0.306587
I0417 12:16:19.805953 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 12:16:19.805961 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:16:19.805968 22508 solver.cpp:238]     Train net output #2: loss = 0.306587 (* 1 = 0.306587 loss)
I0417 12:16:19.805974 22508 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0417 12:16:41.900923 22508 solver.cpp:219] Iteration 29500 (4.52602 iter/s, 22.0945s/100 iters), loss = 0.141758
I0417 12:16:41.901065 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:16:41.901073 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:16:41.901079 22508 solver.cpp:238]     Train net output #2: loss = 0.141758 (* 1 = 0.141758 loss)
I0417 12:16:41.901084 22508 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0417 12:17:03.855031 22508 solver.cpp:219] Iteration 29600 (4.55509 iter/s, 21.9535s/100 iters), loss = 0.193233
I0417 12:17:03.855080 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:17:03.855088 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:17:03.855094 22508 solver.cpp:238]     Train net output #2: loss = 0.193233 (* 1 = 0.193233 loss)
I0417 12:17:03.855099 22508 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0417 12:17:22.059141 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:17:25.790524 22508 solver.cpp:219] Iteration 29700 (4.55893 iter/s, 21.935s/100 iters), loss = 0.377147
I0417 12:17:25.790572 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 12:17:25.790580 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:17:25.790586 22508 solver.cpp:238]     Train net output #2: loss = 0.377147 (* 1 = 0.377147 loss)
I0417 12:17:25.790591 22508 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0417 12:17:47.704192 22508 solver.cpp:219] Iteration 29800 (4.56348 iter/s, 21.9131s/100 iters), loss = 0.19128
I0417 12:17:47.704228 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:17:47.704233 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:17:47.704241 22508 solver.cpp:238]     Train net output #2: loss = 0.191279 (* 1 = 0.191279 loss)
I0417 12:17:47.704244 22508 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0417 12:18:09.718367 22508 solver.cpp:219] Iteration 29900 (4.54264 iter/s, 22.0136s/100 iters), loss = 0.247741
I0417 12:18:09.718559 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:18:09.718571 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:18:09.718583 22508 solver.cpp:238]     Train net output #2: loss = 0.247741 (* 1 = 0.247741 loss)
I0417 12:18:09.718592 22508 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0417 12:18:31.584285 22508 solver.cpp:448] Snapshotting to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_30000.caffemodel
I0417 12:18:31.591331 22508 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_30000.solverstate
I0417 12:18:31.593358 22508 solver.cpp:331] Iteration 30000, Testing net (#0)
I0417 12:18:34.539463 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:18:34.660470 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.6561
I0417 12:18:34.660497 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9607
I0417 12:18:34.660517 22508 solver.cpp:398]     Test net output #2: loss = 1.40636 (* 1 = 1.40636 loss)
I0417 12:18:34.878907 22508 solver.cpp:219] Iteration 30000 (3.97459 iter/s, 25.1598s/100 iters), loss = 0.142591
I0417 12:18:34.878942 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:18:34.878947 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:18:34.878952 22508 solver.cpp:238]     Train net output #2: loss = 0.142591 (* 1 = 0.142591 loss)
I0417 12:18:34.878959 22508 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0417 12:18:51.187579 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:18:56.928534 22508 solver.cpp:219] Iteration 30100 (4.53533 iter/s, 22.0491s/100 iters), loss = 0.161524
I0417 12:18:56.928571 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 12:18:56.928577 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:18:56.928583 22508 solver.cpp:238]     Train net output #2: loss = 0.161524 (* 1 = 0.161524 loss)
I0417 12:18:56.928587 22508 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0417 12:19:19.001114 22508 solver.cpp:219] Iteration 30200 (4.53062 iter/s, 22.072s/100 iters), loss = 0.176411
I0417 12:19:19.001595 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:19:19.001603 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:19:19.001610 22508 solver.cpp:238]     Train net output #2: loss = 0.17641 (* 1 = 0.17641 loss)
I0417 12:19:19.001615 22508 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0417 12:19:41.038549 22508 solver.cpp:219] Iteration 30300 (4.53793 iter/s, 22.0365s/100 iters), loss = 0.208689
I0417 12:19:41.038689 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:19:41.038697 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:19:41.038703 22508 solver.cpp:238]     Train net output #2: loss = 0.208688 (* 1 = 0.208688 loss)
I0417 12:19:41.038708 22508 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0417 12:20:03.079627 22508 solver.cpp:219] Iteration 30400 (4.53711 iter/s, 22.0404s/100 iters), loss = 0.139613
I0417 12:20:03.080076 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:20:03.080085 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:20:03.080090 22508 solver.cpp:238]     Train net output #2: loss = 0.139613 (* 1 = 0.139613 loss)
I0417 12:20:03.080094 22508 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0417 12:20:17.204751 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:20:25.121402 22508 solver.cpp:219] Iteration 30500 (4.53703 iter/s, 22.0408s/100 iters), loss = 0.170962
I0417 12:20:25.121454 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:20:25.121460 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:20:25.121467 22508 solver.cpp:238]     Train net output #2: loss = 0.170962 (* 1 = 0.170962 loss)
I0417 12:20:25.121471 22508 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0417 12:20:47.161061 22508 solver.cpp:219] Iteration 30600 (4.53739 iter/s, 22.0391s/100 iters), loss = 0.181643
I0417 12:20:47.161111 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:20:47.161118 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:20:47.161123 22508 solver.cpp:238]     Train net output #2: loss = 0.181642 (* 1 = 0.181642 loss)
I0417 12:20:47.161128 22508 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0417 12:21:09.137297 22508 solver.cpp:219] Iteration 30700 (4.55048 iter/s, 21.9757s/100 iters), loss = 0.179807
I0417 12:21:09.137421 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:21:09.137429 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:21:09.137436 22508 solver.cpp:238]     Train net output #2: loss = 0.179807 (* 1 = 0.179807 loss)
I0417 12:21:09.137441 22508 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0417 12:21:31.106212 22508 solver.cpp:219] Iteration 30800 (4.55201 iter/s, 21.9683s/100 iters), loss = 0.139939
I0417 12:21:31.106791 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:21:31.106798 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:21:31.106804 22508 solver.cpp:238]     Train net output #2: loss = 0.139939 (* 1 = 0.139939 loss)
I0417 12:21:31.106809 22508 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0417 12:21:43.211518 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:21:53.150081 22508 solver.cpp:219] Iteration 30900 (4.53663 iter/s, 22.0428s/100 iters), loss = 0.186068
I0417 12:21:53.150121 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:21:53.150128 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:21:53.150135 22508 solver.cpp:238]     Train net output #2: loss = 0.186068 (* 1 = 0.186068 loss)
I0417 12:21:53.150138 22508 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0417 12:22:14.987792 22508 solver.cpp:331] Iteration 31000, Testing net (#0)
I0417 12:22:17.927474 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:22:18.048233 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.623
I0417 12:22:18.048257 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9408
I0417 12:22:18.048279 22508 solver.cpp:398]     Test net output #2: loss = 1.58951 (* 1 = 1.58951 loss)
I0417 12:22:18.266758 22508 solver.cpp:219] Iteration 31000 (3.98151 iter/s, 25.1161s/100 iters), loss = 0.205089
I0417 12:22:18.266791 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:22:18.266796 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:22:18.266803 22508 solver.cpp:238]     Train net output #2: loss = 0.205089 (* 1 = 0.205089 loss)
I0417 12:22:18.266808 22508 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0417 12:22:40.312330 22508 solver.cpp:219] Iteration 31100 (4.53616 iter/s, 22.0451s/100 iters), loss = 0.218934
I0417 12:22:40.312368 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:22:40.312374 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:22:40.312382 22508 solver.cpp:238]     Train net output #2: loss = 0.218934 (* 1 = 0.218934 loss)
I0417 12:22:40.312386 22508 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0417 12:23:02.350513 22508 solver.cpp:219] Iteration 31200 (4.53769 iter/s, 22.0377s/100 iters), loss = 0.284182
I0417 12:23:02.350631 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 12:23:02.350638 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:23:02.350646 22508 solver.cpp:238]     Train net output #2: loss = 0.284182 (* 1 = 0.284182 loss)
I0417 12:23:02.350651 22508 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0417 12:23:12.264600 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:23:24.377562 22508 solver.cpp:219] Iteration 31300 (4.54 iter/s, 22.0264s/100 iters), loss = 0.211377
I0417 12:23:24.377605 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:23:24.377612 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:23:24.377619 22508 solver.cpp:238]     Train net output #2: loss = 0.211377 (* 1 = 0.211377 loss)
I0417 12:23:24.377624 22508 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0417 12:23:46.393681 22508 solver.cpp:219] Iteration 31400 (4.54224 iter/s, 22.0156s/100 iters), loss = 0.229509
I0417 12:23:46.393841 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:23:46.393851 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:23:46.393857 22508 solver.cpp:238]     Train net output #2: loss = 0.229509 (* 1 = 0.229509 loss)
I0417 12:23:46.393862 22508 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0417 12:24:08.395156 22508 solver.cpp:219] Iteration 31500 (4.54528 iter/s, 22.0008s/100 iters), loss = 0.170077
I0417 12:24:08.395195 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:24:08.395201 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:24:08.395207 22508 solver.cpp:238]     Train net output #2: loss = 0.170076 (* 1 = 0.170076 loss)
I0417 12:24:08.395211 22508 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0417 12:24:30.346740 22508 solver.cpp:219] Iteration 31600 (4.55559 iter/s, 21.9511s/100 iters), loss = 0.222056
I0417 12:24:30.346879 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:24:30.346889 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:24:30.346895 22508 solver.cpp:238]     Train net output #2: loss = 0.222056 (* 1 = 0.222056 loss)
I0417 12:24:30.346899 22508 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0417 12:24:38.268360 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:24:52.296959 22508 solver.cpp:219] Iteration 31700 (4.55589 iter/s, 21.9496s/100 iters), loss = 0.126905
I0417 12:24:52.296998 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:24:52.297003 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:24:52.297010 22508 solver.cpp:238]     Train net output #2: loss = 0.126905 (* 1 = 0.126905 loss)
I0417 12:24:52.297014 22508 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0417 12:25:14.271001 22508 solver.cpp:219] Iteration 31800 (4.55093 iter/s, 21.9735s/100 iters), loss = 0.169574
I0417 12:25:14.272099 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:25:14.272109 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:25:14.272114 22508 solver.cpp:238]     Train net output #2: loss = 0.169574 (* 1 = 0.169574 loss)
I0417 12:25:14.272120 22508 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0417 12:25:36.259300 22508 solver.cpp:219] Iteration 31900 (4.5482 iter/s, 21.9867s/100 iters), loss = 0.223096
I0417 12:25:36.259897 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:25:36.259904 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:25:36.259910 22508 solver.cpp:238]     Train net output #2: loss = 0.223096 (* 1 = 0.223096 loss)
I0417 12:25:36.259915 22508 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0417 12:25:57.986573 22508 solver.cpp:331] Iteration 32000, Testing net (#0)
I0417 12:26:00.929532 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:26:01.050344 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.1403
I0417 12:26:01.050370 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.4876
I0417 12:26:01.050390 22508 solver.cpp:398]     Test net output #2: loss = 4.61925 (* 1 = 4.61925 loss)
I0417 12:26:01.269090 22508 solver.cpp:219] Iteration 32000 (3.99862 iter/s, 25.0086s/100 iters), loss = 0.323199
I0417 12:26:01.269109 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 12:26:01.269114 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:26:01.269120 22508 solver.cpp:238]     Train net output #2: loss = 0.323198 (* 1 = 0.323198 loss)
I0417 12:26:01.269126 22508 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0417 12:26:07.181563 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:26:23.249728 22508 solver.cpp:219] Iteration 32100 (4.54956 iter/s, 21.9801s/100 iters), loss = 0.190192
I0417 12:26:23.249768 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:26:23.249773 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:26:23.249779 22508 solver.cpp:238]     Train net output #2: loss = 0.190192 (* 1 = 0.190192 loss)
I0417 12:26:23.249783 22508 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0417 12:26:45.342886 22508 solver.cpp:219] Iteration 32200 (4.5264 iter/s, 22.0926s/100 iters), loss = 0.143342
I0417 12:26:45.343032 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 12:26:45.343041 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:26:45.343049 22508 solver.cpp:238]     Train net output #2: loss = 0.143342 (* 1 = 0.143342 loss)
I0417 12:26:45.343052 22508 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0417 12:27:07.431602 22508 solver.cpp:219] Iteration 32300 (4.52733 iter/s, 22.0881s/100 iters), loss = 0.252261
I0417 12:27:07.432086 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:27:07.432095 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 12:27:07.432102 22508 solver.cpp:238]     Train net output #2: loss = 0.252261 (* 1 = 0.252261 loss)
I0417 12:27:07.432107 22508 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0417 12:27:29.499572 22508 solver.cpp:219] Iteration 32400 (4.53166 iter/s, 22.067s/100 iters), loss = 0.209682
I0417 12:27:29.500255 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:27:29.500265 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:27:29.500272 22508 solver.cpp:238]     Train net output #2: loss = 0.209682 (* 1 = 0.209682 loss)
I0417 12:27:29.500277 22508 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0417 12:27:33.253726 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:27:51.547765 22508 solver.cpp:219] Iteration 32500 (4.53576 iter/s, 22.047s/100 iters), loss = 0.19133
I0417 12:27:51.547801 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:27:51.547807 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:27:51.547813 22508 solver.cpp:238]     Train net output #2: loss = 0.19133 (* 1 = 0.19133 loss)
I0417 12:27:51.547817 22508 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0417 12:28:13.616178 22508 solver.cpp:219] Iteration 32600 (4.53147 iter/s, 22.0679s/100 iters), loss = 0.277834
I0417 12:28:13.621239 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 12:28:13.621248 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:28:13.621255 22508 solver.cpp:238]     Train net output #2: loss = 0.277834 (* 1 = 0.277834 loss)
I0417 12:28:13.621260 22508 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0417 12:28:35.669472 22508 solver.cpp:219] Iteration 32700 (4.53561 iter/s, 22.0477s/100 iters), loss = 0.311962
I0417 12:28:35.670058 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0417 12:28:35.670066 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:28:35.670073 22508 solver.cpp:238]     Train net output #2: loss = 0.311962 (* 1 = 0.311962 loss)
I0417 12:28:35.670076 22508 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0417 12:28:57.704579 22508 solver.cpp:219] Iteration 32800 (4.53843 iter/s, 22.034s/100 iters), loss = 0.135968
I0417 12:28:57.704695 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:28:57.704704 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:28:57.704710 22508 solver.cpp:238]     Train net output #2: loss = 0.135968 (* 1 = 0.135968 loss)
I0417 12:28:57.704715 22508 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0417 12:28:59.470741 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:29:19.775477 22508 solver.cpp:219] Iteration 32900 (4.53098 iter/s, 22.0703s/100 iters), loss = 0.11784
I0417 12:29:19.775517 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:29:19.775523 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:29:19.775530 22508 solver.cpp:238]     Train net output #2: loss = 0.11784 (* 1 = 0.11784 loss)
I0417 12:29:19.775534 22508 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0417 12:29:41.619626 22508 solver.cpp:331] Iteration 33000, Testing net (#0)
I0417 12:29:44.567222 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:29:44.688098 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.098
I0417 12:29:44.688127 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.4693
I0417 12:29:44.688148 22508 solver.cpp:398]     Test net output #2: loss = 8.84525 (* 1 = 8.84525 loss)
I0417 12:29:44.906841 22508 solver.cpp:219] Iteration 33000 (3.97918 iter/s, 25.1308s/100 iters), loss = 0.128613
I0417 12:29:44.906862 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 12:29:44.906867 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:29:44.906873 22508 solver.cpp:238]     Train net output #2: loss = 0.128613 (* 1 = 0.128613 loss)
I0417 12:29:44.906879 22508 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0417 12:30:06.967615 22508 solver.cpp:219] Iteration 33100 (4.53304 iter/s, 22.0603s/100 iters), loss = 0.31523
I0417 12:30:06.967653 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 12:30:06.967658 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:30:06.967664 22508 solver.cpp:238]     Train net output #2: loss = 0.31523 (* 1 = 0.31523 loss)
I0417 12:30:06.967669 22508 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0417 12:30:28.797123 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:30:29.011122 22508 solver.cpp:219] Iteration 33200 (4.53659 iter/s, 22.043s/100 iters), loss = 0.148628
I0417 12:30:29.011148 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:30:29.011154 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:30:29.011160 22508 solver.cpp:238]     Train net output #2: loss = 0.148628 (* 1 = 0.148628 loss)
I0417 12:30:29.011165 22508 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0417 12:30:51.030326 22508 solver.cpp:219] Iteration 33300 (4.5416 iter/s, 22.0187s/100 iters), loss = 0.305953
I0417 12:30:51.030364 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:30:51.030370 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:30:51.030377 22508 solver.cpp:238]     Train net output #2: loss = 0.305953 (* 1 = 0.305953 loss)
I0417 12:30:51.030381 22508 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0417 12:31:12.980167 22508 solver.cpp:219] Iteration 33400 (4.55595 iter/s, 21.9493s/100 iters), loss = 0.299891
I0417 12:31:12.980279 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:31:12.980288 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:31:12.980294 22508 solver.cpp:238]     Train net output #2: loss = 0.299891 (* 1 = 0.299891 loss)
I0417 12:31:12.980298 22508 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0417 12:31:35.064285 22508 solver.cpp:219] Iteration 33500 (4.52827 iter/s, 22.0835s/100 iters), loss = 0.123843
I0417 12:31:35.064887 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0417 12:31:35.064895 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:31:35.064905 22508 solver.cpp:238]     Train net output #2: loss = 0.123843 (* 1 = 0.123843 loss)
I0417 12:31:35.064911 22508 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0417 12:31:54.713804 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:31:57.131950 22508 solver.cpp:219] Iteration 33600 (4.53174 iter/s, 22.0666s/100 iters), loss = 0.239157
I0417 12:31:57.132002 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:31:57.132009 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:31:57.132015 22508 solver.cpp:238]     Train net output #2: loss = 0.239157 (* 1 = 0.239157 loss)
I0417 12:31:57.132020 22508 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0417 12:32:19.264665 22508 solver.cpp:219] Iteration 33700 (4.51831 iter/s, 22.1322s/100 iters), loss = 0.37084
I0417 12:32:19.265198 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 12:32:19.265206 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:32:19.265213 22508 solver.cpp:238]     Train net output #2: loss = 0.37084 (* 1 = 0.37084 loss)
I0417 12:32:19.265218 22508 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0417 12:32:41.339843 22508 solver.cpp:219] Iteration 33800 (4.53019 iter/s, 22.0742s/100 iters), loss = 0.156713
I0417 12:32:41.340001 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:32:41.340011 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:32:41.340018 22508 solver.cpp:238]     Train net output #2: loss = 0.156712 (* 1 = 0.156712 loss)
I0417 12:32:41.340023 22508 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0417 12:33:03.418756 22508 solver.cpp:219] Iteration 33900 (4.52934 iter/s, 22.0783s/100 iters), loss = 0.283263
I0417 12:33:03.418792 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:33:03.418799 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:33:03.418805 22508 solver.cpp:238]     Train net output #2: loss = 0.283263 (* 1 = 0.283263 loss)
I0417 12:33:03.418810 22508 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0417 12:33:21.058579 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:33:25.266036 22508 solver.cpp:331] Iteration 34000, Testing net (#0)
I0417 12:33:28.205541 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:33:28.326098 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.5467
I0417 12:33:28.326124 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9206
I0417 12:33:28.326144 22508 solver.cpp:398]     Test net output #2: loss = 1.9431 (* 1 = 1.9431 loss)
I0417 12:33:28.543411 22508 solver.cpp:219] Iteration 34000 (3.98025 iter/s, 25.1241s/100 iters), loss = 0.192352
I0417 12:33:28.543431 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:33:28.543436 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:33:28.543442 22508 solver.cpp:238]     Train net output #2: loss = 0.192351 (* 1 = 0.192351 loss)
I0417 12:33:28.543447 22508 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0417 12:33:50.638923 22508 solver.cpp:219] Iteration 34100 (4.52591 iter/s, 22.095s/100 iters), loss = 0.135225
I0417 12:33:50.638960 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 12:33:50.638967 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:33:50.638972 22508 solver.cpp:238]     Train net output #2: loss = 0.135225 (* 1 = 0.135225 loss)
I0417 12:33:50.638978 22508 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0417 12:34:12.683328 22508 solver.cpp:219] Iteration 34200 (4.53641 iter/s, 22.0439s/100 iters), loss = 0.154924
I0417 12:34:12.683451 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:34:12.683459 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:34:12.683466 22508 solver.cpp:238]     Train net output #2: loss = 0.154924 (* 1 = 0.154924 loss)
I0417 12:34:12.683471 22508 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0417 12:34:34.752027 22508 solver.cpp:219] Iteration 34300 (4.53143 iter/s, 22.0681s/100 iters), loss = 0.18359
I0417 12:34:34.752475 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:34:34.752483 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:34:34.752490 22508 solver.cpp:238]     Train net output #2: loss = 0.18359 (* 1 = 0.18359 loss)
I0417 12:34:34.752493 22508 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0417 12:34:50.144984 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:34:56.708446 22508 solver.cpp:219] Iteration 34400 (4.55467 iter/s, 21.9555s/100 iters), loss = 0.237976
I0417 12:34:56.708479 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 12:34:56.708484 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:34:56.708492 22508 solver.cpp:238]     Train net output #2: loss = 0.237976 (* 1 = 0.237976 loss)
I0417 12:34:56.708495 22508 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0417 12:35:18.667780 22508 solver.cpp:219] Iteration 34500 (4.55398 iter/s, 21.9588s/100 iters), loss = 0.206514
I0417 12:35:18.667816 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:35:18.667822 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:35:18.667829 22508 solver.cpp:238]     Train net output #2: loss = 0.206514 (* 1 = 0.206514 loss)
I0417 12:35:18.667834 22508 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0417 12:35:40.593941 22508 solver.cpp:219] Iteration 34600 (4.56087 iter/s, 21.9256s/100 iters), loss = 0.157971
I0417 12:35:40.594084 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:35:40.594094 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:35:40.594100 22508 solver.cpp:238]     Train net output #2: loss = 0.157971 (* 1 = 0.157971 loss)
I0417 12:35:40.594105 22508 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0417 12:36:02.551506 22508 solver.cpp:219] Iteration 34700 (4.55437 iter/s, 21.9569s/100 iters), loss = 0.361592
I0417 12:36:02.551537 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:36:02.551542 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:36:02.551549 22508 solver.cpp:238]     Train net output #2: loss = 0.361592 (* 1 = 0.361592 loss)
I0417 12:36:02.551553 22508 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0417 12:36:15.925925 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:36:24.497799 22508 solver.cpp:219] Iteration 34800 (4.55669 iter/s, 21.9458s/100 iters), loss = 0.224225
I0417 12:36:24.497833 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:36:24.497838 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:36:24.497843 22508 solver.cpp:238]     Train net output #2: loss = 0.224225 (* 1 = 0.224225 loss)
I0417 12:36:24.497848 22508 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0417 12:36:46.476156 22508 solver.cpp:219] Iteration 34900 (4.55004 iter/s, 21.9778s/100 iters), loss = 0.240826
I0417 12:36:46.476271 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 12:36:46.476279 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:36:46.476286 22508 solver.cpp:238]     Train net output #2: loss = 0.240826 (* 1 = 0.240826 loss)
I0417 12:36:46.476291 22508 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0417 12:37:08.184780 22508 solver.cpp:331] Iteration 35000, Testing net (#0)
I0417 12:37:11.131374 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:37:11.252259 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.3427
I0417 12:37:11.252285 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.8289
I0417 12:37:11.252305 22508 solver.cpp:398]     Test net output #2: loss = 5.59904 (* 1 = 5.59904 loss)
I0417 12:37:11.470185 22508 solver.cpp:219] Iteration 35000 (4.00106 iter/s, 24.9934s/100 iters), loss = 0.178202
I0417 12:37:11.470206 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:37:11.470211 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:37:11.470216 22508 solver.cpp:238]     Train net output #2: loss = 0.178202 (* 1 = 0.178202 loss)
I0417 12:37:11.470224 22508 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0417 12:37:33.481613 22508 solver.cpp:219] Iteration 35100 (4.5432 iter/s, 22.0109s/100 iters), loss = 0.172872
I0417 12:37:33.482322 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:37:33.482331 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:37:33.482337 22508 solver.cpp:238]     Train net output #2: loss = 0.172872 (* 1 = 0.172872 loss)
I0417 12:37:33.482342 22508 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0417 12:37:44.879364 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:37:55.416517 22508 solver.cpp:219] Iteration 35200 (4.55919 iter/s, 21.9337s/100 iters), loss = 0.244604
I0417 12:37:55.416566 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:37:55.416574 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:37:55.416579 22508 solver.cpp:238]     Train net output #2: loss = 0.244604 (* 1 = 0.244604 loss)
I0417 12:37:55.416584 22508 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0417 12:38:17.451072 22508 solver.cpp:219] Iteration 35300 (4.53844 iter/s, 22.034s/100 iters), loss = 0.201646
I0417 12:38:17.451256 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:38:17.451266 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:38:17.451272 22508 solver.cpp:238]     Train net output #2: loss = 0.201646 (* 1 = 0.201646 loss)
I0417 12:38:17.451277 22508 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0417 12:38:39.483858 22508 solver.cpp:219] Iteration 35400 (4.53883 iter/s, 22.0321s/100 iters), loss = 0.160632
I0417 12:38:39.484463 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:38:39.484472 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:38:39.484478 22508 solver.cpp:238]     Train net output #2: loss = 0.160632 (* 1 = 0.160632 loss)
I0417 12:38:39.484483 22508 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0417 12:39:01.537751 22508 solver.cpp:219] Iteration 35500 (4.53457 iter/s, 22.0528s/100 iters), loss = 0.171669
I0417 12:39:01.537883 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:39:01.537891 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:39:01.537899 22508 solver.cpp:238]     Train net output #2: loss = 0.171668 (* 1 = 0.171668 loss)
I0417 12:39:01.537902 22508 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0417 12:39:10.794046 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:39:23.586658 22508 solver.cpp:219] Iteration 35600 (4.5355 iter/s, 22.0483s/100 iters), loss = 0.152409
I0417 12:39:23.587060 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:39:23.587069 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:39:23.587075 22508 solver.cpp:238]     Train net output #2: loss = 0.152408 (* 1 = 0.152408 loss)
I0417 12:39:23.587080 22508 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0417 12:39:45.619316 22508 solver.cpp:219] Iteration 35700 (4.5389 iter/s, 22.0318s/100 iters), loss = 0.139671
I0417 12:39:45.619449 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:39:45.619457 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:39:45.619464 22508 solver.cpp:238]     Train net output #2: loss = 0.139671 (* 1 = 0.139671 loss)
I0417 12:39:45.619469 22508 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0417 12:40:07.681356 22508 solver.cpp:219] Iteration 35800 (4.5328 iter/s, 22.0614s/100 iters), loss = 0.180004
I0417 12:40:07.681394 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:40:07.681402 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:40:07.681412 22508 solver.cpp:238]     Train net output #2: loss = 0.180004 (* 1 = 0.180004 loss)
I0417 12:40:07.681418 22508 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0417 12:40:29.765444 22508 solver.cpp:219] Iteration 35900 (4.52825 iter/s, 22.0836s/100 iters), loss = 0.24716
I0417 12:40:29.766146 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 12:40:29.766157 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:40:29.766172 22508 solver.cpp:238]     Train net output #2: loss = 0.24716 (* 1 = 0.24716 loss)
I0417 12:40:29.766180 22508 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0417 12:40:37.044839 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:40:51.602515 22508 solver.cpp:331] Iteration 36000, Testing net (#0)
I0417 12:40:54.564083 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:40:54.685544 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.5944
I0417 12:40:54.685566 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9547
I0417 12:40:54.685575 22508 solver.cpp:398]     Test net output #2: loss = 1.45301 (* 1 = 1.45301 loss)
I0417 12:40:54.905323 22508 solver.cpp:219] Iteration 36000 (3.97794 iter/s, 25.1386s/100 iters), loss = 0.25494
I0417 12:40:54.905344 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:40:54.905349 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:40:54.905354 22508 solver.cpp:238]     Train net output #2: loss = 0.254939 (* 1 = 0.254939 loss)
I0417 12:40:54.905359 22508 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0417 12:41:17.036236 22508 solver.cpp:219] Iteration 36100 (4.51867 iter/s, 22.1304s/100 iters), loss = 0.170863
I0417 12:41:17.036417 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:41:17.036425 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:41:17.036432 22508 solver.cpp:238]     Train net output #2: loss = 0.170863 (* 1 = 0.170863 loss)
I0417 12:41:17.036437 22508 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0417 12:41:39.128069 22508 solver.cpp:219] Iteration 36200 (4.5267 iter/s, 22.0912s/100 iters), loss = 0.206009
I0417 12:41:39.128108 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:41:39.128113 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:41:39.128119 22508 solver.cpp:238]     Train net output #2: loss = 0.206009 (* 1 = 0.206009 loss)
I0417 12:41:39.128123 22508 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0417 12:42:01.209357 22508 solver.cpp:219] Iteration 36300 (4.52883 iter/s, 22.0808s/100 iters), loss = 0.174196
I0417 12:42:01.209499 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:42:01.209507 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:42:01.209514 22508 solver.cpp:238]     Train net output #2: loss = 0.174195 (* 1 = 0.174195 loss)
I0417 12:42:01.209519 22508 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0417 12:42:06.550349 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:42:23.294140 22508 solver.cpp:219] Iteration 36400 (4.52813 iter/s, 22.0842s/100 iters), loss = 0.232241
I0417 12:42:23.294193 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:42:23.294199 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:42:23.294205 22508 solver.cpp:238]     Train net output #2: loss = 0.232241 (* 1 = 0.232241 loss)
I0417 12:42:23.294210 22508 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0417 12:42:45.346918 22508 solver.cpp:219] Iteration 36500 (4.53469 iter/s, 22.0522s/100 iters), loss = 0.202021
I0417 12:42:45.347057 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:42:45.347065 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:42:45.347074 22508 solver.cpp:238]     Train net output #2: loss = 0.20202 (* 1 = 0.20202 loss)
I0417 12:42:45.347077 22508 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0417 12:43:07.395555 22508 solver.cpp:219] Iteration 36600 (4.53556 iter/s, 22.048s/100 iters), loss = 0.281016
I0417 12:43:07.395604 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 12:43:07.395611 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:43:07.395617 22508 solver.cpp:238]     Train net output #2: loss = 0.281016 (* 1 = 0.281016 loss)
I0417 12:43:07.395622 22508 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0417 12:43:29.458423 22508 solver.cpp:219] Iteration 36700 (4.53261 iter/s, 22.0623s/100 iters), loss = 0.329912
I0417 12:43:29.459127 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 12:43:29.459136 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:43:29.459143 22508 solver.cpp:238]     Train net output #2: loss = 0.329912 (* 1 = 0.329912 loss)
I0417 12:43:29.459147 22508 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0417 12:43:32.547448 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:43:51.504817 22508 solver.cpp:219] Iteration 36800 (4.53614 iter/s, 22.0452s/100 iters), loss = 0.171368
I0417 12:43:51.504856 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:43:51.504863 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:43:51.504868 22508 solver.cpp:238]     Train net output #2: loss = 0.171367 (* 1 = 0.171367 loss)
I0417 12:43:51.504873 22508 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0417 12:44:13.575222 22508 solver.cpp:219] Iteration 36900 (4.53107 iter/s, 22.0698s/100 iters), loss = 0.112265
I0417 12:44:13.575935 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:44:13.575945 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:44:13.575953 22508 solver.cpp:238]     Train net output #2: loss = 0.112264 (* 1 = 0.112264 loss)
I0417 12:44:13.575956 22508 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0417 12:44:35.435799 22508 solver.cpp:331] Iteration 37000, Testing net (#0)
I0417 12:44:38.377568 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:44:38.498241 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.6306
I0417 12:44:38.498266 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9499
I0417 12:44:38.498287 22508 solver.cpp:398]     Test net output #2: loss = 1.51311 (* 1 = 1.51311 loss)
I0417 12:44:38.715888 22508 solver.cpp:219] Iteration 37000 (3.97782 iter/s, 25.1394s/100 iters), loss = 0.262552
I0417 12:44:38.715910 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 12:44:38.715916 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:44:38.715922 22508 solver.cpp:238]     Train net output #2: loss = 0.262551 (* 1 = 0.262551 loss)
I0417 12:44:38.715929 22508 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0417 12:45:00.760993 22508 solver.cpp:219] Iteration 37100 (4.53626 iter/s, 22.0446s/100 iters), loss = 0.160602
I0417 12:45:00.761124 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:45:00.761132 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:45:00.761138 22508 solver.cpp:238]     Train net output #2: loss = 0.160602 (* 1 = 0.160602 loss)
I0417 12:45:00.761143 22508 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0417 12:45:01.865419 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:45:22.746562 22508 solver.cpp:219] Iteration 37200 (4.54857 iter/s, 21.9849s/100 iters), loss = 0.154169
I0417 12:45:22.746604 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:45:22.746610 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:45:22.746618 22508 solver.cpp:238]     Train net output #2: loss = 0.154169 (* 1 = 0.154169 loss)
I0417 12:45:22.746623 22508 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0417 12:45:44.737186 22508 solver.cpp:219] Iteration 37300 (4.5475 iter/s, 21.9901s/100 iters), loss = 0.24913
I0417 12:45:44.737303 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:45:44.737309 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:45:44.737318 22508 solver.cpp:238]     Train net output #2: loss = 0.24913 (* 1 = 0.24913 loss)
I0417 12:45:44.737321 22508 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0417 12:46:06.709095 22508 solver.cpp:219] Iteration 37400 (4.55139 iter/s, 21.9713s/100 iters), loss = 0.132773
I0417 12:46:06.709523 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:46:06.709530 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:46:06.709537 22508 solver.cpp:238]     Train net output #2: loss = 0.132773 (* 1 = 0.132773 loss)
I0417 12:46:06.709542 22508 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0417 12:46:27.587712 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:46:28.686450 22508 solver.cpp:219] Iteration 37500 (4.55033 iter/s, 21.9764s/100 iters), loss = 0.172186
I0417 12:46:28.686483 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:46:28.686489 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:46:28.686496 22508 solver.cpp:238]     Train net output #2: loss = 0.172186 (* 1 = 0.172186 loss)
I0417 12:46:28.686499 22508 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0417 12:46:50.620194 22508 solver.cpp:219] Iteration 37600 (4.55929 iter/s, 21.9332s/100 iters), loss = 0.182171
I0417 12:46:50.620229 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:46:50.620234 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:46:50.620241 22508 solver.cpp:238]     Train net output #2: loss = 0.182171 (* 1 = 0.182171 loss)
I0417 12:46:50.620245 22508 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0417 12:47:12.544077 22508 solver.cpp:219] Iteration 37700 (4.56134 iter/s, 21.9234s/100 iters), loss = 0.194935
I0417 12:47:12.544183 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:47:12.544191 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:47:12.544198 22508 solver.cpp:238]     Train net output #2: loss = 0.194934 (* 1 = 0.194934 loss)
I0417 12:47:12.544203 22508 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0417 12:47:34.542491 22508 solver.cpp:219] Iteration 37800 (4.54591 iter/s, 21.9978s/100 iters), loss = 0.232743
I0417 12:47:34.542529 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:47:34.542538 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:47:34.542547 22508 solver.cpp:238]     Train net output #2: loss = 0.232743 (* 1 = 0.232743 loss)
I0417 12:47:34.542554 22508 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0417 12:47:53.434278 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:47:56.513824 22508 solver.cpp:219] Iteration 37900 (4.55149 iter/s, 21.9708s/100 iters), loss = 0.203682
I0417 12:47:56.513860 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:47:56.513866 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:47:56.513872 22508 solver.cpp:238]     Train net output #2: loss = 0.203682 (* 1 = 0.203682 loss)
I0417 12:47:56.513876 22508 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0417 12:48:18.241739 22508 solver.cpp:331] Iteration 38000, Testing net (#0)
I0417 12:48:21.179389 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:48:21.300001 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.695
I0417 12:48:21.300022 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9665
I0417 12:48:21.300042 22508 solver.cpp:398]     Test net output #2: loss = 1.10609 (* 1 = 1.10609 loss)
I0417 12:48:21.518426 22508 solver.cpp:219] Iteration 38000 (3.99936 iter/s, 25.004s/100 iters), loss = 0.233977
I0417 12:48:21.518446 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:48:21.518451 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:48:21.518456 22508 solver.cpp:238]     Train net output #2: loss = 0.233977 (* 1 = 0.233977 loss)
I0417 12:48:21.518462 22508 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0417 12:48:43.474225 22508 solver.cpp:219] Iteration 38100 (4.55471 iter/s, 21.9553s/100 iters), loss = 0.212558
I0417 12:48:43.474339 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:48:43.474346 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:48:43.474352 22508 solver.cpp:238]     Train net output #2: loss = 0.212558 (* 1 = 0.212558 loss)
I0417 12:48:43.474359 22508 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0417 12:49:05.444967 22508 solver.cpp:219] Iteration 38200 (4.55163 iter/s, 21.9701s/100 iters), loss = 0.245456
I0417 12:49:05.444994 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:49:05.444999 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:49:05.445004 22508 solver.cpp:238]     Train net output #2: loss = 0.245455 (* 1 = 0.245455 loss)
I0417 12:49:05.445008 22508 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0417 12:49:22.364156 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:49:27.415933 22508 solver.cpp:219] Iteration 38300 (4.55157 iter/s, 21.9705s/100 iters), loss = 0.218319
I0417 12:49:27.415979 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:49:27.415985 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:49:27.415992 22508 solver.cpp:238]     Train net output #2: loss = 0.218319 (* 1 = 0.218319 loss)
I0417 12:49:27.415997 22508 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0417 12:49:49.359858 22508 solver.cpp:219] Iteration 38400 (4.55718 iter/s, 21.9434s/100 iters), loss = 0.241637
I0417 12:49:49.359907 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:49:49.359913 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:49:49.359920 22508 solver.cpp:238]     Train net output #2: loss = 0.241637 (* 1 = 0.241637 loss)
I0417 12:49:49.359925 22508 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0417 12:50:11.282523 22508 solver.cpp:219] Iteration 38500 (4.5616 iter/s, 21.9221s/100 iters), loss = 0.165937
I0417 12:50:11.282651 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:50:11.282660 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:50:11.282667 22508 solver.cpp:238]     Train net output #2: loss = 0.165936 (* 1 = 0.165936 loss)
I0417 12:50:11.282671 22508 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0417 12:50:33.249662 22508 solver.cpp:219] Iteration 38600 (4.55238 iter/s, 21.9665s/100 iters), loss = 0.249601
I0417 12:50:33.250241 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:50:33.250248 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:50:33.250254 22508 solver.cpp:238]     Train net output #2: loss = 0.249601 (* 1 = 0.249601 loss)
I0417 12:50:33.250259 22508 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0417 12:50:47.961001 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:50:55.215447 22508 solver.cpp:219] Iteration 38700 (4.55275 iter/s, 21.9647s/100 iters), loss = 0.180409
I0417 12:50:55.215487 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:50:55.215492 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:50:55.215498 22508 solver.cpp:238]     Train net output #2: loss = 0.180409 (* 1 = 0.180409 loss)
I0417 12:50:55.215503 22508 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0417 12:51:17.190989 22508 solver.cpp:219] Iteration 38800 (4.55062 iter/s, 21.975s/100 iters), loss = 0.206701
I0417 12:51:17.191023 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:51:17.191030 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:51:17.191035 22508 solver.cpp:238]     Train net output #2: loss = 0.206701 (* 1 = 0.206701 loss)
I0417 12:51:17.191040 22508 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0417 12:51:39.258527 22508 solver.cpp:219] Iteration 38900 (4.53165 iter/s, 22.067s/100 iters), loss = 0.15273
I0417 12:51:39.259232 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:51:39.259241 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:51:39.259248 22508 solver.cpp:238]     Train net output #2: loss = 0.15273 (* 1 = 0.15273 loss)
I0417 12:51:39.259253 22508 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0417 12:52:01.114557 22508 solver.cpp:331] Iteration 39000, Testing net (#0)
I0417 12:52:04.053004 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:52:04.173632 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.4796
I0417 12:52:04.173661 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.8933
I0417 12:52:04.173681 22508 solver.cpp:398]     Test net output #2: loss = 1.95405 (* 1 = 1.95405 loss)
I0417 12:52:04.391649 22508 solver.cpp:219] Iteration 39000 (3.97901 iter/s, 25.1319s/100 iters), loss = 0.15863
I0417 12:52:04.391669 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 12:52:04.391674 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:52:04.391680 22508 solver.cpp:238]     Train net output #2: loss = 0.158629 (* 1 = 0.158629 loss)
I0417 12:52:04.391685 22508 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0417 12:52:17.185736 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:52:26.456856 22508 solver.cpp:219] Iteration 39100 (4.53213 iter/s, 22.0647s/100 iters), loss = 0.161672
I0417 12:52:26.456894 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:52:26.456900 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:52:26.456907 22508 solver.cpp:238]     Train net output #2: loss = 0.161671 (* 1 = 0.161671 loss)
I0417 12:52:26.456912 22508 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0417 12:52:48.530761 22508 solver.cpp:219] Iteration 39200 (4.53034 iter/s, 22.0734s/100 iters), loss = 0.204056
I0417 12:52:48.530874 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:52:48.530882 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:52:48.530890 22508 solver.cpp:238]     Train net output #2: loss = 0.204056 (* 1 = 0.204056 loss)
I0417 12:52:48.530895 22508 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0417 12:53:10.591621 22508 solver.cpp:219] Iteration 39300 (4.53304 iter/s, 22.0603s/100 iters), loss = 0.162148
I0417 12:53:10.591663 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0417 12:53:10.591670 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:53:10.591676 22508 solver.cpp:238]     Train net output #2: loss = 0.162148 (* 1 = 0.162148 loss)
I0417 12:53:10.591681 22508 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0417 12:53:32.645845 22508 solver.cpp:219] Iteration 39400 (4.53439 iter/s, 22.0537s/100 iters), loss = 0.213629
I0417 12:53:32.646517 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:53:32.646525 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:53:32.646531 22508 solver.cpp:238]     Train net output #2: loss = 0.213629 (* 1 = 0.213629 loss)
I0417 12:53:32.646535 22508 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0417 12:53:43.445992 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:53:54.640599 22508 solver.cpp:219] Iteration 39500 (4.54678 iter/s, 21.9936s/100 iters), loss = 0.165919
I0417 12:53:54.640631 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:53:54.640637 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:53:54.640643 22508 solver.cpp:238]     Train net output #2: loss = 0.165918 (* 1 = 0.165918 loss)
I0417 12:53:54.640647 22508 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0417 12:54:16.593971 22508 solver.cpp:219] Iteration 39600 (4.55522 iter/s, 21.9529s/100 iters), loss = 0.205427
I0417 12:54:16.594100 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:54:16.594108 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:54:16.594115 22508 solver.cpp:238]     Train net output #2: loss = 0.205426 (* 1 = 0.205426 loss)
I0417 12:54:16.594120 22508 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0417 12:54:38.553993 22508 solver.cpp:219] Iteration 39700 (4.55386 iter/s, 21.9594s/100 iters), loss = 0.14308
I0417 12:54:38.554041 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0417 12:54:38.554047 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:54:38.554054 22508 solver.cpp:238]     Train net output #2: loss = 0.14308 (* 1 = 0.14308 loss)
I0417 12:54:38.554059 22508 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0417 12:55:00.518172 22508 solver.cpp:219] Iteration 39800 (4.55298 iter/s, 21.9636s/100 iters), loss = 0.21662
I0417 12:55:00.518271 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:55:00.518280 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:55:00.518287 22508 solver.cpp:238]     Train net output #2: loss = 0.21662 (* 1 = 0.21662 loss)
I0417 12:55:00.518291 22508 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0417 12:55:09.077349 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:55:22.475839 22508 solver.cpp:219] Iteration 39900 (4.55434 iter/s, 21.9571s/100 iters), loss = 0.1867
I0417 12:55:22.476397 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:55:22.476403 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:55:22.476410 22508 solver.cpp:238]     Train net output #2: loss = 0.186699 (* 1 = 0.186699 loss)
I0417 12:55:22.476414 22508 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0417 12:55:44.244118 22508 solver.cpp:448] Snapshotting to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_40000.caffemodel
I0417 12:55:44.251230 22508 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_40000.solverstate
I0417 12:55:44.253268 22508 solver.cpp:331] Iteration 40000, Testing net (#0)
I0417 12:55:47.200965 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:55:47.322091 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.2945
I0417 12:55:47.322116 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.8257
I0417 12:55:47.322124 22508 solver.cpp:398]     Test net output #2: loss = 3.62873 (* 1 = 3.62873 loss)
I0417 12:55:47.539469 22508 solver.cpp:219] Iteration 40000 (3.99002 iter/s, 25.0625s/100 iters), loss = 0.158322
I0417 12:55:47.539489 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:55:47.539494 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:55:47.539499 22508 solver.cpp:238]     Train net output #2: loss = 0.158322 (* 1 = 0.158322 loss)
I0417 12:55:47.539505 22508 sgd_solver.cpp:105] Iteration 40000, lr = 0.1
I0417 12:56:09.479715 22508 solver.cpp:219] Iteration 40100 (4.55794 iter/s, 21.9397s/100 iters), loss = 0.280631
I0417 12:56:09.479753 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 12:56:09.479758 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:56:09.479764 22508 solver.cpp:238]     Train net output #2: loss = 0.280631 (* 1 = 0.280631 loss)
I0417 12:56:09.479768 22508 sgd_solver.cpp:105] Iteration 40100, lr = 0.1
I0417 12:56:31.435230 22508 solver.cpp:219] Iteration 40200 (4.55477 iter/s, 21.955s/100 iters), loss = 0.167503
I0417 12:56:31.435950 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:56:31.435957 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:56:31.435963 22508 solver.cpp:238]     Train net output #2: loss = 0.167503 (* 1 = 0.167503 loss)
I0417 12:56:31.435967 22508 sgd_solver.cpp:105] Iteration 40200, lr = 0.1
I0417 12:56:38.018898 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:56:53.365860 22508 solver.cpp:219] Iteration 40300 (4.56008 iter/s, 21.9294s/100 iters), loss = 0.237919
I0417 12:56:53.365898 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 12:56:53.365903 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 12:56:53.365911 22508 solver.cpp:238]     Train net output #2: loss = 0.237919 (* 1 = 0.237919 loss)
I0417 12:56:53.365914 22508 sgd_solver.cpp:105] Iteration 40300, lr = 0.1
I0417 12:57:15.303501 22508 solver.cpp:219] Iteration 40400 (4.55848 iter/s, 21.9371s/100 iters), loss = 0.210752
I0417 12:57:15.303635 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 12:57:15.303643 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:57:15.303650 22508 solver.cpp:238]     Train net output #2: loss = 0.210751 (* 1 = 0.210751 loss)
I0417 12:57:15.303654 22508 sgd_solver.cpp:105] Iteration 40400, lr = 0.1
I0417 12:57:37.262202 22508 solver.cpp:219] Iteration 40500 (4.55413 iter/s, 21.9581s/100 iters), loss = 0.257684
I0417 12:57:37.262233 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:57:37.262238 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:57:37.262244 22508 solver.cpp:238]     Train net output #2: loss = 0.257683 (* 1 = 0.257683 loss)
I0417 12:57:37.262248 22508 sgd_solver.cpp:105] Iteration 40500, lr = 0.1
I0417 12:57:59.241827 22508 solver.cpp:219] Iteration 40600 (4.54978 iter/s, 21.9791s/100 iters), loss = 0.241412
I0417 12:57:59.241976 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 12:57:59.241986 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:57:59.241991 22508 solver.cpp:238]     Train net output #2: loss = 0.241412 (* 1 = 0.241412 loss)
I0417 12:57:59.241997 22508 sgd_solver.cpp:105] Iteration 40600, lr = 0.1
I0417 12:58:03.639654 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:58:21.194473 22508 solver.cpp:219] Iteration 40700 (4.55539 iter/s, 21.952s/100 iters), loss = 0.168713
I0417 12:58:21.194512 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 12:58:21.194519 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:58:21.194525 22508 solver.cpp:238]     Train net output #2: loss = 0.168713 (* 1 = 0.168713 loss)
I0417 12:58:21.194528 22508 sgd_solver.cpp:105] Iteration 40700, lr = 0.1
I0417 12:58:43.138326 22508 solver.cpp:219] Iteration 40800 (4.5572 iter/s, 21.9433s/100 iters), loss = 0.212552
I0417 12:58:43.138478 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 12:58:43.138485 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:58:43.138492 22508 solver.cpp:238]     Train net output #2: loss = 0.212552 (* 1 = 0.212552 loss)
I0417 12:58:43.138496 22508 sgd_solver.cpp:105] Iteration 40800, lr = 0.1
I0417 12:59:05.056267 22508 solver.cpp:219] Iteration 40900 (4.5626 iter/s, 21.9173s/100 iters), loss = 0.117055
I0417 12:59:05.056303 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0417 12:59:05.056309 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:59:05.056315 22508 solver.cpp:238]     Train net output #2: loss = 0.117055 (* 1 = 0.117055 loss)
I0417 12:59:05.056319 22508 sgd_solver.cpp:105] Iteration 40900, lr = 0.1
I0417 12:59:26.747087 22508 solver.cpp:331] Iteration 41000, Testing net (#0)
I0417 12:59:29.698676 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:59:29.819893 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.5078
I0417 12:59:29.819921 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.884
I0417 12:59:29.819941 22508 solver.cpp:398]     Test net output #2: loss = 2.25393 (* 1 = 2.25393 loss)
I0417 12:59:30.038000 22508 solver.cpp:219] Iteration 41000 (4.00302 iter/s, 24.9811s/100 iters), loss = 0.23024
I0417 12:59:30.038033 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 12:59:30.038038 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:59:30.038044 22508 solver.cpp:238]     Train net output #2: loss = 0.23024 (* 1 = 0.23024 loss)
I0417 12:59:30.038050 22508 sgd_solver.cpp:105] Iteration 41000, lr = 0.1
I0417 12:59:32.453984 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 12:59:51.968433 22508 solver.cpp:219] Iteration 41100 (4.55998 iter/s, 21.9299s/100 iters), loss = 0.170144
I0417 12:59:51.968485 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 12:59:51.968492 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 12:59:51.968498 22508 solver.cpp:238]     Train net output #2: loss = 0.170144 (* 1 = 0.170144 loss)
I0417 12:59:51.968503 22508 sgd_solver.cpp:105] Iteration 41100, lr = 0.1
I0417 13:00:13.946285 22508 solver.cpp:219] Iteration 41200 (4.55015 iter/s, 21.9773s/100 iters), loss = 0.143926
I0417 13:00:13.946439 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 13:00:13.946447 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:00:13.946455 22508 solver.cpp:238]     Train net output #2: loss = 0.143926 (* 1 = 0.143926 loss)
I0417 13:00:13.946461 22508 sgd_solver.cpp:105] Iteration 41200, lr = 0.1
I0417 13:00:35.980011 22508 solver.cpp:219] Iteration 41300 (4.53863 iter/s, 22.0331s/100 iters), loss = 0.139999
I0417 13:00:35.980048 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0417 13:00:35.980054 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:00:35.980060 22508 solver.cpp:238]     Train net output #2: loss = 0.139999 (* 1 = 0.139999 loss)
I0417 13:00:35.980065 22508 sgd_solver.cpp:105] Iteration 41300, lr = 0.1
I0417 13:00:58.069212 22508 solver.cpp:219] Iteration 41400 (4.52721 iter/s, 22.0887s/100 iters), loss = 0.202248
I0417 13:00:58.069381 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 13:00:58.069391 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:00:58.069398 22508 solver.cpp:238]     Train net output #2: loss = 0.202247 (* 1 = 0.202247 loss)
I0417 13:00:58.069402 22508 sgd_solver.cpp:105] Iteration 41400, lr = 0.1
I0417 13:00:58.516201 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:01:20.165663 22508 solver.cpp:219] Iteration 41500 (4.52575 iter/s, 22.0958s/100 iters), loss = 0.226711
I0417 13:01:20.166200 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 13:01:20.166208 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 13:01:20.166215 22508 solver.cpp:238]     Train net output #2: loss = 0.22671 (* 1 = 0.22671 loss)
I0417 13:01:20.166220 22508 sgd_solver.cpp:105] Iteration 41500, lr = 0.1
I0417 13:01:42.234151 22508 solver.cpp:219] Iteration 41600 (4.53156 iter/s, 22.0675s/100 iters), loss = 0.262896
I0417 13:01:42.234302 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 13:01:42.234309 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 13:01:42.234316 22508 solver.cpp:238]     Train net output #2: loss = 0.262896 (* 1 = 0.262896 loss)
I0417 13:01:42.234321 22508 sgd_solver.cpp:105] Iteration 41600, lr = 0.1
I0417 13:02:04.322291 22508 solver.cpp:219] Iteration 41700 (4.52745 iter/s, 22.0875s/100 iters), loss = 0.156167
I0417 13:02:04.322331 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:02:04.322338 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:02:04.322345 22508 solver.cpp:238]     Train net output #2: loss = 0.156166 (* 1 = 0.156166 loss)
I0417 13:02:04.322350 22508 sgd_solver.cpp:105] Iteration 41700, lr = 0.1
I0417 13:02:24.586499 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:02:26.332689 22508 solver.cpp:219] Iteration 41800 (4.54342 iter/s, 22.0099s/100 iters), loss = 0.179377
I0417 13:02:26.332722 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 13:02:26.332728 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:02:26.332734 22508 solver.cpp:238]     Train net output #2: loss = 0.179377 (* 1 = 0.179377 loss)
I0417 13:02:26.332738 22508 sgd_solver.cpp:105] Iteration 41800, lr = 0.1
I0417 13:02:48.338452 22508 solver.cpp:219] Iteration 41900 (4.54437 iter/s, 22.0052s/100 iters), loss = 0.249127
I0417 13:02:48.338500 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 13:02:48.338505 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:02:48.338512 22508 solver.cpp:238]     Train net output #2: loss = 0.249127 (* 1 = 0.249127 loss)
I0417 13:02:48.338517 22508 sgd_solver.cpp:105] Iteration 41900, lr = 0.1
I0417 13:03:10.071650 22508 solver.cpp:331] Iteration 42000, Testing net (#0)
I0417 13:03:13.010551 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:03:13.131145 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.2207
I0417 13:03:13.131183 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.5809
I0417 13:03:13.131191 22508 solver.cpp:398]     Test net output #2: loss = 4.16503 (* 1 = 4.16503 loss)
I0417 13:03:13.348721 22508 solver.cpp:219] Iteration 42000 (3.99845 iter/s, 25.0097s/100 iters), loss = 0.131002
I0417 13:03:13.348745 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 13:03:13.348752 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:03:13.348757 22508 solver.cpp:238]     Train net output #2: loss = 0.131002 (* 1 = 0.131002 loss)
I0417 13:03:13.348763 22508 sgd_solver.cpp:105] Iteration 42000, lr = 0.1
I0417 13:03:35.354192 22508 solver.cpp:219] Iteration 42100 (4.54443 iter/s, 22.005s/100 iters), loss = 0.270782
I0417 13:03:35.354756 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 13:03:35.354763 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:03:35.354770 22508 solver.cpp:238]     Train net output #2: loss = 0.270782 (* 1 = 0.270782 loss)
I0417 13:03:35.354774 22508 sgd_solver.cpp:105] Iteration 42100, lr = 0.1
I0417 13:03:53.587214 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:03:57.310359 22508 solver.cpp:219] Iteration 42200 (4.55475 iter/s, 21.9551s/100 iters), loss = 0.301366
I0417 13:03:57.310402 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 13:03:57.310408 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:03:57.310415 22508 solver.cpp:238]     Train net output #2: loss = 0.301366 (* 1 = 0.301366 loss)
I0417 13:03:57.310420 22508 sgd_solver.cpp:105] Iteration 42200, lr = 0.1
I0417 13:04:19.261288 22508 solver.cpp:219] Iteration 42300 (4.55572 iter/s, 21.9504s/100 iters), loss = 0.176113
I0417 13:04:19.261807 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 13:04:19.261814 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:04:19.261821 22508 solver.cpp:238]     Train net output #2: loss = 0.176113 (* 1 = 0.176113 loss)
I0417 13:04:19.261826 22508 sgd_solver.cpp:105] Iteration 42300, lr = 0.1
I0417 13:04:41.208402 22508 solver.cpp:219] Iteration 42400 (4.55662 iter/s, 21.9461s/100 iters), loss = 0.171367
I0417 13:04:41.208540 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:04:41.208547 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:04:41.208554 22508 solver.cpp:238]     Train net output #2: loss = 0.171367 (* 1 = 0.171367 loss)
I0417 13:04:41.208559 22508 sgd_solver.cpp:105] Iteration 42400, lr = 0.1
I0417 13:05:03.174770 22508 solver.cpp:219] Iteration 42500 (4.55254 iter/s, 21.9657s/100 iters), loss = 0.0969295
I0417 13:05:03.174823 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0417 13:05:03.174829 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:05:03.174836 22508 solver.cpp:238]     Train net output #2: loss = 0.0969292 (* 1 = 0.0969292 loss)
I0417 13:05:03.174840 22508 sgd_solver.cpp:105] Iteration 42500, lr = 0.1
I0417 13:05:19.433526 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:05:25.163185 22508 solver.cpp:219] Iteration 42600 (4.54796 iter/s, 21.9879s/100 iters), loss = 0.178192
I0417 13:05:25.163221 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 13:05:25.163226 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:05:25.163233 22508 solver.cpp:238]     Train net output #2: loss = 0.178191 (* 1 = 0.178191 loss)
I0417 13:05:25.163238 22508 sgd_solver.cpp:105] Iteration 42600, lr = 0.1
I0417 13:05:47.072386 22508 solver.cpp:219] Iteration 42700 (4.5644 iter/s, 21.9087s/100 iters), loss = 0.208964
I0417 13:05:47.072423 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 13:05:47.072428 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:05:47.072435 22508 solver.cpp:238]     Train net output #2: loss = 0.208964 (* 1 = 0.208964 loss)
I0417 13:05:47.072439 22508 sgd_solver.cpp:105] Iteration 42700, lr = 0.1
I0417 13:06:09.052309 22508 solver.cpp:219] Iteration 42800 (4.54972 iter/s, 21.9794s/100 iters), loss = 0.170493
I0417 13:06:09.052412 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 13:06:09.052420 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:06:09.052428 22508 solver.cpp:238]     Train net output #2: loss = 0.170493 (* 1 = 0.170493 loss)
I0417 13:06:09.052433 22508 sgd_solver.cpp:105] Iteration 42800, lr = 0.1
I0417 13:06:31.043540 22508 solver.cpp:219] Iteration 42900 (4.54739 iter/s, 21.9906s/100 iters), loss = 0.133512
I0417 13:06:31.043576 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 13:06:31.043581 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:06:31.043587 22508 solver.cpp:238]     Train net output #2: loss = 0.133512 (* 1 = 0.133512 loss)
I0417 13:06:31.043591 22508 sgd_solver.cpp:105] Iteration 42900, lr = 0.1
I0417 13:06:45.068287 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:06:52.755187 22508 solver.cpp:331] Iteration 43000, Testing net (#0)
I0417 13:06:55.699141 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:06:55.820407 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.3471
I0417 13:06:55.820435 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.8368
I0417 13:06:55.820454 22508 solver.cpp:398]     Test net output #2: loss = 2.89224 (* 1 = 2.89224 loss)
I0417 13:06:56.038626 22508 solver.cpp:219] Iteration 43000 (4.00088 iter/s, 24.9945s/100 iters), loss = 0.134118
I0417 13:06:56.038661 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 13:06:56.038666 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:06:56.038672 22508 solver.cpp:238]     Train net output #2: loss = 0.134118 (* 1 = 0.134118 loss)
I0417 13:06:56.038678 22508 sgd_solver.cpp:105] Iteration 43000, lr = 0.1
I0417 13:07:18.056721 22508 solver.cpp:219] Iteration 43100 (4.54182 iter/s, 22.0176s/100 iters), loss = 0.160736
I0417 13:07:18.057325 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 13:07:18.057334 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 13:07:18.057340 22508 solver.cpp:238]     Train net output #2: loss = 0.160736 (* 1 = 0.160736 loss)
I0417 13:07:18.057345 22508 sgd_solver.cpp:105] Iteration 43100, lr = 0.1
I0417 13:07:40.006177 22508 solver.cpp:219] Iteration 43200 (4.55615 iter/s, 21.9484s/100 iters), loss = 0.120654
I0417 13:07:40.006769 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 13:07:40.006777 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:07:40.006783 22508 solver.cpp:238]     Train net output #2: loss = 0.120654 (* 1 = 0.120654 loss)
I0417 13:07:40.006788 22508 sgd_solver.cpp:105] Iteration 43200, lr = 0.1
I0417 13:08:01.965936 22508 solver.cpp:219] Iteration 43300 (4.55401 iter/s, 21.9587s/100 iters), loss = 0.236669
I0417 13:08:01.966048 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 13:08:01.966056 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:08:01.966063 22508 solver.cpp:238]     Train net output #2: loss = 0.236669 (* 1 = 0.236669 loss)
I0417 13:08:01.966068 22508 sgd_solver.cpp:105] Iteration 43300, lr = 0.1
I0417 13:08:14.039566 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:08:23.939158 22508 solver.cpp:219] Iteration 43400 (4.55112 iter/s, 21.9726s/100 iters), loss = 0.246004
I0417 13:08:23.939198 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 13:08:23.939204 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:08:23.939211 22508 solver.cpp:238]     Train net output #2: loss = 0.246004 (* 1 = 0.246004 loss)
I0417 13:08:23.939215 22508 sgd_solver.cpp:105] Iteration 43400, lr = 0.1
I0417 13:08:45.893611 22508 solver.cpp:219] Iteration 43500 (4.55499 iter/s, 21.9539s/100 iters), loss = 0.145604
I0417 13:08:45.893752 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 13:08:45.893759 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:08:45.893767 22508 solver.cpp:238]     Train net output #2: loss = 0.145603 (* 1 = 0.145603 loss)
I0417 13:08:45.893772 22508 sgd_solver.cpp:105] Iteration 43500, lr = 0.1
I0417 13:09:07.838871 22508 solver.cpp:219] Iteration 43600 (4.55692 iter/s, 21.9446s/100 iters), loss = 0.211627
I0417 13:09:07.838902 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 13:09:07.838907 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:09:07.838913 22508 solver.cpp:238]     Train net output #2: loss = 0.211627 (* 1 = 0.211627 loss)
I0417 13:09:07.838917 22508 sgd_solver.cpp:105] Iteration 43600, lr = 0.1
I0417 13:09:29.778102 22508 solver.cpp:219] Iteration 43700 (4.55815 iter/s, 21.9387s/100 iters), loss = 0.181873
I0417 13:09:29.778744 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:09:29.778753 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:09:29.778759 22508 solver.cpp:238]     Train net output #2: loss = 0.181872 (* 1 = 0.181872 loss)
I0417 13:09:29.778764 22508 sgd_solver.cpp:105] Iteration 43700, lr = 0.1
I0417 13:09:39.653453 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:09:51.712978 22508 solver.cpp:219] Iteration 43800 (4.55918 iter/s, 21.9338s/100 iters), loss = 0.210151
I0417 13:09:51.713013 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 13:09:51.713019 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:09:51.713026 22508 solver.cpp:238]     Train net output #2: loss = 0.210151 (* 1 = 0.210151 loss)
I0417 13:09:51.713029 22508 sgd_solver.cpp:105] Iteration 43800, lr = 0.1
I0417 13:10:13.661875 22508 solver.cpp:219] Iteration 43900 (4.55614 iter/s, 21.9484s/100 iters), loss = 0.125922
I0417 13:10:13.662358 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 13:10:13.662365 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:10:13.662372 22508 solver.cpp:238]     Train net output #2: loss = 0.125922 (* 1 = 0.125922 loss)
I0417 13:10:13.662376 22508 sgd_solver.cpp:105] Iteration 43900, lr = 0.1
I0417 13:10:35.451583 22508 solver.cpp:331] Iteration 44000, Testing net (#0)
I0417 13:10:38.398536 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:10:38.519235 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.6195
I0417 13:10:38.519260 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9675
I0417 13:10:38.519280 22508 solver.cpp:398]     Test net output #2: loss = 1.82016 (* 1 = 1.82016 loss)
I0417 13:10:38.737658 22508 solver.cpp:219] Iteration 44000 (3.98807 iter/s, 25.0748s/100 iters), loss = 0.27669
I0417 13:10:38.737689 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 13:10:38.737694 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:10:38.737699 22508 solver.cpp:238]     Train net output #2: loss = 0.276689 (* 1 = 0.276689 loss)
I0417 13:10:38.737705 22508 sgd_solver.cpp:105] Iteration 44000, lr = 0.1
I0417 13:11:00.709913 22508 solver.cpp:219] Iteration 44100 (4.5513 iter/s, 21.9718s/100 iters), loss = 0.165432
I0417 13:11:00.710034 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 13:11:00.710042 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:11:00.710048 22508 solver.cpp:238]     Train net output #2: loss = 0.165432 (* 1 = 0.165432 loss)
I0417 13:11:00.710054 22508 sgd_solver.cpp:105] Iteration 44100, lr = 0.1
I0417 13:11:08.604147 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:11:22.705638 22508 solver.cpp:219] Iteration 44200 (4.54646 iter/s, 21.9951s/100 iters), loss = 0.228907
I0417 13:11:22.705677 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 13:11:22.705682 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 13:11:22.705688 22508 solver.cpp:238]     Train net output #2: loss = 0.228907 (* 1 = 0.228907 loss)
I0417 13:11:22.705693 22508 sgd_solver.cpp:105] Iteration 44200, lr = 0.1
I0417 13:11:44.675722 22508 solver.cpp:219] Iteration 44300 (4.55175 iter/s, 21.9696s/100 iters), loss = 0.403095
I0417 13:11:44.676350 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.867188
I0417 13:11:44.676360 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 13:11:44.676367 22508 solver.cpp:238]     Train net output #2: loss = 0.403095 (* 1 = 0.403095 loss)
I0417 13:11:44.676370 22508 sgd_solver.cpp:105] Iteration 44300, lr = 0.1
I0417 13:12:06.689978 22508 solver.cpp:219] Iteration 44400 (4.54274 iter/s, 22.0131s/100 iters), loss = 0.167973
I0417 13:12:06.690013 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 13:12:06.690019 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:12:06.690026 22508 solver.cpp:238]     Train net output #2: loss = 0.167973 (* 1 = 0.167973 loss)
I0417 13:12:06.690031 22508 sgd_solver.cpp:105] Iteration 44400, lr = 0.1
I0417 13:12:28.751426 22508 solver.cpp:219] Iteration 44500 (4.5329 iter/s, 22.0609s/100 iters), loss = 0.220162
I0417 13:12:28.751580 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 13:12:28.751590 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:12:28.751596 22508 solver.cpp:238]     Train net output #2: loss = 0.220161 (* 1 = 0.220161 loss)
I0417 13:12:28.751601 22508 sgd_solver.cpp:105] Iteration 44500, lr = 0.1
I0417 13:12:34.715797 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:12:50.829130 22508 solver.cpp:219] Iteration 44600 (4.52959 iter/s, 22.0771s/100 iters), loss = 0.174044
I0417 13:12:50.829174 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 13:12:50.829183 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:12:50.829192 22508 solver.cpp:238]     Train net output #2: loss = 0.174043 (* 1 = 0.174043 loss)
I0417 13:12:50.829200 22508 sgd_solver.cpp:105] Iteration 44600, lr = 0.1
I0417 13:13:12.872459 22508 solver.cpp:219] Iteration 44700 (4.53663 iter/s, 22.0428s/100 iters), loss = 0.0923163
I0417 13:13:12.872584 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0417 13:13:12.872596 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:13:12.872606 22508 solver.cpp:238]     Train net output #2: loss = 0.092316 (* 1 = 0.092316 loss)
I0417 13:13:12.872614 22508 sgd_solver.cpp:105] Iteration 44700, lr = 0.1
I0417 13:13:34.913249 22508 solver.cpp:219] Iteration 44800 (4.53717 iter/s, 22.0402s/100 iters), loss = 0.217187
I0417 13:13:34.913826 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 13:13:34.913835 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:13:34.913841 22508 solver.cpp:238]     Train net output #2: loss = 0.217186 (* 1 = 0.217186 loss)
I0417 13:13:34.913846 22508 sgd_solver.cpp:105] Iteration 44800, lr = 0.1
I0417 13:13:56.967561 22508 solver.cpp:219] Iteration 44900 (4.53448 iter/s, 22.0532s/100 iters), loss = 0.192746
I0417 13:13:56.967702 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 13:13:56.967710 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:13:56.967717 22508 solver.cpp:238]     Train net output #2: loss = 0.192746 (* 1 = 0.192746 loss)
I0417 13:13:56.967721 22508 sgd_solver.cpp:105] Iteration 44900, lr = 0.1
I0417 13:14:00.725903 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:14:18.825551 22508 solver.cpp:331] Iteration 45000, Testing net (#0)
I0417 13:14:21.773308 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:14:21.894289 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.3472
I0417 13:14:21.894317 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.7369
I0417 13:14:21.894336 22508 solver.cpp:398]     Test net output #2: loss = 3.59457 (* 1 = 3.59457 loss)
I0417 13:14:22.112181 22508 solver.cpp:219] Iteration 45000 (3.9771 iter/s, 25.1439s/100 iters), loss = 0.255781
I0417 13:14:22.112215 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 13:14:22.112220 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:14:22.112226 22508 solver.cpp:238]     Train net output #2: loss = 0.25578 (* 1 = 0.25578 loss)
I0417 13:14:22.112232 22508 sgd_solver.cpp:105] Iteration 45000, lr = 0.1
I0417 13:14:44.141118 22508 solver.cpp:219] Iteration 45100 (4.53959 iter/s, 22.0284s/100 iters), loss = 0.131189
I0417 13:14:44.141286 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 13:14:44.141295 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:14:44.141302 22508 solver.cpp:238]     Train net output #2: loss = 0.131189 (* 1 = 0.131189 loss)
I0417 13:14:44.141306 22508 sgd_solver.cpp:105] Iteration 45100, lr = 0.1
I0417 13:15:06.238884 22508 solver.cpp:219] Iteration 45200 (4.52548 iter/s, 22.0971s/100 iters), loss = 0.176607
I0417 13:15:06.238920 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:15:06.238926 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:15:06.238932 22508 solver.cpp:238]     Train net output #2: loss = 0.176607 (* 1 = 0.176607 loss)
I0417 13:15:06.238937 22508 sgd_solver.cpp:105] Iteration 45200, lr = 0.1
I0417 13:15:28.321979 22508 solver.cpp:219] Iteration 45300 (4.52846 iter/s, 22.0826s/100 iters), loss = 0.22151
I0417 13:15:28.322120 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:15:28.322129 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:15:28.322135 22508 solver.cpp:238]     Train net output #2: loss = 0.221509 (* 1 = 0.221509 loss)
I0417 13:15:28.322139 22508 sgd_solver.cpp:105] Iteration 45300, lr = 0.1
I0417 13:15:30.097746 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:15:50.406484 22508 solver.cpp:219] Iteration 45400 (4.52819 iter/s, 22.0839s/100 iters), loss = 0.207759
I0417 13:15:50.406522 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:15:50.406528 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:15:50.406534 22508 solver.cpp:238]     Train net output #2: loss = 0.207759 (* 1 = 0.207759 loss)
I0417 13:15:50.406539 22508 sgd_solver.cpp:105] Iteration 45400, lr = 0.1
I0417 13:16:12.435678 22508 solver.cpp:219] Iteration 45500 (4.53954 iter/s, 22.0287s/100 iters), loss = 0.282873
I0417 13:16:12.435811 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.875
I0417 13:16:12.435818 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:16:12.435825 22508 solver.cpp:238]     Train net output #2: loss = 0.282873 (* 1 = 0.282873 loss)
I0417 13:16:12.435830 22508 sgd_solver.cpp:105] Iteration 45500, lr = 0.1
I0417 13:16:34.501031 22508 solver.cpp:219] Iteration 45600 (4.53212 iter/s, 22.0647s/100 iters), loss = 0.259075
I0417 13:16:34.501070 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.882812
I0417 13:16:34.501075 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:16:34.501081 22508 solver.cpp:238]     Train net output #2: loss = 0.259075 (* 1 = 0.259075 loss)
I0417 13:16:34.501086 22508 sgd_solver.cpp:105] Iteration 45600, lr = 0.1
I0417 13:16:56.339117 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:16:56.556491 22508 solver.cpp:219] Iteration 45700 (4.53413 iter/s, 22.0549s/100 iters), loss = 0.195159
I0417 13:16:56.556520 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:16:56.556526 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:16:56.556532 22508 solver.cpp:238]     Train net output #2: loss = 0.195159 (* 1 = 0.195159 loss)
I0417 13:16:56.556536 22508 sgd_solver.cpp:105] Iteration 45700, lr = 0.1
I0417 13:17:18.639765 22508 solver.cpp:219] Iteration 45800 (4.52842 iter/s, 22.0828s/100 iters), loss = 0.212821
I0417 13:17:18.639816 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:17:18.639822 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:17:18.639829 22508 solver.cpp:238]     Train net output #2: loss = 0.212821 (* 1 = 0.212821 loss)
I0417 13:17:18.639833 22508 sgd_solver.cpp:105] Iteration 45800, lr = 0.1
I0417 13:17:40.676933 22508 solver.cpp:219] Iteration 45900 (4.5379 iter/s, 22.0366s/100 iters), loss = 0.298319
I0417 13:17:40.677085 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 13:17:40.677094 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:17:40.677100 22508 solver.cpp:238]     Train net output #2: loss = 0.298318 (* 1 = 0.298318 loss)
I0417 13:17:40.677105 22508 sgd_solver.cpp:105] Iteration 45900, lr = 0.1
I0417 13:18:02.535624 22508 solver.cpp:331] Iteration 46000, Testing net (#0)
I0417 13:18:05.476274 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:18:05.596755 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.6078
I0417 13:18:05.596781 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9539
I0417 13:18:05.596799 22508 solver.cpp:398]     Test net output #2: loss = 1.7095 (* 1 = 1.7095 loss)
I0417 13:18:05.814188 22508 solver.cpp:219] Iteration 46000 (3.97827 iter/s, 25.1366s/100 iters), loss = 0.282434
I0417 13:18:05.814223 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 13:18:05.814227 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:18:05.814234 22508 solver.cpp:238]     Train net output #2: loss = 0.282434 (* 1 = 0.282434 loss)
I0417 13:18:05.814239 22508 sgd_solver.cpp:105] Iteration 46000, lr = 0.1
I0417 13:18:25.460531 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:18:27.887326 22508 solver.cpp:219] Iteration 46100 (4.5305 iter/s, 22.0726s/100 iters), loss = 0.165197
I0417 13:18:27.887372 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 13:18:27.887378 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:18:27.887384 22508 solver.cpp:238]     Train net output #2: loss = 0.165197 (* 1 = 0.165197 loss)
I0417 13:18:27.887389 22508 sgd_solver.cpp:105] Iteration 46100, lr = 0.1
I0417 13:18:49.946494 22508 solver.cpp:219] Iteration 46200 (4.53337 iter/s, 22.0586s/100 iters), loss = 0.313336
I0417 13:18:49.946532 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.898438
I0417 13:18:49.946538 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:18:49.946544 22508 solver.cpp:238]     Train net output #2: loss = 0.313336 (* 1 = 0.313336 loss)
I0417 13:18:49.946549 22508 sgd_solver.cpp:105] Iteration 46200, lr = 0.1
I0417 13:19:12.010089 22508 solver.cpp:219] Iteration 46300 (4.53246 iter/s, 22.0631s/100 iters), loss = 0.12485
I0417 13:19:12.010241 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:19:12.010249 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:19:12.010257 22508 solver.cpp:238]     Train net output #2: loss = 0.12485 (* 1 = 0.12485 loss)
I0417 13:19:12.010262 22508 sgd_solver.cpp:105] Iteration 46300, lr = 0.1
I0417 13:19:33.916191 22508 solver.cpp:219] Iteration 46400 (4.56507 iter/s, 21.9055s/100 iters), loss = 0.201411
I0417 13:19:33.916781 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:19:33.916790 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:19:33.916796 22508 solver.cpp:238]     Train net output #2: loss = 0.20141 (* 1 = 0.20141 loss)
I0417 13:19:33.916800 22508 sgd_solver.cpp:105] Iteration 46400, lr = 0.1
I0417 13:19:51.568312 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:19:55.975329 22508 solver.cpp:219] Iteration 46500 (4.53349 iter/s, 22.0581s/100 iters), loss = 0.175432
I0417 13:19:55.975363 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:19:55.975370 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:19:55.975376 22508 solver.cpp:238]     Train net output #2: loss = 0.175431 (* 1 = 0.175431 loss)
I0417 13:19:55.975380 22508 sgd_solver.cpp:105] Iteration 46500, lr = 0.1
I0417 13:20:17.992946 22508 solver.cpp:219] Iteration 46600 (4.54193 iter/s, 22.0171s/100 iters), loss = 0.162507
I0417 13:20:17.993408 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 13:20:17.993417 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:20:17.993423 22508 solver.cpp:238]     Train net output #2: loss = 0.162507 (* 1 = 0.162507 loss)
I0417 13:20:17.993427 22508 sgd_solver.cpp:105] Iteration 46600, lr = 0.1
I0417 13:20:39.947113 22508 solver.cpp:219] Iteration 46700 (4.55514 iter/s, 21.9532s/100 iters), loss = 0.208304
I0417 13:20:39.947281 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 13:20:39.947290 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:20:39.947296 22508 solver.cpp:238]     Train net output #2: loss = 0.208304 (* 1 = 0.208304 loss)
I0417 13:20:39.947301 22508 sgd_solver.cpp:105] Iteration 46700, lr = 0.1
I0417 13:21:01.949226 22508 solver.cpp:219] Iteration 46800 (4.54515 iter/s, 22.0015s/100 iters), loss = 0.273882
I0417 13:21:01.949265 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.90625
I0417 13:21:01.949270 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:21:01.949277 22508 solver.cpp:238]     Train net output #2: loss = 0.273882 (* 1 = 0.273882 loss)
I0417 13:21:01.949281 22508 sgd_solver.cpp:105] Iteration 46800, lr = 0.1
I0417 13:21:17.309161 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:21:23.907323 22508 solver.cpp:219] Iteration 46900 (4.55424 iter/s, 21.9576s/100 iters), loss = 0.204315
I0417 13:21:23.907356 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 13:21:23.907362 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.984375
I0417 13:21:23.907369 22508 solver.cpp:238]     Train net output #2: loss = 0.204315 (* 1 = 0.204315 loss)
I0417 13:21:23.907373 22508 sgd_solver.cpp:105] Iteration 46900, lr = 0.1
I0417 13:21:45.632984 22508 solver.cpp:331] Iteration 47000, Testing net (#0)
I0417 13:21:48.577517 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:21:48.698627 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.607
I0417 13:21:48.698653 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9396
I0417 13:21:48.698673 22508 solver.cpp:398]     Test net output #2: loss = 1.86794 (* 1 = 1.86794 loss)
I0417 13:21:48.916357 22508 solver.cpp:219] Iteration 47000 (3.99865 iter/s, 25.0085s/100 iters), loss = 0.314757
I0417 13:21:48.916389 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.890625
I0417 13:21:48.916394 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 13:21:48.916400 22508 solver.cpp:238]     Train net output #2: loss = 0.314757 (* 1 = 0.314757 loss)
I0417 13:21:48.916406 22508 sgd_solver.cpp:105] Iteration 47000, lr = 0.1
I0417 13:22:10.877014 22508 solver.cpp:219] Iteration 47100 (4.55371 iter/s, 21.9601s/100 iters), loss = 0.146948
I0417 13:22:10.877053 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 13:22:10.877059 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:22:10.877065 22508 solver.cpp:238]     Train net output #2: loss = 0.146948 (* 1 = 0.146948 loss)
I0417 13:22:10.877069 22508 sgd_solver.cpp:105] Iteration 47100, lr = 0.1
I0417 13:22:32.884408 22508 solver.cpp:219] Iteration 47200 (4.54404 iter/s, 22.0069s/100 iters), loss = 0.178808
I0417 13:22:32.884557 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.929688
I0417 13:22:32.884565 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:22:32.884572 22508 solver.cpp:238]     Train net output #2: loss = 0.178808 (* 1 = 0.178808 loss)
I0417 13:22:32.884577 22508 sgd_solver.cpp:105] Iteration 47200, lr = 0.1
I0417 13:22:46.264363 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:22:54.831099 22508 solver.cpp:219] Iteration 47300 (4.55663 iter/s, 21.9461s/100 iters), loss = 0.249235
I0417 13:22:54.831137 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.921875
I0417 13:22:54.831143 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:22:54.831149 22508 solver.cpp:238]     Train net output #2: loss = 0.249234 (* 1 = 0.249234 loss)
I0417 13:22:54.831153 22508 sgd_solver.cpp:105] Iteration 47300, lr = 0.1
I0417 13:23:16.832686 22508 solver.cpp:219] Iteration 47400 (4.54524 iter/s, 22.0011s/100 iters), loss = 0.138771
I0417 13:23:16.832820 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 13:23:16.832828 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:23:16.832834 22508 solver.cpp:238]     Train net output #2: loss = 0.138771 (* 1 = 0.138771 loss)
I0417 13:23:16.832839 22508 sgd_solver.cpp:105] Iteration 47400, lr = 0.1
I0417 13:23:38.812052 22508 solver.cpp:219] Iteration 47500 (4.54985 iter/s, 21.9787s/100 iters), loss = 0.226811
I0417 13:23:38.812090 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:23:38.812096 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:23:38.812103 22508 solver.cpp:238]     Train net output #2: loss = 0.226811 (* 1 = 0.226811 loss)
I0417 13:23:38.812106 22508 sgd_solver.cpp:105] Iteration 47500, lr = 0.1
I0417 13:24:00.785094 22508 solver.cpp:219] Iteration 47600 (4.55114 iter/s, 21.9725s/100 iters), loss = 0.155387
I0417 13:24:00.785255 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 13:24:00.785265 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:24:00.785271 22508 solver.cpp:238]     Train net output #2: loss = 0.155386 (* 1 = 0.155386 loss)
I0417 13:24:00.785276 22508 sgd_solver.cpp:105] Iteration 47600, lr = 0.1
I0417 13:24:12.180474 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:24:22.743520 22508 solver.cpp:219] Iteration 47700 (4.5542 iter/s, 21.9578s/100 iters), loss = 0.159159
I0417 13:24:22.743571 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.953125
I0417 13:24:22.743578 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:24:22.743584 22508 solver.cpp:238]     Train net output #2: loss = 0.159158 (* 1 = 0.159158 loss)
I0417 13:24:22.743589 22508 sgd_solver.cpp:105] Iteration 47700, lr = 0.1
I0417 13:24:44.710602 22508 solver.cpp:219] Iteration 47800 (4.55238 iter/s, 21.9665s/100 iters), loss = 0.244893
I0417 13:24:44.710737 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.945312
I0417 13:24:44.710746 22508 solver.cpp:238]     Train net output #1: acctop5 = 0.992188
I0417 13:24:44.710752 22508 solver.cpp:238]     Train net output #2: loss = 0.244893 (* 1 = 0.244893 loss)
I0417 13:24:44.710757 22508 sgd_solver.cpp:105] Iteration 47800, lr = 0.1
I0417 13:25:06.638677 22508 solver.cpp:219] Iteration 47900 (4.56049 iter/s, 21.9274s/100 iters), loss = 0.117806
I0417 13:25:06.638738 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 13:25:06.638746 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:25:06.638752 22508 solver.cpp:238]     Train net output #2: loss = 0.117806 (* 1 = 0.117806 loss)
I0417 13:25:06.638757 22508 sgd_solver.cpp:105] Iteration 47900, lr = 0.1
I0417 13:25:28.365849 22508 solver.cpp:331] Iteration 48000, Testing net (#0)
I0417 13:25:31.310657 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:25:31.431648 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.4505
I0417 13:25:31.431674 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.906
I0417 13:25:31.431694 22508 solver.cpp:398]     Test net output #2: loss = 2.39906 (* 1 = 2.39906 loss)
I0417 13:25:31.650214 22508 solver.cpp:219] Iteration 48000 (3.99825 iter/s, 25.0109s/100 iters), loss = 0.212175
I0417 13:25:31.650234 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.914062
I0417 13:25:31.650240 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:25:31.650245 22508 solver.cpp:238]     Train net output #2: loss = 0.212175 (* 1 = 0.212175 loss)
I0417 13:25:31.650250 22508 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 1
I0417 13:25:31.650254 22508 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0417 13:25:40.921658 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:25:53.715970 22508 solver.cpp:219] Iteration 48100 (4.53201 iter/s, 22.0652s/100 iters), loss = 0.168198
I0417 13:25:53.716022 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.960938
I0417 13:25:53.716028 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:25:53.716035 22508 solver.cpp:238]     Train net output #2: loss = 0.168197 (* 1 = 0.168197 loss)
I0417 13:25:53.716039 22508 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0417 13:26:15.788648 22508 solver.cpp:219] Iteration 48200 (4.5306 iter/s, 22.0721s/100 iters), loss = 0.117987
I0417 13:26:15.789302 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0417 13:26:15.789312 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:26:15.789319 22508 solver.cpp:238]     Train net output #2: loss = 0.117987 (* 1 = 0.117987 loss)
I0417 13:26:15.789324 22508 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0417 13:26:37.854537 22508 solver.cpp:219] Iteration 48300 (4.53212 iter/s, 22.0647s/100 iters), loss = 0.0991665
I0417 13:26:37.854571 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0417 13:26:37.854578 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:26:37.854583 22508 solver.cpp:238]     Train net output #2: loss = 0.0991662 (* 1 = 0.0991662 loss)
I0417 13:26:37.854588 22508 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0417 13:26:59.936178 22508 solver.cpp:219] Iteration 48400 (4.52876 iter/s, 22.0811s/100 iters), loss = 0.160961
I0417 13:26:59.936300 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.9375
I0417 13:26:59.936308 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:26:59.936316 22508 solver.cpp:238]     Train net output #2: loss = 0.160961 (* 1 = 0.160961 loss)
I0417 13:26:59.936321 22508 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0417 13:27:07.225735 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:27:22.018692 22508 solver.cpp:219] Iteration 48500 (4.52859 iter/s, 22.0819s/100 iters), loss = 0.124977
I0417 13:27:22.018731 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0417 13:27:22.018738 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:27:22.018744 22508 solver.cpp:238]     Train net output #2: loss = 0.124977 (* 1 = 0.124977 loss)
I0417 13:27:22.018748 22508 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0417 13:27:44.079921 22508 solver.cpp:219] Iteration 48600 (4.53295 iter/s, 22.0607s/100 iters), loss = 0.0574525
I0417 13:27:44.080040 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0417 13:27:44.080049 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:27:44.080055 22508 solver.cpp:238]     Train net output #2: loss = 0.0574522 (* 1 = 0.0574522 loss)
I0417 13:27:44.080060 22508 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0417 13:28:06.161296 22508 solver.cpp:219] Iteration 48700 (4.52883 iter/s, 22.0808s/100 iters), loss = 0.107376
I0417 13:28:06.161337 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.96875
I0417 13:28:06.161344 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:28:06.161350 22508 solver.cpp:238]     Train net output #2: loss = 0.107376 (* 1 = 0.107376 loss)
I0417 13:28:06.161355 22508 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0417 13:28:28.252605 22508 solver.cpp:219] Iteration 48800 (4.52678 iter/s, 22.0908s/100 iters), loss = 0.114067
I0417 13:28:28.252751 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0417 13:28:28.252759 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:28:28.252766 22508 solver.cpp:238]     Train net output #2: loss = 0.114067 (* 1 = 0.114067 loss)
I0417 13:28:28.252771 22508 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0417 13:28:33.566881 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:28:50.336376 22508 solver.cpp:219] Iteration 48900 (4.52834 iter/s, 22.0831s/100 iters), loss = 0.0540896
I0417 13:28:50.336416 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0417 13:28:50.336422 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:28:50.336429 22508 solver.cpp:238]     Train net output #2: loss = 0.0540893 (* 1 = 0.0540893 loss)
I0417 13:28:50.336434 22508 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0417 13:29:12.171725 22508 solver.cpp:331] Iteration 49000, Testing net (#0)
I0417 13:29:15.122301 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:29:15.243455 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.7597
I0417 13:29:15.243482 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9852
I0417 13:29:15.243502 22508 solver.cpp:398]     Test net output #2: loss = 0.879906 (* 1 = 0.879906 loss)
I0417 13:29:15.461825 22508 solver.cpp:219] Iteration 49000 (3.98012 iter/s, 25.1249s/100 iters), loss = 0.0649586
I0417 13:29:15.461846 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.976562
I0417 13:29:15.461853 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:29:15.461858 22508 solver.cpp:238]     Train net output #2: loss = 0.0649583 (* 1 = 0.0649583 loss)
I0417 13:29:15.461863 22508 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0417 13:29:37.553952 22508 solver.cpp:219] Iteration 49100 (4.5266 iter/s, 22.0916s/100 iters), loss = 0.0508772
I0417 13:29:37.553978 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0417 13:29:37.553983 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:29:37.553988 22508 solver.cpp:238]     Train net output #2: loss = 0.0508769 (* 1 = 0.0508769 loss)
I0417 13:29:37.553993 22508 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0417 13:29:59.630311 22508 solver.cpp:219] Iteration 49200 (4.52984 iter/s, 22.0758s/100 iters), loss = 0.0492391
I0417 13:29:59.630445 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0417 13:29:59.630456 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:29:59.630475 22508 solver.cpp:238]     Train net output #2: loss = 0.0492387 (* 1 = 0.0492387 loss)
I0417 13:29:59.630480 22508 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0417 13:30:02.729395 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:30:21.705102 22508 solver.cpp:219] Iteration 49300 (4.53018 iter/s, 22.0742s/100 iters), loss = 0.0548646
I0417 13:30:21.705140 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.984375
I0417 13:30:21.705147 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:30:21.705152 22508 solver.cpp:238]     Train net output #2: loss = 0.0548643 (* 1 = 0.0548643 loss)
I0417 13:30:21.705157 22508 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0417 13:30:43.780025 22508 solver.cpp:219] Iteration 49400 (4.53014 iter/s, 22.0744s/100 iters), loss = 0.0207558
I0417 13:30:43.780158 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:30:43.780166 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:30:43.780177 22508 solver.cpp:238]     Train net output #2: loss = 0.0207555 (* 1 = 0.0207555 loss)
I0417 13:30:43.780182 22508 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0417 13:31:05.824749 22508 solver.cpp:219] Iteration 49500 (4.53636 iter/s, 22.0441s/100 iters), loss = 0.0202012
I0417 13:31:05.824787 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0417 13:31:05.824795 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:31:05.824800 22508 solver.cpp:238]     Train net output #2: loss = 0.0202009 (* 1 = 0.0202009 loss)
I0417 13:31:05.824805 22508 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0417 13:31:27.895784 22508 solver.cpp:219] Iteration 49600 (4.53093 iter/s, 22.0705s/100 iters), loss = 0.0304772
I0417 13:31:27.896433 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0417 13:31:27.896442 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:31:27.896450 22508 solver.cpp:238]     Train net output #2: loss = 0.0304768 (* 1 = 0.0304768 loss)
I0417 13:31:27.896453 22508 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0417 13:31:29.004835 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:31:49.942720 22508 solver.cpp:219] Iteration 49700 (4.53601 iter/s, 22.0458s/100 iters), loss = 0.0205432
I0417 13:31:49.943332 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:31:49.943341 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:31:49.943347 22508 solver.cpp:238]     Train net output #2: loss = 0.0205429 (* 1 = 0.0205429 loss)
I0417 13:31:49.943352 22508 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0417 13:32:12.026348 22508 solver.cpp:219] Iteration 49800 (4.52847 iter/s, 22.0825s/100 iters), loss = 0.0601995
I0417 13:32:12.026516 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0417 13:32:12.026526 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:32:12.026533 22508 solver.cpp:238]     Train net output #2: loss = 0.0601992 (* 1 = 0.0601992 loss)
I0417 13:32:12.026538 22508 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0417 13:32:34.083212 22508 solver.cpp:219] Iteration 49900 (4.53387 iter/s, 22.0562s/100 iters), loss = 0.0184109
I0417 13:32:34.083905 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:32:34.083914 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:32:34.083920 22508 solver.cpp:238]     Train net output #2: loss = 0.0184106 (* 1 = 0.0184106 loss)
I0417 13:32:34.083925 22508 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0417 13:32:55.017392 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:32:55.891755 22508 solver.cpp:448] Snapshotting to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_50000.caffemodel
I0417 13:32:55.898764 22508 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_50000.solverstate
I0417 13:32:55.900777 22508 solver.cpp:331] Iteration 50000, Testing net (#0)
I0417 13:32:58.848510 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:32:58.969353 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.815
I0417 13:32:58.969379 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9888
I0417 13:32:58.969399 22508 solver.cpp:398]     Test net output #2: loss = 0.714061 (* 1 = 0.714061 loss)
I0417 13:32:59.187352 22508 solver.cpp:219] Iteration 50000 (3.9836 iter/s, 25.1029s/100 iters), loss = 0.0248207
I0417 13:32:59.187384 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:32:59.187389 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:32:59.187394 22508 solver.cpp:238]     Train net output #2: loss = 0.0248204 (* 1 = 0.0248204 loss)
I0417 13:32:59.187400 22508 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0417 13:33:21.177003 22508 solver.cpp:219] Iteration 50100 (4.5477 iter/s, 21.9891s/100 iters), loss = 0.015291
I0417 13:33:21.177043 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:33:21.177049 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:33:21.177055 22508 solver.cpp:238]     Train net output #2: loss = 0.0152907 (* 1 = 0.0152907 loss)
I0417 13:33:21.177059 22508 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0417 13:33:43.151428 22508 solver.cpp:219] Iteration 50200 (4.55085 iter/s, 21.9739s/100 iters), loss = 0.0413287
I0417 13:33:43.151569 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0417 13:33:43.151576 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:33:43.151583 22508 solver.cpp:238]     Train net output #2: loss = 0.0413284 (* 1 = 0.0413284 loss)
I0417 13:33:43.151588 22508 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0417 13:34:05.130317 22508 solver.cpp:219] Iteration 50300 (4.54995 iter/s, 21.9783s/100 iters), loss = 0.0378758
I0417 13:34:05.130365 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0417 13:34:05.130373 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:34:05.130379 22508 solver.cpp:238]     Train net output #2: loss = 0.0378755 (* 1 = 0.0378755 loss)
I0417 13:34:05.130383 22508 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0417 13:34:24.046838 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:34:27.130728 22508 solver.cpp:219] Iteration 50400 (4.54548 iter/s, 21.9999s/100 iters), loss = 0.0340918
I0417 13:34:27.130760 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0417 13:34:27.130767 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:34:27.130774 22508 solver.cpp:238]     Train net output #2: loss = 0.0340915 (* 1 = 0.0340915 loss)
I0417 13:34:27.130777 22508 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0417 13:34:49.057682 22508 solver.cpp:219] Iteration 50500 (4.56071 iter/s, 21.9264s/100 iters), loss = 0.0235363
I0417 13:34:49.057719 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:34:49.057725 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:34:49.057731 22508 solver.cpp:238]     Train net output #2: loss = 0.023536 (* 1 = 0.023536 loss)
I0417 13:34:49.057735 22508 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0417 13:35:11.001505 22508 solver.cpp:219] Iteration 50600 (4.5572 iter/s, 21.9433s/100 iters), loss = 0.0418327
I0417 13:35:11.001667 22508 solver.cpp:238]     Train net output #0: acctop1 = 0.992188
I0417 13:35:11.001677 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:35:11.001683 22508 solver.cpp:238]     Train net output #2: loss = 0.0418324 (* 1 = 0.0418324 loss)
I0417 13:35:11.001688 22508 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0417 13:35:32.958408 22508 solver.cpp:219] Iteration 50700 (4.55451 iter/s, 21.9562s/100 iters), loss = 0.0144005
I0417 13:35:32.959004 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:35:32.959012 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:35:32.959018 22508 solver.cpp:238]     Train net output #2: loss = 0.0144002 (* 1 = 0.0144002 loss)
I0417 13:35:32.959022 22508 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0417 13:35:49.854995 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:35:54.904048 22508 solver.cpp:219] Iteration 50800 (4.55694 iter/s, 21.9446s/100 iters), loss = 0.012099
I0417 13:35:54.904086 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:35:54.904093 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:35:54.904098 22508 solver.cpp:238]     Train net output #2: loss = 0.0120987 (* 1 = 0.0120987 loss)
I0417 13:35:54.904103 22508 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0417 13:36:16.869561 22508 solver.cpp:219] Iteration 50900 (4.5527 iter/s, 21.965s/100 iters), loss = 0.0100574
I0417 13:36:16.869606 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:36:16.869613 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:36:16.869621 22508 solver.cpp:238]     Train net output #2: loss = 0.0100571 (* 1 = 0.0100571 loss)
I0417 13:36:16.869624 22508 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0417 13:36:38.598080 22508 solver.cpp:331] Iteration 51000, Testing net (#0)
I0417 13:36:41.545788 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:36:41.666595 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8098
I0417 13:36:41.666620 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9887
I0417 13:36:41.666642 22508 solver.cpp:398]     Test net output #2: loss = 0.78778 (* 1 = 0.78778 loss)
I0417 13:36:41.884030 22508 solver.cpp:219] Iteration 51000 (3.99778 iter/s, 25.0139s/100 iters), loss = 0.0133126
I0417 13:36:41.884063 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:36:41.884068 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:36:41.884073 22508 solver.cpp:238]     Train net output #2: loss = 0.0133123 (* 1 = 0.0133123 loss)
I0417 13:36:41.884078 22508 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0417 13:37:03.838273 22508 solver.cpp:219] Iteration 51100 (4.55504 iter/s, 21.9537s/100 iters), loss = 0.0208013
I0417 13:37:03.838325 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:37:03.838331 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:37:03.838337 22508 solver.cpp:238]     Train net output #2: loss = 0.0208009 (* 1 = 0.0208009 loss)
I0417 13:37:03.838342 22508 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0417 13:37:18.549769 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:37:25.807370 22508 solver.cpp:219] Iteration 51200 (4.55196 iter/s, 21.9686s/100 iters), loss = 0.0128464
I0417 13:37:25.807409 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:37:25.807415 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:37:25.807420 22508 solver.cpp:238]     Train net output #2: loss = 0.012846 (* 1 = 0.012846 loss)
I0417 13:37:25.807425 22508 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0417 13:37:47.784557 22508 solver.cpp:219] Iteration 51300 (4.55028 iter/s, 21.9767s/100 iters), loss = 0.0116874
I0417 13:37:47.784593 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:37:47.784600 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:37:47.784605 22508 solver.cpp:238]     Train net output #2: loss = 0.0116871 (* 1 = 0.0116871 loss)
I0417 13:37:47.784610 22508 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0417 13:38:09.730123 22508 solver.cpp:219] Iteration 51400 (4.55684 iter/s, 21.945s/100 iters), loss = 0.00778255
I0417 13:38:09.730288 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:38:09.730298 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:38:09.730305 22508 solver.cpp:238]     Train net output #2: loss = 0.00778224 (* 1 = 0.00778224 loss)
I0417 13:38:09.730309 22508 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0417 13:38:31.707968 22508 solver.cpp:219] Iteration 51500 (4.55017 iter/s, 21.9772s/100 iters), loss = 0.0136097
I0417 13:38:31.708004 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:38:31.708009 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:38:31.708016 22508 solver.cpp:238]     Train net output #2: loss = 0.0136094 (* 1 = 0.0136094 loss)
I0417 13:38:31.708020 22508 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0417 13:38:44.431704 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:38:53.633065 22508 solver.cpp:219] Iteration 51600 (4.56109 iter/s, 21.9246s/100 iters), loss = 0.0124194
I0417 13:38:53.633100 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:38:53.633106 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:38:53.633112 22508 solver.cpp:238]     Train net output #2: loss = 0.012419 (* 1 = 0.012419 loss)
I0417 13:38:53.633116 22508 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0417 13:39:15.573611 22508 solver.cpp:219] Iteration 51700 (4.55788 iter/s, 21.94s/100 iters), loss = 0.0141684
I0417 13:39:15.573741 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:39:15.573750 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:39:15.573756 22508 solver.cpp:238]     Train net output #2: loss = 0.0141681 (* 1 = 0.0141681 loss)
I0417 13:39:15.573761 22508 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0417 13:39:37.566910 22508 solver.cpp:219] Iteration 51800 (4.54697 iter/s, 21.9927s/100 iters), loss = 0.0109076
I0417 13:39:37.566958 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:39:37.566964 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:39:37.566970 22508 solver.cpp:238]     Train net output #2: loss = 0.0109072 (* 1 = 0.0109072 loss)
I0417 13:39:37.566975 22508 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0417 13:39:59.538918 22508 solver.cpp:219] Iteration 51900 (4.55136 iter/s, 21.9715s/100 iters), loss = 0.0150504
I0417 13:39:59.539047 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:39:59.539054 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:39:59.539062 22508 solver.cpp:238]     Train net output #2: loss = 0.0150501 (* 1 = 0.0150501 loss)
I0417 13:39:59.539065 22508 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0417 13:40:10.310775 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:40:21.298991 22508 solver.cpp:331] Iteration 52000, Testing net (#0)
I0417 13:40:24.249244 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:40:24.370075 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8143
I0417 13:40:24.370101 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9881
I0417 13:40:24.370121 22508 solver.cpp:398]     Test net output #2: loss = 0.795365 (* 1 = 0.795365 loss)
I0417 13:40:24.587664 22508 solver.cpp:219] Iteration 52000 (3.99232 iter/s, 25.0481s/100 iters), loss = 0.0137917
I0417 13:40:24.587697 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:40:24.587702 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:40:24.587707 22508 solver.cpp:238]     Train net output #2: loss = 0.0137914 (* 1 = 0.0137914 loss)
I0417 13:40:24.587714 22508 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0417 13:40:46.523097 22508 solver.cpp:219] Iteration 52100 (4.55894 iter/s, 21.9349s/100 iters), loss = 0.00816932
I0417 13:40:46.523284 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:40:46.523293 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:40:46.523299 22508 solver.cpp:238]     Train net output #2: loss = 0.008169 (* 1 = 0.008169 loss)
I0417 13:40:46.523304 22508 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0417 13:41:08.450610 22508 solver.cpp:219] Iteration 52200 (4.56062 iter/s, 21.9268s/100 iters), loss = 0.0099382
I0417 13:41:08.450649 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:41:08.450655 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:41:08.450664 22508 solver.cpp:238]     Train net output #2: loss = 0.00993788 (* 1 = 0.00993788 loss)
I0417 13:41:08.450670 22508 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0417 13:41:30.399766 22508 solver.cpp:219] Iteration 52300 (4.55609 iter/s, 21.9486s/100 iters), loss = 0.00769428
I0417 13:41:30.399909 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:41:30.399916 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:41:30.399922 22508 solver.cpp:238]     Train net output #2: loss = 0.00769396 (* 1 = 0.00769396 loss)
I0417 13:41:30.399927 22508 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0417 13:41:38.958011 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:41:52.412252 22508 solver.cpp:219] Iteration 52400 (4.54301 iter/s, 22.0119s/100 iters), loss = 0.0113326
I0417 13:41:52.412291 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:41:52.412297 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:41:52.412303 22508 solver.cpp:238]     Train net output #2: loss = 0.0113322 (* 1 = 0.0113322 loss)
I0417 13:41:52.412307 22508 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0417 13:42:14.506037 22508 solver.cpp:219] Iteration 52500 (4.52627 iter/s, 22.0932s/100 iters), loss = 0.0112349
I0417 13:42:14.506695 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:42:14.506705 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:42:14.506711 22508 solver.cpp:238]     Train net output #2: loss = 0.0112346 (* 1 = 0.0112346 loss)
I0417 13:42:14.506716 22508 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0417 13:42:36.595810 22508 solver.cpp:219] Iteration 52600 (4.52722 iter/s, 22.0886s/100 iters), loss = 0.0114862
I0417 13:42:36.595861 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:42:36.595867 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:42:36.595875 22508 solver.cpp:238]     Train net output #2: loss = 0.0114859 (* 1 = 0.0114859 loss)
I0417 13:42:36.595880 22508 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0417 13:42:58.659844 22508 solver.cpp:219] Iteration 52700 (4.53237 iter/s, 22.0635s/100 iters), loss = 0.0104718
I0417 13:42:58.659961 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:42:58.659970 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:42:58.659976 22508 solver.cpp:238]     Train net output #2: loss = 0.0104715 (* 1 = 0.0104715 loss)
I0417 13:42:58.659981 22508 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0417 13:43:05.287858 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:43:20.745532 22508 solver.cpp:219] Iteration 52800 (4.52795 iter/s, 22.0851s/100 iters), loss = 0.00842208
I0417 13:43:20.746063 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:43:20.746070 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:43:20.746078 22508 solver.cpp:238]     Train net output #2: loss = 0.00842176 (* 1 = 0.00842176 loss)
I0417 13:43:20.746083 22508 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0417 13:43:42.795132 22508 solver.cpp:219] Iteration 52900 (4.53544 iter/s, 22.0486s/100 iters), loss = 0.00922876
I0417 13:43:42.795295 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:43:42.795305 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:43:42.795311 22508 solver.cpp:238]     Train net output #2: loss = 0.00922844 (* 1 = 0.00922844 loss)
I0417 13:43:42.795315 22508 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0417 13:44:04.659027 22508 solver.cpp:331] Iteration 53000, Testing net (#0)
I0417 13:44:07.603178 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:44:07.723920 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8146
I0417 13:44:07.723947 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9886
I0417 13:44:07.723965 22508 solver.cpp:398]     Test net output #2: loss = 0.822299 (* 1 = 0.822299 loss)
I0417 13:44:07.942023 22508 solver.cpp:219] Iteration 53000 (3.97675 iter/s, 25.1462s/100 iters), loss = 0.00604472
I0417 13:44:07.942055 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:44:07.942060 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:44:07.942066 22508 solver.cpp:238]     Train net output #2: loss = 0.00604441 (* 1 = 0.00604441 loss)
I0417 13:44:07.942072 22508 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0417 13:44:30.019963 22508 solver.cpp:219] Iteration 53100 (4.52951 iter/s, 22.0774s/100 iters), loss = 0.009626
I0417 13:44:30.020094 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:44:30.020102 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:44:30.020109 22508 solver.cpp:238]     Train net output #2: loss = 0.00962569 (* 1 = 0.00962569 loss)
I0417 13:44:30.020114 22508 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0417 13:44:34.432039 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:44:52.101071 22508 solver.cpp:219] Iteration 53200 (4.52889 iter/s, 22.0805s/100 iters), loss = 0.00788168
I0417 13:44:52.101109 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:44:52.101114 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:44:52.101120 22508 solver.cpp:238]     Train net output #2: loss = 0.00788136 (* 1 = 0.00788136 loss)
I0417 13:44:52.101125 22508 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0417 13:45:14.181582 22508 solver.cpp:219] Iteration 53300 (4.52899 iter/s, 22.08s/100 iters), loss = 0.0141315
I0417 13:45:14.181726 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:45:14.181735 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:45:14.181741 22508 solver.cpp:238]     Train net output #2: loss = 0.0141311 (* 1 = 0.0141311 loss)
I0417 13:45:14.181746 22508 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0417 13:45:36.249207 22508 solver.cpp:219] Iteration 53400 (4.53166 iter/s, 22.067s/100 iters), loss = 0.00507906
I0417 13:45:36.249249 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:45:36.249256 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:45:36.249265 22508 solver.cpp:238]     Train net output #2: loss = 0.00507874 (* 1 = 0.00507874 loss)
I0417 13:45:36.249270 22508 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0417 13:45:58.278264 22508 solver.cpp:219] Iteration 53500 (4.53957 iter/s, 22.0285s/100 iters), loss = 0.0144496
I0417 13:45:58.278388 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:45:58.278396 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:45:58.278404 22508 solver.cpp:238]     Train net output #2: loss = 0.0144493 (* 1 = 0.0144493 loss)
I0417 13:45:58.278409 22508 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0417 13:46:00.706902 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:46:20.301410 22508 solver.cpp:219] Iteration 53600 (4.5408 iter/s, 22.0225s/100 iters), loss = 0.00713558
I0417 13:46:20.301980 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:46:20.301987 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:46:20.301995 22508 solver.cpp:238]     Train net output #2: loss = 0.00713527 (* 1 = 0.00713527 loss)
I0417 13:46:20.301998 22508 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0417 13:46:42.279193 22508 solver.cpp:219] Iteration 53700 (4.55027 iter/s, 21.9767s/100 iters), loss = 0.00872317
I0417 13:46:42.279368 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:46:42.279377 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:46:42.279384 22508 solver.cpp:238]     Train net output #2: loss = 0.00872286 (* 1 = 0.00872286 loss)
I0417 13:46:42.279388 22508 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0417 13:47:04.322649 22508 solver.cpp:219] Iteration 53800 (4.53663 iter/s, 22.0428s/100 iters), loss = 0.00824404
I0417 13:47:04.322702 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:47:04.322708 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:47:04.322715 22508 solver.cpp:238]     Train net output #2: loss = 0.00824373 (* 1 = 0.00824373 loss)
I0417 13:47:04.322720 22508 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0417 13:47:26.293699 22508 solver.cpp:219] Iteration 53900 (4.55156 iter/s, 21.9705s/100 iters), loss = 0.00877567
I0417 13:47:26.293834 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:47:26.293843 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:47:26.293850 22508 solver.cpp:238]     Train net output #2: loss = 0.00877536 (* 1 = 0.00877536 loss)
I0417 13:47:26.293855 22508 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0417 13:47:26.735735 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:47:48.054916 22508 solver.cpp:331] Iteration 54000, Testing net (#0)
I0417 13:47:51.001909 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:47:51.122994 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8174
I0417 13:47:51.123019 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9878
I0417 13:47:51.123039 22508 solver.cpp:398]     Test net output #2: loss = 0.83186 (* 1 = 0.83186 loss)
I0417 13:47:51.341635 22508 solver.cpp:219] Iteration 54000 (3.99245 iter/s, 25.0473s/100 iters), loss = 0.00786885
I0417 13:47:51.341667 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:47:51.341672 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:47:51.341678 22508 solver.cpp:238]     Train net output #2: loss = 0.00786854 (* 1 = 0.00786854 loss)
I0417 13:47:51.341684 22508 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0417 13:48:13.309222 22508 solver.cpp:219] Iteration 54100 (4.55227 iter/s, 21.9671s/100 iters), loss = 0.00484316
I0417 13:48:13.315208 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:48:13.315217 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:48:13.315224 22508 solver.cpp:238]     Train net output #2: loss = 0.00484284 (* 1 = 0.00484284 loss)
I0417 13:48:13.315230 22508 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0417 13:48:35.301182 22508 solver.cpp:219] Iteration 54200 (4.54845 iter/s, 21.9855s/100 iters), loss = 0.00600179
I0417 13:48:35.301743 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:48:35.301751 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:48:35.301759 22508 solver.cpp:238]     Train net output #2: loss = 0.00600147 (* 1 = 0.00600147 loss)
I0417 13:48:35.301764 22508 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0417 13:48:55.489630 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:48:57.248509 22508 solver.cpp:219] Iteration 54300 (4.55658 iter/s, 21.9463s/100 iters), loss = 0.00783266
I0417 13:48:57.248541 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:48:57.248546 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:48:57.248553 22508 solver.cpp:238]     Train net output #2: loss = 0.00783234 (* 1 = 0.00783234 loss)
I0417 13:48:57.248556 22508 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0417 13:49:19.228116 22508 solver.cpp:219] Iteration 54400 (4.54978 iter/s, 21.9791s/100 iters), loss = 0.00569299
I0417 13:49:19.228627 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:49:19.228636 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:49:19.228642 22508 solver.cpp:238]     Train net output #2: loss = 0.00569267 (* 1 = 0.00569267 loss)
I0417 13:49:19.228646 22508 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0417 13:49:41.164201 22508 solver.cpp:219] Iteration 54500 (4.55891 iter/s, 21.9351s/100 iters), loss = 0.00502739
I0417 13:49:41.164377 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:49:41.164386 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:49:41.164393 22508 solver.cpp:238]     Train net output #2: loss = 0.00502707 (* 1 = 0.00502707 loss)
I0417 13:49:41.164399 22508 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0417 13:50:03.190017 22508 solver.cpp:219] Iteration 54600 (4.54026 iter/s, 22.0251s/100 iters), loss = 0.00416727
I0417 13:50:03.190400 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:50:03.190407 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:50:03.190414 22508 solver.cpp:238]     Train net output #2: loss = 0.00416695 (* 1 = 0.00416695 loss)
I0417 13:50:03.190418 22508 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0417 13:50:21.509045 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:50:25.248215 22508 solver.cpp:219] Iteration 54700 (4.53364 iter/s, 22.0573s/100 iters), loss = 0.00826361
I0417 13:50:25.248265 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:50:25.248270 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:50:25.248278 22508 solver.cpp:238]     Train net output #2: loss = 0.0082633 (* 1 = 0.0082633 loss)
I0417 13:50:25.248283 22508 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0417 13:50:47.337749 22508 solver.cpp:219] Iteration 54800 (4.52714 iter/s, 22.089s/100 iters), loss = 0.0105014
I0417 13:50:47.337800 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:50:47.337805 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:50:47.337812 22508 solver.cpp:238]     Train net output #2: loss = 0.0105011 (* 1 = 0.0105011 loss)
I0417 13:50:47.337817 22508 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0417 13:51:09.382966 22508 solver.cpp:219] Iteration 54900 (4.53624 iter/s, 22.0447s/100 iters), loss = 0.00604254
I0417 13:51:09.383080 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:51:09.383088 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:51:09.383095 22508 solver.cpp:238]     Train net output #2: loss = 0.00604222 (* 1 = 0.00604222 loss)
I0417 13:51:09.383100 22508 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0417 13:51:31.235134 22508 solver.cpp:331] Iteration 55000, Testing net (#0)
I0417 13:51:34.190207 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:51:34.311285 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8132
I0417 13:51:34.311312 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9882
I0417 13:51:34.311331 22508 solver.cpp:398]     Test net output #2: loss = 0.855245 (* 1 = 0.855245 loss)
I0417 13:51:34.529162 22508 solver.cpp:219] Iteration 55000 (3.97685 iter/s, 25.1455s/100 iters), loss = 0.00390117
I0417 13:51:34.529196 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:51:34.529202 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:51:34.529208 22508 solver.cpp:238]     Train net output #2: loss = 0.00390085 (* 1 = 0.00390085 loss)
I0417 13:51:34.529214 22508 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0417 13:51:50.879271 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:51:56.628832 22508 solver.cpp:219] Iteration 55100 (4.52506 iter/s, 22.0992s/100 iters), loss = 0.00682911
I0417 13:51:56.628870 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:51:56.628875 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:51:56.628881 22508 solver.cpp:238]     Train net output #2: loss = 0.00682879 (* 1 = 0.00682879 loss)
I0417 13:51:56.628886 22508 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0417 13:52:18.692677 22508 solver.cpp:219] Iteration 55200 (4.53241 iter/s, 22.0633s/100 iters), loss = 0.00415702
I0417 13:52:18.692726 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:52:18.692734 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:52:18.692739 22508 solver.cpp:238]     Train net output #2: loss = 0.0041567 (* 1 = 0.0041567 loss)
I0417 13:52:18.692744 22508 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0417 13:52:40.772732 22508 solver.cpp:219] Iteration 55300 (4.52908 iter/s, 22.0795s/100 iters), loss = 0.00781129
I0417 13:52:40.772864 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:52:40.772872 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:52:40.772879 22508 solver.cpp:238]     Train net output #2: loss = 0.00781097 (* 1 = 0.00781097 loss)
I0417 13:52:40.772883 22508 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0417 13:53:02.828099 22508 solver.cpp:219] Iteration 55400 (4.53417 iter/s, 22.0547s/100 iters), loss = 0.00395242
I0417 13:53:02.828141 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:53:02.828147 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:53:02.828153 22508 solver.cpp:238]     Train net output #2: loss = 0.00395211 (* 1 = 0.00395211 loss)
I0417 13:53:02.828157 22508 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0417 13:53:16.932487 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:53:24.875332 22508 solver.cpp:219] Iteration 55500 (4.53583 iter/s, 22.0467s/100 iters), loss = 0.0035087
I0417 13:53:24.875381 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:53:24.875387 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:53:24.875394 22508 solver.cpp:238]     Train net output #2: loss = 0.00350839 (* 1 = 0.00350839 loss)
I0417 13:53:24.875399 22508 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0417 13:53:46.953635 22508 solver.cpp:219] Iteration 55600 (4.52944 iter/s, 22.0778s/100 iters), loss = 0.00481761
I0417 13:53:46.953758 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:53:46.953768 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:53:46.953774 22508 solver.cpp:238]     Train net output #2: loss = 0.0048173 (* 1 = 0.0048173 loss)
I0417 13:53:46.953779 22508 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0417 13:54:09.011162 22508 solver.cpp:219] Iteration 55700 (4.53373 iter/s, 22.0569s/100 iters), loss = 0.00281005
I0417 13:54:09.011214 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:54:09.011220 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:54:09.011226 22508 solver.cpp:238]     Train net output #2: loss = 0.00280974 (* 1 = 0.00280974 loss)
I0417 13:54:09.011231 22508 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0417 13:54:30.962957 22508 solver.cpp:219] Iteration 55800 (4.55555 iter/s, 21.9513s/100 iters), loss = 0.00632174
I0417 13:54:30.963533 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:54:30.963541 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:54:30.963547 22508 solver.cpp:238]     Train net output #2: loss = 0.00632143 (* 1 = 0.00632143 loss)
I0417 13:54:30.963552 22508 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0417 13:54:43.052757 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:54:52.911253 22508 solver.cpp:219] Iteration 55900 (4.55638 iter/s, 21.9472s/100 iters), loss = 0.0049242
I0417 13:54:52.911289 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:54:52.911295 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:54:52.911301 22508 solver.cpp:238]     Train net output #2: loss = 0.00492388 (* 1 = 0.00492388 loss)
I0417 13:54:52.911305 22508 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0417 13:55:14.638934 22508 solver.cpp:331] Iteration 56000, Testing net (#0)
I0417 13:55:17.579174 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:55:17.699919 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.815
I0417 13:55:17.699945 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9881
I0417 13:55:17.699965 22508 solver.cpp:398]     Test net output #2: loss = 0.866512 (* 1 = 0.866512 loss)
I0417 13:55:17.917534 22508 solver.cpp:219] Iteration 56000 (3.99909 iter/s, 25.0057s/100 iters), loss = 0.00317789
I0417 13:55:17.917567 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:55:17.917572 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:55:17.917578 22508 solver.cpp:238]     Train net output #2: loss = 0.00317758 (* 1 = 0.00317758 loss)
I0417 13:55:17.917584 22508 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0417 13:55:39.943383 22508 solver.cpp:219] Iteration 56100 (4.54023 iter/s, 22.0253s/100 iters), loss = 0.00422669
I0417 13:55:39.943418 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:55:39.943424 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:55:39.943430 22508 solver.cpp:238]     Train net output #2: loss = 0.00422637 (* 1 = 0.00422637 loss)
I0417 13:55:39.943435 22508 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0417 13:56:01.997874 22508 solver.cpp:219] Iteration 56200 (4.53433 iter/s, 22.054s/100 iters), loss = 0.00304041
I0417 13:56:01.997999 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:56:01.998008 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:56:01.998014 22508 solver.cpp:238]     Train net output #2: loss = 0.0030401 (* 1 = 0.0030401 loss)
I0417 13:56:01.998019 22508 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0417 13:56:11.899297 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:56:24.006909 22508 solver.cpp:219] Iteration 56300 (4.54372 iter/s, 22.0084s/100 iters), loss = 0.00619379
I0417 13:56:24.006949 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:56:24.006955 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:56:24.006961 22508 solver.cpp:238]     Train net output #2: loss = 0.00619348 (* 1 = 0.00619348 loss)
I0417 13:56:24.006965 22508 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0417 13:56:46.031828 22508 solver.cpp:219] Iteration 56400 (4.54042 iter/s, 22.0244s/100 iters), loss = 0.00345256
I0417 13:56:46.031961 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:56:46.031970 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:56:46.031977 22508 solver.cpp:238]     Train net output #2: loss = 0.00345225 (* 1 = 0.00345225 loss)
I0417 13:56:46.031981 22508 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0417 13:57:08.041533 22508 solver.cpp:219] Iteration 56500 (4.54358 iter/s, 22.0091s/100 iters), loss = 0.00508081
I0417 13:57:08.041585 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:57:08.041591 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:57:08.041599 22508 solver.cpp:238]     Train net output #2: loss = 0.0050805 (* 1 = 0.0050805 loss)
I0417 13:57:08.041602 22508 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0417 13:57:30.046382 22508 solver.cpp:219] Iteration 56600 (4.54456 iter/s, 22.0043s/100 iters), loss = 0.00865616
I0417 13:57:30.046532 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:57:30.046540 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:57:30.046547 22508 solver.cpp:238]     Train net output #2: loss = 0.00865584 (* 1 = 0.00865584 loss)
I0417 13:57:30.046552 22508 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0417 13:57:37.957267 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:57:52.012801 22508 solver.cpp:219] Iteration 56700 (4.55254 iter/s, 21.9658s/100 iters), loss = 0.00469468
I0417 13:57:52.012850 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:57:52.012856 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:57:52.012863 22508 solver.cpp:238]     Train net output #2: loss = 0.00469437 (* 1 = 0.00469437 loss)
I0417 13:57:52.012867 22508 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0417 13:58:13.966440 22508 solver.cpp:219] Iteration 56800 (4.55517 iter/s, 21.9531s/100 iters), loss = 0.0131603
I0417 13:58:13.966819 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:58:13.966827 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:58:13.966835 22508 solver.cpp:238]     Train net output #2: loss = 0.01316 (* 1 = 0.01316 loss)
I0417 13:58:13.966843 22508 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0417 13:58:35.925645 22508 solver.cpp:219] Iteration 56900 (4.55408 iter/s, 21.9583s/100 iters), loss = 0.0056917
I0417 13:58:35.925683 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:58:35.925690 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:58:35.925701 22508 solver.cpp:238]     Train net output #2: loss = 0.00569139 (* 1 = 0.00569139 loss)
I0417 13:58:35.925707 22508 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0417 13:58:57.640780 22508 solver.cpp:331] Iteration 57000, Testing net (#0)
I0417 13:59:00.583930 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:59:00.704545 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8155
I0417 13:59:00.704573 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9881
I0417 13:59:00.704586 22508 solver.cpp:398]     Test net output #2: loss = 0.880544 (* 1 = 0.880544 loss)
I0417 13:59:00.922423 22508 solver.cpp:219] Iteration 57000 (4.00061 iter/s, 24.9962s/100 iters), loss = 0.00423867
I0417 13:59:00.922446 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:59:00.922451 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:59:00.922456 22508 solver.cpp:238]     Train net output #2: loss = 0.00423835 (* 1 = 0.00423835 loss)
I0417 13:59:00.922463 22508 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0417 13:59:06.849465 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 13:59:22.942734 22508 solver.cpp:219] Iteration 57100 (4.54137 iter/s, 22.0198s/100 iters), loss = 0.00340932
I0417 13:59:22.942771 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:59:22.942777 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:59:22.942783 22508 solver.cpp:238]     Train net output #2: loss = 0.00340901 (* 1 = 0.00340901 loss)
I0417 13:59:22.942787 22508 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0417 13:59:45.026633 22508 solver.cpp:219] Iteration 57200 (4.52829 iter/s, 22.0834s/100 iters), loss = 0.00207583
I0417 13:59:45.026768 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 13:59:45.026777 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 13:59:45.026784 22508 solver.cpp:238]     Train net output #2: loss = 0.00207552 (* 1 = 0.00207552 loss)
I0417 13:59:45.026788 22508 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0417 14:00:07.041632 22508 solver.cpp:219] Iteration 57300 (4.54249 iter/s, 22.0144s/100 iters), loss = 0.00293503
I0417 14:00:07.042032 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:00:07.042039 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:00:07.042047 22508 solver.cpp:238]     Train net output #2: loss = 0.00293472 (* 1 = 0.00293472 loss)
I0417 14:00:07.042052 22508 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0417 14:00:29.073184 22508 solver.cpp:219] Iteration 57400 (4.53913 iter/s, 22.0307s/100 iters), loss = 0.00556495
I0417 14:00:29.073314 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:00:29.073323 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:00:29.073329 22508 solver.cpp:238]     Train net output #2: loss = 0.00556464 (* 1 = 0.00556464 loss)
I0417 14:00:29.073334 22508 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0417 14:00:32.814086 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:00:51.025046 22508 solver.cpp:219] Iteration 57500 (4.55555 iter/s, 21.9512s/100 iters), loss = 0.00423522
I0417 14:00:51.025086 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:00:51.025092 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:00:51.025099 22508 solver.cpp:238]     Train net output #2: loss = 0.00423491 (* 1 = 0.00423491 loss)
I0417 14:00:51.025104 22508 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0417 14:01:13.031296 22508 solver.cpp:219] Iteration 57600 (4.54427 iter/s, 22.0057s/100 iters), loss = 0.00339546
I0417 14:01:13.032063 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:01:13.032073 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:01:13.032080 22508 solver.cpp:238]     Train net output #2: loss = 0.00339515 (* 1 = 0.00339515 loss)
I0417 14:01:13.032086 22508 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0417 14:01:35.055107 22508 solver.cpp:219] Iteration 57700 (4.5408 iter/s, 22.0226s/100 iters), loss = 0.00280105
I0417 14:01:35.055676 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:01:35.055683 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:01:35.055691 22508 solver.cpp:238]     Train net output #2: loss = 0.00280073 (* 1 = 0.00280073 loss)
I0417 14:01:35.055696 22508 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0417 14:01:57.043110 22508 solver.cpp:219] Iteration 57800 (4.54815 iter/s, 21.9869s/100 iters), loss = 0.00263338
I0417 14:01:57.043270 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:01:57.043278 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:01:57.043285 22508 solver.cpp:238]     Train net output #2: loss = 0.00263307 (* 1 = 0.00263307 loss)
I0417 14:01:57.043292 22508 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0417 14:01:58.813133 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:02:19.129971 22508 solver.cpp:219] Iteration 57900 (4.52771 iter/s, 22.0862s/100 iters), loss = 0.00445765
I0417 14:02:19.130384 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:02:19.130393 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:02:19.130400 22508 solver.cpp:238]     Train net output #2: loss = 0.00445733 (* 1 = 0.00445733 loss)
I0417 14:02:19.130404 22508 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0417 14:02:41.031782 22508 solver.cpp:331] Iteration 58000, Testing net (#0)
I0417 14:02:43.978334 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:02:44.099330 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8164
I0417 14:02:44.099373 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9888
I0417 14:02:44.099393 22508 solver.cpp:398]     Test net output #2: loss = 0.882102 (* 1 = 0.882102 loss)
I0417 14:02:44.317464 22508 solver.cpp:219] Iteration 58000 (3.97038 iter/s, 25.1865s/100 iters), loss = 0.0034137
I0417 14:02:44.317487 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:02:44.317493 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:02:44.317499 22508 solver.cpp:238]     Train net output #2: loss = 0.00341338 (* 1 = 0.00341338 loss)
I0417 14:02:44.317505 22508 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0417 14:03:06.374907 22508 solver.cpp:219] Iteration 58100 (4.53372 iter/s, 22.0569s/100 iters), loss = 0.0034028
I0417 14:03:06.374950 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:03:06.374958 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:03:06.374965 22508 solver.cpp:238]     Train net output #2: loss = 0.00340248 (* 1 = 0.00340248 loss)
I0417 14:03:06.374970 22508 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0417 14:03:28.159257 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:03:28.375463 22508 solver.cpp:219] Iteration 58200 (4.54545 iter/s, 22s/100 iters), loss = 0.00347258
I0417 14:03:28.375495 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:03:28.375500 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:03:28.375507 22508 solver.cpp:238]     Train net output #2: loss = 0.00347227 (* 1 = 0.00347227 loss)
I0417 14:03:28.375511 22508 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0417 14:03:50.370198 22508 solver.cpp:219] Iteration 58300 (4.54665 iter/s, 21.9942s/100 iters), loss = 0.00514213
I0417 14:03:50.370231 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:03:50.370236 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:03:50.370242 22508 solver.cpp:238]     Train net output #2: loss = 0.00514182 (* 1 = 0.00514182 loss)
I0417 14:03:50.370247 22508 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0417 14:04:12.349632 22508 solver.cpp:219] Iteration 58400 (4.54982 iter/s, 21.9789s/100 iters), loss = 0.00576408
I0417 14:04:12.349756 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:04:12.349764 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:04:12.349771 22508 solver.cpp:238]     Train net output #2: loss = 0.00576376 (* 1 = 0.00576376 loss)
I0417 14:04:12.349776 22508 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0417 14:04:34.387564 22508 solver.cpp:219] Iteration 58500 (4.53776 iter/s, 22.0373s/100 iters), loss = 0.0029731
I0417 14:04:34.387603 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:04:34.387609 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:04:34.387615 22508 solver.cpp:238]     Train net output #2: loss = 0.00297279 (* 1 = 0.00297279 loss)
I0417 14:04:34.387620 22508 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0417 14:04:53.926905 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:04:56.345707 22508 solver.cpp:219] Iteration 58600 (4.55423 iter/s, 21.9576s/100 iters), loss = 0.0032943
I0417 14:04:56.345757 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:04:56.345765 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:04:56.345777 22508 solver.cpp:238]     Train net output #2: loss = 0.00329399 (* 1 = 0.00329399 loss)
I0417 14:04:56.345787 22508 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0417 14:05:18.312502 22508 solver.cpp:219] Iteration 58700 (4.55244 iter/s, 21.9663s/100 iters), loss = 0.00390933
I0417 14:05:18.312549 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:05:18.312556 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:05:18.312562 22508 solver.cpp:238]     Train net output #2: loss = 0.00390902 (* 1 = 0.00390902 loss)
I0417 14:05:18.312567 22508 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0417 14:05:40.211827 22508 solver.cpp:219] Iteration 58800 (4.56646 iter/s, 21.8988s/100 iters), loss = 0.00308453
I0417 14:05:40.211969 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:05:40.211977 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:05:40.211983 22508 solver.cpp:238]     Train net output #2: loss = 0.00308421 (* 1 = 0.00308421 loss)
I0417 14:05:40.211988 22508 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0417 14:06:02.196652 22508 solver.cpp:219] Iteration 58900 (4.54872 iter/s, 21.9842s/100 iters), loss = 0.00302324
I0417 14:06:02.196691 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:06:02.196696 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:06:02.196702 22508 solver.cpp:238]     Train net output #2: loss = 0.00302293 (* 1 = 0.00302293 loss)
I0417 14:06:02.196707 22508 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0417 14:06:19.804752 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:06:23.966058 22508 solver.cpp:331] Iteration 59000, Testing net (#0)
I0417 14:06:26.916306 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:06:27.037468 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8153
I0417 14:06:27.037494 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9881
I0417 14:06:27.037514 22508 solver.cpp:398]     Test net output #2: loss = 0.884064 (* 1 = 0.884064 loss)
I0417 14:06:27.255735 22508 solver.cpp:219] Iteration 59000 (3.99066 iter/s, 25.0585s/100 iters), loss = 0.00404874
I0417 14:06:27.255767 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:06:27.255774 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:06:27.255779 22508 solver.cpp:238]     Train net output #2: loss = 0.00404843 (* 1 = 0.00404843 loss)
I0417 14:06:27.255784 22508 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0417 14:06:49.326283 22508 solver.cpp:219] Iteration 59100 (4.53103 iter/s, 22.07s/100 iters), loss = 0.00415244
I0417 14:06:49.326325 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:06:49.326331 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:06:49.326337 22508 solver.cpp:238]     Train net output #2: loss = 0.00415213 (* 1 = 0.00415213 loss)
I0417 14:06:49.326341 22508 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0417 14:07:11.377148 22508 solver.cpp:219] Iteration 59200 (4.53508 iter/s, 22.0503s/100 iters), loss = 0.00324691
I0417 14:07:11.377326 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:07:11.377336 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:07:11.377344 22508 solver.cpp:238]     Train net output #2: loss = 0.0032466 (* 1 = 0.0032466 loss)
I0417 14:07:11.377349 22508 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0417 14:07:33.392774 22508 solver.cpp:219] Iteration 59300 (4.54237 iter/s, 22.015s/100 iters), loss = 0.00207117
I0417 14:07:33.393360 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:07:33.393368 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:07:33.393375 22508 solver.cpp:238]     Train net output #2: loss = 0.00207086 (* 1 = 0.00207086 loss)
I0417 14:07:33.393380 22508 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0417 14:07:48.813968 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:07:55.422291 22508 solver.cpp:219] Iteration 59400 (4.53959 iter/s, 22.0284s/100 iters), loss = 0.00261099
I0417 14:07:55.422327 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:07:55.422333 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:07:55.422339 22508 solver.cpp:238]     Train net output #2: loss = 0.00261067 (* 1 = 0.00261067 loss)
I0417 14:07:55.422344 22508 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0417 14:08:17.455221 22508 solver.cpp:219] Iteration 59500 (4.53877 iter/s, 22.0324s/100 iters), loss = 0.00307619
I0417 14:08:17.455683 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:08:17.455690 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:08:17.455698 22508 solver.cpp:238]     Train net output #2: loss = 0.00307588 (* 1 = 0.00307588 loss)
I0417 14:08:17.455703 22508 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0417 14:08:39.418273 22508 solver.cpp:219] Iteration 59600 (4.5533 iter/s, 21.9621s/100 iters), loss = 0.00262387
I0417 14:08:39.418388 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:08:39.418396 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:08:39.418402 22508 solver.cpp:238]     Train net output #2: loss = 0.00262356 (* 1 = 0.00262356 loss)
I0417 14:08:39.418409 22508 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0417 14:09:01.389701 22508 solver.cpp:219] Iteration 59700 (4.55149 iter/s, 21.9708s/100 iters), loss = 0.00315788
I0417 14:09:01.389727 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:09:01.389732 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:09:01.389739 22508 solver.cpp:238]     Train net output #2: loss = 0.00315756 (* 1 = 0.00315756 loss)
I0417 14:09:01.389742 22508 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0417 14:09:14.798568 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:09:23.367352 22508 solver.cpp:219] Iteration 59800 (4.55018 iter/s, 21.9771s/100 iters), loss = 0.00292012
I0417 14:09:23.367399 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:09:23.367406 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:09:23.367413 22508 solver.cpp:238]     Train net output #2: loss = 0.00291981 (* 1 = 0.00291981 loss)
I0417 14:09:23.367418 22508 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0417 14:09:45.347923 22508 solver.cpp:219] Iteration 59900 (4.54958 iter/s, 21.98s/100 iters), loss = 0.00414881
I0417 14:09:45.348039 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:09:45.348047 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:09:45.348054 22508 solver.cpp:238]     Train net output #2: loss = 0.0041485 (* 1 = 0.0041485 loss)
I0417 14:09:45.348060 22508 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0417 14:10:07.164157 22508 solver.cpp:448] Snapshotting to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_60000.caffemodel
I0417 14:10:07.171144 22508 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_60000.solverstate
I0417 14:10:07.173173 22508 solver.cpp:331] Iteration 60000, Testing net (#0)
I0417 14:10:10.119529 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:10:10.240501 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8152
I0417 14:10:10.240526 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9884
I0417 14:10:10.240546 22508 solver.cpp:398]     Test net output #2: loss = 0.890329 (* 1 = 0.890329 loss)
I0417 14:10:10.458765 22508 solver.cpp:219] Iteration 60000 (3.98245 iter/s, 25.1102s/100 iters), loss = 0.00432086
I0417 14:10:10.458798 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:10:10.458803 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:10:10.458808 22508 solver.cpp:238]     Train net output #2: loss = 0.00432055 (* 1 = 0.00432055 loss)
I0417 14:10:10.458814 22508 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I0417 14:10:32.460505 22508 solver.cpp:219] Iteration 60100 (4.5452 iter/s, 22.0012s/100 iters), loss = 0.00265295
I0417 14:10:32.461236 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:10:32.461246 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:10:32.461253 22508 solver.cpp:238]     Train net output #2: loss = 0.00265264 (* 1 = 0.00265264 loss)
I0417 14:10:32.461257 22508 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I0417 14:10:43.865612 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:10:54.433801 22508 solver.cpp:219] Iteration 60200 (4.55123 iter/s, 21.9721s/100 iters), loss = 0.00366383
I0417 14:10:54.433850 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:10:54.433856 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:10:54.433863 22508 solver.cpp:238]     Train net output #2: loss = 0.00366352 (* 1 = 0.00366352 loss)
I0417 14:10:54.433867 22508 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I0417 14:11:16.429630 22508 solver.cpp:219] Iteration 60300 (4.54643 iter/s, 21.9953s/100 iters), loss = 0.0032124
I0417 14:11:16.429775 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:11:16.429782 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:11:16.429790 22508 solver.cpp:238]     Train net output #2: loss = 0.00321208 (* 1 = 0.00321208 loss)
I0417 14:11:16.429793 22508 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I0417 14:11:38.449816 22508 solver.cpp:219] Iteration 60400 (4.54142 iter/s, 22.0195s/100 iters), loss = 0.00299191
I0417 14:11:38.449857 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:11:38.449863 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:11:38.449870 22508 solver.cpp:238]     Train net output #2: loss = 0.0029916 (* 1 = 0.0029916 loss)
I0417 14:11:38.449874 22508 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I0417 14:12:00.519502 22508 solver.cpp:219] Iteration 60500 (4.53121 iter/s, 22.0692s/100 iters), loss = 0.00315962
I0417 14:12:00.519649 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:12:00.519659 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:12:00.519665 22508 solver.cpp:238]     Train net output #2: loss = 0.00315931 (* 1 = 0.00315931 loss)
I0417 14:12:00.519670 22508 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I0417 14:12:09.793103 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:12:22.558321 22508 solver.cpp:219] Iteration 60600 (4.53758 iter/s, 22.0382s/100 iters), loss = 0.00253837
I0417 14:12:22.558372 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:12:22.558378 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:12:22.558385 22508 solver.cpp:238]     Train net output #2: loss = 0.00253806 (* 1 = 0.00253806 loss)
I0417 14:12:22.558389 22508 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I0417 14:12:44.562676 22508 solver.cpp:219] Iteration 60700 (4.54467 iter/s, 22.0038s/100 iters), loss = 0.00293372
I0417 14:12:44.562810 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:12:44.562819 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:12:44.562826 22508 solver.cpp:238]     Train net output #2: loss = 0.00293341 (* 1 = 0.00293341 loss)
I0417 14:12:44.562831 22508 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I0417 14:13:06.503584 22508 solver.cpp:219] Iteration 60800 (4.55783 iter/s, 21.9403s/100 iters), loss = 0.00353757
I0417 14:13:06.503625 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:13:06.503631 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:13:06.503638 22508 solver.cpp:238]     Train net output #2: loss = 0.00353726 (* 1 = 0.00353726 loss)
I0417 14:13:06.503641 22508 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I0417 14:13:28.467830 22508 solver.cpp:219] Iteration 60900 (4.55296 iter/s, 21.9637s/100 iters), loss = 0.00332745
I0417 14:13:28.468498 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:13:28.468508 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:13:28.468513 22508 solver.cpp:238]     Train net output #2: loss = 0.00332714 (* 1 = 0.00332714 loss)
I0417 14:13:28.468518 22508 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I0417 14:13:35.716225 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:13:50.206645 22508 solver.cpp:331] Iteration 61000, Testing net (#0)
I0417 14:13:53.150766 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:13:53.271760 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8166
I0417 14:13:53.271785 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9881
I0417 14:13:53.271803 22508 solver.cpp:398]     Test net output #2: loss = 0.898634 (* 1 = 0.898634 loss)
I0417 14:13:53.489424 22508 solver.cpp:219] Iteration 61000 (3.99674 iter/s, 25.0204s/100 iters), loss = 0.00404997
I0417 14:13:53.489445 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:13:53.489451 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:13:53.489457 22508 solver.cpp:238]     Train net output #2: loss = 0.00404965 (* 1 = 0.00404965 loss)
I0417 14:13:53.489464 22508 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I0417 14:14:15.471034 22508 solver.cpp:219] Iteration 61100 (4.54936 iter/s, 21.9811s/100 iters), loss = 0.00208943
I0417 14:14:15.471547 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:14:15.471556 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:14:15.471562 22508 solver.cpp:238]     Train net output #2: loss = 0.00208912 (* 1 = 0.00208912 loss)
I0417 14:14:15.471566 22508 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I0417 14:14:37.435323 22508 solver.cpp:219] Iteration 61200 (4.55305 iter/s, 21.9633s/100 iters), loss = 0.003482
I0417 14:14:37.435359 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:14:37.435365 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:14:37.435371 22508 solver.cpp:238]     Train net output #2: loss = 0.00348169 (* 1 = 0.00348169 loss)
I0417 14:14:37.435375 22508 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I0417 14:14:59.373023 22508 solver.cpp:219] Iteration 61300 (4.55847 iter/s, 21.9372s/100 iters), loss = 0.00539459
I0417 14:14:59.373199 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:14:59.373208 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:14:59.373215 22508 solver.cpp:238]     Train net output #2: loss = 0.00539428 (* 1 = 0.00539428 loss)
I0417 14:14:59.373219 22508 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I0417 14:15:04.653344 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:15:21.389724 22508 solver.cpp:219] Iteration 61400 (4.54214 iter/s, 22.016s/100 iters), loss = 0.00289743
I0417 14:15:21.390297 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:15:21.390305 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:15:21.390312 22508 solver.cpp:238]     Train net output #2: loss = 0.00289712 (* 1 = 0.00289712 loss)
I0417 14:15:21.390316 22508 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I0417 14:15:43.442109 22508 solver.cpp:219] Iteration 61500 (4.53487 iter/s, 22.0513s/100 iters), loss = 0.00549997
I0417 14:15:43.442253 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:15:43.442261 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:15:43.442267 22508 solver.cpp:238]     Train net output #2: loss = 0.00549966 (* 1 = 0.00549966 loss)
I0417 14:15:43.442272 22508 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I0417 14:16:05.529604 22508 solver.cpp:219] Iteration 61600 (4.52758 iter/s, 22.0869s/100 iters), loss = 0.00218552
I0417 14:16:05.529640 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:16:05.529646 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:16:05.529652 22508 solver.cpp:238]     Train net output #2: loss = 0.00218521 (* 1 = 0.00218521 loss)
I0417 14:16:05.529656 22508 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I0417 14:16:27.627598 22508 solver.cpp:219] Iteration 61700 (4.52541 iter/s, 22.0975s/100 iters), loss = 0.00255661
I0417 14:16:27.627723 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:16:27.627732 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:16:27.627738 22508 solver.cpp:238]     Train net output #2: loss = 0.0025563 (* 1 = 0.0025563 loss)
I0417 14:16:27.627743 22508 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I0417 14:16:30.727077 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:16:49.707710 22508 solver.cpp:219] Iteration 61800 (4.52909 iter/s, 22.0795s/100 iters), loss = 0.0041879
I0417 14:16:49.707747 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:16:49.707752 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:16:49.707759 22508 solver.cpp:238]     Train net output #2: loss = 0.00418759 (* 1 = 0.00418759 loss)
I0417 14:16:49.707763 22508 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I0417 14:17:11.812325 22508 solver.cpp:219] Iteration 61900 (4.52405 iter/s, 22.1041s/100 iters), loss = 0.00267432
I0417 14:17:11.812419 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:17:11.812427 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:17:11.812434 22508 solver.cpp:238]     Train net output #2: loss = 0.00267401 (* 1 = 0.00267401 loss)
I0417 14:17:11.812438 22508 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I0417 14:17:33.689273 22508 solver.cpp:331] Iteration 62000, Testing net (#0)
I0417 14:17:36.620868 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:17:36.741644 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8162
I0417 14:17:36.741668 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9879
I0417 14:17:36.741690 22508 solver.cpp:398]     Test net output #2: loss = 0.900167 (* 1 = 0.900167 loss)
I0417 14:17:36.960700 22508 solver.cpp:219] Iteration 62000 (3.9765 iter/s, 25.1477s/100 iters), loss = 0.00208287
I0417 14:17:36.960721 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:17:36.960726 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:17:36.960731 22508 solver.cpp:238]     Train net output #2: loss = 0.00208256 (* 1 = 0.00208256 loss)
I0417 14:17:36.960736 22508 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I0417 14:17:59.053114 22508 solver.cpp:219] Iteration 62100 (4.52655 iter/s, 22.0919s/100 iters), loss = 0.00281385
I0417 14:17:59.053259 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:17:59.053268 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:17:59.053274 22508 solver.cpp:238]     Train net output #2: loss = 0.00281354 (* 1 = 0.00281354 loss)
I0417 14:17:59.053279 22508 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I0417 14:18:00.162421 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:18:21.142195 22508 solver.cpp:219] Iteration 62200 (4.52725 iter/s, 22.0884s/100 iters), loss = 0.00426175
I0417 14:18:21.142755 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:18:21.142762 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:18:21.142769 22508 solver.cpp:238]     Train net output #2: loss = 0.00426144 (* 1 = 0.00426144 loss)
I0417 14:18:21.142774 22508 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I0417 14:18:43.201305 22508 solver.cpp:219] Iteration 62300 (4.53349 iter/s, 22.0581s/100 iters), loss = 0.00358194
I0417 14:18:43.201427 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:18:43.201434 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:18:43.201442 22508 solver.cpp:238]     Train net output #2: loss = 0.00358163 (* 1 = 0.00358163 loss)
I0417 14:18:43.201447 22508 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I0417 14:19:05.293606 22508 solver.cpp:219] Iteration 62400 (4.52659 iter/s, 22.0917s/100 iters), loss = 0.00249065
I0417 14:19:05.293639 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:19:05.293644 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:19:05.293651 22508 solver.cpp:238]     Train net output #2: loss = 0.00249034 (* 1 = 0.00249034 loss)
I0417 14:19:05.293655 22508 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I0417 14:19:26.288216 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:19:27.388674 22508 solver.cpp:219] Iteration 62500 (4.526 iter/s, 22.0945s/100 iters), loss = 0.00350893
I0417 14:19:27.388715 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:19:27.388722 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:19:27.388728 22508 solver.cpp:238]     Train net output #2: loss = 0.00350862 (* 1 = 0.00350862 loss)
I0417 14:19:27.388733 22508 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I0417 14:19:49.425554 22508 solver.cpp:219] Iteration 62600 (4.53796 iter/s, 22.0363s/100 iters), loss = 0.00389725
I0417 14:19:49.426131 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:19:49.426137 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:19:49.426144 22508 solver.cpp:238]     Train net output #2: loss = 0.00389693 (* 1 = 0.00389693 loss)
I0417 14:19:49.426149 22508 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I0417 14:20:11.513389 22508 solver.cpp:219] Iteration 62700 (4.5276 iter/s, 22.0868s/100 iters), loss = 0.0031047
I0417 14:20:11.513506 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:20:11.513514 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:20:11.513520 22508 solver.cpp:238]     Train net output #2: loss = 0.00310439 (* 1 = 0.00310439 loss)
I0417 14:20:11.513525 22508 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I0417 14:20:33.582628 22508 solver.cpp:219] Iteration 62800 (4.53132 iter/s, 22.0686s/100 iters), loss = 0.00224776
I0417 14:20:33.582669 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:20:33.582675 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:20:33.582681 22508 solver.cpp:238]     Train net output #2: loss = 0.00224744 (* 1 = 0.00224744 loss)
I0417 14:20:33.582685 22508 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I0417 14:20:52.589388 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:20:55.696841 22508 solver.cpp:219] Iteration 62900 (4.52209 iter/s, 22.1137s/100 iters), loss = 0.00433308
I0417 14:20:55.696876 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:20:55.696882 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:20:55.696887 22508 solver.cpp:238]     Train net output #2: loss = 0.00433277 (* 1 = 0.00433277 loss)
I0417 14:20:55.696892 22508 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I0417 14:21:17.488363 22508 solver.cpp:331] Iteration 63000, Testing net (#0)
I0417 14:21:20.429934 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:21:20.550469 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8152
I0417 14:21:20.550495 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9878
I0417 14:21:20.550503 22508 solver.cpp:398]     Test net output #2: loss = 0.911527 (* 1 = 0.911527 loss)
I0417 14:21:20.768631 22508 solver.cpp:219] Iteration 63000 (3.98864 iter/s, 25.0712s/100 iters), loss = 0.00282074
I0417 14:21:20.768652 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:21:20.768656 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:21:20.768662 22508 solver.cpp:238]     Train net output #2: loss = 0.00282042 (* 1 = 0.00282042 loss)
I0417 14:21:20.768668 22508 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I0417 14:21:42.860471 22508 solver.cpp:219] Iteration 63100 (4.52666 iter/s, 22.0913s/100 iters), loss = 0.00270175
I0417 14:21:42.860611 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:21:42.860620 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:21:42.860626 22508 solver.cpp:238]     Train net output #2: loss = 0.00270144 (* 1 = 0.00270144 loss)
I0417 14:21:42.860631 22508 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I0417 14:22:04.939270 22508 solver.cpp:219] Iteration 63200 (4.52936 iter/s, 22.0782s/100 iters), loss = 0.00102418
I0417 14:22:04.939309 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:22:04.939316 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:22:04.939321 22508 solver.cpp:238]     Train net output #2: loss = 0.00102387 (* 1 = 0.00102387 loss)
I0417 14:22:04.939327 22508 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I0417 14:22:21.955667 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:22:27.035692 22508 solver.cpp:219] Iteration 63300 (4.52573 iter/s, 22.0959s/100 iters), loss = 0.00297346
I0417 14:22:27.035742 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:22:27.035748 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:22:27.035754 22508 solver.cpp:238]     Train net output #2: loss = 0.00297315 (* 1 = 0.00297315 loss)
I0417 14:22:27.035759 22508 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I0417 14:22:49.159749 22508 solver.cpp:219] Iteration 63400 (4.52008 iter/s, 22.1235s/100 iters), loss = 0.00212216
I0417 14:22:49.159797 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:22:49.159803 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:22:49.159811 22508 solver.cpp:238]     Train net output #2: loss = 0.00212185 (* 1 = 0.00212185 loss)
I0417 14:22:49.159816 22508 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I0417 14:23:11.233134 22508 solver.cpp:219] Iteration 63500 (4.53045 iter/s, 22.0728s/100 iters), loss = 0.00309216
I0417 14:23:11.233242 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:23:11.233249 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:23:11.233256 22508 solver.cpp:238]     Train net output #2: loss = 0.00309185 (* 1 = 0.00309185 loss)
I0417 14:23:11.233261 22508 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I0417 14:23:33.285789 22508 solver.cpp:219] Iteration 63600 (4.53472 iter/s, 22.0521s/100 iters), loss = 0.00278525
I0417 14:23:33.285837 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:23:33.285845 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:23:33.285851 22508 solver.cpp:238]     Train net output #2: loss = 0.00278493 (* 1 = 0.00278493 loss)
I0417 14:23:33.285856 22508 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I0417 14:23:48.050060 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:23:55.339974 22508 solver.cpp:219] Iteration 63700 (4.5344 iter/s, 22.0536s/100 iters), loss = 0.00175409
I0417 14:23:55.340014 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:23:55.340020 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:23:55.340026 22508 solver.cpp:238]     Train net output #2: loss = 0.00175377 (* 1 = 0.00175377 loss)
I0417 14:23:55.340030 22508 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I0417 14:24:17.413278 22508 solver.cpp:219] Iteration 63800 (4.53047 iter/s, 22.0728s/100 iters), loss = 0.00208692
I0417 14:24:17.413748 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:24:17.413755 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:24:17.413761 22508 solver.cpp:238]     Train net output #2: loss = 0.00208661 (* 1 = 0.00208661 loss)
I0417 14:24:17.413766 22508 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I0417 14:24:39.416960 22508 solver.cpp:219] Iteration 63900 (4.54489 iter/s, 22.0027s/100 iters), loss = 0.00233348
I0417 14:24:39.417088 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:24:39.417095 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:24:39.417102 22508 solver.cpp:238]     Train net output #2: loss = 0.00233317 (* 1 = 0.00233317 loss)
I0417 14:24:39.417106 22508 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I0417 14:25:01.171689 22508 solver.cpp:331] Iteration 64000, Testing net (#0)
I0417 14:25:04.113706 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:25:04.234232 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8157
I0417 14:25:04.234258 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9879
I0417 14:25:04.234277 22508 solver.cpp:398]     Test net output #2: loss = 0.906707 (* 1 = 0.906707 loss)
I0417 14:25:04.452767 22508 solver.cpp:219] Iteration 64000 (3.99439 iter/s, 25.0351s/100 iters), loss = 0.00130396
I0417 14:25:04.452803 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:25:04.452808 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:25:04.452814 22508 solver.cpp:238]     Train net output #2: loss = 0.00130365 (* 1 = 0.00130365 loss)
I0417 14:25:04.452819 22508 sgd_solver.cpp:46] MultiStep Status: Iteration 64000, step = 2
I0417 14:25:04.452823 22508 sgd_solver.cpp:105] Iteration 64000, lr = 0.001
I0417 14:25:17.204744 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:25:26.431861 22508 solver.cpp:219] Iteration 64100 (4.54989 iter/s, 21.9786s/100 iters), loss = 0.00320344
I0417 14:25:26.431912 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:25:26.431917 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:25:26.431924 22508 solver.cpp:238]     Train net output #2: loss = 0.00320313 (* 1 = 0.00320313 loss)
I0417 14:25:26.431928 22508 sgd_solver.cpp:105] Iteration 64100, lr = 0.001
I0417 14:25:48.419513 22508 solver.cpp:219] Iteration 64200 (4.54812 iter/s, 21.9871s/100 iters), loss = 0.00238255
I0417 14:25:48.419627 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:25:48.419634 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:25:48.419641 22508 solver.cpp:238]     Train net output #2: loss = 0.00238224 (* 1 = 0.00238224 loss)
I0417 14:25:48.419646 22508 sgd_solver.cpp:105] Iteration 64200, lr = 0.001
I0417 14:26:10.388886 22508 solver.cpp:219] Iteration 64300 (4.55192 iter/s, 21.9688s/100 iters), loss = 0.00244092
I0417 14:26:10.388926 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:26:10.388932 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:26:10.388938 22508 solver.cpp:238]     Train net output #2: loss = 0.00244061 (* 1 = 0.00244061 loss)
I0417 14:26:10.388943 22508 sgd_solver.cpp:105] Iteration 64300, lr = 0.001
I0417 14:26:32.316021 22508 solver.cpp:219] Iteration 64400 (4.56067 iter/s, 21.9266s/100 iters), loss = 0.00224986
I0417 14:26:32.316171 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:26:32.316180 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:26:32.316187 22508 solver.cpp:238]     Train net output #2: loss = 0.00224955 (* 1 = 0.00224955 loss)
I0417 14:26:32.316192 22508 sgd_solver.cpp:105] Iteration 64400, lr = 0.001
I0417 14:26:43.046680 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:26:54.257377 22508 solver.cpp:219] Iteration 64500 (4.55773 iter/s, 21.9407s/100 iters), loss = 0.00395958
I0417 14:26:54.257416 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:26:54.257421 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:26:54.257427 22508 solver.cpp:238]     Train net output #2: loss = 0.00395927 (* 1 = 0.00395927 loss)
I0417 14:26:54.257431 22508 sgd_solver.cpp:105] Iteration 64500, lr = 0.001
I0417 14:27:16.179656 22508 solver.cpp:219] Iteration 64600 (4.56168 iter/s, 21.9217s/100 iters), loss = 0.00252689
I0417 14:27:16.180366 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:27:16.180374 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:27:16.180382 22508 solver.cpp:238]     Train net output #2: loss = 0.00252658 (* 1 = 0.00252658 loss)
I0417 14:27:16.180385 22508 sgd_solver.cpp:105] Iteration 64600, lr = 0.001
I0417 14:27:38.143290 22508 solver.cpp:219] Iteration 64700 (4.55323 iter/s, 21.9624s/100 iters), loss = 0.00257271
I0417 14:27:38.143324 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:27:38.143329 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:27:38.143337 22508 solver.cpp:238]     Train net output #2: loss = 0.00257239 (* 1 = 0.00257239 loss)
I0417 14:27:38.143340 22508 sgd_solver.cpp:105] Iteration 64700, lr = 0.001
I0417 14:28:00.131973 22508 solver.cpp:219] Iteration 64800 (4.5479 iter/s, 21.9882s/100 iters), loss = 0.00214665
I0417 14:28:00.132098 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:28:00.132107 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:28:00.132114 22508 solver.cpp:238]     Train net output #2: loss = 0.00214634 (* 1 = 0.00214634 loss)
I0417 14:28:00.132118 22508 sgd_solver.cpp:105] Iteration 64800, lr = 0.001
I0417 14:28:08.706861 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:28:22.103770 22508 solver.cpp:219] Iteration 64900 (4.55142 iter/s, 21.9712s/100 iters), loss = 0.00268325
I0417 14:28:22.104339 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:28:22.104346 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:28:22.104352 22508 solver.cpp:238]     Train net output #2: loss = 0.00268294 (* 1 = 0.00268294 loss)
I0417 14:28:22.104357 22508 sgd_solver.cpp:105] Iteration 64900, lr = 0.001
I0417 14:28:43.888471 22508 solver.cpp:331] Iteration 65000, Testing net (#0)
I0417 14:28:46.828325 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:28:46.948947 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.82
I0417 14:28:46.948968 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9871
I0417 14:28:46.948988 22508 solver.cpp:398]     Test net output #2: loss = 0.912652 (* 1 = 0.912652 loss)
I0417 14:28:47.167461 22508 solver.cpp:219] Iteration 65000 (3.99001 iter/s, 25.0626s/100 iters), loss = 0.00217375
I0417 14:28:47.167491 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:28:47.167497 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:28:47.167502 22508 solver.cpp:238]     Train net output #2: loss = 0.00217344 (* 1 = 0.00217344 loss)
I0417 14:28:47.167507 22508 sgd_solver.cpp:105] Iteration 65000, lr = 0.001
I0417 14:29:09.073423 22508 solver.cpp:219] Iteration 65100 (4.56507 iter/s, 21.9054s/100 iters), loss = 0.00278245
I0417 14:29:09.073462 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:29:09.073467 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:29:09.073474 22508 solver.cpp:238]     Train net output #2: loss = 0.00278214 (* 1 = 0.00278214 loss)
I0417 14:29:09.073478 22508 sgd_solver.cpp:105] Iteration 65100, lr = 0.001
I0417 14:29:31.126627 22508 solver.cpp:219] Iteration 65200 (4.5346 iter/s, 22.0527s/100 iters), loss = 0.00249722
I0417 14:29:31.126824 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:29:31.126833 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:29:31.126840 22508 solver.cpp:238]     Train net output #2: loss = 0.00249691 (* 1 = 0.00249691 loss)
I0417 14:29:31.126844 22508 sgd_solver.cpp:105] Iteration 65200, lr = 0.001
I0417 14:29:37.744065 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:29:53.211408 22508 solver.cpp:219] Iteration 65300 (4.52815 iter/s, 22.0841s/100 iters), loss = 0.00254969
I0417 14:29:53.211447 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:29:53.211454 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:29:53.211460 22508 solver.cpp:238]     Train net output #2: loss = 0.00254938 (* 1 = 0.00254938 loss)
I0417 14:29:53.211464 22508 sgd_solver.cpp:105] Iteration 65300, lr = 0.001
I0417 14:30:15.288182 22508 solver.cpp:219] Iteration 65400 (4.52976 iter/s, 22.0762s/100 iters), loss = 0.00196679
I0417 14:30:15.288805 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:30:15.288812 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:30:15.288820 22508 solver.cpp:238]     Train net output #2: loss = 0.00196648 (* 1 = 0.00196648 loss)
I0417 14:30:15.288823 22508 sgd_solver.cpp:105] Iteration 65400, lr = 0.001
I0417 14:30:37.363718 22508 solver.cpp:219] Iteration 65500 (4.53013 iter/s, 22.0744s/100 iters), loss = 0.00196857
I0417 14:30:37.363751 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:30:37.363757 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:30:37.363765 22508 solver.cpp:238]     Train net output #2: loss = 0.00196826 (* 1 = 0.00196826 loss)
I0417 14:30:37.363770 22508 sgd_solver.cpp:105] Iteration 65500, lr = 0.001
I0417 14:30:59.412000 22508 solver.cpp:219] Iteration 65600 (4.53561 iter/s, 22.0478s/100 iters), loss = 0.00292318
I0417 14:30:59.412139 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:30:59.412147 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:30:59.412154 22508 solver.cpp:238]     Train net output #2: loss = 0.00292287 (* 1 = 0.00292287 loss)
I0417 14:30:59.412159 22508 sgd_solver.cpp:105] Iteration 65600, lr = 0.001
I0417 14:31:03.826896 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:31:21.504967 22508 solver.cpp:219] Iteration 65700 (4.52646 iter/s, 22.0923s/100 iters), loss = 0.00290897
I0417 14:31:21.505537 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:31:21.505545 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:31:21.505551 22508 solver.cpp:238]     Train net output #2: loss = 0.00290866 (* 1 = 0.00290866 loss)
I0417 14:31:21.505556 22508 sgd_solver.cpp:105] Iteration 65700, lr = 0.001
I0417 14:31:43.577419 22508 solver.cpp:219] Iteration 65800 (4.53075 iter/s, 22.0714s/100 iters), loss = 0.0024826
I0417 14:31:43.577549 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:31:43.577558 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:31:43.577564 22508 solver.cpp:238]     Train net output #2: loss = 0.00248229 (* 1 = 0.00248229 loss)
I0417 14:31:43.577569 22508 sgd_solver.cpp:105] Iteration 65800, lr = 0.001
I0417 14:32:05.674578 22508 solver.cpp:219] Iteration 65900 (4.5256 iter/s, 22.0965s/100 iters), loss = 0.00156055
I0417 14:32:05.674636 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:32:05.674644 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:32:05.674651 22508 solver.cpp:238]     Train net output #2: loss = 0.00156023 (* 1 = 0.00156023 loss)
I0417 14:32:05.674657 22508 sgd_solver.cpp:105] Iteration 65900, lr = 0.001
I0417 14:32:27.525670 22508 solver.cpp:331] Iteration 66000, Testing net (#0)
I0417 14:32:30.476119 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:32:30.597290 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8203
I0417 14:32:30.597316 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.986201
I0417 14:32:30.597338 22508 solver.cpp:398]     Test net output #2: loss = 0.922023 (* 1 = 0.922023 loss)
I0417 14:32:30.815421 22508 solver.cpp:219] Iteration 66000 (3.97769 iter/s, 25.1402s/100 iters), loss = 0.00380675
I0417 14:32:30.815444 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:32:30.815449 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:32:30.815455 22508 solver.cpp:238]     Train net output #2: loss = 0.00380643 (* 1 = 0.00380643 loss)
I0417 14:32:30.815462 22508 sgd_solver.cpp:105] Iteration 66000, lr = 0.001
I0417 14:32:33.250989 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:32:52.872710 22508 solver.cpp:219] Iteration 66100 (4.53376 iter/s, 22.0568s/100 iters), loss = 0.00235745
I0417 14:32:52.872756 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:32:52.872763 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:32:52.872772 22508 solver.cpp:238]     Train net output #2: loss = 0.00235714 (* 1 = 0.00235714 loss)
I0417 14:32:52.872778 22508 sgd_solver.cpp:105] Iteration 66100, lr = 0.001
I0417 14:33:14.859522 22508 solver.cpp:219] Iteration 66200 (4.54829 iter/s, 21.9863s/100 iters), loss = 0.00196913
I0417 14:33:14.860221 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:33:14.860230 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:33:14.860237 22508 solver.cpp:238]     Train net output #2: loss = 0.00196882 (* 1 = 0.00196882 loss)
I0417 14:33:14.860242 22508 sgd_solver.cpp:105] Iteration 66200, lr = 0.001
I0417 14:33:36.883898 22508 solver.cpp:219] Iteration 66300 (4.54067 iter/s, 22.0232s/100 iters), loss = 0.00270426
I0417 14:33:36.883941 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:33:36.883949 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:33:36.883955 22508 solver.cpp:238]     Train net output #2: loss = 0.00270395 (* 1 = 0.00270395 loss)
I0417 14:33:36.883960 22508 sgd_solver.cpp:105] Iteration 66300, lr = 0.001
I0417 14:33:58.844197 22508 solver.cpp:219] Iteration 66400 (4.55378 iter/s, 21.9598s/100 iters), loss = 0.00273718
I0417 14:33:58.844310 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:33:58.844319 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:33:58.844327 22508 solver.cpp:238]     Train net output #2: loss = 0.00273687 (* 1 = 0.00273687 loss)
I0417 14:33:58.844332 22508 sgd_solver.cpp:105] Iteration 66400, lr = 0.001
I0417 14:33:59.292001 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:34:20.830206 22508 solver.cpp:219] Iteration 66500 (4.54847 iter/s, 21.9854s/100 iters), loss = 0.00357115
I0417 14:34:20.830255 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:34:20.830261 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:34:20.830267 22508 solver.cpp:238]     Train net output #2: loss = 0.00357084 (* 1 = 0.00357084 loss)
I0417 14:34:20.830271 22508 sgd_solver.cpp:105] Iteration 66500, lr = 0.001
I0417 14:34:42.810279 22508 solver.cpp:219] Iteration 66600 (4.54969 iter/s, 21.9795s/100 iters), loss = 0.00185341
I0417 14:34:42.810430 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:34:42.810437 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:34:42.810444 22508 solver.cpp:238]     Train net output #2: loss = 0.0018531 (* 1 = 0.0018531 loss)
I0417 14:34:42.810448 22508 sgd_solver.cpp:105] Iteration 66600, lr = 0.001
I0417 14:35:04.718906 22508 solver.cpp:219] Iteration 66700 (4.56455 iter/s, 21.908s/100 iters), loss = 0.00232527
I0417 14:35:04.718946 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:35:04.718952 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:35:04.718958 22508 solver.cpp:238]     Train net output #2: loss = 0.00232496 (* 1 = 0.00232496 loss)
I0417 14:35:04.718962 22508 sgd_solver.cpp:105] Iteration 66700, lr = 0.001
I0417 14:35:24.987900 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:35:26.748199 22508 solver.cpp:219] Iteration 66800 (4.53952 iter/s, 22.0288s/100 iters), loss = 0.00208917
I0417 14:35:26.748229 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:35:26.748234 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:35:26.748241 22508 solver.cpp:238]     Train net output #2: loss = 0.00208886 (* 1 = 0.00208886 loss)
I0417 14:35:26.748245 22508 sgd_solver.cpp:105] Iteration 66800, lr = 0.001
I0417 14:35:48.827558 22508 solver.cpp:219] Iteration 66900 (4.52923 iter/s, 22.0788s/100 iters), loss = 0.00223777
I0417 14:35:48.827594 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:35:48.827600 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:35:48.827607 22508 solver.cpp:238]     Train net output #2: loss = 0.00223746 (* 1 = 0.00223746 loss)
I0417 14:35:48.827611 22508 sgd_solver.cpp:105] Iteration 66900, lr = 0.001
I0417 14:36:10.683403 22508 solver.cpp:331] Iteration 67000, Testing net (#0)
I0417 14:36:13.622681 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:36:13.744061 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8198
I0417 14:36:13.744093 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9865
I0417 14:36:13.744113 22508 solver.cpp:398]     Test net output #2: loss = 0.925859 (* 1 = 0.925859 loss)
I0417 14:36:13.962983 22508 solver.cpp:219] Iteration 67000 (3.97854 iter/s, 25.1348s/100 iters), loss = 0.00303725
I0417 14:36:13.963017 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:36:13.963022 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:36:13.963029 22508 solver.cpp:238]     Train net output #2: loss = 0.00303694 (* 1 = 0.00303694 loss)
I0417 14:36:13.963035 22508 sgd_solver.cpp:105] Iteration 67000, lr = 0.001
I0417 14:36:36.034327 22508 solver.cpp:219] Iteration 67100 (4.53087 iter/s, 22.0708s/100 iters), loss = 0.00198882
I0417 14:36:36.034369 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:36:36.034375 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:36:36.034381 22508 solver.cpp:238]     Train net output #2: loss = 0.00198851 (* 1 = 0.00198851 loss)
I0417 14:36:36.034385 22508 sgd_solver.cpp:105] Iteration 67100, lr = 0.001
I0417 14:36:54.343200 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:36:58.089311 22508 solver.cpp:219] Iteration 67200 (4.53423 iter/s, 22.0545s/100 iters), loss = 0.00231302
I0417 14:36:58.089357 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:36:58.089365 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:36:58.089371 22508 solver.cpp:238]     Train net output #2: loss = 0.0023127 (* 1 = 0.0023127 loss)
I0417 14:36:58.089375 22508 sgd_solver.cpp:105] Iteration 67200, lr = 0.001
I0417 14:37:20.158663 22508 solver.cpp:219] Iteration 67300 (4.53128 iter/s, 22.0688s/100 iters), loss = 0.00338057
I0417 14:37:20.159221 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:37:20.159229 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:37:20.159237 22508 solver.cpp:238]     Train net output #2: loss = 0.00338026 (* 1 = 0.00338026 loss)
I0417 14:37:20.159241 22508 sgd_solver.cpp:105] Iteration 67300, lr = 0.001
I0417 14:37:42.199916 22508 solver.cpp:219] Iteration 67400 (4.53716 iter/s, 22.0402s/100 iters), loss = 0.00358086
I0417 14:37:42.200080 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:37:42.200089 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:37:42.200096 22508 solver.cpp:238]     Train net output #2: loss = 0.00358055 (* 1 = 0.00358055 loss)
I0417 14:37:42.200101 22508 sgd_solver.cpp:105] Iteration 67400, lr = 0.001
I0417 14:38:04.298213 22508 solver.cpp:219] Iteration 67500 (4.52537 iter/s, 22.0976s/100 iters), loss = 0.00223307
I0417 14:38:04.298267 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:38:04.298274 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:38:04.298280 22508 solver.cpp:238]     Train net output #2: loss = 0.00223276 (* 1 = 0.00223276 loss)
I0417 14:38:04.298285 22508 sgd_solver.cpp:105] Iteration 67500, lr = 0.001
I0417 14:38:20.575135 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:38:26.266182 22508 solver.cpp:219] Iteration 67600 (4.5522 iter/s, 21.9674s/100 iters), loss = 0.00320375
I0417 14:38:26.266222 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:38:26.266227 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:38:26.266233 22508 solver.cpp:238]     Train net output #2: loss = 0.00320344 (* 1 = 0.00320344 loss)
I0417 14:38:26.266237 22508 sgd_solver.cpp:105] Iteration 67600, lr = 0.001
I0417 14:38:48.248309 22508 solver.cpp:219] Iteration 67700 (4.54926 iter/s, 21.9816s/100 iters), loss = 0.00239966
I0417 14:38:48.248345 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:38:48.248352 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:38:48.248358 22508 solver.cpp:238]     Train net output #2: loss = 0.00239934 (* 1 = 0.00239934 loss)
I0417 14:38:48.248361 22508 sgd_solver.cpp:105] Iteration 67700, lr = 0.001
I0417 14:39:10.294245 22508 solver.cpp:219] Iteration 67800 (4.53609 iter/s, 22.0454s/100 iters), loss = 0.00380861
I0417 14:39:10.294950 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:39:10.294960 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:39:10.294967 22508 solver.cpp:238]     Train net output #2: loss = 0.0038083 (* 1 = 0.0038083 loss)
I0417 14:39:10.294971 22508 sgd_solver.cpp:105] Iteration 67800, lr = 0.001
I0417 14:39:32.326557 22508 solver.cpp:219] Iteration 67900 (4.53904 iter/s, 22.0311s/100 iters), loss = 0.00259298
I0417 14:39:32.326599 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:39:32.326606 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:39:32.326611 22508 solver.cpp:238]     Train net output #2: loss = 0.00259267 (* 1 = 0.00259267 loss)
I0417 14:39:32.326617 22508 sgd_solver.cpp:105] Iteration 67900, lr = 0.001
I0417 14:39:46.408826 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:39:54.132066 22508 solver.cpp:331] Iteration 68000, Testing net (#0)
I0417 14:39:57.069720 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:39:57.190124 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8209
I0417 14:39:57.190147 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9861
I0417 14:39:57.190171 22508 solver.cpp:398]     Test net output #2: loss = 0.927834 (* 1 = 0.927834 loss)
I0417 14:39:57.407881 22508 solver.cpp:219] Iteration 68000 (3.98713 iter/s, 25.0807s/100 iters), loss = 0.00207934
I0417 14:39:57.407915 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:39:57.407922 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:39:57.407927 22508 solver.cpp:238]     Train net output #2: loss = 0.00207903 (* 1 = 0.00207903 loss)
I0417 14:39:57.407932 22508 sgd_solver.cpp:105] Iteration 68000, lr = 0.001
I0417 14:40:19.406064 22508 solver.cpp:219] Iteration 68100 (4.54594 iter/s, 21.9977s/100 iters), loss = 0.00345374
I0417 14:40:19.406769 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:40:19.406777 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:40:19.406785 22508 solver.cpp:238]     Train net output #2: loss = 0.00345343 (* 1 = 0.00345343 loss)
I0417 14:40:19.406788 22508 sgd_solver.cpp:105] Iteration 68100, lr = 0.001
I0417 14:40:41.396765 22508 solver.cpp:219] Iteration 68200 (4.54762 iter/s, 21.9895s/100 iters), loss = 0.00202412
I0417 14:40:41.396821 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:40:41.396827 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:40:41.396836 22508 solver.cpp:238]     Train net output #2: loss = 0.0020238 (* 1 = 0.0020238 loss)
I0417 14:40:41.396841 22508 sgd_solver.cpp:105] Iteration 68200, lr = 0.001
I0417 14:41:03.390229 22508 solver.cpp:219] Iteration 68300 (4.54692 iter/s, 21.9929s/100 iters), loss = 0.00301253
I0417 14:41:03.390379 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:41:03.390388 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:41:03.390395 22508 solver.cpp:238]     Train net output #2: loss = 0.00301222 (* 1 = 0.00301222 loss)
I0417 14:41:03.390399 22508 sgd_solver.cpp:105] Iteration 68300, lr = 0.001
I0417 14:41:15.535146 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:41:25.410883 22508 solver.cpp:219] Iteration 68400 (4.54132 iter/s, 22.02s/100 iters), loss = 0.00178969
I0417 14:41:25.410922 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:41:25.410928 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:41:25.410934 22508 solver.cpp:238]     Train net output #2: loss = 0.00178937 (* 1 = 0.00178937 loss)
I0417 14:41:25.410938 22508 sgd_solver.cpp:105] Iteration 68400, lr = 0.001
I0417 14:41:47.442008 22508 solver.cpp:219] Iteration 68500 (4.53914 iter/s, 22.0306s/100 iters), loss = 0.0014134
I0417 14:41:47.442142 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:41:47.442149 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:41:47.442157 22508 solver.cpp:238]     Train net output #2: loss = 0.00141309 (* 1 = 0.00141309 loss)
I0417 14:41:47.442162 22508 sgd_solver.cpp:105] Iteration 68500, lr = 0.001
I0417 14:42:09.442940 22508 solver.cpp:219] Iteration 68600 (4.54539 iter/s, 22.0003s/100 iters), loss = 0.00318323
I0417 14:42:09.442976 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:42:09.442982 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:42:09.442988 22508 solver.cpp:238]     Train net output #2: loss = 0.00318292 (* 1 = 0.00318292 loss)
I0417 14:42:09.442992 22508 sgd_solver.cpp:105] Iteration 68600, lr = 0.001
I0417 14:42:31.433923 22508 solver.cpp:219] Iteration 68700 (4.54743 iter/s, 21.9905s/100 iters), loss = 0.00342427
I0417 14:42:31.434046 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:42:31.434054 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:42:31.434062 22508 solver.cpp:238]     Train net output #2: loss = 0.00342396 (* 1 = 0.00342396 loss)
I0417 14:42:31.434067 22508 sgd_solver.cpp:105] Iteration 68700, lr = 0.001
I0417 14:42:41.341795 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:42:53.419898 22508 solver.cpp:219] Iteration 68800 (4.54848 iter/s, 21.9854s/100 iters), loss = 0.00199734
I0417 14:42:53.419935 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:42:53.419941 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:42:53.419947 22508 solver.cpp:238]     Train net output #2: loss = 0.00199703 (* 1 = 0.00199703 loss)
I0417 14:42:53.419951 22508 sgd_solver.cpp:105] Iteration 68800, lr = 0.001
I0417 14:43:15.382683 22508 solver.cpp:219] Iteration 68900 (4.55327 iter/s, 21.9622s/100 iters), loss = 0.00247221
I0417 14:43:15.383400 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:43:15.383409 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:43:15.383415 22508 solver.cpp:238]     Train net output #2: loss = 0.0024719 (* 1 = 0.0024719 loss)
I0417 14:43:15.383420 22508 sgd_solver.cpp:105] Iteration 68900, lr = 0.001
I0417 14:43:37.166692 22508 solver.cpp:331] Iteration 69000, Testing net (#0)
I0417 14:43:40.111856 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:43:40.232966 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8211
I0417 14:43:40.232992 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9863
I0417 14:43:40.233013 22508 solver.cpp:398]     Test net output #2: loss = 0.928653 (* 1 = 0.928653 loss)
I0417 14:43:40.451484 22508 solver.cpp:219] Iteration 69000 (3.98922 iter/s, 25.0675s/100 iters), loss = 0.00306417
I0417 14:43:40.451517 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:43:40.451524 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:43:40.451529 22508 solver.cpp:238]     Train net output #2: loss = 0.00306386 (* 1 = 0.00306386 loss)
I0417 14:43:40.451534 22508 sgd_solver.cpp:105] Iteration 69000, lr = 0.001
I0417 14:44:02.412343 22508 solver.cpp:219] Iteration 69100 (4.55366 iter/s, 21.9603s/100 iters), loss = 0.00357812
I0417 14:44:02.412499 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:44:02.412508 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:44:02.412515 22508 solver.cpp:238]     Train net output #2: loss = 0.00357781 (* 1 = 0.00357781 loss)
I0417 14:44:02.412520 22508 sgd_solver.cpp:105] Iteration 69100, lr = 0.001
I0417 14:44:10.321130 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:44:24.373280 22508 solver.cpp:219] Iteration 69200 (4.55367 iter/s, 21.9603s/100 iters), loss = 0.0024815
I0417 14:44:24.373865 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:44:24.373873 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:44:24.373879 22508 solver.cpp:238]     Train net output #2: loss = 0.00248119 (* 1 = 0.00248119 loss)
I0417 14:44:24.373884 22508 sgd_solver.cpp:105] Iteration 69200, lr = 0.001
I0417 14:44:46.324064 22508 solver.cpp:219] Iteration 69300 (4.55587 iter/s, 21.9497s/100 iters), loss = 0.00363815
I0417 14:44:46.324308 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:44:46.324317 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:44:46.324323 22508 solver.cpp:238]     Train net output #2: loss = 0.00363784 (* 1 = 0.00363784 loss)
I0417 14:44:46.324328 22508 sgd_solver.cpp:105] Iteration 69300, lr = 0.001
I0417 14:45:08.369181 22508 solver.cpp:219] Iteration 69400 (4.5363 iter/s, 22.0444s/100 iters), loss = 0.00235129
I0417 14:45:08.369227 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:45:08.369233 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:45:08.369240 22508 solver.cpp:238]     Train net output #2: loss = 0.00235098 (* 1 = 0.00235098 loss)
I0417 14:45:08.369246 22508 sgd_solver.cpp:105] Iteration 69400, lr = 0.001
I0417 14:45:30.428742 22508 solver.cpp:219] Iteration 69500 (4.53329 iter/s, 22.059s/100 iters), loss = 0.00173811
I0417 14:45:30.428900 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:45:30.428908 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:45:30.428915 22508 solver.cpp:238]     Train net output #2: loss = 0.0017378 (* 1 = 0.0017378 loss)
I0417 14:45:30.428920 22508 sgd_solver.cpp:105] Iteration 69500, lr = 0.001
I0417 14:45:36.393652 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:45:52.499034 22508 solver.cpp:219] Iteration 69600 (4.53111 iter/s, 22.0696s/100 iters), loss = 0.00320181
I0417 14:45:52.499071 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:45:52.499078 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:45:52.499083 22508 solver.cpp:238]     Train net output #2: loss = 0.00320149 (* 1 = 0.00320149 loss)
I0417 14:45:52.499089 22508 sgd_solver.cpp:105] Iteration 69600, lr = 0.001
I0417 14:46:14.587366 22508 solver.cpp:219] Iteration 69700 (4.52739 iter/s, 22.0878s/100 iters), loss = 0.0014741
I0417 14:46:14.587894 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:46:14.587903 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:46:14.587910 22508 solver.cpp:238]     Train net output #2: loss = 0.00147379 (* 1 = 0.00147379 loss)
I0417 14:46:14.587915 22508 sgd_solver.cpp:105] Iteration 69700, lr = 0.001
I0417 14:46:36.663003 22508 solver.cpp:219] Iteration 69800 (4.53009 iter/s, 22.0746s/100 iters), loss = 0.00188636
I0417 14:46:36.663039 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:46:36.663046 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:46:36.663053 22508 solver.cpp:238]     Train net output #2: loss = 0.00188605 (* 1 = 0.00188605 loss)
I0417 14:46:36.663056 22508 sgd_solver.cpp:105] Iteration 69800, lr = 0.001
I0417 14:46:58.716809 22508 solver.cpp:219] Iteration 69900 (4.53447 iter/s, 22.0533s/100 iters), loss = 0.00354239
I0417 14:46:58.716953 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:46:58.716961 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:46:58.716969 22508 solver.cpp:238]     Train net output #2: loss = 0.00354208 (* 1 = 0.00354208 loss)
I0417 14:46:58.716974 22508 sgd_solver.cpp:105] Iteration 69900, lr = 0.001
I0417 14:47:02.485324 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:47:20.610689 22508 solver.cpp:448] Snapshotting to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_70000.caffemodel
I0417 14:47:20.617672 22508 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_70000.solverstate
I0417 14:47:20.619715 22508 solver.cpp:331] Iteration 70000, Testing net (#0)
I0417 14:47:23.565269 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:47:23.686142 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8205
I0417 14:47:23.686173 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9862
I0417 14:47:23.686182 22508 solver.cpp:398]     Test net output #2: loss = 0.928594 (* 1 = 0.928594 loss)
I0417 14:47:23.904336 22508 solver.cpp:219] Iteration 70000 (3.97033 iter/s, 25.1868s/100 iters), loss = 0.00260096
I0417 14:47:23.904358 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:47:23.904363 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:47:23.904368 22508 solver.cpp:238]     Train net output #2: loss = 0.00260064 (* 1 = 0.00260064 loss)
I0417 14:47:23.904374 22508 sgd_solver.cpp:105] Iteration 70000, lr = 0.001
I0417 14:47:45.990205 22508 solver.cpp:219] Iteration 70100 (4.52789 iter/s, 22.0854s/100 iters), loss = 0.00233994
I0417 14:47:45.990345 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:47:45.990352 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:47:45.990360 22508 solver.cpp:238]     Train net output #2: loss = 0.00233963 (* 1 = 0.00233963 loss)
I0417 14:47:45.990365 22508 sgd_solver.cpp:105] Iteration 70100, lr = 0.001
I0417 14:48:08.049778 22508 solver.cpp:219] Iteration 70200 (4.53331 iter/s, 22.0589s/100 iters), loss = 0.00223944
I0417 14:48:08.049826 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:48:08.049834 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:48:08.049839 22508 solver.cpp:238]     Train net output #2: loss = 0.00223913 (* 1 = 0.00223913 loss)
I0417 14:48:08.049844 22508 sgd_solver.cpp:105] Iteration 70200, lr = 0.001
I0417 14:48:30.112696 22508 solver.cpp:219] Iteration 70300 (4.5326 iter/s, 22.0624s/100 iters), loss = 0.00150869
I0417 14:48:30.112826 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:48:30.112834 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:48:30.112841 22508 solver.cpp:238]     Train net output #2: loss = 0.00150838 (* 1 = 0.00150838 loss)
I0417 14:48:30.112846 22508 sgd_solver.cpp:105] Iteration 70300, lr = 0.001
I0417 14:48:31.882684 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:48:52.149317 22508 solver.cpp:219] Iteration 70400 (4.53803 iter/s, 22.036s/100 iters), loss = 0.00258363
I0417 14:48:52.149354 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:48:52.149360 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:48:52.149366 22508 solver.cpp:238]     Train net output #2: loss = 0.00258332 (* 1 = 0.00258332 loss)
I0417 14:48:52.149370 22508 sgd_solver.cpp:105] Iteration 70400, lr = 0.001
I0417 14:49:14.172615 22508 solver.cpp:219] Iteration 70500 (4.54076 iter/s, 22.0228s/100 iters), loss = 0.00203161
I0417 14:49:14.173220 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:49:14.173230 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:49:14.173238 22508 solver.cpp:238]     Train net output #2: loss = 0.0020313 (* 1 = 0.0020313 loss)
I0417 14:49:14.173247 22508 sgd_solver.cpp:105] Iteration 70500, lr = 0.001
I0417 14:49:36.136055 22508 solver.cpp:219] Iteration 70600 (4.55325 iter/s, 21.9623s/100 iters), loss = 0.00235549
I0417 14:49:36.136678 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:49:36.136687 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:49:36.136695 22508 solver.cpp:238]     Train net output #2: loss = 0.00235518 (* 1 = 0.00235518 loss)
I0417 14:49:36.136700 22508 sgd_solver.cpp:105] Iteration 70600, lr = 0.001
I0417 14:49:57.999083 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:49:58.215183 22508 solver.cpp:219] Iteration 70700 (4.52939 iter/s, 22.078s/100 iters), loss = 0.00226582
I0417 14:49:58.215209 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:49:58.215215 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:49:58.215221 22508 solver.cpp:238]     Train net output #2: loss = 0.00226551 (* 1 = 0.00226551 loss)
I0417 14:49:58.215226 22508 sgd_solver.cpp:105] Iteration 70700, lr = 0.001
I0417 14:50:20.225034 22508 solver.cpp:219] Iteration 70800 (4.54353 iter/s, 22.0093s/100 iters), loss = 0.00263417
I0417 14:50:20.225438 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:50:20.225445 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:50:20.225452 22508 solver.cpp:238]     Train net output #2: loss = 0.00263386 (* 1 = 0.00263386 loss)
I0417 14:50:20.225457 22508 sgd_solver.cpp:105] Iteration 70800, lr = 0.001
I0417 14:50:42.153022 22508 solver.cpp:219] Iteration 70900 (4.56057 iter/s, 21.9271s/100 iters), loss = 0.00272996
I0417 14:50:42.153139 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:50:42.153147 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:50:42.153153 22508 solver.cpp:238]     Train net output #2: loss = 0.00272965 (* 1 = 0.00272965 loss)
I0417 14:50:42.153158 22508 sgd_solver.cpp:105] Iteration 70900, lr = 0.001
I0417 14:51:03.914108 22508 solver.cpp:331] Iteration 71000, Testing net (#0)
I0417 14:51:06.860235 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:51:06.981504 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8201
I0417 14:51:06.981529 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.986
I0417 14:51:06.981537 22508 solver.cpp:398]     Test net output #2: loss = 0.929094 (* 1 = 0.929094 loss)
I0417 14:51:07.199584 22508 solver.cpp:219] Iteration 71000 (3.99267 iter/s, 25.0459s/100 iters), loss = 0.00159609
I0417 14:51:07.199604 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:51:07.199610 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:51:07.199615 22508 solver.cpp:238]     Train net output #2: loss = 0.00159578 (* 1 = 0.00159578 loss)
I0417 14:51:07.199621 22508 sgd_solver.cpp:105] Iteration 71000, lr = 0.001
I0417 14:51:26.847743 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:51:29.273493 22508 solver.cpp:219] Iteration 71100 (4.53034 iter/s, 22.0734s/100 iters), loss = 0.00180803
I0417 14:51:29.273540 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:51:29.273546 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:51:29.273553 22508 solver.cpp:238]     Train net output #2: loss = 0.00180772 (* 1 = 0.00180772 loss)
I0417 14:51:29.273558 22508 sgd_solver.cpp:105] Iteration 71100, lr = 0.001
I0417 14:51:51.351083 22508 solver.cpp:219] Iteration 71200 (4.52959 iter/s, 22.077s/100 iters), loss = 0.00299247
I0417 14:51:51.351132 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:51:51.351140 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:51:51.351146 22508 solver.cpp:238]     Train net output #2: loss = 0.00299216 (* 1 = 0.00299216 loss)
I0417 14:51:51.351151 22508 sgd_solver.cpp:105] Iteration 71200, lr = 0.001
I0417 14:52:13.437032 22508 solver.cpp:219] Iteration 71300 (4.52788 iter/s, 22.0854s/100 iters), loss = 0.00199664
I0417 14:52:13.437686 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:52:13.437696 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:52:13.437703 22508 solver.cpp:238]     Train net output #2: loss = 0.00199633 (* 1 = 0.00199633 loss)
I0417 14:52:13.437707 22508 sgd_solver.cpp:105] Iteration 71300, lr = 0.001
I0417 14:52:35.509446 22508 solver.cpp:219] Iteration 71400 (4.53078 iter/s, 22.0713s/100 iters), loss = 0.00279599
I0417 14:52:35.509487 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:52:35.509493 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:52:35.509500 22508 solver.cpp:238]     Train net output #2: loss = 0.00279568 (* 1 = 0.00279568 loss)
I0417 14:52:35.509505 22508 sgd_solver.cpp:105] Iteration 71400, lr = 0.001
I0417 14:52:53.160715 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:52:57.566644 22508 solver.cpp:219] Iteration 71500 (4.53378 iter/s, 22.0567s/100 iters), loss = 0.00262693
I0417 14:52:57.566678 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:52:57.566684 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:52:57.566689 22508 solver.cpp:238]     Train net output #2: loss = 0.00262662 (* 1 = 0.00262662 loss)
I0417 14:52:57.566694 22508 sgd_solver.cpp:105] Iteration 71500, lr = 0.001
I0417 14:53:19.662050 22508 solver.cpp:219] Iteration 71600 (4.52594 iter/s, 22.0949s/100 iters), loss = 0.0041468
I0417 14:53:19.662621 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:53:19.662627 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:53:19.662634 22508 solver.cpp:238]     Train net output #2: loss = 0.00414649 (* 1 = 0.00414649 loss)
I0417 14:53:19.662638 22508 sgd_solver.cpp:105] Iteration 71600, lr = 0.001
I0417 14:53:41.739123 22508 solver.cpp:219] Iteration 71700 (4.52981 iter/s, 22.076s/100 iters), loss = 0.00180572
I0417 14:53:41.739272 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:53:41.739281 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:53:41.739290 22508 solver.cpp:238]     Train net output #2: loss = 0.0018054 (* 1 = 0.0018054 loss)
I0417 14:53:41.739297 22508 sgd_solver.cpp:105] Iteration 71700, lr = 0.001
I0417 14:54:03.807070 22508 solver.cpp:219] Iteration 71800 (4.53159 iter/s, 22.0673s/100 iters), loss = 0.00101979
I0417 14:54:03.807107 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:54:03.807113 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:54:03.807121 22508 solver.cpp:238]     Train net output #2: loss = 0.00101947 (* 1 = 0.00101947 loss)
I0417 14:54:03.807124 22508 sgd_solver.cpp:105] Iteration 71800, lr = 0.001
I0417 14:54:19.250282 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:54:25.883004 22508 solver.cpp:219] Iteration 71900 (4.52993 iter/s, 22.0754s/100 iters), loss = 0.00252565
I0417 14:54:25.883057 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:54:25.883064 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:54:25.883071 22508 solver.cpp:238]     Train net output #2: loss = 0.00252534 (* 1 = 0.00252534 loss)
I0417 14:54:25.883075 22508 sgd_solver.cpp:105] Iteration 71900, lr = 0.001
I0417 14:54:47.726637 22508 solver.cpp:331] Iteration 72000, Testing net (#0)
I0417 14:54:50.669164 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:54:50.789849 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8204
I0417 14:54:50.789873 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9862
I0417 14:54:50.789896 22508 solver.cpp:398]     Test net output #2: loss = 0.928804 (* 1 = 0.928804 loss)
I0417 14:54:51.008182 22508 solver.cpp:219] Iteration 72000 (3.98017 iter/s, 25.1246s/100 iters), loss = 0.00317549
I0417 14:54:51.008215 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:54:51.008221 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:54:51.008227 22508 solver.cpp:238]     Train net output #2: loss = 0.00317518 (* 1 = 0.00317518 loss)
I0417 14:54:51.008234 22508 sgd_solver.cpp:105] Iteration 72000, lr = 0.001
I0417 14:55:13.086987 22508 solver.cpp:219] Iteration 72100 (4.52934 iter/s, 22.0783s/100 iters), loss = 0.00212586
I0417 14:55:13.087030 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:55:13.087035 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:55:13.087043 22508 solver.cpp:238]     Train net output #2: loss = 0.00212555 (* 1 = 0.00212555 loss)
I0417 14:55:13.087046 22508 sgd_solver.cpp:105] Iteration 72100, lr = 0.001
I0417 14:55:35.144430 22508 solver.cpp:219] Iteration 72200 (4.53373 iter/s, 22.0569s/100 iters), loss = 0.00206268
I0417 14:55:35.144582 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:55:35.144592 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:55:35.144598 22508 solver.cpp:238]     Train net output #2: loss = 0.00206236 (* 1 = 0.00206236 loss)
I0417 14:55:35.144603 22508 sgd_solver.cpp:105] Iteration 72200, lr = 0.001
I0417 14:55:48.582238 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:55:57.187893 22508 solver.cpp:219] Iteration 72300 (4.53662 iter/s, 22.0428s/100 iters), loss = 0.00328053
I0417 14:55:57.187927 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:55:57.187933 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:55:57.187940 22508 solver.cpp:238]     Train net output #2: loss = 0.00328022 (* 1 = 0.00328022 loss)
I0417 14:55:57.187944 22508 sgd_solver.cpp:105] Iteration 72300, lr = 0.001
I0417 14:56:19.240173 22508 solver.cpp:219] Iteration 72400 (4.53479 iter/s, 22.0517s/100 iters), loss = 0.00328079
I0417 14:56:19.240312 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:56:19.240320 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:56:19.240327 22508 solver.cpp:238]     Train net output #2: loss = 0.00328047 (* 1 = 0.00328047 loss)
I0417 14:56:19.240331 22508 sgd_solver.cpp:105] Iteration 72400, lr = 0.001
I0417 14:56:41.305467 22508 solver.cpp:219] Iteration 72500 (4.53213 iter/s, 22.0647s/100 iters), loss = 0.00333178
I0417 14:56:41.305517 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:56:41.305526 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:56:41.305531 22508 solver.cpp:238]     Train net output #2: loss = 0.00333147 (* 1 = 0.00333147 loss)
I0417 14:56:41.305536 22508 sgd_solver.cpp:105] Iteration 72500, lr = 0.001
I0417 14:57:03.364888 22508 solver.cpp:219] Iteration 72600 (4.53332 iter/s, 22.0589s/100 iters), loss = 0.00362517
I0417 14:57:03.365012 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:57:03.365020 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:57:03.365027 22508 solver.cpp:238]     Train net output #2: loss = 0.00362486 (* 1 = 0.00362486 loss)
I0417 14:57:03.365039 22508 sgd_solver.cpp:105] Iteration 72600, lr = 0.001
I0417 14:57:14.842994 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:57:25.409365 22508 solver.cpp:219] Iteration 72700 (4.53641 iter/s, 22.0439s/100 iters), loss = 0.00299334
I0417 14:57:25.409401 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:57:25.409407 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:57:25.409413 22508 solver.cpp:238]     Train net output #2: loss = 0.00299303 (* 1 = 0.00299303 loss)
I0417 14:57:25.409417 22508 sgd_solver.cpp:105] Iteration 72700, lr = 0.001
I0417 14:57:47.355298 22508 solver.cpp:219] Iteration 72800 (4.55676 iter/s, 21.9454s/100 iters), loss = 0.00214351
I0417 14:57:47.355437 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:57:47.355444 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:57:47.355451 22508 solver.cpp:238]     Train net output #2: loss = 0.0021432 (* 1 = 0.0021432 loss)
I0417 14:57:47.355456 22508 sgd_solver.cpp:105] Iteration 72800, lr = 0.001
I0417 14:58:09.282081 22508 solver.cpp:219] Iteration 72900 (4.56076 iter/s, 21.9262s/100 iters), loss = 0.00228579
I0417 14:58:09.282124 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:58:09.282130 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:58:09.282136 22508 solver.cpp:238]     Train net output #2: loss = 0.00228548 (* 1 = 0.00228548 loss)
I0417 14:58:09.282140 22508 sgd_solver.cpp:105] Iteration 72900, lr = 0.001
I0417 14:58:31.016839 22508 solver.cpp:331] Iteration 73000, Testing net (#0)
I0417 14:58:33.964745 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:58:34.085602 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8204
I0417 14:58:34.085628 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9857
I0417 14:58:34.085649 22508 solver.cpp:398]     Test net output #2: loss = 0.929022 (* 1 = 0.929022 loss)
I0417 14:58:34.303061 22508 solver.cpp:219] Iteration 73000 (3.99674 iter/s, 25.0204s/100 iters), loss = 0.00267362
I0417 14:58:34.303081 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:58:34.303086 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:58:34.303092 22508 solver.cpp:238]     Train net output #2: loss = 0.00267331 (* 1 = 0.00267331 loss)
I0417 14:58:34.303097 22508 sgd_solver.cpp:105] Iteration 73000, lr = 0.001
I0417 14:58:43.563280 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 14:58:56.270124 22508 solver.cpp:219] Iteration 73100 (4.55238 iter/s, 21.9666s/100 iters), loss = 0.00236669
I0417 14:58:56.270151 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:58:56.270156 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:58:56.270161 22508 solver.cpp:238]     Train net output #2: loss = 0.00236638 (* 1 = 0.00236638 loss)
I0417 14:58:56.270169 22508 sgd_solver.cpp:105] Iteration 73100, lr = 0.001
I0417 14:59:18.243963 22508 solver.cpp:219] Iteration 73200 (4.55097 iter/s, 21.9733s/100 iters), loss = 0.00195823
I0417 14:59:18.244071 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:59:18.244079 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:59:18.244086 22508 solver.cpp:238]     Train net output #2: loss = 0.00195792 (* 1 = 0.00195792 loss)
I0417 14:59:18.244091 22508 sgd_solver.cpp:105] Iteration 73200, lr = 0.001
I0417 14:59:40.185334 22508 solver.cpp:219] Iteration 73300 (4.55772 iter/s, 21.9408s/100 iters), loss = 0.00243193
I0417 14:59:40.185369 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 14:59:40.185374 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 14:59:40.185380 22508 solver.cpp:238]     Train net output #2: loss = 0.00243161 (* 1 = 0.00243161 loss)
I0417 14:59:40.185384 22508 sgd_solver.cpp:105] Iteration 73300, lr = 0.001
I0417 15:00:02.132707 22508 solver.cpp:219] Iteration 73400 (4.55646 iter/s, 21.9468s/100 iters), loss = 0.0026556
I0417 15:00:02.132841 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:00:02.132849 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:00:02.132856 22508 solver.cpp:238]     Train net output #2: loss = 0.00265529 (* 1 = 0.00265529 loss)
I0417 15:00:02.132861 22508 sgd_solver.cpp:105] Iteration 73400, lr = 0.001
I0417 15:00:09.383234 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:00:24.093328 22508 solver.cpp:219] Iteration 73500 (4.55373 iter/s, 21.96s/100 iters), loss = 0.00319173
I0417 15:00:24.093366 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:00:24.093372 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:00:24.093379 22508 solver.cpp:238]     Train net output #2: loss = 0.00319142 (* 1 = 0.00319142 loss)
I0417 15:00:24.093382 22508 sgd_solver.cpp:105] Iteration 73500, lr = 0.001
I0417 15:00:46.041466 22508 solver.cpp:219] Iteration 73600 (4.55631 iter/s, 21.9476s/100 iters), loss = 0.00262698
I0417 15:00:46.041646 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:00:46.041654 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:00:46.041661 22508 solver.cpp:238]     Train net output #2: loss = 0.00262667 (* 1 = 0.00262667 loss)
I0417 15:00:46.041666 22508 sgd_solver.cpp:105] Iteration 73600, lr = 0.001
I0417 15:01:08.018534 22508 solver.cpp:219] Iteration 73700 (4.55034 iter/s, 21.9764s/100 iters), loss = 0.00194241
I0417 15:01:08.018573 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:01:08.018579 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:01:08.018585 22508 solver.cpp:238]     Train net output #2: loss = 0.0019421 (* 1 = 0.0019421 loss)
I0417 15:01:08.018589 22508 sgd_solver.cpp:105] Iteration 73700, lr = 0.001
I0417 15:01:30.057235 22508 solver.cpp:219] Iteration 73800 (4.53758 iter/s, 22.0382s/100 iters), loss = 0.00352486
I0417 15:01:30.057373 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:01:30.057380 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:01:30.057389 22508 solver.cpp:238]     Train net output #2: loss = 0.00352454 (* 1 = 0.00352454 loss)
I0417 15:01:30.057394 22508 sgd_solver.cpp:105] Iteration 73800, lr = 0.001
I0417 15:01:35.330400 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:01:52.046006 22508 solver.cpp:219] Iteration 73900 (4.54791 iter/s, 21.9881s/100 iters), loss = 0.00229716
I0417 15:01:52.046056 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:01:52.046063 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:01:52.046069 22508 solver.cpp:238]     Train net output #2: loss = 0.00229685 (* 1 = 0.00229685 loss)
I0417 15:01:52.046074 22508 sgd_solver.cpp:105] Iteration 73900, lr = 0.001
I0417 15:02:13.833899 22508 solver.cpp:331] Iteration 74000, Testing net (#0)
I0417 15:02:16.790976 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:02:16.912231 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8209
I0417 15:02:16.912251 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9862
I0417 15:02:16.912258 22508 solver.cpp:398]     Test net output #2: loss = 0.928974 (* 1 = 0.928974 loss)
I0417 15:02:17.130620 22508 solver.cpp:219] Iteration 74000 (3.9866 iter/s, 25.084s/100 iters), loss = 0.00185514
I0417 15:02:17.130652 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:02:17.130658 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:02:17.130663 22508 solver.cpp:238]     Train net output #2: loss = 0.00185482 (* 1 = 0.00185482 loss)
I0417 15:02:17.130669 22508 sgd_solver.cpp:105] Iteration 74000, lr = 0.001
I0417 15:02:39.083495 22508 solver.cpp:219] Iteration 74100 (4.55532 iter/s, 21.9523s/100 iters), loss = 0.0027081
I0417 15:02:39.083556 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:02:39.083562 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:02:39.083570 22508 solver.cpp:238]     Train net output #2: loss = 0.00270778 (* 1 = 0.00270778 loss)
I0417 15:02:39.083573 22508 sgd_solver.cpp:105] Iteration 74100, lr = 0.001
I0417 15:03:01.016741 22508 solver.cpp:219] Iteration 74200 (4.5594 iter/s, 21.9327s/100 iters), loss = 0.00223469
I0417 15:03:01.016868 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:03:01.016876 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:03:01.016883 22508 solver.cpp:238]     Train net output #2: loss = 0.00223438 (* 1 = 0.00223438 loss)
I0417 15:03:01.016888 22508 sgd_solver.cpp:105] Iteration 74200, lr = 0.001
I0417 15:03:04.089458 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:03:22.959621 22508 solver.cpp:219] Iteration 74300 (4.55741 iter/s, 21.9423s/100 iters), loss = 0.00313334
I0417 15:03:22.959657 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:03:22.959662 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:03:22.959668 22508 solver.cpp:238]     Train net output #2: loss = 0.00313302 (* 1 = 0.00313302 loss)
I0417 15:03:22.959673 22508 sgd_solver.cpp:105] Iteration 74300, lr = 0.001
I0417 15:03:44.908938 22508 solver.cpp:219] Iteration 74400 (4.55606 iter/s, 21.9488s/100 iters), loss = 0.00262652
I0417 15:03:44.909091 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:03:44.909101 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:03:44.909107 22508 solver.cpp:238]     Train net output #2: loss = 0.00262621 (* 1 = 0.00262621 loss)
I0417 15:03:44.909112 22508 sgd_solver.cpp:105] Iteration 74400, lr = 0.001
I0417 15:04:06.843045 22508 solver.cpp:219] Iteration 74500 (4.55924 iter/s, 21.9335s/100 iters), loss = 0.00219797
I0417 15:04:06.843077 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:04:06.843083 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:04:06.843089 22508 solver.cpp:238]     Train net output #2: loss = 0.00219765 (* 1 = 0.00219765 loss)
I0417 15:04:06.843093 22508 sgd_solver.cpp:105] Iteration 74500, lr = 0.001
I0417 15:04:28.811887 22508 solver.cpp:219] Iteration 74600 (4.55201 iter/s, 21.9683s/100 iters), loss = 0.00166748
I0417 15:04:28.812587 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:04:28.812595 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:04:28.812602 22508 solver.cpp:238]     Train net output #2: loss = 0.00166716 (* 1 = 0.00166716 loss)
I0417 15:04:28.812605 22508 sgd_solver.cpp:105] Iteration 74600, lr = 0.001
I0417 15:04:29.907878 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:04:50.742987 22508 solver.cpp:219] Iteration 74700 (4.55998 iter/s, 21.9299s/100 iters), loss = 0.00441367
I0417 15:04:50.743039 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:04:50.743046 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:04:50.743052 22508 solver.cpp:238]     Train net output #2: loss = 0.00441335 (* 1 = 0.00441335 loss)
I0417 15:04:50.743057 22508 sgd_solver.cpp:105] Iteration 74700, lr = 0.001
I0417 15:05:12.660504 22508 solver.cpp:219] Iteration 74800 (4.56267 iter/s, 21.917s/100 iters), loss = 0.00243159
I0417 15:05:12.660620 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:05:12.660627 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:05:12.660634 22508 solver.cpp:238]     Train net output #2: loss = 0.00243128 (* 1 = 0.00243128 loss)
I0417 15:05:12.660639 22508 sgd_solver.cpp:105] Iteration 74800, lr = 0.001
I0417 15:05:34.606338 22508 solver.cpp:219] Iteration 74900 (4.5568 iter/s, 21.9452s/100 iters), loss = 0.00168965
I0417 15:05:34.606376 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:05:34.606384 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:05:34.606389 22508 solver.cpp:238]     Train net output #2: loss = 0.00168934 (* 1 = 0.00168934 loss)
I0417 15:05:34.606393 22508 sgd_solver.cpp:105] Iteration 74900, lr = 0.001
I0417 15:05:55.439348 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:05:56.311574 22508 solver.cpp:331] Iteration 75000, Testing net (#0)
I0417 15:05:59.261533 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:05:59.382906 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.821
I0417 15:05:59.382931 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9861
I0417 15:05:59.382952 22508 solver.cpp:398]     Test net output #2: loss = 0.929088 (* 1 = 0.929088 loss)
I0417 15:05:59.600391 22508 solver.cpp:219] Iteration 75000 (4.00105 iter/s, 24.9935s/100 iters), loss = 0.00265531
I0417 15:05:59.600425 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:05:59.600430 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:05:59.600435 22508 solver.cpp:238]     Train net output #2: loss = 0.00265499 (* 1 = 0.00265499 loss)
I0417 15:05:59.600443 22508 sgd_solver.cpp:105] Iteration 75000, lr = 0.001
I0417 15:06:21.550539 22508 solver.cpp:219] Iteration 75100 (4.55588 iter/s, 21.9496s/100 iters), loss = 0.00306365
I0417 15:06:21.551120 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:06:21.551126 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:06:21.551136 22508 solver.cpp:238]     Train net output #2: loss = 0.00306333 (* 1 = 0.00306333 loss)
I0417 15:06:21.551141 22508 sgd_solver.cpp:105] Iteration 75100, lr = 0.001
I0417 15:06:43.506819 22508 solver.cpp:219] Iteration 75200 (4.55473 iter/s, 21.9552s/100 iters), loss = 0.00271043
I0417 15:06:43.507009 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:06:43.507021 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:06:43.507032 22508 solver.cpp:238]     Train net output #2: loss = 0.00271012 (* 1 = 0.00271012 loss)
I0417 15:06:43.507043 22508 sgd_solver.cpp:105] Iteration 75200, lr = 0.001
I0417 15:07:05.436295 22508 solver.cpp:219] Iteration 75300 (4.56021 iter/s, 21.9288s/100 iters), loss = 0.00281485
I0417 15:07:05.436331 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:07:05.436336 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:07:05.436342 22508 solver.cpp:238]     Train net output #2: loss = 0.00281453 (* 1 = 0.00281453 loss)
I0417 15:07:05.436347 22508 sgd_solver.cpp:105] Iteration 75300, lr = 0.001
I0417 15:07:24.354441 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:07:27.429605 22508 solver.cpp:219] Iteration 75400 (4.54695 iter/s, 21.9928s/100 iters), loss = 0.00267018
I0417 15:07:27.429637 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:07:27.429643 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:07:27.429649 22508 solver.cpp:238]     Train net output #2: loss = 0.00266987 (* 1 = 0.00266987 loss)
I0417 15:07:27.429654 22508 sgd_solver.cpp:105] Iteration 75400, lr = 0.001
I0417 15:07:49.401657 22508 solver.cpp:219] Iteration 75500 (4.55135 iter/s, 21.9715s/100 iters), loss = 0.00222653
I0417 15:07:49.401695 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:07:49.401701 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:07:49.401707 22508 solver.cpp:238]     Train net output #2: loss = 0.00222622 (* 1 = 0.00222622 loss)
I0417 15:07:49.401712 22508 sgd_solver.cpp:105] Iteration 75500, lr = 0.001
I0417 15:08:11.441850 22508 solver.cpp:219] Iteration 75600 (4.53727 iter/s, 22.0397s/100 iters), loss = 0.00165171
I0417 15:08:11.441973 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:08:11.441985 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:08:11.441995 22508 solver.cpp:238]     Train net output #2: loss = 0.0016514 (* 1 = 0.0016514 loss)
I0417 15:08:11.442005 22508 sgd_solver.cpp:105] Iteration 75600, lr = 0.001
I0417 15:08:33.523679 22508 solver.cpp:219] Iteration 75700 (4.52874 iter/s, 22.0812s/100 iters), loss = 0.00124724
I0417 15:08:33.524220 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:08:33.524227 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:08:33.524235 22508 solver.cpp:238]     Train net output #2: loss = 0.00124692 (* 1 = 0.00124692 loss)
I0417 15:08:33.524240 22508 sgd_solver.cpp:105] Iteration 75700, lr = 0.001
I0417 15:08:50.503794 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:08:55.575830 22508 solver.cpp:219] Iteration 75800 (4.53492 iter/s, 22.0511s/100 iters), loss = 0.00178083
I0417 15:08:55.575880 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:08:55.575886 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:08:55.575892 22508 solver.cpp:238]     Train net output #2: loss = 0.00178052 (* 1 = 0.00178052 loss)
I0417 15:08:55.575897 22508 sgd_solver.cpp:105] Iteration 75800, lr = 0.001
I0417 15:09:17.648267 22508 solver.cpp:219] Iteration 75900 (4.53065 iter/s, 22.0719s/100 iters), loss = 0.00231604
I0417 15:09:17.648305 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:09:17.648311 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:09:17.648319 22508 solver.cpp:238]     Train net output #2: loss = 0.00231573 (* 1 = 0.00231573 loss)
I0417 15:09:17.648322 22508 sgd_solver.cpp:105] Iteration 75900, lr = 0.001
I0417 15:09:39.515274 22508 solver.cpp:331] Iteration 76000, Testing net (#0)
I0417 15:09:42.452719 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:09:42.573179 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8206
I0417 15:09:42.573205 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9861
I0417 15:09:42.573225 22508 solver.cpp:398]     Test net output #2: loss = 0.929122 (* 1 = 0.929122 loss)
I0417 15:09:42.791676 22508 solver.cpp:219] Iteration 76000 (3.97728 iter/s, 25.1428s/100 iters), loss = 0.00293456
I0417 15:09:42.791708 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:09:42.791714 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:09:42.791720 22508 solver.cpp:238]     Train net output #2: loss = 0.00293425 (* 1 = 0.00293425 loss)
I0417 15:09:42.791726 22508 sgd_solver.cpp:105] Iteration 76000, lr = 0.001
I0417 15:10:04.867220 22508 solver.cpp:219] Iteration 76100 (4.53001 iter/s, 22.075s/100 iters), loss = 0.00208711
I0417 15:10:04.867259 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:10:04.867264 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:10:04.867270 22508 solver.cpp:238]     Train net output #2: loss = 0.0020868 (* 1 = 0.0020868 loss)
I0417 15:10:04.867274 22508 sgd_solver.cpp:105] Iteration 76100, lr = 0.001
I0417 15:10:19.672557 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:10:26.931830 22508 solver.cpp:219] Iteration 76200 (4.53225 iter/s, 22.0641s/100 iters), loss = 0.00268271
I0417 15:10:26.931865 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:10:26.931871 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:10:26.931877 22508 solver.cpp:238]     Train net output #2: loss = 0.0026824 (* 1 = 0.0026824 loss)
I0417 15:10:26.931882 22508 sgd_solver.cpp:105] Iteration 76200, lr = 0.001
I0417 15:10:48.962379 22508 solver.cpp:219] Iteration 76300 (4.53926 iter/s, 22.03s/100 iters), loss = 0.00244611
I0417 15:10:48.962416 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:10:48.962422 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:10:48.962429 22508 solver.cpp:238]     Train net output #2: loss = 0.0024458 (* 1 = 0.0024458 loss)
I0417 15:10:48.962433 22508 sgd_solver.cpp:105] Iteration 76300, lr = 0.001
I0417 15:11:10.997601 22508 solver.cpp:219] Iteration 76400 (4.5383 iter/s, 22.0347s/100 iters), loss = 0.00239732
I0417 15:11:10.997709 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:11:10.997717 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:11:10.997725 22508 solver.cpp:238]     Train net output #2: loss = 0.00239701 (* 1 = 0.00239701 loss)
I0417 15:11:10.997730 22508 sgd_solver.cpp:105] Iteration 76400, lr = 0.001
I0417 15:11:33.056707 22508 solver.cpp:219] Iteration 76500 (4.5334 iter/s, 22.0585s/100 iters), loss = 0.00148329
I0417 15:11:33.057286 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:11:33.057294 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:11:33.057301 22508 solver.cpp:238]     Train net output #2: loss = 0.00148298 (* 1 = 0.00148298 loss)
I0417 15:11:33.057304 22508 sgd_solver.cpp:105] Iteration 76500, lr = 0.001
I0417 15:11:45.863781 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:11:55.120988 22508 solver.cpp:219] Iteration 76600 (4.53243 iter/s, 22.0632s/100 iters), loss = 0.00275167
I0417 15:11:55.121026 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:11:55.121031 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:11:55.121037 22508 solver.cpp:238]     Train net output #2: loss = 0.00275136 (* 1 = 0.00275136 loss)
I0417 15:11:55.121042 22508 sgd_solver.cpp:105] Iteration 76600, lr = 0.001
I0417 15:12:17.170588 22508 solver.cpp:219] Iteration 76700 (4.53534 iter/s, 22.0491s/100 iters), loss = 0.00261789
I0417 15:12:17.170758 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:12:17.170766 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:12:17.170773 22508 solver.cpp:238]     Train net output #2: loss = 0.00261757 (* 1 = 0.00261757 loss)
I0417 15:12:17.170778 22508 sgd_solver.cpp:105] Iteration 76700, lr = 0.001
I0417 15:12:39.224797 22508 solver.cpp:219] Iteration 76800 (4.53442 iter/s, 22.0535s/100 iters), loss = 0.00190717
I0417 15:12:39.224846 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:12:39.224853 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:12:39.224860 22508 solver.cpp:238]     Train net output #2: loss = 0.00190686 (* 1 = 0.00190686 loss)
I0417 15:12:39.224864 22508 sgd_solver.cpp:105] Iteration 76800, lr = 0.001
I0417 15:13:01.277711 22508 solver.cpp:219] Iteration 76900 (4.53466 iter/s, 22.0524s/100 iters), loss = 0.00294538
I0417 15:13:01.277832 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:13:01.277840 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:13:01.277848 22508 solver.cpp:238]     Train net output #2: loss = 0.00294506 (* 1 = 0.00294506 loss)
I0417 15:13:01.277853 22508 sgd_solver.cpp:105] Iteration 76900, lr = 0.001
I0417 15:13:12.095288 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:13:23.151159 22508 solver.cpp:331] Iteration 77000, Testing net (#0)
I0417 15:13:26.097328 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:13:26.217972 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8207
I0417 15:13:26.218000 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.986
I0417 15:13:26.218019 22508 solver.cpp:398]     Test net output #2: loss = 0.9294 (* 1 = 0.9294 loss)
I0417 15:13:26.435494 22508 solver.cpp:219] Iteration 77000 (3.97502 iter/s, 25.1571s/100 iters), loss = 0.00327176
I0417 15:13:26.435516 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:13:26.435523 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:13:26.435528 22508 solver.cpp:238]     Train net output #2: loss = 0.00327145 (* 1 = 0.00327145 loss)
I0417 15:13:26.435534 22508 sgd_solver.cpp:105] Iteration 77000, lr = 0.001
I0417 15:13:48.504730 22508 solver.cpp:219] Iteration 77100 (4.5313 iter/s, 22.0687s/100 iters), loss = 0.00306493
I0417 15:13:48.504875 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:13:48.504884 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:13:48.504892 22508 solver.cpp:238]     Train net output #2: loss = 0.00306462 (* 1 = 0.00306462 loss)
I0417 15:13:48.504897 22508 sgd_solver.cpp:105] Iteration 77100, lr = 0.001
I0417 15:14:10.543609 22508 solver.cpp:219] Iteration 77200 (4.53757 iter/s, 22.0382s/100 iters), loss = 0.00284553
I0417 15:14:10.543661 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:14:10.543668 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:14:10.543675 22508 solver.cpp:238]     Train net output #2: loss = 0.00284521 (* 1 = 0.00284521 loss)
I0417 15:14:10.543679 22508 sgd_solver.cpp:105] Iteration 77200, lr = 0.001
I0417 15:14:32.565822 22508 solver.cpp:219] Iteration 77300 (4.54098 iter/s, 22.0217s/100 iters), loss = 0.00175903
I0417 15:14:32.566530 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:14:32.566540 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:14:32.566546 22508 solver.cpp:238]     Train net output #2: loss = 0.00175872 (* 1 = 0.00175872 loss)
I0417 15:14:32.566551 22508 sgd_solver.cpp:105] Iteration 77300, lr = 0.001
I0417 15:14:41.152604 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:14:54.548429 22508 solver.cpp:219] Iteration 77400 (4.5493 iter/s, 21.9814s/100 iters), loss = 0.00309619
I0417 15:14:54.548468 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:14:54.548473 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:14:54.548480 22508 solver.cpp:238]     Train net output #2: loss = 0.00309587 (* 1 = 0.00309587 loss)
I0417 15:14:54.548485 22508 sgd_solver.cpp:105] Iteration 77400, lr = 0.001
I0417 15:15:16.549860 22508 solver.cpp:219] Iteration 77500 (4.54527 iter/s, 22.0009s/100 iters), loss = 0.00262059
I0417 15:15:16.550011 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:15:16.550020 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:15:16.550027 22508 solver.cpp:238]     Train net output #2: loss = 0.00262028 (* 1 = 0.00262028 loss)
I0417 15:15:16.550031 22508 sgd_solver.cpp:105] Iteration 77500, lr = 0.001
I0417 15:15:38.552000 22508 solver.cpp:219] Iteration 77600 (4.54515 iter/s, 22.0015s/100 iters), loss = 0.00204956
I0417 15:15:38.552032 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:15:38.552038 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:15:38.552044 22508 solver.cpp:238]     Train net output #2: loss = 0.00204925 (* 1 = 0.00204925 loss)
I0417 15:15:38.552049 22508 sgd_solver.cpp:105] Iteration 77600, lr = 0.001
I0417 15:16:00.565888 22508 solver.cpp:219] Iteration 77700 (4.5427 iter/s, 22.0134s/100 iters), loss = 0.00306491
I0417 15:16:00.566018 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:16:00.566026 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:16:00.566032 22508 solver.cpp:238]     Train net output #2: loss = 0.00306459 (* 1 = 0.00306459 loss)
I0417 15:16:00.566037 22508 sgd_solver.cpp:105] Iteration 77700, lr = 0.001
I0417 15:16:07.170300 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:16:22.537586 22508 solver.cpp:219] Iteration 77800 (4.55144 iter/s, 21.9711s/100 iters), loss = 0.00243174
I0417 15:16:22.538169 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:16:22.538178 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:16:22.538187 22508 solver.cpp:238]     Train net output #2: loss = 0.00243143 (* 1 = 0.00243143 loss)
I0417 15:16:22.538192 22508 sgd_solver.cpp:105] Iteration 77800, lr = 0.001
I0417 15:16:44.495615 22508 solver.cpp:219] Iteration 77900 (4.55437 iter/s, 21.957s/100 iters), loss = 0.00158745
I0417 15:16:44.495764 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:16:44.495772 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:16:44.495780 22508 solver.cpp:238]     Train net output #2: loss = 0.00158714 (* 1 = 0.00158714 loss)
I0417 15:16:44.495785 22508 sgd_solver.cpp:105] Iteration 77900, lr = 0.001
I0417 15:17:06.227901 22508 solver.cpp:331] Iteration 78000, Testing net (#0)
I0417 15:17:09.162598 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:17:09.282979 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8206
I0417 15:17:09.283006 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.986
I0417 15:17:09.283026 22508 solver.cpp:398]     Test net output #2: loss = 0.929136 (* 1 = 0.929136 loss)
I0417 15:17:09.501480 22508 solver.cpp:219] Iteration 78000 (3.99917 iter/s, 25.0052s/100 iters), loss = 0.00156408
I0417 15:17:09.501514 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:17:09.501519 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:17:09.501524 22508 solver.cpp:238]     Train net output #2: loss = 0.00156376 (* 1 = 0.00156376 loss)
I0417 15:17:09.501530 22508 sgd_solver.cpp:105] Iteration 78000, lr = 0.001
I0417 15:17:31.453016 22508 solver.cpp:219] Iteration 78100 (4.5556 iter/s, 21.951s/100 iters), loss = 0.0036648
I0417 15:17:31.453193 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:17:31.453207 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:17:31.453214 22508 solver.cpp:238]     Train net output #2: loss = 0.00366448 (* 1 = 0.00366448 loss)
I0417 15:17:31.453219 22508 sgd_solver.cpp:105] Iteration 78100, lr = 0.001
I0417 15:17:35.835414 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:17:53.361845 22508 solver.cpp:219] Iteration 78200 (4.56451 iter/s, 21.9082s/100 iters), loss = 0.0029289
I0417 15:17:53.362404 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:17:53.362411 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:17:53.362418 22508 solver.cpp:238]     Train net output #2: loss = 0.00292859 (* 1 = 0.00292859 loss)
I0417 15:17:53.362422 22508 sgd_solver.cpp:105] Iteration 78200, lr = 0.001
I0417 15:18:15.283006 22508 solver.cpp:219] Iteration 78300 (4.56202 iter/s, 21.9201s/100 iters), loss = 0.00293842
I0417 15:18:15.283145 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:18:15.283152 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:18:15.283159 22508 solver.cpp:238]     Train net output #2: loss = 0.00293811 (* 1 = 0.00293811 loss)
I0417 15:18:15.283164 22508 sgd_solver.cpp:105] Iteration 78300, lr = 0.001
I0417 15:18:37.214350 22508 solver.cpp:219] Iteration 78400 (4.55981 iter/s, 21.9307s/100 iters), loss = 0.00154345
I0417 15:18:37.214393 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:18:37.214401 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:18:37.214407 22508 solver.cpp:238]     Train net output #2: loss = 0.00154314 (* 1 = 0.00154314 loss)
I0417 15:18:37.214412 22508 sgd_solver.cpp:105] Iteration 78400, lr = 0.001
I0417 15:18:59.129000 22508 solver.cpp:219] Iteration 78500 (4.56327 iter/s, 21.9141s/100 iters), loss = 0.00330395
I0417 15:18:59.129087 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:18:59.129094 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:18:59.129101 22508 solver.cpp:238]     Train net output #2: loss = 0.00330364 (* 1 = 0.00330364 loss)
I0417 15:18:59.129104 22508 sgd_solver.cpp:105] Iteration 78500, lr = 0.001
I0417 15:19:01.543972 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:19:21.117089 22508 solver.cpp:219] Iteration 78600 (4.54804 iter/s, 21.9875s/100 iters), loss = 0.00217193
I0417 15:19:21.117626 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:19:21.117635 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:19:21.117640 22508 solver.cpp:238]     Train net output #2: loss = 0.00217162 (* 1 = 0.00217162 loss)
I0417 15:19:21.117645 22508 sgd_solver.cpp:105] Iteration 78600, lr = 0.001
I0417 15:19:43.054388 22508 solver.cpp:219] Iteration 78700 (4.55866 iter/s, 21.9363s/100 iters), loss = 0.00216212
I0417 15:19:43.054529 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:19:43.054538 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:19:43.054543 22508 solver.cpp:238]     Train net output #2: loss = 0.0021618 (* 1 = 0.0021618 loss)
I0417 15:19:43.054550 22508 sgd_solver.cpp:105] Iteration 78700, lr = 0.001
I0417 15:20:04.992586 22508 solver.cpp:219] Iteration 78800 (4.55839 iter/s, 21.9376s/100 iters), loss = 0.00373665
I0417 15:20:04.992638 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:20:04.992645 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:20:04.992650 22508 solver.cpp:238]     Train net output #2: loss = 0.00373634 (* 1 = 0.00373634 loss)
I0417 15:20:04.992655 22508 sgd_solver.cpp:105] Iteration 78800, lr = 0.001
I0417 15:20:26.942791 22508 solver.cpp:219] Iteration 78900 (4.55588 iter/s, 21.9497s/100 iters), loss = 0.00217864
I0417 15:20:26.942915 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:20:26.942924 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:20:26.942929 22508 solver.cpp:238]     Train net output #2: loss = 0.00217833 (* 1 = 0.00217833 loss)
I0417 15:20:26.942934 22508 sgd_solver.cpp:105] Iteration 78900, lr = 0.001
I0417 15:20:27.386987 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:20:48.667624 22508 solver.cpp:331] Iteration 79000, Testing net (#0)
I0417 15:20:51.608104 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:20:51.728801 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8203
I0417 15:20:51.728826 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.986
I0417 15:20:51.728833 22508 solver.cpp:398]     Test net output #2: loss = 0.929196 (* 1 = 0.929196 loss)
I0417 15:20:51.947324 22508 solver.cpp:219] Iteration 79000 (3.99938 iter/s, 25.0039s/100 iters), loss = 0.00255918
I0417 15:20:51.947343 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:20:51.947348 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:20:51.947355 22508 solver.cpp:238]     Train net output #2: loss = 0.00255887 (* 1 = 0.00255887 loss)
I0417 15:20:51.947360 22508 sgd_solver.cpp:105] Iteration 79000, lr = 0.001
I0417 15:21:13.913347 22508 solver.cpp:219] Iteration 79100 (4.55259 iter/s, 21.9655s/100 iters), loss = 0.0014926
I0417 15:21:13.913524 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:21:13.913533 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:21:13.913540 22508 solver.cpp:238]     Train net output #2: loss = 0.00149229 (* 1 = 0.00149229 loss)
I0417 15:21:13.913547 22508 sgd_solver.cpp:105] Iteration 79100, lr = 0.001
I0417 15:21:35.872243 22508 solver.cpp:219] Iteration 79200 (4.5541 iter/s, 21.9582s/100 iters), loss = 0.00237429
I0417 15:21:35.872283 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:21:35.872289 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:21:35.872295 22508 solver.cpp:238]     Train net output #2: loss = 0.00237398 (* 1 = 0.00237398 loss)
I0417 15:21:35.872299 22508 sgd_solver.cpp:105] Iteration 79200, lr = 0.001
I0417 15:21:56.074764 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:21:57.827426 22508 solver.cpp:219] Iteration 79300 (4.55484 iter/s, 21.9547s/100 iters), loss = 0.00201847
I0417 15:21:57.827457 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:21:57.827463 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:21:57.827471 22508 solver.cpp:238]     Train net output #2: loss = 0.00201815 (* 1 = 0.00201815 loss)
I0417 15:21:57.827474 22508 sgd_solver.cpp:105] Iteration 79300, lr = 0.001
I0417 15:22:19.816094 22508 solver.cpp:219] Iteration 79400 (4.5479 iter/s, 21.9881s/100 iters), loss = 0.00193622
I0417 15:22:19.816658 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:22:19.816665 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:22:19.816673 22508 solver.cpp:238]     Train net output #2: loss = 0.00193591 (* 1 = 0.00193591 loss)
I0417 15:22:19.816676 22508 sgd_solver.cpp:105] Iteration 79400, lr = 0.001
I0417 15:22:41.788522 22508 solver.cpp:219] Iteration 79500 (4.55138 iter/s, 21.9714s/100 iters), loss = 0.00303377
I0417 15:22:41.788672 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:22:41.788681 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:22:41.788686 22508 solver.cpp:238]     Train net output #2: loss = 0.00303346 (* 1 = 0.00303346 loss)
I0417 15:22:41.788691 22508 sgd_solver.cpp:105] Iteration 79500, lr = 0.001
I0417 15:23:03.720877 22508 solver.cpp:219] Iteration 79600 (4.55961 iter/s, 21.9317s/100 iters), loss = 0.00182393
I0417 15:23:03.720913 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:23:03.720919 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:23:03.720926 22508 solver.cpp:238]     Train net output #2: loss = 0.00182362 (* 1 = 0.00182362 loss)
I0417 15:23:03.720930 22508 sgd_solver.cpp:105] Iteration 79600, lr = 0.001
I0417 15:23:21.940930 22512 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:23:25.680667 22508 solver.cpp:219] Iteration 79700 (4.55389 iter/s, 21.9593s/100 iters), loss = 0.00230366
I0417 15:23:25.680716 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:23:25.680722 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:23:25.680728 22508 solver.cpp:238]     Train net output #2: loss = 0.00230335 (* 1 = 0.00230335 loss)
I0417 15:23:25.680733 22508 sgd_solver.cpp:105] Iteration 79700, lr = 0.001
I0417 15:23:47.632899 22508 solver.cpp:219] Iteration 79800 (4.55546 iter/s, 21.9517s/100 iters), loss = 0.00303671
I0417 15:23:47.632936 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:23:47.632941 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:23:47.632947 22508 solver.cpp:238]     Train net output #2: loss = 0.00303639 (* 1 = 0.00303639 loss)
I0417 15:23:47.632951 22508 sgd_solver.cpp:105] Iteration 79800, lr = 0.001
I0417 15:24:09.613329 22508 solver.cpp:219] Iteration 79900 (4.54961 iter/s, 21.9799s/100 iters), loss = 0.00298412
I0417 15:24:09.613456 22508 solver.cpp:238]     Train net output #0: acctop1 = 1
I0417 15:24:09.613464 22508 solver.cpp:238]     Train net output #1: acctop5 = 1
I0417 15:24:09.613472 22508 solver.cpp:238]     Train net output #2: loss = 0.00298381 (* 1 = 0.00298381 loss)
I0417 15:24:09.613477 22508 sgd_solver.cpp:105] Iteration 79900, lr = 0.001
I0417 15:24:31.424840 22508 solver.cpp:448] Snapshotting to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_80000.caffemodel
I0417 15:24:31.431927 22508 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /optimus_data/backed_up/dnn-model/cifar10/ResNet20/ResNet20_iter_80000.solverstate
I0417 15:24:31.475858 22508 solver.cpp:311] Iteration 80000, loss = 0.00212398
I0417 15:24:31.475881 22508 solver.cpp:331] Iteration 80000, Testing net (#0)
I0417 15:24:34.426100 22513 data_layer.cpp:73] Restarting data prefetching from start.
I0417 15:24:34.547209 22508 solver.cpp:398]     Test net output #0: acctop1 = 0.8204
I0417 15:24:34.547235 22508 solver.cpp:398]     Test net output #1: acctop5 = 0.9861
I0417 15:24:34.547253 22508 solver.cpp:398]     Test net output #2: loss = 0.929632 (* 1 = 0.929632 loss)
I0417 15:24:34.547258 22508 solver.cpp:316] Optimization Done.
I0417 15:24:34.547263 22508 caffe.cpp:259] Optimization Done.
